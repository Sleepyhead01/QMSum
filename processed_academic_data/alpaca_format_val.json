[{"instruction":"what were the main discussion points of the meeting ?","input":"professor e: so . ok . does n't look like it crashed . that 's great . grad g: so i think maybe what 's causing it to crash is i keep starting it and then stopping it to see if it 's working . and so i think starting it and then stopping it and starting it again causes it to crash . so , i wo n't do that anymore . postdoc b: and it looks like you 've found a way of uh mapping the location to the without having people have to give their names each time ? phd a: sounds like an initialization thing . postdoc b: i mean it 's like you have the so you know that grad g: no . postdoc b: i mean , are you going to write down that i sat here ? grad g: i 'm gon na collect the digit forms and write it down . postdoc b: ok . phd c: oh , ok . grad g: so so they should be right with what 's on the digit forms . ok , so i 'll go ahead and start with digits . u and i should say that uh , you just pau you just read each line an and then pause briefly . professor e: and start by giving the transcript number . phd a: tran phd d: transcript uh . ok , ok . phd a: oh sorry , go ahead . professor e: so uh , you see , don , the unbridled excitement of the work that we have on this project . grad h: ok . professor e: it 's just uh grad h: umh . professor e: uh , you know , it does n't seem like a bad idea to have { comment } that information . grad g: and i 'm surprised i sort of i 'm surprised i forgot that , professor e: yeah , i i 'd i think it 's some grad g: but uh i think that would be a good thing to add . after i just printed out a zillion of them . professor e: yeah , well , that 's um , so i i do have a a an agenda suggestion . uh , we i think the things that we talk about in this meeting uh tend to be a mixture of uh procedural uh mundane things and uh research points and um i was thinking i think it was a meeting a couple of weeks ago that we we spent much of the time talking about the mundane stuff cuz that 's easier to get out of the way and then we sort of drifted into the research and maybe five minutes into that andreas had to leave . so uh i 'm suggesting we turn it around and and uh sort of we have anybody has some mundane points that we could send an email later , uh hold them for a bit , and let 's talk about the the research - y kind of things . um , so um the one th one thing i know that we have on that is uh we had talked a a couple weeks before um uh about the uh the stuff you were doing with with uh um uh l l attempting to locate events , we had a little go around trying to figure out what you meant by `` events `` but i think , you know , what we had meant by `` events `` i guess was uh points of overlap between speakers . but i th i gather from our discussion a little earlier today that you also mean uh interruptions with something else phd d: yeah . professor e: like some other noise . phd d: uh - huh . yeah . professor e: yes ? you mean that as an event also . phd d: to professor e: so at any rate you were you 've you 've done some work on that phd d: right . professor e: and um then the other thing would be it might be nice to have a preliminary discussion of some of the other uh research uh areas that uh we 're thinking about doing . um , i think especially since you you have n't been in in these meetings for a little bit , maybe you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , uh and one of the things i know that also came up uh is some discussions that that uh that uh jane had with lokendra uh about some some some um uh work about i i i d i i do n't want to try to say cuz i i 'll say it wrong , but anyway some some potential collaboration there about about the about the working with these data . phd c: oh . sure . professor e: so . so , uh . grad g: you wan na just go around ? professor e: uh . well , i do n't know if we if this is sort of like everybody has something to contribute sort of thing , i think there 's just just a couple a couple people primarily um but um uh , wh why do n't actually i think that that last one i just said we could do fairly quickly so why do n't you you start with that . postdoc b: ok . shall i shall i just start ? ok . professor e: yeah , just explain what it was . postdoc b: um , so , uh , he was interested in the question of you know , relating to his to the research he presented recently , um of inference structures , and uh , the need to build in , um , this this sort of uh mechanism for understanding of language . and he gave the example in his talk about how um , e a i 'm remembering it just off the top of my head right now , but it 's something about how um , i `` joe slipped `` you know , `` john had washed the floor `` or something like that . and i do n't have it quite right , but that kind of thing , where you have to draw the inference that , ok , there 's this time sequence , but also the the the causal aspects of the uh floor and and how it might have been the cause of the fall and that um it was the other person who fell than the one who cleaned it and it { comment } these sorts of things . so , i looked through the transcript that we have so far , { comment } and um , fou identified a couple different types of things of that type and um , one of them was something like uh , during the course of the transcript , um um , w we had gone through the part where everyone said which channel they were on and which device they were on , and um , the question was raised `` well , should we restart the recording at this point ? `` and and dan ellis said , `` well , we 're just so far ahead of the game right now we really do n't need to `` . now , how would you interpret that without a lot of inference ? so , the inferences that are involved are things like , ok , so , how do you interpret `` ahead of the game `` ? you know . so it 's the it 's i what you what you int what you draw you know , the conclusions that you need to draw are that space is involved in recording , grad g: hmm , metaphorically . postdoc b: that um , i that i we have enough space , and he continues , like `` we 're so ahead of the game cuz now we have built - in downsampling `` . so you have to sort of get the idea that um , `` ahead of the game `` is sp speaking with respect to space limitations , that um that in fact downsampling is gaining us enough space , and that therefore we can keep the recording we 've done so far . but there are a lot of different things like that . grad g: so , do you think his interest is in using this as a data source , or training material , or what ? professor e: well , i i should maybe interject to say this started off with a discussion that i had with him , so um we were trying to think of ways that his interests could interact with ours grad g: mm - hmm . professor e: and um uh i thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with jane 's help , look into some of the data that we 're already have and see , is there anything to this at all ? grad g: mm - hmm . professor e: is there any point which you think that , you know , you could gain some advantage and some potential use for it . cuz it could be that you 'd look through it and you say `` well , this is just the wrong task for for him to pursue his `` grad g: wrong , yeah . professor e: and and uh i got the impression from your mail that in fact there was enough things like this just in the little sample that that you looked at that that it 's plausible at least . postdoc b: it 's possible . uh , he was he he you know we met and he was gon na go and uh you know , y look through them more systematically professor e: yeah . postdoc b: and then uh meet again . professor e: yeah . postdoc b: so it 's , you know , not a matter of a professor e: yeah . postdoc b: but , yeah , i think i think it was optimistic . professor e: so anyway , that 's that 's e a quite different thing from anything we 've talked about that , you know , might might might come out from some of this . phd c: but he can use text , basically . i mean , he 's talking about just using text postdoc b: that 's his major i mentioned several that w had to do with implications drawn from intonational contours phd c: pretty much , or ? postdoc b: and that was n't as directly relevant to what he 's doing . he 's interested in these these knowledge structures , phd c: ok . phd d: yeah , interesting . postdoc b: inferences that you draw i from professor e: i mean , he certainly could use text , but we were in fact looking to see if there is there is there something in common between our interest in meetings and his interest in in in this stuff . so . grad g: and i imagine that transcripts of speech i mean text that is speech probably has more of those than sort of prepared writing . i i do n't know whether it would or not , but it seems like it would . professor e: i do n't know , probably de probably depends on what the prepared writing was . but . postdoc b: yeah , i do n't think i would make that leap , because i in narratives , you know i mean , if you spell out everything in a narrative , it can be really tedious , grad g: mm - hmm . postdoc b: so . grad g: yeah , i 'm just thinking , you know , when you 're when you 're face to face , you have a lot of backchannel and and postdoc b: oh . that aspect . grad g: yeah . and so i think it 's just easier to do that sort of broad inference jumping if it 's face to face . i mean , so , if i just read that dan was saying `` we 're ahead of the game `` { comment } in that in that context , postdoc b: well yeah . grad g: i might not realize that he was talking about disk space as opposed to anything else . postdoc b: i you know , i i had several that had to do with backchannels and this was n't one of them . grad g: uh - huh . postdoc b: this this one really does um m make you leap from so he said , you know , `` we 're ahead of the game , w we have built - in downsampling `` . grad g: mm - hmm . postdoc b: and the inference , i if you had it written down , would be grad g: i guess it would be the same . postdoc b: uh - huh . but there are others that have backchannelling , it 's just he was less interested in those . phd f: can i sorry to interrupt . um , i f f f i 've @ @ { comment } d a minute uh , several minutes ago , i , like , briefly was was not listening and so who is `` he `` in this context ? phd c: yeah , there 's a lot of pronoun phd f: ok . so i was just realizing we 've you guys have been talking about `` he `` um for at least uh , i do n't know , three three four minutes without ever mentioning the person 's name again . phd c: i believe it . yeah . actually to make it worse , { comment } uh , morgan uses `` you `` and `` you `` phd f: so this is this is this is gon na be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort . grad g: it 's in my notes . phd c: with gaze and no identification , or i just wrote this down . yeah , actually . cuz morgan will say well , `` you had some ideas `` phd d: yeah . phd f: you just wrote this ? phd c: and he never said li - he looked grad g: well , i think he 's doing that intentionally , phd c: right , so it 's great . grad g: are n't you ? phd c: so this is really great phd f: right . phd c: because the thing is , because he 's looking at the per even for addressees in the conversation , phd d: yeah . phd f: mm - hmm . phd c: i bet you could pick that up in the acoustics . just because your gaze is also correlated with the directionality of your voice . professor e: uh - huh . could be . postdoc b: can we professor e: yeah . that would be tou grad g: oh , that would be interesting . phd c: yeah , so that , i mean , to even know um when phd d: yeah . phd c: yeah , if you have the p z ms you should be able to pick up what a person is looking at from their voice . grad g: well , especially with morgan , with the way we have the microphones arranged . i 'm sort of right on axis and it would be very hard to tell . phd c: right . grad g: uh . postdoc b: oh , but you 'd have the phd c: put morgan always like this postdoc b: you 'd have fainter phd c: and postdoc b: would n't you get fainter reception out here ? professor e: well , these grad g: sure , but i think if i 'm talking like this ? right now i 'm looking at jane and talking , now i 'm looking at chuck and talking , i do n't think the microphones would pick up that difference . phd c: but you do n't have this this problem . postdoc b: i see . phd c: morgan is the one who does this most . grad g: so if i 'm talking at you , or i 'm talking at you . professor e: i probably been affect no , i th i think i 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about `` oh gee is somebody going to say something bad ? `` and so on . grad g: lawyers . professor e: and so i so i 'm i 'm tending to stay away from people 's names even though uh postdoc b: i am too . phd c: even though you could pick up later on , just from the acoustics who you were t who you were looking at . postdoc b: i am too . grad g: and we did mention who `` he `` was . phd c: yeah . professor e: yeah . phd f: right , but i missed it . grad g: early in the conversation . phd f: but it was uh phd c: yeah , yeah . professor e: yeah . grad g: do sh - can i say professor e: yeah . no no , there 's phd f: yeah . grad g: or or is that just too sensitive ? professor e: no no , it is n't sensitive at all . postdoc b: well professor e: i was just i was just i was overreacting just because we 've been talking about it . postdoc b: and in fact , it is it is it is sensitive . phd c: no , but that it 's interesting . professor e: it 's ok to postdoc b: i i came up with something from the human subjects people that i wanted to mention . i mean , it fits into the m area of the mundane , but they did say you know , i asked her very specifically about this clause of how , um , you know , it says `` no individuals will be identified uh , `` in any publication using the data . `` ok , well , individuals being identified , let 's say you have a a snippet that says , `` joe s uh thinks such - and - such about about this field , but i think he 's wrongheaded . `` now i mean , we 're we 're gon na be careful not to have the `` wrongheaded `` part in there , but but you know , let 's say we say , you know , `` joe used to think so - and - so about this area , in his publication he says that but i think he 's changed his mind . `` or whatever . then the issue of of being able to trace joe , because we know he 's well - known in this field , and all this and and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive . professor e: b but i postdoc b: so i think it 's really really kind of adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wan na be able to have to remove ? professor e: yeah , well , there 's that . but i i mean i think also to some extent it 's just educating the human subjects people , in a way , because there 's if uh you know , there 's court transcripts , there 's there 's transcripts of radio shows i mean people say people 's names all the time . so i think it it ca n't be bad to say people 's names . it 's just that i i mean you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of of of slandering anybody , phd c: but , then it wo n't i mean , if we if we professor e: but grad g: it 's not a meeting . phd c: yeah . i mean we should do whatever 's natural in a meeting if if we were n't being recorded . professor e: yeah . right , so i so my behavior is probably not natural . phd c: `` if person x `` professor e: so . postdoc b: well , my feeling on it was that it was n't really important who said it , you know . professor e: yeah . phd f: well , if you ha since you have to um go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark grad g: well , we t we t we talked about this during the anon anonymization . phd f: right . grad g: if we wan na go through and extract from the audio and the written every time someone says a name . and i thought that our conclusion was that we did n't want to do that . professor e: yeah , we really ca n't . but a actually , i 'm sorry . i really would like to push finish this off . postdoc b: i understand . no i just i just was suggesting that it 's not a bad policy p potentially . professor e: so it 's postdoc b: so , we need to talk about this later . professor e: yeah , i di i did n't intend it an a policy though . postdoc b: uh - huh . professor e: it was it was just it was just unconscious well , semi - conscious behavior . i sorta knew i was doing it but it was phd f: well , i still do n't know who `` he `` is . professor e: i i do i do n't remember who `` he `` is . phd c: no , you have to say , you still do n't know who `` he `` is , with that prosody . professor e: ah . uh , we were talking about dan at one point { comment } and we were talking about lokendra at another point . postdoc b: yeah , depends on which one you mean . professor e: and i do n't i do n't remember which which part . phd f: oh . phd c: it 's ambiguous , so it 's ok . professor e: uh , i think grad g: well , the inference structures was lokendra . phd f: but no . the inference stuff was was was lokendra . professor e: yeah . yeah . yeah . phd f: ok . that makes sense , yeah . phd c: and the downsampling must have been dan . professor e: um grad g: yeah . professor e: good yeah . phd c: it 's an inference . professor e: yeah , you could do all these inferences , yeah . grad g: yeah . professor e: yeah . um , i i would like to move it into into uh what jose uh has been doing postdoc b: yeah . professor e: because he 's actually been doing something . phd d: uh - huh . ok . professor e: so . right . phd f: as opposed to the rest of us . phd d: well - { comment } ok . i i remind that me my first objective eh , in the project is to to study difference parameters to to find a a good solution to detect eh , the overlapping zone in eh speech recorded . but eh , tsk , { comment } ehhh { comment } in that way { comment } i i i begin to to study and to analyze the ehn the recorded speech eh the different session to to find and to locate and to mark eh the the different overlapping zone . and eh so eh i was eh i am transcribing the the first session and i i have found eh , eh one thousand acoustic events , eh besides the overlapping zones , eh i i i mean the eh breaths eh aspiration eh , eh , talk eh , eh , clap , eh { comment } i do n't know what is the different names eh you use to to name the the n speech phd a: nonspeech sounds ? phd d: yeah . grad g: oh , i do n't think we 've been doing it at that level of detail . so . phd d: yeah . eh , i i i do i do n't need to to to mmm to m to label the the different acoustic , but i prefer because eh i would like to to study if eh , i i will find eh , eh , a good eh parameters eh to detect overlapping i would like to to to test these parameters eh with the another eh , eh acoustic events , to nnn to eh to find what is the ehm the false eh , the false eh hypothesis eh , nnn , which eh are produced when we use the the ehm this eh parameter eh i mean pitch eh , eh , difference eh , feature grad g: mm - hmm . phd a: you know i think some of these um that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there . grad g: so it was phd d: yeah . phd a: i mean , if it 's a tapping sound , you would n't necessarily or , you know , something like that , it 'd be it might be hard to know that it was two separate events . phd d: yeah . yeah . yeah . yeah . grad g: well you were n't talking about just overlaps phd d: ye grad g: were you ? you were just talking about acoustic events . phd d: i i i i t i t i talk eh about eh acoustic events in general , grad g: someone starts , someone stops yeah . phd a: oh . phd d: but eh my my objective eh will be eh to study eh overlapping zone . grad g: mm - hmm . phd d: eh ? { comment } n eh in twelve minutes i found eh , eh one thousand acoustic events . professor e: how many overlaps were there uh in it ? no no , how many of them were the overlaps of speech , though ? phd d: how many ? eh almost eh three hundred eh in one session grad g: oh , god ! phd d: in five eh in forty - five minutes . phd a: three hundred overlapping speech phd d: alm - three hundred overlapping zone . grad g: ugh . phd c: overlapping speech . phd d: with the overlapping zone , overlapping speech speech what eh different duration . phd a: mm - hmm . professor e: sure . postdoc b: does this ? so if you had an overlap involving three people , how many times was that counted ? phd d: yeah , three people , two people . eh , um i would like to consider eh one people with difference noise eh in the background , be professor e: no no , but i think what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ? phd d: oh . oh . yeah . i consider one event eh for th for that eh for all the zone . this th i i i con i consider i consider eh an acoustic event , the overlapping zone , the period where three speaker or eh are talking together . grad g: well so let 's postdoc b: for grad g: so let 's say me and jane are talking at the same time , and then liz starts talking also over all of us . how many events would that be ? phd d: so - i do n't understand . grad g: so , two people are talking , { comment } and then a third person starts talking . phd d: yeah ? grad g: is there an event right here ? phd d: eh no . no no . for me is the overlapping zone , because because you you have s you have more one eh , more one voice eh , eh produced in a in in a moment . professor e: i see . grad g: so i if two or more people are talking . professor e: ok . yeah . so i think yeah . we just wanted to understand how you 're defining it . phd d: yeah . if professor e: so then , in the region between since there there is some continuous region , in between regions where there is only one person speaking . phd d: uh - huh . professor e: and one contiguous region like that you 're calling an event . phd d: uh - huh . professor e: is it are you calling the beginning or the end of it the event , phd d: yeah . professor e: or are you calling the entire length of it the event ? phd d: i consider the the , nnn the nnn , nnn eh , the entirety eh , eh , all all the time there were the voice has overlapped . professor e: ok . phd d: this is the idea . but eh i i do n't distinguish between the the numbers of eh speaker . uh , i 'm not considering eh the the ehm eh , the fact of eh , eh , for example , what did you say ? eh at first eh , eh two talkers are uh , eh speaking , and eh , eh a third person eh join to to that . for me , it 's eh it 's eh , all overlap zone , with eh several numbers of speakers is eh , eh the same acoustic event . wi - but uh , without any mark between the zone of the overlapping zone with two speakers eh speaking together , and the zone with the three speakers . postdoc b: that would j just be one . phd d: it one . one . postdoc b: ok . phd d: eh , with eh , a beginning mark and the ending mark . because eh for me , is the is the zone with eh some kind of eh distortion the spectral . professor e: got it . phd d: i do n't mind by the moment , by the moment . grad g: well , but but you could imagine that three people talking has a different spectral characteristic than two . phd d: i i do n't yeah , but eh but eh i have to study . { comment } what will happen in a general way , professor e: could . grad g: so . you had to start somewhere . professor e: yeah . we just w phd c: so there 's a lot of overlap . phd d: i i do n't know what eh will will happen with the grad g: yep . phd c: so . grad g: that 's a lot of overlap , phd d: yeah ? professor e: so again , that 's that 's three three hundred in forty - five minutes that are that are speakers , just speakers . grad g: yeah , for forty - five minutes . phd d: yeah . yeah . professor e: uh - huh . ok . yeah . postdoc b: but a a a th professor e: so that 's about eight per minute . postdoc b: but a thousand events in twelve minutes , that 's phd d: yeah , but yeah . phd c: but that can include taps . phd d: but professor e: uh . yeah . postdoc b: well , but a thousand taps in eight minutes is a l in twelve minutes is a lot . phd d: general . phd c: actually phd d: i i con i consider i consider acoustic events eh , the silent too . postdoc b: silent . grad g: silence starting or silence ending phd d: yeah , silent , ground to bec to detect eh because i consider acoustic event all the things are not eh speech . phd c: oh , ok . professor e: mm - hmm . phd a: oh . phd d: in ge in in in a general point of view . phd c: oh . professor e: ok , so how many of those thousand were silence ? phd c: alright . phd d: in the per phd f: not speech not speech or too much speech . phd d: too much speech . professor e: right . so how many of those thousand were silence , silent sections ? phd d: yeah . uh silent , i i i i do n't i i have n't the eh i i would like to to do a stylistic study professor e: yeah . phd d: and give you eh with the report eh from eh the the study from the the the session one session . professor e: yeah . yeah . phd d: and i i found that eh another thing . when eh eh i w i i was eh look at eh nnn , the difference speech file , um , for example , eh if eh we use the ehm the mixed file , to to transcribe , the the events and the words , i i saw that eh the eh speech signal , collected by the eh this kind of mike eh of this kind of mike , eh are different from the eh mixed signal eh , we eh collected by headphone . grad g: yep . phd d: and it 's right . professor e: yeah . grad g: right . phd d: but the problem is the following . the the the i i i knew that eh the signal eh , eh would be different , but eh the the problem is eh , eh we eh detected eh difference events in the speech file eh collected by by that mike uh qui compared with the mixed file . and so if when you transcribe eh only eh using the nnn the mixed file , it 's possible eh if you use the transcription to evaluate a different system , it 's possible you eh in the eh i and you use the eh speech file collected by the eh fet mike , to eh to nnn to do the experiments with the the system , professor e: mm - hmm . grad g: right . phd d: its possible to evaluate eh , eh or to consider eh acoustic events that which you marked eh in the mixed file , but eh they do n't appear in the eh speech signal eh collected by the by the mike . grad g: right . the the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . phd d: yeah . yeah . oh , it 's a good idea . it 's a good idea i think . grad g: so i agree that if someone wants to do speech event transcription , that the mixed signals here phd d: yeah . grad g: i mean , if i 'm tapping on the table , you it 's not gon na show up on any of the mikes , but it 's gon na show up rather loudly in the pzm . phd d: yeah . yeah . yeah . so and i i i say eh that eh , eh , or this eh only because eh i c i i in my opinion , it 's necessary to eh to eh to put the transcription on the speech file , collected by the objective signal . grad g: so . phd d: i mean the the the signal collected by the eh , the real mike in the future , in the prototype to to eh correct the initial eh segmentation eh with the eh real speech professor e: mm - hmm . the the the far - field , yeah . phd d: you have to to analyze you have to to process . because i i found a difference . professor e: yeah , well , just i mean , just in that that one s ten second , or whatever it was , example that adam had that that we we passed on to others a few months ago , there was that business where i g i guess it was adam and jane were talking at the same time and and uh , in the close - talking mikes you could n't hear the overlap , and in the distant mike you could . so yeah , it 's clear that if you wan na study if you wan na find all the places where there were overlap , it 's probably better to use a distant mike . phd f: that 's good . professor e: on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes , phd d: yeah . phd c: but why ca n't you use the combination of the close - talking mikes , time aligned ? professor e: so it 's grad g: if you use the combination of the close - talking mikes , you would hear jane interrupting me , but you would n't hear the paper rustling . and so if you 're interested in phd c: i i mean if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem , professor e: some { comment } of it 's masking masked . phd d: yeah . phd a: were you interrupting him or was he interrupting you ? professor e: right . phd c: right ? grad g: right . phd d: yeah . grad g: although the other issue is that the mixed close - talking mikes i mean , i 'm doing weird normalizations and things like that . phd c: but it 's known . phd d: yeah . phd c: i mean , the normalization you do is over the whole conversation grad g: yep . phd c: is n't it , over the whole meeting . grad g: right . yep . phd c: so if you wanted to study people overlapping people , that 's not a problem . phd d: i i i think eh i saw the nnn the eh but eh i eh i have eh any results . i i i saw the the speech file collected by eh the fet mike , and eh eh signal eh to eh to noise eh relation is eh low . it 's low . professor e: mm - hmm . phd d: it 's very low . you would comp if we compare it with eh the headphone . grad g: yep . phd d: and i i found that nnn that eh , ehm , pr probably , grad g: did did you phd d: i 'm not sure eh by the moment , but it 's it 's probably that eh a lot of eh , eh for example , in the overlapping zone , on eh in in several eh parts of the files where you you can find eh , eh eh , smooth eh eh speech eh from eh one eh eh talker in the in the meeting , professor e: mm - hmm . mm - hmm . phd d: it 's probably in in that eh in in those files you you can not find you can not process because eh it 's confused with with noise . professor e: mm - hmm . phd d: and there are a lot of i think . but i have to study with more detail . but eh my idea is to to process only nnn , this eh nnn , this kind of s of eh speech . because i think it 's more realistic . i 'm not sure it 's a good idea , but eh professor e: no i grad g: well , it 's more realistic but it 'll it 'll be a lot harder . phd d: yeah . professor e: well , it 'd be hard , but on the other hand as you point out , if your if i if if your concern is to get uh the overlapping people people 's speech , you will you will get that somewhat better . phd d: mm - hmm . yeah . professor e: um , are you making any use uh you were you were working with th the data that had already been transcribed . phd d: with by jane . professor e: does it uh yes . phd d: yeah . professor e: now um did you make any use of that ? see i was wondering cuz we st we have these ten hours of other stuff that is not yet transcribed . phd d: yeah . yeah . professor e: do you phd d: the the transcription by jane , t eh i eh , i i i want to use to to nnn , eh to put i i it 's a reference for me . but eh the transcription eh for example , i i do n't i i 'm not interested in the in the in the words , transcription words , eh transcribed eh eh in eh follow in the in the in the speech file , but eh eh jane eh for example eh put a mark eh at the beginning eh of each eh talker , in the in the meeting , um eh she she nnn includes information about the zone where eh there are eh there is an overlapping zone . but eh there is n't any any mark , time temporal mark , to to c eh to mmm e - heh , to label { comment } the beginning and the end of the of the professor e: mm - hmm . ok . right , so she is phd d: ta i 'm i i i think eh we need this information to professor e: right . so the twelve you you it took you twelve hours of course this included maybe some some time where you were learning about what what you wanted to do , but but uh , it took you something like twelve hours to mark the forty - five minutes , your grad g: twelve minutes . phd d: twelve minutes . professor e: s twelve minutes ! phd d: twelve minutes . twelve . professor e: i thought you did forty - five minutes of phd d: no , forty - five minutes is the is the session , all the session . postdoc b: oh . professor e: oh , you have n't done the whole session . phd d: yeah , all is the the session . professor e: this is just twelve minutes . phd d: tw - twelve hours of work to to segment eh and label eh twelve minutes from a session of part of f professor e: oh . so { comment } let me back up again . so the when you said there were three hundred speaker overlaps , phd d: yeah . professor e: that 's in twelve minutes ? phd d: no no no . i i consider all the all the session because eh i i count the nnn the nnn the overlappings marked by by jane , professor e: oh , ok . postdoc b: oh , i see . phd d: in in in in the fin in in the forty - five minutes . professor e: ok . so it 's three hundred in forty - five minutes , but you have you have time uh , uh marked twelve minute the the the um overlaps in twelve minutes of it . phd d: yeah . professor e: got it . phd f: so , can i ask can i ask whether you found uh , you know , how accurate uh jane 's uh uh labels were as far as grad g: well , not just the overlaps , everything . phd f: you know , did she miss some overlaps ? or did she n ? phd d: but , by by the moment , i i do n't compare , my my temporal mark with eh jane , but eh i i want to do it . because eh eh i per perhaps i have eh errors in the in the marks , i and if i i compare with eh jane , it 's probably i i i can correct and and and to get eh eh a more accurately eh eh transcription in the file . professor e: yeah . grad g: well , also jane jane was doing word level . phd d: yeah . professor e: yeah . grad g: so we were n't concerned with { comment } exactly when an overlap started and stopped . phd f: right . right . phd c: well , not only a word level , but actually phd d: well phd f: i 'm expect i 'm not expecting phd d: no , it 's phd c: i mean , you did n't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or grad g: right . professor e: mm - hmm . grad g: yep . postdoc b: well phd d: yeah . yeah . postdoc b: well , yeah , b yeah , i would say time bin . so my my goal is to get words with reference to a time bin , beginning and end point . phd c: yeah . phd d: yeah . phd c: right . phd d: yeah . postdoc b: and and sometimes , you know , it was like you could have an overlap where someone said something in the middle , phd d: yeah . postdoc b: but , yeah , w it just was n't important for our purposes to have it that i disrupt that unit in order to have , you know , a the words in the order in which they were spoken , it would have it would have been hard with the interface that we have . phd d: yeah . postdoc b: now , my a adam 's working on a of course , on a revised overlapping interface , phd d: uh - huh . grad g: right . phd d: i i i think it 's it 's a good eh work , postdoc b: but phd d: but eh i think we need eh eh more information . phd f: no , of course . postdoc b: yeah . phd f: i expect you to find more overlaps than than jane grad g: always need more for postdoc b: yeah . phd d: no , no . i i have to go to phd f: because you 're looking at it at a much more detailed level . phd d: i want eh i wanted to eh compare the the transcription . professor e: i have grad g: but if it takes sixty to one professor e: well , i but i have a suggestion about that . um , obviously this is very , very time - consuming , and you 're finding lots of things which i 'm sure are gon na be very interesting , but in the interests of making progress , uh might i s how how would it affect your time if you only marked speaker overlaps ? phd d: only . professor e: yes . phd d: yeah . professor e: do not mark any other events , phd d: uh - huh . professor e: but only mark speaker do you think that would speed it up quite a bit ? phd d: ok . ok . i i i i w i i wanted to professor e: do y do you think that would speed it up ? uh , speed up your your your marking ? phd d: nnn , i do n't understand very . professor e: it took you a long time to mark twelve minutes . phd d: yeah . oh , yeah , yeah . professor e: now , my suggestion was for the other thirty - three phd d: on - only to mark only to mark overlapping zone , but professor e: yeah , and my question is , if you did that , if you followed my suggestion , would it take much less time ? phd d: oh , yeah . sure . professor e: yeah ok . phd d: yeah sure . professor e: then i think it 's a good idea . phd d: sure sure . professor e: then i think it 's a good idea , because it phd d: sure , because i i need a lot of time to to put the label or to do that . yeah . professor e: yeah , i mean , we we know that there 's noise . grad g: and phd d: uh - huh . professor e: there 's there 's uh continual noise uh from fans and so forth , and there is uh more impulsive noise from uh taps and so forth phd d: yeah . professor e: and and something in between with paper rustling . we know that all that 's there and it 's a g worthwhile thing to study , but obviously it takes a lot of time to mark all of these things . phd d: yeah . professor e: whereas th i i would think that uh you we can study more or less as a distinct phenomenon the overlapping of people talking . phd d: uh - huh . ok . ok . professor e: so . then you can get the cuz you need if it 's three hundred uh i i it sounds like you probably only have fifty or sixty or seventy events right now that are really phd d: yeah . professor e: and and you need to have a lot more than that to have any kind of uh even visual sense of of what 's going on , much less any kind of reasonable statistics . grad g: right . phd c: now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the grad g: well , that 's that 's what i was gon na bring up . phd c: i mean , you should n't need to do this p completely by hand , professor e: um , ok , yeah . so let 's back up because you were n't here for an earlier conversation . phd c: right ? i 'm sorry . professor e: so the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as i mean there 's a bunch of things i mean , increased energy is - is sort of an obvious one . phd c: mm - hmm . in the far - field mike . professor e: yeah . phd c: oh , ok . professor e: um , and uh , it 's not obvious , i mean , you could you could do the dumbest thing and get get it ninety percent of the time . but when you start going past that and trying to do better , it 's not obvious what combination of features is gon na give you the you know , the right detector . so the idea is to have some ground truth first . and so the i the idea of the manual marking was to say `` ok this , i you know , it 's it 's really here `` . phd a: but i think liz is saying why not get it out of the transcripts ? phd c: what i mean is get it from the close - talking mikes . professor e: uh , yeah . phd c: a or ge get a first pass from those , professor e: we t we t w we t we talked about that . phd c: and then go through sort of it 'd be a lot faster probably to phd f: and you can grad g: yeah , that 's his , uh professor e: we we we talked about that . s but so it 's a bootstrapping thing and the thing is , phd c: yeah , i just professor e: the idea was , i we i i we thought it would be useful for him to look at the data anyway , and and then whatever he could mark would be helpful , phd c: right . professor e: and we could uh it 's a question of what you bootstrap from . you know , do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then then do your simple measurements , uh from the close - talking mike . i mean , even with the close - talking mike you 're not gon na get it right all the time . phd c: well , that 's what i wonder , because um or how bad it is , professor e: well phd c: be um , because that would be interesting grad g: i 'm working on a program to do that , and phd c: especially because the bottleneck is the transcription . right ? i mean , we 've got a lot more data than we have transcriptions for . we have the audio data , we have the close - talking mike , professor e: yeah . phd c: so i mean it seems like one kind of project that 's not perfect , but um , that you can get the training data for pretty quickly is , you know , if you infer form the close - talking mikes where the on - off points are of speech , professor e: right , we discussed that . phd c: you know , how can we detect that from a far - field ? grad g: and postdoc b: oh . grad g: i 've i 've written a program to do that , phd c: ok , i 'm sorry i missed the grad g: and it , uh professor e: it 's ok . grad g: and so but it 's it 's doing something very , very simple . it just takes a threshold , based on on the volume , phd c: uh - huh . phd f: or you can set the threshold low and then weed out the false alarms by hand . phd c: right , by hand . yeah . phd f: yeah . grad g: um , and then it does a median filter , and then it looks for runs . and , it seems to work , i 've i 'm sort of fiddling with the parameters , to get it to actually generate something , and i have n't i do n't what i 'm working on was working on was getting it to a form where we can import it into the user interface that we have , into transcriber . and so i told i said it would take about a day . i 've worked on it for about half a day , grad h: i have to go . grad g: so give me another half day and i we 'll have something we can play with . phd c: ok . professor e: see , this is where we really need the meeting recorder query stuff to be working , because we 've had these meetings and we 've had this discussion about this , and i 'm sort of remembering a little bit about what we decided , phd c: right . i 'm sorry . i just professor e: but i could n't remember all of it . phd c: it professor e: so , i think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when when he he gets his thing going , grad g: but professor e: uh , and phd c: well , it 's definitely good to have somebody look at it . i was just thinking as a way to speed up you know , the amount of postdoc b: mm - hmm . professor e: that was that was exactly the notion that that that we discussed . phd c: ok . grad g: thanks . postdoc b: another thing we discussed was um that phd c: it looks good . professor e: so . phd c: i 'll be in touch . thanks . professor e: s see ya . yeah . postdoc b: was that um there m there was this already a script i believe uh that dan had written , { comment } that uh handle bleedthrough , i mean cuz you have this this close you have contamination from other people who speak loudly . grad g: yeah , and i have n't tried using that . it would probably help the program that i 'm doing to first feed it through that . it 's a cross - correlation filter . so i i have n't tried that , but that if it it might be something it might be a good way of cleaning it up a little . postdoc b: so , some thought of maybe having yeah , having that be a preprocessor and then run it through yours . grad g: exactly . yep . professor e: but but that 's a refinement postdoc b: that 's what we were discussing . professor e: and i think we wan na see try the simple thing first , cuz you add this complex thing up uh afterwards that does something good y y yo you sort of wan na see what the simple thing does first . grad g: yep . professor e: but uh , having having somebody have some experience , again , with with uh with marking it from a human standpoint , we 're i mean , i do n't expect jose to to do it for uh f fifty hours of { comment } of speech , but i mean we { comment } if uh if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it . phd d: yeah . sure . sure . professor e: and when when uh adam was doing his automatic thing he could then compare to that and see what it was different . phd c: oh yeah , definitely . phd a: you know , i did i did uh something almost identical to this at one of my previous jobs , and it works pretty well . i mean , i almost exactly what you described , an energy detector with a median filter , you look for runs . and uh , you know , you can grad g: it seemed like the right thing to do . phd a: yeah . i mean , you you can get y i mean , you get them pretty close . grad g: that was with zero literature search . phd a: and so i think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to to do it . grad g: that 's good validation . phd a: yeah . postdoc b: is this proprietary ? phd a: uh . { comment } no . no . grad g: yeah , do you have a patent on it ? phd a: it was when i was working for the government . professor e: oh , then everybody owns it . it 's the people . postdoc b: well , i mean , is this something that we could just co - opt , or is it ? phd a: nah . postdoc b: no . ok . professor e: well , i i i he 's pretty close , anyway . i think i think it 's phd a: yeah , he 's it it does n't take a long time . postdoc b: right . i just thought if it was tried and true , then { comment } and he 's gone through additional levels of of development . grad g: just output . although if you if you have some parameters like what 's a good window size for the median filter phd a: oh ! { comment } i have to remember . i 'll think about it , and try to remember . phd f: and it might be different for government people . grad g: that 's alright . professor e: yeah , good enough for government work , as they say . phd c: they they phd a: di - dif different different bandwidth . phd f: they grad g: i was doing pretty short , you know , tenth of a second , { comment } sorts of numbers . phd f: ok . professor e: uh , i do n't know , it if if we want to uh so , uh , maybe we should move on to other other things in limited time . postdoc b: can i ask one question about his statistics ? so so in the tw twelve minutes , um , if we took three hundred and divided it by four , which is about the length of twelve minutes , i um , i 'd expect like there should be seventy - five overlaps . professor e: yeah . postdoc b: did you find uh more than seventy - five overlaps in that period , or ? phd d: more than ? postdoc b: more than how many overlaps in your twelve minutes ? phd d: how many ? eh , not @ @ i onl - only i i transcribe eh only twelve minutes from the professor e: yeah . phd d: but eh i i do n't co eh i do n't count eh the the overlap . postdoc b: the overlaps . ok . phd d: i consider i i the the nnn the the three hundred is eh considered only you your transcription . i have to to finish transcribing . so . grad g: i b i bet they 're more , because the beginning of the meeting had a lot more overlaps than than sort of the middle . phd d: yeah . grad g: middle or end . postdoc b: i 'm not sure . phd d: yeah . grad g: because i we 're we 're dealing with the uh , in the early meetings , we 're recording while we 're saying who 's talking on what microphone , { comment } and things like that , phd d: yeah . grad g: and that seems to be a lot of overlap . postdoc b: i think it 's an empirical question . phd d: yeah . postdoc b: i think we could find that out . phd d: yeah . grad g: yep . postdoc b: i 'm i 'm not sure that the beginning had more . professor e: so so i was gon na ask , i guess about any any other things that that that either of you wanted to talk about , especially since andreas is leaving in five minutes , that that you wan na go with . phd c: can i just ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz i 'm i wanted to get a feel for that to sort of be able to know what what can be done first and like how many meetings are we recording professor e: right so there 's this this there 's this forty - five minute piece that jane transcribed . phd c: and professor e: that piece was then uh sent to ibm so they could transcribe so we have some comparison point . then there 's s a larger piece that 's been recorded and uh put on cd - rom and sent uh to ibm . right ? and then we do n't know . phd c: how many meetings is that ? like how many grad g: what 's that ? professor e: that was about ten hours , and there was about phd c: t ten it 's like ten meetings or something ? uh - huh . grad g: yeah , something like that . and then then we phd a: ten meetings that have been sent to ibm ? phd c: and professor e: yeah . grad g: well , i have n't sent them yet because i was having this problem with the missing files . professor e: oh . oh , that 's right , that had those have not been sent . phd a: h how many total have we recorded now , altogether ? professor e: we 're saying about twelve hours . grad g: about twelve by now . twelve or thirteen . phd c: uh - huh . and we 're recording only this meeting , like continuously we 're only recording this one now ? or ? professor e: no . no , so the the that 's the that 's the biggest one uh , chunk so far , grad g: nope . phd a: it was the morning one . phd c: ok . professor e: but there 's at least one meeting recorded of uh the uh uh natural language guys . grad g: jerry . phd c: do they meet every week , professor e: and then there phd c: or every professor e: uh , they do . w w and we talked to them about recording some more and we 're going to , uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded , phd c: great . professor e: and we 're gon na start recording them . they 're they meet on tuesdays . we 're gon na start recording them next week . so actually , we 're gon na h start having a a pretty significant chunk and so , you know , adam 's sort of struggling with trying to get things to be less buggy , and come up quicker when they do crash and stuff things like that , now that uh the things are starting to happen . so right now , yeah , i th i 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that that amount is gon na grow uh so that the meeting meetings will probably ultimately i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , you know , twenty or thirty percent of it , not not not eighty or ninety . but . phd c: so there 's probably there 's three to four a week , grad g: that 's what we 're aiming for . phd c: that we 're aiming for . professor e: yeah . phd c: and they 're each about an hour or something . professor e: yeah , yeah . grad g: although yeah . we 'll find out tomorrow whether we can really do this or not . phd c: so ok . professor e: yeah and th the the other thing is i 'm not pos i 'm sort of thinking as we 've been through this a few times , that i really do n't know maybe you wan na do it once for the novelty , but i do n't know if in general we wan na have meetings that we record from outside this group do the digits . grad g: right . professor e: because it 's just an added bunch of weird stuff . phd c: yeah . professor e: and , you know , we we h we 're highly motivated . uh in fact , the morning group is really motivated cuz they 're working on connected digits , so it 's grad g: actually that 's something i wanted to ask , is i have a bunch of scripts to help with the transcription of the digits . professor e: yeah . grad g: we do n't have to hand - transcribe the digits because we 're reading them and i have those . phd c: right . professor e: yeah . grad g: and so i have some scripts that let you very quickly extract the sections of each utterance . but i have n't been ru i have n't been doing that . um , if i did that , is someone gon na be working on it ? professor e: uh , yeah , i i think definitely s so absolutely . grad g: i mean , is it something of interest ? professor e: yeah , whoever we have working on the acoustics for the meeting recorder are gon na start with that . grad g: ok . i mean , i i 'm i 'm interested in it , i just do n't have time to do it now . phd f: i was these meetings i 'm sure someone thought of this , but these this uh reading of the numbers would be extremely helpful to do um adaptation . grad g: so phd f: um . grad g: yep . yep . phd c: actually i have o grad g: i i would really like someone to do adaptation . phd f: mm - hmm . grad g: so if we got someone interested in that , i think it would be great for meeting recorder . professor e: well i mean , one of the things i wanted to do , uh , that i i talked to to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , grad g: since it 's the same people over and over . phd f: mm - hmm . professor e: to try to get rid of some of the effects of the the the far - field effects . um , i mean we have the party line has been that echo cancellation is not the right way to handle the situation phd f: mm - hmm . professor e: because people move around , and uh , if if it 's if it 's uh not a simple echo , like a cross - talk kind of echo , but it 's actually room acoustics , it 's it 's it 's you ca n't really do inversion , phd f: mm - hmm . professor e: and even echo cancellation is going to uh be something it may you someone may be moving enough that you are not able to adapt quickly and so the tack that we 've taken is more `` lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal `` . phd f: mm - hmm . professor e: uh , that 's the party line . but it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous . it 's good good to sort of test them , actually . and so we have n't had anybody try to do a good serious job on echo cancellation and we should know how well that can do . so that 's something i 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . um , there was a have been some nice talks recently by by lucent on on their b phd f: hmm . professor e: the block echo cancellation particularly appealed to me , uh you know , trying and change it sample by sample , but you have some reasonable sized blocks . { comment } and um , you know , th phd a: w what is the um the artifact you try to you 're trying to get rid of when you do that ? phd f: ciao . professor e: uh so it 's it you have a a direct uh uh , what 's the difference in if you were trying to construct a linear filter , that would um phd f: i 'm signing off . professor e: yeah . that would subtract off { comment } the um uh parts of the signal that were the aspects of the signal that were different between the close - talk and the distant . you know , so so uh um i guess in most echo cancellation yeah , so you given that um yeah , so you 're trying to so you 'd there 's a a distance between the close and the distant mikes so there 's a time delay there , and after the time delay , there 's these various reflections . and if you figure out well what 's the there 's a a least squares algorithm that adjusts itself adjusts the weight so that you try to subtract essentially to subtract off uh different uh different reflections . right ? so let 's take the simple case where you just had you had some uh some delay in a satellite connection or something and then there 's a there 's an echo . it comes back . and you want to adjust this filter so that it will maximally reduce the effect of this echo . phd a: so that would mean like if you were listening to the data that was recorded on one of those . uh , just the raw data , you would you might hear kind of an echo ? and and then this noise cancellation would get professor e: well , i 'm i 'm i 'm saying that 's a simplified version of what 's really happening . { comment } what 's really happening is well , when i 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , uh , the indirect sound that 's bounced around the room a number of times . ok ? so now , if you um try to r you to completely remove the effect of that is sort of impractical for a number of technical reasons , but i but not to try to completely remove it , that is , invert the the room response , but just to try to uh uh eliminate some of the the effect of some of the echos . um , a number of people have done this so that , say , if you 're talking to a speakerphone , uh it makes it more like it would be , if you were talking right up to it . so this is sort of the st the straight - forward approach . you say i i i want to use this uh this item but i want to subtract off various kinds of echos . so you construct a filter , and you have this this filtered version uh of the speech um gets uh uh gets subtracted off from the original speech . then you try to you try to minimize the energy in some sense . and so um uh with some constraints . phd a: kind of a clean up thing , that professor e: it 's a clean up thing . right . phd a: ok . professor e: so , echo cancelling is is , you know , commonly done in telephony , and and and it 's sort of the obvious thing to do in this situation if you if , you know , you 're gon na be talking some distance from a mike . phd a: when uh , i would have meetings with the folks in cambridge when i was at bbn over the phone , they had a um some kind of a special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . and then it was uh and then it would come on and it was very clear , professor e: yeah . phd a: you know . professor e: right . so it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . so um , uh anyway that 's that 's kind of a reasonable thing that i 'd like to have somebody try somebody look and and the digits would be a reasonable thing to do that with . i think that 'd be enough data plenty of data to do that with , and i for that sort of task you would n't care whether it was uh large vocabulary speech or anything . uh . um postdoc b: is brian kingsbury 's work related to that , or is it a different type of reverberation ? professor e: brian 's { comment } kingsbury 's work is an example of what we did f f from the opposite dogma . right ? which is what i was calling the `` party line `` , which is that uh doing that sort of thing is not really what we want . we want something more flexible , uh i i where people might change their position , and there might be , you know there 's also um oh yeah , noise . so the echo cancellation does not really allow for noise . it 's if you have a clean situation but you just have some delays , then we 'll figure out the right the right set of weights for your taps for your filter in order to produce the effect of those those echos . but um if there 's noise , then the very signal that it 's looking at is corrupted so that it 's decision about what the right you know , right right uh delays are is , uh is right delayed signal is is is uh is incorrect . and so , in a noisy situation , um , also in a in a situation that 's very reverberant { comment } with long reverberation times { comment } and really long delays , it 's it 's sort of typically impractical . so for those kind of reasons , and also a a c a complete inversion , if you actually i mentioned that it 's kind of hard to really do the inversion of the room acoustics . um , that 's difficult because um often times the the um the system transfer function is such that when it 's inverted you get something that 's unstable , and so , if you you do your estimate of what the system is , and then you try to invert it , you get a filter that actually uh , you know , rings , and and uh goes to infinity . so it 's so there 's there 's there 's that sort of technical reason , and the fact that things move , and there 's air currents i mean there 's all sorts of all sorts of reasons why it 's not really practical . so for all those kinds of reasons , uh we we we sort of um , concluded we did n't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which is n't really inversion , and um we decided to do this approach of taking uh , just picking uh features , which were uh will give you more something that was more stable , in the presence of , or absence of , room reverberation , and that 's what brian was trying to do . so , um , let me just say a couple things that i was i was gon na bring up . uh . let 's see . i guess you you actually already said this thing about the uh about the consent forms , which was that we now do n't have to so this was the human subjects folks who said this , { comment } or that that ? postdoc b: the a apparently i mean , we 're gon na do a revised form , of course . um but once a person has signed it once , then that 's valid for a certain number of meetings . she wanted me to actually estimate how many meetings and put that on the consent form . i told her that would be a little bit difficult to say . so i think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something . it wo n't be that many people who do it that often , but um just , you know , so long as they do n't forget that they 've done it , i guess . professor e: ok . um , back on the data thing , so there 's this sort of one hour , ten hour , a hundred hour sort of thing that that we have . we have we have an hour uh that that is transcribed , we have we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , uh by the end of the semester we 'll have , i do n't know , forty or fifty or something , if we if this really uh well , do we have that much ? phd c: not really . it 's three to four per week . professor e: let 's see , we have phd c: so that 's what you know , that professor e: uh eight weeks , uh is phd c: so that 's not a lot of hours . professor e: eight weeks times three hours is twenty - four , so that 's yeah , so like thirty thirty hours ? phd a: three three hours . phd c: yeah . i mean , is there i know this sounds tough but we 've got the room set up . um i was starting to think of some projects where you would use well , similar to what we talked about with uh energy detection on the close - talking mikes . there are a number of interesting questions that you can ask about how interactions happen in a meeting , that do n't require any transcription . so what are the patterns , the energy patterns over the meeting ? and i 'm really interested in this but we do n't have a whole lot of data . so i was thinking , you know , we 've got the room set up and you can always think of , also for political reasons , if icsi collected you know , two hundred hours , that looks different than forty hours , even if we do n't transcribe it ourselves , professor e: but i do n't think we 're gon na stop at the end of this semester . phd c: so professor e: right ? so , i th i think that if we are able to keep that up for a few months , we are gon na have more like a hundred hours . phd c: i mean , is there are there any other meetings here that we can record , especially meetings that have some kind of conflict in them { comment } or some kind of deci i mean , that are less well i do n't uh , that have some more emotional aspects to them , or strong grad g: we had some good ones earlier . phd c: there 's laughter , um i 'm talking more about strong differences of opinion meetings , maybe with manager types , or grad g: i think it 's hard to record those . phd c: to be allowed to record them ? postdoc b: it 's also likely that people will cancel out afterwards . phd c: ok . professor e: yeah , people will get postdoc b: but i but i wanted to raise the kpfa idea . phd c: ok . well , if there is , anyway . professor e: yeah , i was gon na mention that . grad g: oh , that 's a good idea . that 's that would be a good match . professor e: yeah . so yeah . so i i uh , i i 'd mentioned to adam , and that was another thing i was gon na talk uh , mention to them before { comment } that uh there 's uh it it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media . because , you know , we had talked before about the problem about using found data , { comment } that that uh it 's just set up however they have it set up and we do n't have any say about it and it 's typically one microphone , in a , uh , uh or and and so it does n't really give us the the the uh characteristics we want . um and so i do think we 're gon na continue recording here and record what we can . but um , it did occur to me that we could go to friends in broadcast media and say `` hey you have this panel show , or this you know , this discussion show , and um can you record multi - channel ? `` and uh they may be willing to record it uh with phd c: with lapel mikes or something ? professor e: well , they probably already use lapel , but they might be able to have it it would n't be that weird for them to have another mike that was somewhat distant . phd c: right . professor e: it would n't be exactly this setup , but it would be that sort of thing , and what we were gon na get from uw , you know , assuming they they they start recording , is n't als also is not going to be this exact setup . phd c: right . no , i think that 'd be great , if we can get more data . professor e: so , { comment } i i i i was thinking of looking into that . the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , { comment } uh that we could invite them to have like some of their { comment } record some of their shows here . postdoc b: wow ! phd c: well or the thing is , they 're not as averse to wearing one of these head - mount i mean , they 're on the radio , grad g: right , as we are . phd c: right ? so . { comment } um , i think that 'd be fantastic professor e: right . phd c: cuz those kinds of panels and those have interesting professor e: yeah . phd c: th - that 's an a side of style a style that we 're not collecting here , so it 'd be great . professor e: and and the i mean , the other side to it was the what which is where we were coming from i 'll i 'll talk to you more about it later { comment } is that is that there 's there 's uh the radio stations and television stations already have stuff worked out presumably , uh related to , you know , legal issues and and permissions and all that . i mean , they already do what they do do whatever they do . so it 's uh , it 's so it 's so it 's another source . so i think it 's something we should look into , you know , we 'll collect what we collect here hopefully they will collect more at uw also and um and maybe we have this other source . but yeah i think that it 's not unreasonable to aim at getting , you know , significantly in excess of a hundred hours . i mean , that was sort of our goal . the thing was , i was hoping that we could @ @ in the under this controlled situation we could at least collect , you know , thirty to fifty hours . and at the rate we 're going we 'll get pretty close to that i think this semester . and if we continue to collect some next semester , i think we should , uh phd c: right . yeah i was mostly trying to think , `` ok , if you start a project , within say a month , you know , how much data do you have to work with . and you you wan na s you wan na sort of fr freeze your your data for awhile so um right now and we do n't have the transcripts back yet from ibm right ? do oh , do we now ? professor e: well , we do n't even have it for this f you know , forty - five minutes , that was phd c: so um , not complaining , i was just trying to think , you know , what kinds of projects can you do now versus uh six months from now professor e: yeah . phd c: and they 're pretty different , because professor e: yeah . so i was thinking right now it 's sort of this exploratory stuff where you you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like , grad g: right . phd c: um right . right , right . professor e: and and and uh and meanwhile we collect , and it 's more like yeah , three months from now , or six months from now you can you can do a lot of other things . phd c: cuz i 'm not actually sure , just logistically that i can spend you know , i do n't wan na charge the time that i have on the project too early , before there 's enough data to make good use of the time . and that 's and especially with the student grad g: right . phd c: uh for instance this guy who seems professor e: yeah . phd c: uh anyway , i should n't say too much , but um if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will i have to work with , with that person . and so it 's professor e: i yeah , so i would think , exploratory things now . uh , three months from now um , i mean the transcriptions i think are a bit of an unknown cuz we have n't gotten those back yet as far as the timing , but i think as far as the collection , it does n't seem to me l like , uh , unreasonable to say that uh in january , you know , ro roughly uh which is roughly three months from now , we should have at least something like , you know , twenty - five , thirty hours . phd c: and we just do n't know about the transcription part of that , professor e: so that 's postdoc b: yeah , we need to i think that there 's a possibility that the transcript will need to be adjusted afterwards , phd c: so . i mean , it postdoc b: and uh es especially since these people wo n't be uh used to dealing with multi - channel uh transcriptions . phd c: right . professor e: yeah . postdoc b: so i think that we 'll need to adjust some and also if we wan na add things like um , well , more refined coding of overlaps , then definitely i think we should count on having an extra pass through . i wanted to ask another a a aspect of the data collection . there 'd be no reason why a person could n't get together several uh , you know , friends , and come and argue about a topic if they wanted to , right ? professor e: if they really have something they wan na talk about as opposed to something @ @ i mean , what we 're trying to stay away from was artificial constructions , but i think if it 's a real why not ? yeah . phd c: i mean , i 'm thinking , politically grad g: stage some political debates . postdoc b: you could do this , phd c: well yeah , postdoc b: you know . you could . phd c: or just if you 're if you ha if there are meetings here that happen that we can record even if we do n't um have them do the digits , { comment } or maybe have them do a shorter digit thing { comment } like if it was , you know , uh , one string of digits , or something , they 'd probably be willing to do . grad g: we do n't have to do the digits at all if we do n't want to . phd c: then , having the data is very valuable , cuz i think it 's um politically better for us to say we have this many hours of audio data , especially with the itr , if we put in a proposal on it . it 'll just look like icsi 's collected a lot more audio data . um , whether it 's transcribed or not um , is another issue , but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer . postdoc b: it seems like you could hold some meetings . grad g: yep . postdoc b: you know , you and maybe adam ? phd c: so . postdoc b: you you could you could maybe hold some additional meetings , if you wanted . phd a: would it help at all i mean , we 're already talking about sort of two levels of detail in meetings . one is uh um without doing the digits or , i guess the full - blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted stuff . phd c: need the close - talking mikes . phd a: you do , ok . phd c: i mean , absolutely , professor e: yeah . yeah . phd c: yeah . i 'm really scared grad g: it seems like it 's a big part of this corpus is to have the close - talking mikes . phd a: i see , ok . phd c: um or at least , like , me personally ? i would { comment } i could n't use that data . professor e: yeah . postdoc b: i agree . and mari also , phd c: um . postdoc b: we had this came up when she she was here . that 's important . phd c: so it 's a great idea , professor e: yeah , i i b by the by the way , i do n't think the transcriptions are actually , in the long run , such a big bottleneck . phd c: and if it were true than i would just do that , but it 's not that bad like the room is not the bottleneck , and we have enough time in the room , it 's getting the people to come in and put on the and get the setup going . professor e: i think the issue is just that we 're we 're blazing that path . right ? and and um d do you have any idea when when uh the you 'll be able to send uh the ten hours to them ? grad g: well , i 've been burning two c ds a day , which is about all i can do with the time i have . professor e: yeah . yeah . grad g: so it 'll be early next week . professor e: yeah , ok . so early next week we send it to them , and then then we check with them to see if they 've got it and we we start , you know asking about the timing for it . grad g: yep . professor e: so i think once they get it sorted out about how they 're gon na do it , which i think they 're pretty well along on , cuz they were able to read the files and so on . grad g: yep . professor e: right ? grad g: yeah , but professor e: well grad g: yeah , who knows where they are . phd a: have they ever responded to you ? grad g: nope . professor e: yeah , but you know , so they they they have you know , they 're volunteering their time and they have a lot of other things to do , phd c: what if grad g: yeah , you we ca n't complain . professor e: right ? but they but at any rate , they 'll i i think once they get that sorted out , they 're they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it , and uh i think it 's not going to be i do n't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , i think . it 's not going to be thirty grad g: yep . i think that 's probably true . phd c: really ? so it 's the amount of professor e: it 's it 's just getting it going . grad g: it 's pipeline , pipeline issues . phd c: right . what about these lunch meetings grad g: once the pipeline fills . phd c: i mean , i do n't know , if there 's any way without too much more overhead , even if we do n't ship it right away to ibm even if we just collect it here for awhile , { comment } to record you know , two or three more meeting a week , just to have the data , even if they 're um not doing the digits , but they do wear the headphones ? professor e: but the lunch meetings are pretty much one person getting up and phd c: no , i meant , um , sorry , the meetings where people eat their lunch downstairs , maybe they do n't wan na be recorded , but grad g: oh , and we 're just chatting ? phd c: just the ch the chatting . grad g: yeah , we have a lot of those . phd c: i actually i actually think that 's useful data , um the chatting , grad g: yeah , the problem with that is i would i think i would feel a little constrained to you know ? uh , some of the meetings phd c: but ok . you do n't wan na do it , cuz ok . grad g: you know , our `` soccer ball `` meeting ? phd c: alright . grad g: i guess none of you were there for our soccer ball meeting . phd c: alright , { comment } so i 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it . grad g: that was hilarious . professor e: yeah . well , we should also check with mari again , because they because they were really intending , you know , maybe just did n't happen , but they were really intending to be duplicating this in some level . so then that would double what we had . uh . and there 's a lot of different meetings at uw uh i mean really m a lot more { comment } than we have here right cuz we 're not right on campus , grad g: right . professor e: so . phd a: is the uh , notion of recording any of chuck 's meetings dead in the water , or is that still a possibility ? professor e: uh , they seem to have some problems with it . we can we can talk about that later . um , but , again , jerry is jerry 's open so i mean , we have two speech meetings , one uh network meeting , uh jerry was open to it but i i s one of the things that i think is a little a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably ca n't do it every week . you know ? i i i i think that that people are gon na feel uh are gon na feel a little bit constrained . now , it might get a little better if we do n't have them do the digits all the time . and the then so then they can just really sort of try to put the mikes on and then just charge in and grad g: yep . phd c: what if we give people you know , we cater a lunch in exchange for them having their meeting here or something ? postdoc b: well , you know , i i do think eating while you 're doing a meeting is going to be increasing the noise . phd c: ok . postdoc b: but i had another question , which is um , you know , in principle , w um , i know that you do n't want artificial topics , phd c: alright , alright , alright . postdoc b: but um it does seem to me that we might be able to get subjects from campus to come down and do something that would n't be too artificial . i mean , we could political discussions , or or something or other , phd c: no , definitely . postdoc b: and i you know , people who are because , you know , there 's also this constraint . we d it 's like , you know , the the uh goldibears goldi goldilocks , it 's like you do n't want meetings that are too large , but you do n't want meetings that are too small . and um a and it just seems like maybe we could exploit the subj human subject p p pool , in the positive sense of the word . phd a: well , even i mean , coming down from campus is sort of a big thing , but what about postdoc b: we could pay subjects . phd a: or what about people in the in the building ? phd c: yeah , i was thinking , there 's all these other peo phd a: i mean , there 's the state of california downstairs , and phd c: yeah . i mean grad g: i just really doubt that uh any of the state of california meetings would be recordable and then releasable to the general public . postdoc b: yeah . phd a: oh . phd c: mm - hmm . grad g: so i i mean i talked with some people at the haas business school who are i who are interested in speech recognition phd c: alright , well . grad g: and , they sort of hummed and hawed and said `` well maybe we could have meetings down here `` , but then i got email from them that said `` no , we decided we 're not really interested and we do n't wan na come down and hold meetings . `` so , i think it 's gon na be a problem to get people regularly . phd a: what about joachim , maybe he can professor e: but but we c but i think , you know , we get some scattered things from this and that . and i i d i do think that maybe we can get somewhere with the with the radio . phd c: mm - hmm . professor e: uh i i have better contacts in radio than in television , but phd a: you could get a lot of lively discussions from those radio ones . phd c: well , and they 're already they 're these things are already recorded , grad g: yep . professor e: yeah . phd c: we do n't have to ask them to even and i 'm not sure wh how they record it , but they must record from individual professor e: n well no , i 'm not talking about ones that are already recorded . i 'm talking about new ones phd c: why why not ? professor e: because because because we would be asking them to do something different . phd c: well , we can find out . i know for instance mark liberman was interested uh in in ldc getting data , uh , and professor e: right , that 's the found data idea . phd c: yeah . professor e: but what i 'm saying is uh if i talk to people that i know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike . phd c: mm - hmm . professor e: and u i think routinely they would not do this . so , since i 'm interested in the distant mike stuff , i wan na make sure that there is at least that somewhere phd c: right . great . ok . professor e: and uh but if we ask them to do that they might be intrigued enough by the idea that they uh might be e e willing to the i might be able to talk them into it . phd c: mm - hmm . grad g: um . we 're getting towards the end of our disk space , so we should think about trying to wrap up here . phd c: that 's a good way to end a meeting . professor e: ok . well i do n't why do n't we why d u why do n't we uh uh turn them turn grad g: ok , leave leave them on for a moment until i turn this off , cuz that 's when it crashed last time . postdoc b: oh . that 's good to know . professor e: turning off the microphone made it crash . well postdoc b: that 's good to know . professor e: ok .","output":"the group discussed topics including a potential collaboration with another icsi member regarding the analysis of inference structures , efforts by speaker mn005 to detect speaker overlap , the current status of recordings and transcriptions , and future efforts to collect meeting data . in addition to weekly meetings by the bmr group , efforts are in progress to record meetings by other icsi research groups , as well as routine discussions by non-icsi members ."},{"instruction":"what was agreed upon on sample transcripts ?","input":"professor e: so . ok . does n't look like it crashed . that 's great . grad g: so i think maybe what 's causing it to crash is i keep starting it and then stopping it to see if it 's working . and so i think starting it and then stopping it and starting it again causes it to crash . so , i wo n't do that anymore . postdoc b: and it looks like you 've found a way of uh mapping the location to the without having people have to give their names each time ? phd a: sounds like an initialization thing . postdoc b: i mean it 's like you have the so you know that grad g: no . postdoc b: i mean , are you going to write down that i sat here ? grad g: i 'm gon na collect the digit forms and write it down . postdoc b: ok . phd c: oh , ok . grad g: so so they should be right with what 's on the digit forms . ok , so i 'll go ahead and start with digits . u and i should say that uh , you just pau you just read each line an and then pause briefly . professor e: and start by giving the transcript number . phd a: tran phd d: transcript uh . ok , ok . phd a: oh sorry , go ahead . professor e: so uh , you see , don , the unbridled excitement of the work that we have on this project . grad h: ok . professor e: it 's just uh grad h: umh . professor e: uh , you know , it does n't seem like a bad idea to have { comment } that information . grad g: and i 'm surprised i sort of i 'm surprised i forgot that , professor e: yeah , i i 'd i think it 's some grad g: but uh i think that would be a good thing to add . after i just printed out a zillion of them . professor e: yeah , well , that 's um , so i i do have a a an agenda suggestion . uh , we i think the things that we talk about in this meeting uh tend to be a mixture of uh procedural uh mundane things and uh research points and um i was thinking i think it was a meeting a couple of weeks ago that we we spent much of the time talking about the mundane stuff cuz that 's easier to get out of the way and then we sort of drifted into the research and maybe five minutes into that andreas had to leave . so uh i 'm suggesting we turn it around and and uh sort of we have anybody has some mundane points that we could send an email later , uh hold them for a bit , and let 's talk about the the research - y kind of things . um , so um the one th one thing i know that we have on that is uh we had talked a a couple weeks before um uh about the uh the stuff you were doing with with uh um uh l l attempting to locate events , we had a little go around trying to figure out what you meant by `` events `` but i think , you know , what we had meant by `` events `` i guess was uh points of overlap between speakers . but i th i gather from our discussion a little earlier today that you also mean uh interruptions with something else phd d: yeah . professor e: like some other noise . phd d: uh - huh . yeah . professor e: yes ? you mean that as an event also . phd d: to professor e: so at any rate you were you 've you 've done some work on that phd d: right . professor e: and um then the other thing would be it might be nice to have a preliminary discussion of some of the other uh research uh areas that uh we 're thinking about doing . um , i think especially since you you have n't been in in these meetings for a little bit , maybe you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , uh and one of the things i know that also came up uh is some discussions that that uh that uh jane had with lokendra uh about some some some um uh work about i i i d i i do n't want to try to say cuz i i 'll say it wrong , but anyway some some potential collaboration there about about the about the working with these data . phd c: oh . sure . professor e: so . so , uh . grad g: you wan na just go around ? professor e: uh . well , i do n't know if we if this is sort of like everybody has something to contribute sort of thing , i think there 's just just a couple a couple people primarily um but um uh , wh why do n't actually i think that that last one i just said we could do fairly quickly so why do n't you you start with that . postdoc b: ok . shall i shall i just start ? ok . professor e: yeah , just explain what it was . postdoc b: um , so , uh , he was interested in the question of you know , relating to his to the research he presented recently , um of inference structures , and uh , the need to build in , um , this this sort of uh mechanism for understanding of language . and he gave the example in his talk about how um , e a i 'm remembering it just off the top of my head right now , but it 's something about how um , i `` joe slipped `` you know , `` john had washed the floor `` or something like that . and i do n't have it quite right , but that kind of thing , where you have to draw the inference that , ok , there 's this time sequence , but also the the the causal aspects of the uh floor and and how it might have been the cause of the fall and that um it was the other person who fell than the one who cleaned it and it { comment } these sorts of things . so , i looked through the transcript that we have so far , { comment } and um , fou identified a couple different types of things of that type and um , one of them was something like uh , during the course of the transcript , um um , w we had gone through the part where everyone said which channel they were on and which device they were on , and um , the question was raised `` well , should we restart the recording at this point ? `` and and dan ellis said , `` well , we 're just so far ahead of the game right now we really do n't need to `` . now , how would you interpret that without a lot of inference ? so , the inferences that are involved are things like , ok , so , how do you interpret `` ahead of the game `` ? you know . so it 's the it 's i what you what you int what you draw you know , the conclusions that you need to draw are that space is involved in recording , grad g: hmm , metaphorically . postdoc b: that um , i that i we have enough space , and he continues , like `` we 're so ahead of the game cuz now we have built - in downsampling `` . so you have to sort of get the idea that um , `` ahead of the game `` is sp speaking with respect to space limitations , that um that in fact downsampling is gaining us enough space , and that therefore we can keep the recording we 've done so far . but there are a lot of different things like that . grad g: so , do you think his interest is in using this as a data source , or training material , or what ? professor e: well , i i should maybe interject to say this started off with a discussion that i had with him , so um we were trying to think of ways that his interests could interact with ours grad g: mm - hmm . professor e: and um uh i thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with jane 's help , look into some of the data that we 're already have and see , is there anything to this at all ? grad g: mm - hmm . professor e: is there any point which you think that , you know , you could gain some advantage and some potential use for it . cuz it could be that you 'd look through it and you say `` well , this is just the wrong task for for him to pursue his `` grad g: wrong , yeah . professor e: and and uh i got the impression from your mail that in fact there was enough things like this just in the little sample that that you looked at that that it 's plausible at least . postdoc b: it 's possible . uh , he was he he you know we met and he was gon na go and uh you know , y look through them more systematically professor e: yeah . postdoc b: and then uh meet again . professor e: yeah . postdoc b: so it 's , you know , not a matter of a professor e: yeah . postdoc b: but , yeah , i think i think it was optimistic . professor e: so anyway , that 's that 's e a quite different thing from anything we 've talked about that , you know , might might might come out from some of this . phd c: but he can use text , basically . i mean , he 's talking about just using text postdoc b: that 's his major i mentioned several that w had to do with implications drawn from intonational contours phd c: pretty much , or ? postdoc b: and that was n't as directly relevant to what he 's doing . he 's interested in these these knowledge structures , phd c: ok . phd d: yeah , interesting . postdoc b: inferences that you draw i from professor e: i mean , he certainly could use text , but we were in fact looking to see if there is there is there something in common between our interest in meetings and his interest in in in this stuff . so . grad g: and i imagine that transcripts of speech i mean text that is speech probably has more of those than sort of prepared writing . i i do n't know whether it would or not , but it seems like it would . professor e: i do n't know , probably de probably depends on what the prepared writing was . but . postdoc b: yeah , i do n't think i would make that leap , because i in narratives , you know i mean , if you spell out everything in a narrative , it can be really tedious , grad g: mm - hmm . postdoc b: so . grad g: yeah , i 'm just thinking , you know , when you 're when you 're face to face , you have a lot of backchannel and and postdoc b: oh . that aspect . grad g: yeah . and so i think it 's just easier to do that sort of broad inference jumping if it 's face to face . i mean , so , if i just read that dan was saying `` we 're ahead of the game `` { comment } in that in that context , postdoc b: well yeah . grad g: i might not realize that he was talking about disk space as opposed to anything else . postdoc b: i you know , i i had several that had to do with backchannels and this was n't one of them . grad g: uh - huh . postdoc b: this this one really does um m make you leap from so he said , you know , `` we 're ahead of the game , w we have built - in downsampling `` . grad g: mm - hmm . postdoc b: and the inference , i if you had it written down , would be grad g: i guess it would be the same . postdoc b: uh - huh . but there are others that have backchannelling , it 's just he was less interested in those . phd f: can i sorry to interrupt . um , i f f f i 've @ @ { comment } d a minute uh , several minutes ago , i , like , briefly was was not listening and so who is `` he `` in this context ? phd c: yeah , there 's a lot of pronoun phd f: ok . so i was just realizing we 've you guys have been talking about `` he `` um for at least uh , i do n't know , three three four minutes without ever mentioning the person 's name again . phd c: i believe it . yeah . actually to make it worse , { comment } uh , morgan uses `` you `` and `` you `` phd f: so this is this is this is gon na be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort . grad g: it 's in my notes . phd c: with gaze and no identification , or i just wrote this down . yeah , actually . cuz morgan will say well , `` you had some ideas `` phd d: yeah . phd f: you just wrote this ? phd c: and he never said li - he looked grad g: well , i think he 's doing that intentionally , phd c: right , so it 's great . grad g: are n't you ? phd c: so this is really great phd f: right . phd c: because the thing is , because he 's looking at the per even for addressees in the conversation , phd d: yeah . phd f: mm - hmm . phd c: i bet you could pick that up in the acoustics . just because your gaze is also correlated with the directionality of your voice . professor e: uh - huh . could be . postdoc b: can we professor e: yeah . that would be tou grad g: oh , that would be interesting . phd c: yeah , so that , i mean , to even know um when phd d: yeah . phd c: yeah , if you have the p z ms you should be able to pick up what a person is looking at from their voice . grad g: well , especially with morgan , with the way we have the microphones arranged . i 'm sort of right on axis and it would be very hard to tell . phd c: right . grad g: uh . postdoc b: oh , but you 'd have the phd c: put morgan always like this postdoc b: you 'd have fainter phd c: and postdoc b: would n't you get fainter reception out here ? professor e: well , these grad g: sure , but i think if i 'm talking like this ? right now i 'm looking at jane and talking , now i 'm looking at chuck and talking , i do n't think the microphones would pick up that difference . phd c: but you do n't have this this problem . postdoc b: i see . phd c: morgan is the one who does this most . grad g: so if i 'm talking at you , or i 'm talking at you . professor e: i probably been affect no , i th i think i 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about `` oh gee is somebody going to say something bad ? `` and so on . grad g: lawyers . professor e: and so i so i 'm i 'm tending to stay away from people 's names even though uh postdoc b: i am too . phd c: even though you could pick up later on , just from the acoustics who you were t who you were looking at . postdoc b: i am too . grad g: and we did mention who `` he `` was . phd c: yeah . professor e: yeah . phd f: right , but i missed it . grad g: early in the conversation . phd f: but it was uh phd c: yeah , yeah . professor e: yeah . grad g: do sh - can i say professor e: yeah . no no , there 's phd f: yeah . grad g: or or is that just too sensitive ? professor e: no no , it is n't sensitive at all . postdoc b: well professor e: i was just i was just i was overreacting just because we 've been talking about it . postdoc b: and in fact , it is it is it is sensitive . phd c: no , but that it 's interesting . professor e: it 's ok to postdoc b: i i came up with something from the human subjects people that i wanted to mention . i mean , it fits into the m area of the mundane , but they did say you know , i asked her very specifically about this clause of how , um , you know , it says `` no individuals will be identified uh , `` in any publication using the data . `` ok , well , individuals being identified , let 's say you have a a snippet that says , `` joe s uh thinks such - and - such about about this field , but i think he 's wrongheaded . `` now i mean , we 're we 're gon na be careful not to have the `` wrongheaded `` part in there , but but you know , let 's say we say , you know , `` joe used to think so - and - so about this area , in his publication he says that but i think he 's changed his mind . `` or whatever . then the issue of of being able to trace joe , because we know he 's well - known in this field , and all this and and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive . professor e: b but i postdoc b: so i think it 's really really kind of adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wan na be able to have to remove ? professor e: yeah , well , there 's that . but i i mean i think also to some extent it 's just educating the human subjects people , in a way , because there 's if uh you know , there 's court transcripts , there 's there 's transcripts of radio shows i mean people say people 's names all the time . so i think it it ca n't be bad to say people 's names . it 's just that i i mean you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of of of slandering anybody , phd c: but , then it wo n't i mean , if we if we professor e: but grad g: it 's not a meeting . phd c: yeah . i mean we should do whatever 's natural in a meeting if if we were n't being recorded . professor e: yeah . right , so i so my behavior is probably not natural . phd c: `` if person x `` professor e: so . postdoc b: well , my feeling on it was that it was n't really important who said it , you know . professor e: yeah . phd f: well , if you ha since you have to um go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark grad g: well , we t we t we talked about this during the anon anonymization . phd f: right . grad g: if we wan na go through and extract from the audio and the written every time someone says a name . and i thought that our conclusion was that we did n't want to do that . professor e: yeah , we really ca n't . but a actually , i 'm sorry . i really would like to push finish this off . postdoc b: i understand . no i just i just was suggesting that it 's not a bad policy p potentially . professor e: so it 's postdoc b: so , we need to talk about this later . professor e: yeah , i di i did n't intend it an a policy though . postdoc b: uh - huh . professor e: it was it was just it was just unconscious well , semi - conscious behavior . i sorta knew i was doing it but it was phd f: well , i still do n't know who `` he `` is . professor e: i i do i do n't remember who `` he `` is . phd c: no , you have to say , you still do n't know who `` he `` is , with that prosody . professor e: ah . uh , we were talking about dan at one point { comment } and we were talking about lokendra at another point . postdoc b: yeah , depends on which one you mean . professor e: and i do n't i do n't remember which which part . phd f: oh . phd c: it 's ambiguous , so it 's ok . professor e: uh , i think grad g: well , the inference structures was lokendra . phd f: but no . the inference stuff was was was lokendra . professor e: yeah . yeah . yeah . phd f: ok . that makes sense , yeah . phd c: and the downsampling must have been dan . professor e: um grad g: yeah . professor e: good yeah . phd c: it 's an inference . professor e: yeah , you could do all these inferences , yeah . grad g: yeah . professor e: yeah . um , i i would like to move it into into uh what jose uh has been doing postdoc b: yeah . professor e: because he 's actually been doing something . phd d: uh - huh . ok . professor e: so . right . phd f: as opposed to the rest of us . phd d: well - { comment } ok . i i remind that me my first objective eh , in the project is to to study difference parameters to to find a a good solution to detect eh , the overlapping zone in eh speech recorded . but eh , tsk , { comment } ehhh { comment } in that way { comment } i i i begin to to study and to analyze the ehn the recorded speech eh the different session to to find and to locate and to mark eh the the different overlapping zone . and eh so eh i was eh i am transcribing the the first session and i i have found eh , eh one thousand acoustic events , eh besides the overlapping zones , eh i i i mean the eh breaths eh aspiration eh , eh , talk eh , eh , clap , eh { comment } i do n't know what is the different names eh you use to to name the the n speech phd a: nonspeech sounds ? phd d: yeah . grad g: oh , i do n't think we 've been doing it at that level of detail . so . phd d: yeah . eh , i i i do i do n't need to to to mmm to m to label the the different acoustic , but i prefer because eh i would like to to study if eh , i i will find eh , eh , a good eh parameters eh to detect overlapping i would like to to to test these parameters eh with the another eh , eh acoustic events , to nnn to eh to find what is the ehm the false eh , the false eh hypothesis eh , nnn , which eh are produced when we use the the ehm this eh parameter eh i mean pitch eh , eh , difference eh , feature grad g: mm - hmm . phd a: you know i think some of these um that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there . grad g: so it was phd d: yeah . phd a: i mean , if it 's a tapping sound , you would n't necessarily or , you know , something like that , it 'd be it might be hard to know that it was two separate events . phd d: yeah . yeah . yeah . yeah . grad g: well you were n't talking about just overlaps phd d: ye grad g: were you ? you were just talking about acoustic events . phd d: i i i i t i t i talk eh about eh acoustic events in general , grad g: someone starts , someone stops yeah . phd a: oh . phd d: but eh my my objective eh will be eh to study eh overlapping zone . grad g: mm - hmm . phd d: eh ? { comment } n eh in twelve minutes i found eh , eh one thousand acoustic events . professor e: how many overlaps were there uh in it ? no no , how many of them were the overlaps of speech , though ? phd d: how many ? eh almost eh three hundred eh in one session grad g: oh , god ! phd d: in five eh in forty - five minutes . phd a: three hundred overlapping speech phd d: alm - three hundred overlapping zone . grad g: ugh . phd c: overlapping speech . phd d: with the overlapping zone , overlapping speech speech what eh different duration . phd a: mm - hmm . professor e: sure . postdoc b: does this ? so if you had an overlap involving three people , how many times was that counted ? phd d: yeah , three people , two people . eh , um i would like to consider eh one people with difference noise eh in the background , be professor e: no no , but i think what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ? phd d: oh . oh . yeah . i consider one event eh for th for that eh for all the zone . this th i i i con i consider i consider eh an acoustic event , the overlapping zone , the period where three speaker or eh are talking together . grad g: well so let 's postdoc b: for grad g: so let 's say me and jane are talking at the same time , and then liz starts talking also over all of us . how many events would that be ? phd d: so - i do n't understand . grad g: so , two people are talking , { comment } and then a third person starts talking . phd d: yeah ? grad g: is there an event right here ? phd d: eh no . no no . for me is the overlapping zone , because because you you have s you have more one eh , more one voice eh , eh produced in a in in a moment . professor e: i see . grad g: so i if two or more people are talking . professor e: ok . yeah . so i think yeah . we just wanted to understand how you 're defining it . phd d: yeah . if professor e: so then , in the region between since there there is some continuous region , in between regions where there is only one person speaking . phd d: uh - huh . professor e: and one contiguous region like that you 're calling an event . phd d: uh - huh . professor e: is it are you calling the beginning or the end of it the event , phd d: yeah . professor e: or are you calling the entire length of it the event ? phd d: i consider the the , nnn the nnn , nnn eh , the entirety eh , eh , all all the time there were the voice has overlapped . professor e: ok . phd d: this is the idea . but eh i i do n't distinguish between the the numbers of eh speaker . uh , i 'm not considering eh the the ehm eh , the fact of eh , eh , for example , what did you say ? eh at first eh , eh two talkers are uh , eh speaking , and eh , eh a third person eh join to to that . for me , it 's eh it 's eh , all overlap zone , with eh several numbers of speakers is eh , eh the same acoustic event . wi - but uh , without any mark between the zone of the overlapping zone with two speakers eh speaking together , and the zone with the three speakers . postdoc b: that would j just be one . phd d: it one . one . postdoc b: ok . phd d: eh , with eh , a beginning mark and the ending mark . because eh for me , is the is the zone with eh some kind of eh distortion the spectral . professor e: got it . phd d: i do n't mind by the moment , by the moment . grad g: well , but but you could imagine that three people talking has a different spectral characteristic than two . phd d: i i do n't yeah , but eh but eh i have to study . { comment } what will happen in a general way , professor e: could . grad g: so . you had to start somewhere . professor e: yeah . we just w phd c: so there 's a lot of overlap . phd d: i i do n't know what eh will will happen with the grad g: yep . phd c: so . grad g: that 's a lot of overlap , phd d: yeah ? professor e: so again , that 's that 's three three hundred in forty - five minutes that are that are speakers , just speakers . grad g: yeah , for forty - five minutes . phd d: yeah . yeah . professor e: uh - huh . ok . yeah . postdoc b: but a a a th professor e: so that 's about eight per minute . postdoc b: but a thousand events in twelve minutes , that 's phd d: yeah , but yeah . phd c: but that can include taps . phd d: but professor e: uh . yeah . postdoc b: well , but a thousand taps in eight minutes is a l in twelve minutes is a lot . phd d: general . phd c: actually phd d: i i con i consider i consider acoustic events eh , the silent too . postdoc b: silent . grad g: silence starting or silence ending phd d: yeah , silent , ground to bec to detect eh because i consider acoustic event all the things are not eh speech . phd c: oh , ok . professor e: mm - hmm . phd a: oh . phd d: in ge in in in a general point of view . phd c: oh . professor e: ok , so how many of those thousand were silence ? phd c: alright . phd d: in the per phd f: not speech not speech or too much speech . phd d: too much speech . professor e: right . so how many of those thousand were silence , silent sections ? phd d: yeah . uh silent , i i i i do n't i i have n't the eh i i would like to to do a stylistic study professor e: yeah . phd d: and give you eh with the report eh from eh the the study from the the the session one session . professor e: yeah . yeah . phd d: and i i found that eh another thing . when eh eh i w i i was eh look at eh nnn , the difference speech file , um , for example , eh if eh we use the ehm the mixed file , to to transcribe , the the events and the words , i i saw that eh the eh speech signal , collected by the eh this kind of mike eh of this kind of mike , eh are different from the eh mixed signal eh , we eh collected by headphone . grad g: yep . phd d: and it 's right . professor e: yeah . grad g: right . phd d: but the problem is the following . the the the i i i knew that eh the signal eh , eh would be different , but eh the the problem is eh , eh we eh detected eh difference events in the speech file eh collected by by that mike uh qui compared with the mixed file . and so if when you transcribe eh only eh using the nnn the mixed file , it 's possible eh if you use the transcription to evaluate a different system , it 's possible you eh in the eh i and you use the eh speech file collected by the eh fet mike , to eh to nnn to do the experiments with the the system , professor e: mm - hmm . grad g: right . phd d: its possible to evaluate eh , eh or to consider eh acoustic events that which you marked eh in the mixed file , but eh they do n't appear in the eh speech signal eh collected by the by the mike . grad g: right . the the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . phd d: yeah . yeah . oh , it 's a good idea . it 's a good idea i think . grad g: so i agree that if someone wants to do speech event transcription , that the mixed signals here phd d: yeah . grad g: i mean , if i 'm tapping on the table , you it 's not gon na show up on any of the mikes , but it 's gon na show up rather loudly in the pzm . phd d: yeah . yeah . yeah . so and i i i say eh that eh , eh , or this eh only because eh i c i i in my opinion , it 's necessary to eh to eh to put the transcription on the speech file , collected by the objective signal . grad g: so . phd d: i mean the the the signal collected by the eh , the real mike in the future , in the prototype to to eh correct the initial eh segmentation eh with the eh real speech professor e: mm - hmm . the the the far - field , yeah . phd d: you have to to analyze you have to to process . because i i found a difference . professor e: yeah , well , just i mean , just in that that one s ten second , or whatever it was , example that adam had that that we we passed on to others a few months ago , there was that business where i g i guess it was adam and jane were talking at the same time and and uh , in the close - talking mikes you could n't hear the overlap , and in the distant mike you could . so yeah , it 's clear that if you wan na study if you wan na find all the places where there were overlap , it 's probably better to use a distant mike . phd f: that 's good . professor e: on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes , phd d: yeah . phd c: but why ca n't you use the combination of the close - talking mikes , time aligned ? professor e: so it 's grad g: if you use the combination of the close - talking mikes , you would hear jane interrupting me , but you would n't hear the paper rustling . and so if you 're interested in phd c: i i mean if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem , professor e: some { comment } of it 's masking masked . phd d: yeah . phd a: were you interrupting him or was he interrupting you ? professor e: right . phd c: right ? grad g: right . phd d: yeah . grad g: although the other issue is that the mixed close - talking mikes i mean , i 'm doing weird normalizations and things like that . phd c: but it 's known . phd d: yeah . phd c: i mean , the normalization you do is over the whole conversation grad g: yep . phd c: is n't it , over the whole meeting . grad g: right . yep . phd c: so if you wanted to study people overlapping people , that 's not a problem . phd d: i i i think eh i saw the nnn the eh but eh i eh i have eh any results . i i i saw the the speech file collected by eh the fet mike , and eh eh signal eh to eh to noise eh relation is eh low . it 's low . professor e: mm - hmm . phd d: it 's very low . you would comp if we compare it with eh the headphone . grad g: yep . phd d: and i i found that nnn that eh , ehm , pr probably , grad g: did did you phd d: i 'm not sure eh by the moment , but it 's it 's probably that eh a lot of eh , eh for example , in the overlapping zone , on eh in in several eh parts of the files where you you can find eh , eh eh , smooth eh eh speech eh from eh one eh eh talker in the in the meeting , professor e: mm - hmm . mm - hmm . phd d: it 's probably in in that eh in in those files you you can not find you can not process because eh it 's confused with with noise . professor e: mm - hmm . phd d: and there are a lot of i think . but i have to study with more detail . but eh my idea is to to process only nnn , this eh nnn , this kind of s of eh speech . because i think it 's more realistic . i 'm not sure it 's a good idea , but eh professor e: no i grad g: well , it 's more realistic but it 'll it 'll be a lot harder . phd d: yeah . professor e: well , it 'd be hard , but on the other hand as you point out , if your if i if if your concern is to get uh the overlapping people people 's speech , you will you will get that somewhat better . phd d: mm - hmm . yeah . professor e: um , are you making any use uh you were you were working with th the data that had already been transcribed . phd d: with by jane . professor e: does it uh yes . phd d: yeah . professor e: now um did you make any use of that ? see i was wondering cuz we st we have these ten hours of other stuff that is not yet transcribed . phd d: yeah . yeah . professor e: do you phd d: the the transcription by jane , t eh i eh , i i i want to use to to nnn , eh to put i i it 's a reference for me . but eh the transcription eh for example , i i do n't i i 'm not interested in the in the in the words , transcription words , eh transcribed eh eh in eh follow in the in the in the speech file , but eh eh jane eh for example eh put a mark eh at the beginning eh of each eh talker , in the in the meeting , um eh she she nnn includes information about the zone where eh there are eh there is an overlapping zone . but eh there is n't any any mark , time temporal mark , to to c eh to mmm e - heh , to label { comment } the beginning and the end of the of the professor e: mm - hmm . ok . right , so she is phd d: ta i 'm i i i think eh we need this information to professor e: right . so the twelve you you it took you twelve hours of course this included maybe some some time where you were learning about what what you wanted to do , but but uh , it took you something like twelve hours to mark the forty - five minutes , your grad g: twelve minutes . phd d: twelve minutes . professor e: s twelve minutes ! phd d: twelve minutes . twelve . professor e: i thought you did forty - five minutes of phd d: no , forty - five minutes is the is the session , all the session . postdoc b: oh . professor e: oh , you have n't done the whole session . phd d: yeah , all is the the session . professor e: this is just twelve minutes . phd d: tw - twelve hours of work to to segment eh and label eh twelve minutes from a session of part of f professor e: oh . so { comment } let me back up again . so the when you said there were three hundred speaker overlaps , phd d: yeah . professor e: that 's in twelve minutes ? phd d: no no no . i i consider all the all the session because eh i i count the nnn the nnn the overlappings marked by by jane , professor e: oh , ok . postdoc b: oh , i see . phd d: in in in in the fin in in the forty - five minutes . professor e: ok . so it 's three hundred in forty - five minutes , but you have you have time uh , uh marked twelve minute the the the um overlaps in twelve minutes of it . phd d: yeah . professor e: got it . phd f: so , can i ask can i ask whether you found uh , you know , how accurate uh jane 's uh uh labels were as far as grad g: well , not just the overlaps , everything . phd f: you know , did she miss some overlaps ? or did she n ? phd d: but , by by the moment , i i do n't compare , my my temporal mark with eh jane , but eh i i want to do it . because eh eh i per perhaps i have eh errors in the in the marks , i and if i i compare with eh jane , it 's probably i i i can correct and and and to get eh eh a more accurately eh eh transcription in the file . professor e: yeah . grad g: well , also jane jane was doing word level . phd d: yeah . professor e: yeah . grad g: so we were n't concerned with { comment } exactly when an overlap started and stopped . phd f: right . right . phd c: well , not only a word level , but actually phd d: well phd f: i 'm expect i 'm not expecting phd d: no , it 's phd c: i mean , you did n't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or grad g: right . professor e: mm - hmm . grad g: yep . postdoc b: well phd d: yeah . yeah . postdoc b: well , yeah , b yeah , i would say time bin . so my my goal is to get words with reference to a time bin , beginning and end point . phd c: yeah . phd d: yeah . phd c: right . phd d: yeah . postdoc b: and and sometimes , you know , it was like you could have an overlap where someone said something in the middle , phd d: yeah . postdoc b: but , yeah , w it just was n't important for our purposes to have it that i disrupt that unit in order to have , you know , a the words in the order in which they were spoken , it would have it would have been hard with the interface that we have . phd d: yeah . postdoc b: now , my a adam 's working on a of course , on a revised overlapping interface , phd d: uh - huh . grad g: right . phd d: i i i think it 's it 's a good eh work , postdoc b: but phd d: but eh i think we need eh eh more information . phd f: no , of course . postdoc b: yeah . phd f: i expect you to find more overlaps than than jane grad g: always need more for postdoc b: yeah . phd d: no , no . i i have to go to phd f: because you 're looking at it at a much more detailed level . phd d: i want eh i wanted to eh compare the the transcription . professor e: i have grad g: but if it takes sixty to one professor e: well , i but i have a suggestion about that . um , obviously this is very , very time - consuming , and you 're finding lots of things which i 'm sure are gon na be very interesting , but in the interests of making progress , uh might i s how how would it affect your time if you only marked speaker overlaps ? phd d: only . professor e: yes . phd d: yeah . professor e: do not mark any other events , phd d: uh - huh . professor e: but only mark speaker do you think that would speed it up quite a bit ? phd d: ok . ok . i i i i w i i wanted to professor e: do y do you think that would speed it up ? uh , speed up your your your marking ? phd d: nnn , i do n't understand very . professor e: it took you a long time to mark twelve minutes . phd d: yeah . oh , yeah , yeah . professor e: now , my suggestion was for the other thirty - three phd d: on - only to mark only to mark overlapping zone , but professor e: yeah , and my question is , if you did that , if you followed my suggestion , would it take much less time ? phd d: oh , yeah . sure . professor e: yeah ok . phd d: yeah sure . professor e: then i think it 's a good idea . phd d: sure sure . professor e: then i think it 's a good idea , because it phd d: sure , because i i need a lot of time to to put the label or to do that . yeah . professor e: yeah , i mean , we we know that there 's noise . grad g: and phd d: uh - huh . professor e: there 's there 's uh continual noise uh from fans and so forth , and there is uh more impulsive noise from uh taps and so forth phd d: yeah . professor e: and and something in between with paper rustling . we know that all that 's there and it 's a g worthwhile thing to study , but obviously it takes a lot of time to mark all of these things . phd d: yeah . professor e: whereas th i i would think that uh you we can study more or less as a distinct phenomenon the overlapping of people talking . phd d: uh - huh . ok . ok . professor e: so . then you can get the cuz you need if it 's three hundred uh i i it sounds like you probably only have fifty or sixty or seventy events right now that are really phd d: yeah . professor e: and and you need to have a lot more than that to have any kind of uh even visual sense of of what 's going on , much less any kind of reasonable statistics . grad g: right . phd c: now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the grad g: well , that 's that 's what i was gon na bring up . phd c: i mean , you should n't need to do this p completely by hand , professor e: um , ok , yeah . so let 's back up because you were n't here for an earlier conversation . phd c: right ? i 'm sorry . professor e: so the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as i mean there 's a bunch of things i mean , increased energy is - is sort of an obvious one . phd c: mm - hmm . in the far - field mike . professor e: yeah . phd c: oh , ok . professor e: um , and uh , it 's not obvious , i mean , you could you could do the dumbest thing and get get it ninety percent of the time . but when you start going past that and trying to do better , it 's not obvious what combination of features is gon na give you the you know , the right detector . so the idea is to have some ground truth first . and so the i the idea of the manual marking was to say `` ok this , i you know , it 's it 's really here `` . phd a: but i think liz is saying why not get it out of the transcripts ? phd c: what i mean is get it from the close - talking mikes . professor e: uh , yeah . phd c: a or ge get a first pass from those , professor e: we t we t w we t we talked about that . phd c: and then go through sort of it 'd be a lot faster probably to phd f: and you can grad g: yeah , that 's his , uh professor e: we we we talked about that . s but so it 's a bootstrapping thing and the thing is , phd c: yeah , i just professor e: the idea was , i we i i we thought it would be useful for him to look at the data anyway , and and then whatever he could mark would be helpful , phd c: right . professor e: and we could uh it 's a question of what you bootstrap from . you know , do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then then do your simple measurements , uh from the close - talking mike . i mean , even with the close - talking mike you 're not gon na get it right all the time . phd c: well , that 's what i wonder , because um or how bad it is , professor e: well phd c: be um , because that would be interesting grad g: i 'm working on a program to do that , and phd c: especially because the bottleneck is the transcription . right ? i mean , we 've got a lot more data than we have transcriptions for . we have the audio data , we have the close - talking mike , professor e: yeah . phd c: so i mean it seems like one kind of project that 's not perfect , but um , that you can get the training data for pretty quickly is , you know , if you infer form the close - talking mikes where the on - off points are of speech , professor e: right , we discussed that . phd c: you know , how can we detect that from a far - field ? grad g: and postdoc b: oh . grad g: i 've i 've written a program to do that , phd c: ok , i 'm sorry i missed the grad g: and it , uh professor e: it 's ok . grad g: and so but it 's it 's doing something very , very simple . it just takes a threshold , based on on the volume , phd c: uh - huh . phd f: or you can set the threshold low and then weed out the false alarms by hand . phd c: right , by hand . yeah . phd f: yeah . grad g: um , and then it does a median filter , and then it looks for runs . and , it seems to work , i 've i 'm sort of fiddling with the parameters , to get it to actually generate something , and i have n't i do n't what i 'm working on was working on was getting it to a form where we can import it into the user interface that we have , into transcriber . and so i told i said it would take about a day . i 've worked on it for about half a day , grad h: i have to go . grad g: so give me another half day and i we 'll have something we can play with . phd c: ok . professor e: see , this is where we really need the meeting recorder query stuff to be working , because we 've had these meetings and we 've had this discussion about this , and i 'm sort of remembering a little bit about what we decided , phd c: right . i 'm sorry . i just professor e: but i could n't remember all of it . phd c: it professor e: so , i think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when when he he gets his thing going , grad g: but professor e: uh , and phd c: well , it 's definitely good to have somebody look at it . i was just thinking as a way to speed up you know , the amount of postdoc b: mm - hmm . professor e: that was that was exactly the notion that that that we discussed . phd c: ok . grad g: thanks . postdoc b: another thing we discussed was um that phd c: it looks good . professor e: so . phd c: i 'll be in touch . thanks . professor e: s see ya . yeah . postdoc b: was that um there m there was this already a script i believe uh that dan had written , { comment } that uh handle bleedthrough , i mean cuz you have this this close you have contamination from other people who speak loudly . grad g: yeah , and i have n't tried using that . it would probably help the program that i 'm doing to first feed it through that . it 's a cross - correlation filter . so i i have n't tried that , but that if it it might be something it might be a good way of cleaning it up a little . postdoc b: so , some thought of maybe having yeah , having that be a preprocessor and then run it through yours . grad g: exactly . yep . professor e: but but that 's a refinement postdoc b: that 's what we were discussing . professor e: and i think we wan na see try the simple thing first , cuz you add this complex thing up uh afterwards that does something good y y yo you sort of wan na see what the simple thing does first . grad g: yep . professor e: but uh , having having somebody have some experience , again , with with uh with marking it from a human standpoint , we 're i mean , i do n't expect jose to to do it for uh f fifty hours of { comment } of speech , but i mean we { comment } if uh if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it . phd d: yeah . sure . sure . professor e: and when when uh adam was doing his automatic thing he could then compare to that and see what it was different . phd c: oh yeah , definitely . phd a: you know , i did i did uh something almost identical to this at one of my previous jobs , and it works pretty well . i mean , i almost exactly what you described , an energy detector with a median filter , you look for runs . and uh , you know , you can grad g: it seemed like the right thing to do . phd a: yeah . i mean , you you can get y i mean , you get them pretty close . grad g: that was with zero literature search . phd a: and so i think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to to do it . grad g: that 's good validation . phd a: yeah . postdoc b: is this proprietary ? phd a: uh . { comment } no . no . grad g: yeah , do you have a patent on it ? phd a: it was when i was working for the government . professor e: oh , then everybody owns it . it 's the people . postdoc b: well , i mean , is this something that we could just co - opt , or is it ? phd a: nah . postdoc b: no . ok . professor e: well , i i i he 's pretty close , anyway . i think i think it 's phd a: yeah , he 's it it does n't take a long time . postdoc b: right . i just thought if it was tried and true , then { comment } and he 's gone through additional levels of of development . grad g: just output . although if you if you have some parameters like what 's a good window size for the median filter phd a: oh ! { comment } i have to remember . i 'll think about it , and try to remember . phd f: and it might be different for government people . grad g: that 's alright . professor e: yeah , good enough for government work , as they say . phd c: they they phd a: di - dif different different bandwidth . phd f: they grad g: i was doing pretty short , you know , tenth of a second , { comment } sorts of numbers . phd f: ok . professor e: uh , i do n't know , it if if we want to uh so , uh , maybe we should move on to other other things in limited time . postdoc b: can i ask one question about his statistics ? so so in the tw twelve minutes , um , if we took three hundred and divided it by four , which is about the length of twelve minutes , i um , i 'd expect like there should be seventy - five overlaps . professor e: yeah . postdoc b: did you find uh more than seventy - five overlaps in that period , or ? phd d: more than ? postdoc b: more than how many overlaps in your twelve minutes ? phd d: how many ? eh , not @ @ i onl - only i i transcribe eh only twelve minutes from the professor e: yeah . phd d: but eh i i do n't co eh i do n't count eh the the overlap . postdoc b: the overlaps . ok . phd d: i consider i i the the nnn the the three hundred is eh considered only you your transcription . i have to to finish transcribing . so . grad g: i b i bet they 're more , because the beginning of the meeting had a lot more overlaps than than sort of the middle . phd d: yeah . grad g: middle or end . postdoc b: i 'm not sure . phd d: yeah . grad g: because i we 're we 're dealing with the uh , in the early meetings , we 're recording while we 're saying who 's talking on what microphone , { comment } and things like that , phd d: yeah . grad g: and that seems to be a lot of overlap . postdoc b: i think it 's an empirical question . phd d: yeah . postdoc b: i think we could find that out . phd d: yeah . grad g: yep . postdoc b: i 'm i 'm not sure that the beginning had more . professor e: so so i was gon na ask , i guess about any any other things that that that either of you wanted to talk about , especially since andreas is leaving in five minutes , that that you wan na go with . phd c: can i just ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz i 'm i wanted to get a feel for that to sort of be able to know what what can be done first and like how many meetings are we recording professor e: right so there 's this this there 's this forty - five minute piece that jane transcribed . phd c: and professor e: that piece was then uh sent to ibm so they could transcribe so we have some comparison point . then there 's s a larger piece that 's been recorded and uh put on cd - rom and sent uh to ibm . right ? and then we do n't know . phd c: how many meetings is that ? like how many grad g: what 's that ? professor e: that was about ten hours , and there was about phd c: t ten it 's like ten meetings or something ? uh - huh . grad g: yeah , something like that . and then then we phd a: ten meetings that have been sent to ibm ? phd c: and professor e: yeah . grad g: well , i have n't sent them yet because i was having this problem with the missing files . professor e: oh . oh , that 's right , that had those have not been sent . phd a: h how many total have we recorded now , altogether ? professor e: we 're saying about twelve hours . grad g: about twelve by now . twelve or thirteen . phd c: uh - huh . and we 're recording only this meeting , like continuously we 're only recording this one now ? or ? professor e: no . no , so the the that 's the that 's the biggest one uh , chunk so far , grad g: nope . phd a: it was the morning one . phd c: ok . professor e: but there 's at least one meeting recorded of uh the uh uh natural language guys . grad g: jerry . phd c: do they meet every week , professor e: and then there phd c: or every professor e: uh , they do . w w and we talked to them about recording some more and we 're going to , uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded , phd c: great . professor e: and we 're gon na start recording them . they 're they meet on tuesdays . we 're gon na start recording them next week . so actually , we 're gon na h start having a a pretty significant chunk and so , you know , adam 's sort of struggling with trying to get things to be less buggy , and come up quicker when they do crash and stuff things like that , now that uh the things are starting to happen . so right now , yeah , i th i 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that that amount is gon na grow uh so that the meeting meetings will probably ultimately i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , you know , twenty or thirty percent of it , not not not eighty or ninety . but . phd c: so there 's probably there 's three to four a week , grad g: that 's what we 're aiming for . phd c: that we 're aiming for . professor e: yeah . phd c: and they 're each about an hour or something . professor e: yeah , yeah . grad g: although yeah . we 'll find out tomorrow whether we can really do this or not . phd c: so ok . professor e: yeah and th the the other thing is i 'm not pos i 'm sort of thinking as we 've been through this a few times , that i really do n't know maybe you wan na do it once for the novelty , but i do n't know if in general we wan na have meetings that we record from outside this group do the digits . grad g: right . professor e: because it 's just an added bunch of weird stuff . phd c: yeah . professor e: and , you know , we we h we 're highly motivated . uh in fact , the morning group is really motivated cuz they 're working on connected digits , so it 's grad g: actually that 's something i wanted to ask , is i have a bunch of scripts to help with the transcription of the digits . professor e: yeah . grad g: we do n't have to hand - transcribe the digits because we 're reading them and i have those . phd c: right . professor e: yeah . grad g: and so i have some scripts that let you very quickly extract the sections of each utterance . but i have n't been ru i have n't been doing that . um , if i did that , is someone gon na be working on it ? professor e: uh , yeah , i i think definitely s so absolutely . grad g: i mean , is it something of interest ? professor e: yeah , whoever we have working on the acoustics for the meeting recorder are gon na start with that . grad g: ok . i mean , i i 'm i 'm interested in it , i just do n't have time to do it now . phd f: i was these meetings i 'm sure someone thought of this , but these this uh reading of the numbers would be extremely helpful to do um adaptation . grad g: so phd f: um . grad g: yep . yep . phd c: actually i have o grad g: i i would really like someone to do adaptation . phd f: mm - hmm . grad g: so if we got someone interested in that , i think it would be great for meeting recorder . professor e: well i mean , one of the things i wanted to do , uh , that i i talked to to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , grad g: since it 's the same people over and over . phd f: mm - hmm . professor e: to try to get rid of some of the effects of the the the far - field effects . um , i mean we have the party line has been that echo cancellation is not the right way to handle the situation phd f: mm - hmm . professor e: because people move around , and uh , if if it 's if it 's uh not a simple echo , like a cross - talk kind of echo , but it 's actually room acoustics , it 's it 's it 's you ca n't really do inversion , phd f: mm - hmm . professor e: and even echo cancellation is going to uh be something it may you someone may be moving enough that you are not able to adapt quickly and so the tack that we 've taken is more `` lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal `` . phd f: mm - hmm . professor e: uh , that 's the party line . but it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous . it 's good good to sort of test them , actually . and so we have n't had anybody try to do a good serious job on echo cancellation and we should know how well that can do . so that 's something i 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . um , there was a have been some nice talks recently by by lucent on on their b phd f: hmm . professor e: the block echo cancellation particularly appealed to me , uh you know , trying and change it sample by sample , but you have some reasonable sized blocks . { comment } and um , you know , th phd a: w what is the um the artifact you try to you 're trying to get rid of when you do that ? phd f: ciao . professor e: uh so it 's it you have a a direct uh uh , what 's the difference in if you were trying to construct a linear filter , that would um phd f: i 'm signing off . professor e: yeah . that would subtract off { comment } the um uh parts of the signal that were the aspects of the signal that were different between the close - talk and the distant . you know , so so uh um i guess in most echo cancellation yeah , so you given that um yeah , so you 're trying to so you 'd there 's a a distance between the close and the distant mikes so there 's a time delay there , and after the time delay , there 's these various reflections . and if you figure out well what 's the there 's a a least squares algorithm that adjusts itself adjusts the weight so that you try to subtract essentially to subtract off uh different uh different reflections . right ? so let 's take the simple case where you just had you had some uh some delay in a satellite connection or something and then there 's a there 's an echo . it comes back . and you want to adjust this filter so that it will maximally reduce the effect of this echo . phd a: so that would mean like if you were listening to the data that was recorded on one of those . uh , just the raw data , you would you might hear kind of an echo ? and and then this noise cancellation would get professor e: well , i 'm i 'm i 'm saying that 's a simplified version of what 's really happening . { comment } what 's really happening is well , when i 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , uh , the indirect sound that 's bounced around the room a number of times . ok ? so now , if you um try to r you to completely remove the effect of that is sort of impractical for a number of technical reasons , but i but not to try to completely remove it , that is , invert the the room response , but just to try to uh uh eliminate some of the the effect of some of the echos . um , a number of people have done this so that , say , if you 're talking to a speakerphone , uh it makes it more like it would be , if you were talking right up to it . so this is sort of the st the straight - forward approach . you say i i i want to use this uh this item but i want to subtract off various kinds of echos . so you construct a filter , and you have this this filtered version uh of the speech um gets uh uh gets subtracted off from the original speech . then you try to you try to minimize the energy in some sense . and so um uh with some constraints . phd a: kind of a clean up thing , that professor e: it 's a clean up thing . right . phd a: ok . professor e: so , echo cancelling is is , you know , commonly done in telephony , and and and it 's sort of the obvious thing to do in this situation if you if , you know , you 're gon na be talking some distance from a mike . phd a: when uh , i would have meetings with the folks in cambridge when i was at bbn over the phone , they had a um some kind of a special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . and then it was uh and then it would come on and it was very clear , professor e: yeah . phd a: you know . professor e: right . so it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . so um , uh anyway that 's that 's kind of a reasonable thing that i 'd like to have somebody try somebody look and and the digits would be a reasonable thing to do that with . i think that 'd be enough data plenty of data to do that with , and i for that sort of task you would n't care whether it was uh large vocabulary speech or anything . uh . um postdoc b: is brian kingsbury 's work related to that , or is it a different type of reverberation ? professor e: brian 's { comment } kingsbury 's work is an example of what we did f f from the opposite dogma . right ? which is what i was calling the `` party line `` , which is that uh doing that sort of thing is not really what we want . we want something more flexible , uh i i where people might change their position , and there might be , you know there 's also um oh yeah , noise . so the echo cancellation does not really allow for noise . it 's if you have a clean situation but you just have some delays , then we 'll figure out the right the right set of weights for your taps for your filter in order to produce the effect of those those echos . but um if there 's noise , then the very signal that it 's looking at is corrupted so that it 's decision about what the right you know , right right uh delays are is , uh is right delayed signal is is is uh is incorrect . and so , in a noisy situation , um , also in a in a situation that 's very reverberant { comment } with long reverberation times { comment } and really long delays , it 's it 's sort of typically impractical . so for those kind of reasons , and also a a c a complete inversion , if you actually i mentioned that it 's kind of hard to really do the inversion of the room acoustics . um , that 's difficult because um often times the the um the system transfer function is such that when it 's inverted you get something that 's unstable , and so , if you you do your estimate of what the system is , and then you try to invert it , you get a filter that actually uh , you know , rings , and and uh goes to infinity . so it 's so there 's there 's there 's that sort of technical reason , and the fact that things move , and there 's air currents i mean there 's all sorts of all sorts of reasons why it 's not really practical . so for all those kinds of reasons , uh we we we sort of um , concluded we did n't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which is n't really inversion , and um we decided to do this approach of taking uh , just picking uh features , which were uh will give you more something that was more stable , in the presence of , or absence of , room reverberation , and that 's what brian was trying to do . so , um , let me just say a couple things that i was i was gon na bring up . uh . let 's see . i guess you you actually already said this thing about the uh about the consent forms , which was that we now do n't have to so this was the human subjects folks who said this , { comment } or that that ? postdoc b: the a apparently i mean , we 're gon na do a revised form , of course . um but once a person has signed it once , then that 's valid for a certain number of meetings . she wanted me to actually estimate how many meetings and put that on the consent form . i told her that would be a little bit difficult to say . so i think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something . it wo n't be that many people who do it that often , but um just , you know , so long as they do n't forget that they 've done it , i guess . professor e: ok . um , back on the data thing , so there 's this sort of one hour , ten hour , a hundred hour sort of thing that that we have . we have we have an hour uh that that is transcribed , we have we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , uh by the end of the semester we 'll have , i do n't know , forty or fifty or something , if we if this really uh well , do we have that much ? phd c: not really . it 's three to four per week . professor e: let 's see , we have phd c: so that 's what you know , that professor e: uh eight weeks , uh is phd c: so that 's not a lot of hours . professor e: eight weeks times three hours is twenty - four , so that 's yeah , so like thirty thirty hours ? phd a: three three hours . phd c: yeah . i mean , is there i know this sounds tough but we 've got the room set up . um i was starting to think of some projects where you would use well , similar to what we talked about with uh energy detection on the close - talking mikes . there are a number of interesting questions that you can ask about how interactions happen in a meeting , that do n't require any transcription . so what are the patterns , the energy patterns over the meeting ? and i 'm really interested in this but we do n't have a whole lot of data . so i was thinking , you know , we 've got the room set up and you can always think of , also for political reasons , if icsi collected you know , two hundred hours , that looks different than forty hours , even if we do n't transcribe it ourselves , professor e: but i do n't think we 're gon na stop at the end of this semester . phd c: so professor e: right ? so , i th i think that if we are able to keep that up for a few months , we are gon na have more like a hundred hours . phd c: i mean , is there are there any other meetings here that we can record , especially meetings that have some kind of conflict in them { comment } or some kind of deci i mean , that are less well i do n't uh , that have some more emotional aspects to them , or strong grad g: we had some good ones earlier . phd c: there 's laughter , um i 'm talking more about strong differences of opinion meetings , maybe with manager types , or grad g: i think it 's hard to record those . phd c: to be allowed to record them ? postdoc b: it 's also likely that people will cancel out afterwards . phd c: ok . professor e: yeah , people will get postdoc b: but i but i wanted to raise the kpfa idea . phd c: ok . well , if there is , anyway . professor e: yeah , i was gon na mention that . grad g: oh , that 's a good idea . that 's that would be a good match . professor e: yeah . so yeah . so i i uh , i i 'd mentioned to adam , and that was another thing i was gon na talk uh , mention to them before { comment } that uh there 's uh it it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media . because , you know , we had talked before about the problem about using found data , { comment } that that uh it 's just set up however they have it set up and we do n't have any say about it and it 's typically one microphone , in a , uh , uh or and and so it does n't really give us the the the uh characteristics we want . um and so i do think we 're gon na continue recording here and record what we can . but um , it did occur to me that we could go to friends in broadcast media and say `` hey you have this panel show , or this you know , this discussion show , and um can you record multi - channel ? `` and uh they may be willing to record it uh with phd c: with lapel mikes or something ? professor e: well , they probably already use lapel , but they might be able to have it it would n't be that weird for them to have another mike that was somewhat distant . phd c: right . professor e: it would n't be exactly this setup , but it would be that sort of thing , and what we were gon na get from uw , you know , assuming they they they start recording , is n't als also is not going to be this exact setup . phd c: right . no , i think that 'd be great , if we can get more data . professor e: so , { comment } i i i i was thinking of looking into that . the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , { comment } uh that we could invite them to have like some of their { comment } record some of their shows here . postdoc b: wow ! phd c: well or the thing is , they 're not as averse to wearing one of these head - mount i mean , they 're on the radio , grad g: right , as we are . phd c: right ? so . { comment } um , i think that 'd be fantastic professor e: right . phd c: cuz those kinds of panels and those have interesting professor e: yeah . phd c: th - that 's an a side of style a style that we 're not collecting here , so it 'd be great . professor e: and and the i mean , the other side to it was the what which is where we were coming from i 'll i 'll talk to you more about it later { comment } is that is that there 's there 's uh the radio stations and television stations already have stuff worked out presumably , uh related to , you know , legal issues and and permissions and all that . i mean , they already do what they do do whatever they do . so it 's uh , it 's so it 's so it 's another source . so i think it 's something we should look into , you know , we 'll collect what we collect here hopefully they will collect more at uw also and um and maybe we have this other source . but yeah i think that it 's not unreasonable to aim at getting , you know , significantly in excess of a hundred hours . i mean , that was sort of our goal . the thing was , i was hoping that we could @ @ in the under this controlled situation we could at least collect , you know , thirty to fifty hours . and at the rate we 're going we 'll get pretty close to that i think this semester . and if we continue to collect some next semester , i think we should , uh phd c: right . yeah i was mostly trying to think , `` ok , if you start a project , within say a month , you know , how much data do you have to work with . and you you wan na s you wan na sort of fr freeze your your data for awhile so um right now and we do n't have the transcripts back yet from ibm right ? do oh , do we now ? professor e: well , we do n't even have it for this f you know , forty - five minutes , that was phd c: so um , not complaining , i was just trying to think , you know , what kinds of projects can you do now versus uh six months from now professor e: yeah . phd c: and they 're pretty different , because professor e: yeah . so i was thinking right now it 's sort of this exploratory stuff where you you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like , grad g: right . phd c: um right . right , right . professor e: and and and uh and meanwhile we collect , and it 's more like yeah , three months from now , or six months from now you can you can do a lot of other things . phd c: cuz i 'm not actually sure , just logistically that i can spend you know , i do n't wan na charge the time that i have on the project too early , before there 's enough data to make good use of the time . and that 's and especially with the student grad g: right . phd c: uh for instance this guy who seems professor e: yeah . phd c: uh anyway , i should n't say too much , but um if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will i have to work with , with that person . and so it 's professor e: i yeah , so i would think , exploratory things now . uh , three months from now um , i mean the transcriptions i think are a bit of an unknown cuz we have n't gotten those back yet as far as the timing , but i think as far as the collection , it does n't seem to me l like , uh , unreasonable to say that uh in january , you know , ro roughly uh which is roughly three months from now , we should have at least something like , you know , twenty - five , thirty hours . phd c: and we just do n't know about the transcription part of that , professor e: so that 's postdoc b: yeah , we need to i think that there 's a possibility that the transcript will need to be adjusted afterwards , phd c: so . i mean , it postdoc b: and uh es especially since these people wo n't be uh used to dealing with multi - channel uh transcriptions . phd c: right . professor e: yeah . postdoc b: so i think that we 'll need to adjust some and also if we wan na add things like um , well , more refined coding of overlaps , then definitely i think we should count on having an extra pass through . i wanted to ask another a a aspect of the data collection . there 'd be no reason why a person could n't get together several uh , you know , friends , and come and argue about a topic if they wanted to , right ? professor e: if they really have something they wan na talk about as opposed to something @ @ i mean , what we 're trying to stay away from was artificial constructions , but i think if it 's a real why not ? yeah . phd c: i mean , i 'm thinking , politically grad g: stage some political debates . postdoc b: you could do this , phd c: well yeah , postdoc b: you know . you could . phd c: or just if you 're if you ha if there are meetings here that happen that we can record even if we do n't um have them do the digits , { comment } or maybe have them do a shorter digit thing { comment } like if it was , you know , uh , one string of digits , or something , they 'd probably be willing to do . grad g: we do n't have to do the digits at all if we do n't want to . phd c: then , having the data is very valuable , cuz i think it 's um politically better for us to say we have this many hours of audio data , especially with the itr , if we put in a proposal on it . it 'll just look like icsi 's collected a lot more audio data . um , whether it 's transcribed or not um , is another issue , but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer . postdoc b: it seems like you could hold some meetings . grad g: yep . postdoc b: you know , you and maybe adam ? phd c: so . postdoc b: you you could you could maybe hold some additional meetings , if you wanted . phd a: would it help at all i mean , we 're already talking about sort of two levels of detail in meetings . one is uh um without doing the digits or , i guess the full - blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted stuff . phd c: need the close - talking mikes . phd a: you do , ok . phd c: i mean , absolutely , professor e: yeah . yeah . phd c: yeah . i 'm really scared grad g: it seems like it 's a big part of this corpus is to have the close - talking mikes . phd a: i see , ok . phd c: um or at least , like , me personally ? i would { comment } i could n't use that data . professor e: yeah . postdoc b: i agree . and mari also , phd c: um . postdoc b: we had this came up when she she was here . that 's important . phd c: so it 's a great idea , professor e: yeah , i i b by the by the way , i do n't think the transcriptions are actually , in the long run , such a big bottleneck . phd c: and if it were true than i would just do that , but it 's not that bad like the room is not the bottleneck , and we have enough time in the room , it 's getting the people to come in and put on the and get the setup going . professor e: i think the issue is just that we 're we 're blazing that path . right ? and and um d do you have any idea when when uh the you 'll be able to send uh the ten hours to them ? grad g: well , i 've been burning two c ds a day , which is about all i can do with the time i have . professor e: yeah . yeah . grad g: so it 'll be early next week . professor e: yeah , ok . so early next week we send it to them , and then then we check with them to see if they 've got it and we we start , you know asking about the timing for it . grad g: yep . professor e: so i think once they get it sorted out about how they 're gon na do it , which i think they 're pretty well along on , cuz they were able to read the files and so on . grad g: yep . professor e: right ? grad g: yeah , but professor e: well grad g: yeah , who knows where they are . phd a: have they ever responded to you ? grad g: nope . professor e: yeah , but you know , so they they they have you know , they 're volunteering their time and they have a lot of other things to do , phd c: what if grad g: yeah , you we ca n't complain . professor e: right ? but they but at any rate , they 'll i i think once they get that sorted out , they 're they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it , and uh i think it 's not going to be i do n't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , i think . it 's not going to be thirty grad g: yep . i think that 's probably true . phd c: really ? so it 's the amount of professor e: it 's it 's just getting it going . grad g: it 's pipeline , pipeline issues . phd c: right . what about these lunch meetings grad g: once the pipeline fills . phd c: i mean , i do n't know , if there 's any way without too much more overhead , even if we do n't ship it right away to ibm even if we just collect it here for awhile , { comment } to record you know , two or three more meeting a week , just to have the data , even if they 're um not doing the digits , but they do wear the headphones ? professor e: but the lunch meetings are pretty much one person getting up and phd c: no , i meant , um , sorry , the meetings where people eat their lunch downstairs , maybe they do n't wan na be recorded , but grad g: oh , and we 're just chatting ? phd c: just the ch the chatting . grad g: yeah , we have a lot of those . phd c: i actually i actually think that 's useful data , um the chatting , grad g: yeah , the problem with that is i would i think i would feel a little constrained to you know ? uh , some of the meetings phd c: but ok . you do n't wan na do it , cuz ok . grad g: you know , our `` soccer ball `` meeting ? phd c: alright . grad g: i guess none of you were there for our soccer ball meeting . phd c: alright , { comment } so i 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it . grad g: that was hilarious . professor e: yeah . well , we should also check with mari again , because they because they were really intending , you know , maybe just did n't happen , but they were really intending to be duplicating this in some level . so then that would double what we had . uh . and there 's a lot of different meetings at uw uh i mean really m a lot more { comment } than we have here right cuz we 're not right on campus , grad g: right . professor e: so . phd a: is the uh , notion of recording any of chuck 's meetings dead in the water , or is that still a possibility ? professor e: uh , they seem to have some problems with it . we can we can talk about that later . um , but , again , jerry is jerry 's open so i mean , we have two speech meetings , one uh network meeting , uh jerry was open to it but i i s one of the things that i think is a little a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably ca n't do it every week . you know ? i i i i think that that people are gon na feel uh are gon na feel a little bit constrained . now , it might get a little better if we do n't have them do the digits all the time . and the then so then they can just really sort of try to put the mikes on and then just charge in and grad g: yep . phd c: what if we give people you know , we cater a lunch in exchange for them having their meeting here or something ? postdoc b: well , you know , i i do think eating while you 're doing a meeting is going to be increasing the noise . phd c: ok . postdoc b: but i had another question , which is um , you know , in principle , w um , i know that you do n't want artificial topics , phd c: alright , alright , alright . postdoc b: but um it does seem to me that we might be able to get subjects from campus to come down and do something that would n't be too artificial . i mean , we could political discussions , or or something or other , phd c: no , definitely . postdoc b: and i you know , people who are because , you know , there 's also this constraint . we d it 's like , you know , the the uh goldibears goldi goldilocks , it 's like you do n't want meetings that are too large , but you do n't want meetings that are too small . and um a and it just seems like maybe we could exploit the subj human subject p p pool , in the positive sense of the word . phd a: well , even i mean , coming down from campus is sort of a big thing , but what about postdoc b: we could pay subjects . phd a: or what about people in the in the building ? phd c: yeah , i was thinking , there 's all these other peo phd a: i mean , there 's the state of california downstairs , and phd c: yeah . i mean grad g: i just really doubt that uh any of the state of california meetings would be recordable and then releasable to the general public . postdoc b: yeah . phd a: oh . phd c: mm - hmm . grad g: so i i mean i talked with some people at the haas business school who are i who are interested in speech recognition phd c: alright , well . grad g: and , they sort of hummed and hawed and said `` well maybe we could have meetings down here `` , but then i got email from them that said `` no , we decided we 're not really interested and we do n't wan na come down and hold meetings . `` so , i think it 's gon na be a problem to get people regularly . phd a: what about joachim , maybe he can professor e: but but we c but i think , you know , we get some scattered things from this and that . and i i d i do think that maybe we can get somewhere with the with the radio . phd c: mm - hmm . professor e: uh i i have better contacts in radio than in television , but phd a: you could get a lot of lively discussions from those radio ones . phd c: well , and they 're already they 're these things are already recorded , grad g: yep . professor e: yeah . phd c: we do n't have to ask them to even and i 'm not sure wh how they record it , but they must record from individual professor e: n well no , i 'm not talking about ones that are already recorded . i 'm talking about new ones phd c: why why not ? professor e: because because because we would be asking them to do something different . phd c: well , we can find out . i know for instance mark liberman was interested uh in in ldc getting data , uh , and professor e: right , that 's the found data idea . phd c: yeah . professor e: but what i 'm saying is uh if i talk to people that i know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike . phd c: mm - hmm . professor e: and u i think routinely they would not do this . so , since i 'm interested in the distant mike stuff , i wan na make sure that there is at least that somewhere phd c: right . great . ok . professor e: and uh but if we ask them to do that they might be intrigued enough by the idea that they uh might be e e willing to the i might be able to talk them into it . phd c: mm - hmm . grad g: um . we 're getting towards the end of our disk space , so we should think about trying to wrap up here . phd c: that 's a good way to end a meeting . professor e: ok . well i do n't why do n't we why d u why do n't we uh uh turn them turn grad g: ok , leave leave them on for a moment until i turn this off , cuz that 's when it crashed last time . postdoc b: oh . that 's good to know . professor e: turning off the microphone made it crash . well postdoc b: that 's good to know . professor e: ok .","output":"to save time , speaker mn005 will only mark the sample of transcribed data for regions of overlapping speech , as opposed to marking all acoustic events . the digits extraction task will be delegated to whomever is working on acoustics for the meeting recorder project ."},{"instruction":"what was said on speech overlap ?","input":"professor e: so . ok . does n't look like it crashed . that 's great . grad g: so i think maybe what 's causing it to crash is i keep starting it and then stopping it to see if it 's working . and so i think starting it and then stopping it and starting it again causes it to crash . so , i wo n't do that anymore . postdoc b: and it looks like you 've found a way of uh mapping the location to the without having people have to give their names each time ? phd a: sounds like an initialization thing . postdoc b: i mean it 's like you have the so you know that grad g: no . postdoc b: i mean , are you going to write down that i sat here ? grad g: i 'm gon na collect the digit forms and write it down . postdoc b: ok . phd c: oh , ok . grad g: so so they should be right with what 's on the digit forms . ok , so i 'll go ahead and start with digits . u and i should say that uh , you just pau you just read each line an and then pause briefly . professor e: and start by giving the transcript number . phd a: tran phd d: transcript uh . ok , ok . phd a: oh sorry , go ahead . professor e: so uh , you see , don , the unbridled excitement of the work that we have on this project . grad h: ok . professor e: it 's just uh grad h: umh . professor e: uh , you know , it does n't seem like a bad idea to have { comment } that information . grad g: and i 'm surprised i sort of i 'm surprised i forgot that , professor e: yeah , i i 'd i think it 's some grad g: but uh i think that would be a good thing to add . after i just printed out a zillion of them . professor e: yeah , well , that 's um , so i i do have a a an agenda suggestion . uh , we i think the things that we talk about in this meeting uh tend to be a mixture of uh procedural uh mundane things and uh research points and um i was thinking i think it was a meeting a couple of weeks ago that we we spent much of the time talking about the mundane stuff cuz that 's easier to get out of the way and then we sort of drifted into the research and maybe five minutes into that andreas had to leave . so uh i 'm suggesting we turn it around and and uh sort of we have anybody has some mundane points that we could send an email later , uh hold them for a bit , and let 's talk about the the research - y kind of things . um , so um the one th one thing i know that we have on that is uh we had talked a a couple weeks before um uh about the uh the stuff you were doing with with uh um uh l l attempting to locate events , we had a little go around trying to figure out what you meant by `` events `` but i think , you know , what we had meant by `` events `` i guess was uh points of overlap between speakers . but i th i gather from our discussion a little earlier today that you also mean uh interruptions with something else phd d: yeah . professor e: like some other noise . phd d: uh - huh . yeah . professor e: yes ? you mean that as an event also . phd d: to professor e: so at any rate you were you 've you 've done some work on that phd d: right . professor e: and um then the other thing would be it might be nice to have a preliminary discussion of some of the other uh research uh areas that uh we 're thinking about doing . um , i think especially since you you have n't been in in these meetings for a little bit , maybe you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , uh and one of the things i know that also came up uh is some discussions that that uh that uh jane had with lokendra uh about some some some um uh work about i i i d i i do n't want to try to say cuz i i 'll say it wrong , but anyway some some potential collaboration there about about the about the working with these data . phd c: oh . sure . professor e: so . so , uh . grad g: you wan na just go around ? professor e: uh . well , i do n't know if we if this is sort of like everybody has something to contribute sort of thing , i think there 's just just a couple a couple people primarily um but um uh , wh why do n't actually i think that that last one i just said we could do fairly quickly so why do n't you you start with that . postdoc b: ok . shall i shall i just start ? ok . professor e: yeah , just explain what it was . postdoc b: um , so , uh , he was interested in the question of you know , relating to his to the research he presented recently , um of inference structures , and uh , the need to build in , um , this this sort of uh mechanism for understanding of language . and he gave the example in his talk about how um , e a i 'm remembering it just off the top of my head right now , but it 's something about how um , i `` joe slipped `` you know , `` john had washed the floor `` or something like that . and i do n't have it quite right , but that kind of thing , where you have to draw the inference that , ok , there 's this time sequence , but also the the the causal aspects of the uh floor and and how it might have been the cause of the fall and that um it was the other person who fell than the one who cleaned it and it { comment } these sorts of things . so , i looked through the transcript that we have so far , { comment } and um , fou identified a couple different types of things of that type and um , one of them was something like uh , during the course of the transcript , um um , w we had gone through the part where everyone said which channel they were on and which device they were on , and um , the question was raised `` well , should we restart the recording at this point ? `` and and dan ellis said , `` well , we 're just so far ahead of the game right now we really do n't need to `` . now , how would you interpret that without a lot of inference ? so , the inferences that are involved are things like , ok , so , how do you interpret `` ahead of the game `` ? you know . so it 's the it 's i what you what you int what you draw you know , the conclusions that you need to draw are that space is involved in recording , grad g: hmm , metaphorically . postdoc b: that um , i that i we have enough space , and he continues , like `` we 're so ahead of the game cuz now we have built - in downsampling `` . so you have to sort of get the idea that um , `` ahead of the game `` is sp speaking with respect to space limitations , that um that in fact downsampling is gaining us enough space , and that therefore we can keep the recording we 've done so far . but there are a lot of different things like that . grad g: so , do you think his interest is in using this as a data source , or training material , or what ? professor e: well , i i should maybe interject to say this started off with a discussion that i had with him , so um we were trying to think of ways that his interests could interact with ours grad g: mm - hmm . professor e: and um uh i thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with jane 's help , look into some of the data that we 're already have and see , is there anything to this at all ? grad g: mm - hmm . professor e: is there any point which you think that , you know , you could gain some advantage and some potential use for it . cuz it could be that you 'd look through it and you say `` well , this is just the wrong task for for him to pursue his `` grad g: wrong , yeah . professor e: and and uh i got the impression from your mail that in fact there was enough things like this just in the little sample that that you looked at that that it 's plausible at least . postdoc b: it 's possible . uh , he was he he you know we met and he was gon na go and uh you know , y look through them more systematically professor e: yeah . postdoc b: and then uh meet again . professor e: yeah . postdoc b: so it 's , you know , not a matter of a professor e: yeah . postdoc b: but , yeah , i think i think it was optimistic . professor e: so anyway , that 's that 's e a quite different thing from anything we 've talked about that , you know , might might might come out from some of this . phd c: but he can use text , basically . i mean , he 's talking about just using text postdoc b: that 's his major i mentioned several that w had to do with implications drawn from intonational contours phd c: pretty much , or ? postdoc b: and that was n't as directly relevant to what he 's doing . he 's interested in these these knowledge structures , phd c: ok . phd d: yeah , interesting . postdoc b: inferences that you draw i from professor e: i mean , he certainly could use text , but we were in fact looking to see if there is there is there something in common between our interest in meetings and his interest in in in this stuff . so . grad g: and i imagine that transcripts of speech i mean text that is speech probably has more of those than sort of prepared writing . i i do n't know whether it would or not , but it seems like it would . professor e: i do n't know , probably de probably depends on what the prepared writing was . but . postdoc b: yeah , i do n't think i would make that leap , because i in narratives , you know i mean , if you spell out everything in a narrative , it can be really tedious , grad g: mm - hmm . postdoc b: so . grad g: yeah , i 'm just thinking , you know , when you 're when you 're face to face , you have a lot of backchannel and and postdoc b: oh . that aspect . grad g: yeah . and so i think it 's just easier to do that sort of broad inference jumping if it 's face to face . i mean , so , if i just read that dan was saying `` we 're ahead of the game `` { comment } in that in that context , postdoc b: well yeah . grad g: i might not realize that he was talking about disk space as opposed to anything else . postdoc b: i you know , i i had several that had to do with backchannels and this was n't one of them . grad g: uh - huh . postdoc b: this this one really does um m make you leap from so he said , you know , `` we 're ahead of the game , w we have built - in downsampling `` . grad g: mm - hmm . postdoc b: and the inference , i if you had it written down , would be grad g: i guess it would be the same . postdoc b: uh - huh . but there are others that have backchannelling , it 's just he was less interested in those . phd f: can i sorry to interrupt . um , i f f f i 've @ @ { comment } d a minute uh , several minutes ago , i , like , briefly was was not listening and so who is `` he `` in this context ? phd c: yeah , there 's a lot of pronoun phd f: ok . so i was just realizing we 've you guys have been talking about `` he `` um for at least uh , i do n't know , three three four minutes without ever mentioning the person 's name again . phd c: i believe it . yeah . actually to make it worse , { comment } uh , morgan uses `` you `` and `` you `` phd f: so this is this is this is gon na be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort . grad g: it 's in my notes . phd c: with gaze and no identification , or i just wrote this down . yeah , actually . cuz morgan will say well , `` you had some ideas `` phd d: yeah . phd f: you just wrote this ? phd c: and he never said li - he looked grad g: well , i think he 's doing that intentionally , phd c: right , so it 's great . grad g: are n't you ? phd c: so this is really great phd f: right . phd c: because the thing is , because he 's looking at the per even for addressees in the conversation , phd d: yeah . phd f: mm - hmm . phd c: i bet you could pick that up in the acoustics . just because your gaze is also correlated with the directionality of your voice . professor e: uh - huh . could be . postdoc b: can we professor e: yeah . that would be tou grad g: oh , that would be interesting . phd c: yeah , so that , i mean , to even know um when phd d: yeah . phd c: yeah , if you have the p z ms you should be able to pick up what a person is looking at from their voice . grad g: well , especially with morgan , with the way we have the microphones arranged . i 'm sort of right on axis and it would be very hard to tell . phd c: right . grad g: uh . postdoc b: oh , but you 'd have the phd c: put morgan always like this postdoc b: you 'd have fainter phd c: and postdoc b: would n't you get fainter reception out here ? professor e: well , these grad g: sure , but i think if i 'm talking like this ? right now i 'm looking at jane and talking , now i 'm looking at chuck and talking , i do n't think the microphones would pick up that difference . phd c: but you do n't have this this problem . postdoc b: i see . phd c: morgan is the one who does this most . grad g: so if i 'm talking at you , or i 'm talking at you . professor e: i probably been affect no , i th i think i 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about `` oh gee is somebody going to say something bad ? `` and so on . grad g: lawyers . professor e: and so i so i 'm i 'm tending to stay away from people 's names even though uh postdoc b: i am too . phd c: even though you could pick up later on , just from the acoustics who you were t who you were looking at . postdoc b: i am too . grad g: and we did mention who `` he `` was . phd c: yeah . professor e: yeah . phd f: right , but i missed it . grad g: early in the conversation . phd f: but it was uh phd c: yeah , yeah . professor e: yeah . grad g: do sh - can i say professor e: yeah . no no , there 's phd f: yeah . grad g: or or is that just too sensitive ? professor e: no no , it is n't sensitive at all . postdoc b: well professor e: i was just i was just i was overreacting just because we 've been talking about it . postdoc b: and in fact , it is it is it is sensitive . phd c: no , but that it 's interesting . professor e: it 's ok to postdoc b: i i came up with something from the human subjects people that i wanted to mention . i mean , it fits into the m area of the mundane , but they did say you know , i asked her very specifically about this clause of how , um , you know , it says `` no individuals will be identified uh , `` in any publication using the data . `` ok , well , individuals being identified , let 's say you have a a snippet that says , `` joe s uh thinks such - and - such about about this field , but i think he 's wrongheaded . `` now i mean , we 're we 're gon na be careful not to have the `` wrongheaded `` part in there , but but you know , let 's say we say , you know , `` joe used to think so - and - so about this area , in his publication he says that but i think he 's changed his mind . `` or whatever . then the issue of of being able to trace joe , because we know he 's well - known in this field , and all this and and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive . professor e: b but i postdoc b: so i think it 's really really kind of adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wan na be able to have to remove ? professor e: yeah , well , there 's that . but i i mean i think also to some extent it 's just educating the human subjects people , in a way , because there 's if uh you know , there 's court transcripts , there 's there 's transcripts of radio shows i mean people say people 's names all the time . so i think it it ca n't be bad to say people 's names . it 's just that i i mean you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of of of slandering anybody , phd c: but , then it wo n't i mean , if we if we professor e: but grad g: it 's not a meeting . phd c: yeah . i mean we should do whatever 's natural in a meeting if if we were n't being recorded . professor e: yeah . right , so i so my behavior is probably not natural . phd c: `` if person x `` professor e: so . postdoc b: well , my feeling on it was that it was n't really important who said it , you know . professor e: yeah . phd f: well , if you ha since you have to um go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark grad g: well , we t we t we talked about this during the anon anonymization . phd f: right . grad g: if we wan na go through and extract from the audio and the written every time someone says a name . and i thought that our conclusion was that we did n't want to do that . professor e: yeah , we really ca n't . but a actually , i 'm sorry . i really would like to push finish this off . postdoc b: i understand . no i just i just was suggesting that it 's not a bad policy p potentially . professor e: so it 's postdoc b: so , we need to talk about this later . professor e: yeah , i di i did n't intend it an a policy though . postdoc b: uh - huh . professor e: it was it was just it was just unconscious well , semi - conscious behavior . i sorta knew i was doing it but it was phd f: well , i still do n't know who `` he `` is . professor e: i i do i do n't remember who `` he `` is . phd c: no , you have to say , you still do n't know who `` he `` is , with that prosody . professor e: ah . uh , we were talking about dan at one point { comment } and we were talking about lokendra at another point . postdoc b: yeah , depends on which one you mean . professor e: and i do n't i do n't remember which which part . phd f: oh . phd c: it 's ambiguous , so it 's ok . professor e: uh , i think grad g: well , the inference structures was lokendra . phd f: but no . the inference stuff was was was lokendra . professor e: yeah . yeah . yeah . phd f: ok . that makes sense , yeah . phd c: and the downsampling must have been dan . professor e: um grad g: yeah . professor e: good yeah . phd c: it 's an inference . professor e: yeah , you could do all these inferences , yeah . grad g: yeah . professor e: yeah . um , i i would like to move it into into uh what jose uh has been doing postdoc b: yeah . professor e: because he 's actually been doing something . phd d: uh - huh . ok . professor e: so . right . phd f: as opposed to the rest of us . phd d: well - { comment } ok . i i remind that me my first objective eh , in the project is to to study difference parameters to to find a a good solution to detect eh , the overlapping zone in eh speech recorded . but eh , tsk , { comment } ehhh { comment } in that way { comment } i i i begin to to study and to analyze the ehn the recorded speech eh the different session to to find and to locate and to mark eh the the different overlapping zone . and eh so eh i was eh i am transcribing the the first session and i i have found eh , eh one thousand acoustic events , eh besides the overlapping zones , eh i i i mean the eh breaths eh aspiration eh , eh , talk eh , eh , clap , eh { comment } i do n't know what is the different names eh you use to to name the the n speech phd a: nonspeech sounds ? phd d: yeah . grad g: oh , i do n't think we 've been doing it at that level of detail . so . phd d: yeah . eh , i i i do i do n't need to to to mmm to m to label the the different acoustic , but i prefer because eh i would like to to study if eh , i i will find eh , eh , a good eh parameters eh to detect overlapping i would like to to to test these parameters eh with the another eh , eh acoustic events , to nnn to eh to find what is the ehm the false eh , the false eh hypothesis eh , nnn , which eh are produced when we use the the ehm this eh parameter eh i mean pitch eh , eh , difference eh , feature grad g: mm - hmm . phd a: you know i think some of these um that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there . grad g: so it was phd d: yeah . phd a: i mean , if it 's a tapping sound , you would n't necessarily or , you know , something like that , it 'd be it might be hard to know that it was two separate events . phd d: yeah . yeah . yeah . yeah . grad g: well you were n't talking about just overlaps phd d: ye grad g: were you ? you were just talking about acoustic events . phd d: i i i i t i t i talk eh about eh acoustic events in general , grad g: someone starts , someone stops yeah . phd a: oh . phd d: but eh my my objective eh will be eh to study eh overlapping zone . grad g: mm - hmm . phd d: eh ? { comment } n eh in twelve minutes i found eh , eh one thousand acoustic events . professor e: how many overlaps were there uh in it ? no no , how many of them were the overlaps of speech , though ? phd d: how many ? eh almost eh three hundred eh in one session grad g: oh , god ! phd d: in five eh in forty - five minutes . phd a: three hundred overlapping speech phd d: alm - three hundred overlapping zone . grad g: ugh . phd c: overlapping speech . phd d: with the overlapping zone , overlapping speech speech what eh different duration . phd a: mm - hmm . professor e: sure . postdoc b: does this ? so if you had an overlap involving three people , how many times was that counted ? phd d: yeah , three people , two people . eh , um i would like to consider eh one people with difference noise eh in the background , be professor e: no no , but i think what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ? phd d: oh . oh . yeah . i consider one event eh for th for that eh for all the zone . this th i i i con i consider i consider eh an acoustic event , the overlapping zone , the period where three speaker or eh are talking together . grad g: well so let 's postdoc b: for grad g: so let 's say me and jane are talking at the same time , and then liz starts talking also over all of us . how many events would that be ? phd d: so - i do n't understand . grad g: so , two people are talking , { comment } and then a third person starts talking . phd d: yeah ? grad g: is there an event right here ? phd d: eh no . no no . for me is the overlapping zone , because because you you have s you have more one eh , more one voice eh , eh produced in a in in a moment . professor e: i see . grad g: so i if two or more people are talking . professor e: ok . yeah . so i think yeah . we just wanted to understand how you 're defining it . phd d: yeah . if professor e: so then , in the region between since there there is some continuous region , in between regions where there is only one person speaking . phd d: uh - huh . professor e: and one contiguous region like that you 're calling an event . phd d: uh - huh . professor e: is it are you calling the beginning or the end of it the event , phd d: yeah . professor e: or are you calling the entire length of it the event ? phd d: i consider the the , nnn the nnn , nnn eh , the entirety eh , eh , all all the time there were the voice has overlapped . professor e: ok . phd d: this is the idea . but eh i i do n't distinguish between the the numbers of eh speaker . uh , i 'm not considering eh the the ehm eh , the fact of eh , eh , for example , what did you say ? eh at first eh , eh two talkers are uh , eh speaking , and eh , eh a third person eh join to to that . for me , it 's eh it 's eh , all overlap zone , with eh several numbers of speakers is eh , eh the same acoustic event . wi - but uh , without any mark between the zone of the overlapping zone with two speakers eh speaking together , and the zone with the three speakers . postdoc b: that would j just be one . phd d: it one . one . postdoc b: ok . phd d: eh , with eh , a beginning mark and the ending mark . because eh for me , is the is the zone with eh some kind of eh distortion the spectral . professor e: got it . phd d: i do n't mind by the moment , by the moment . grad g: well , but but you could imagine that three people talking has a different spectral characteristic than two . phd d: i i do n't yeah , but eh but eh i have to study . { comment } what will happen in a general way , professor e: could . grad g: so . you had to start somewhere . professor e: yeah . we just w phd c: so there 's a lot of overlap . phd d: i i do n't know what eh will will happen with the grad g: yep . phd c: so . grad g: that 's a lot of overlap , phd d: yeah ? professor e: so again , that 's that 's three three hundred in forty - five minutes that are that are speakers , just speakers . grad g: yeah , for forty - five minutes . phd d: yeah . yeah . professor e: uh - huh . ok . yeah . postdoc b: but a a a th professor e: so that 's about eight per minute . postdoc b: but a thousand events in twelve minutes , that 's phd d: yeah , but yeah . phd c: but that can include taps . phd d: but professor e: uh . yeah . postdoc b: well , but a thousand taps in eight minutes is a l in twelve minutes is a lot . phd d: general . phd c: actually phd d: i i con i consider i consider acoustic events eh , the silent too . postdoc b: silent . grad g: silence starting or silence ending phd d: yeah , silent , ground to bec to detect eh because i consider acoustic event all the things are not eh speech . phd c: oh , ok . professor e: mm - hmm . phd a: oh . phd d: in ge in in in a general point of view . phd c: oh . professor e: ok , so how many of those thousand were silence ? phd c: alright . phd d: in the per phd f: not speech not speech or too much speech . phd d: too much speech . professor e: right . so how many of those thousand were silence , silent sections ? phd d: yeah . uh silent , i i i i do n't i i have n't the eh i i would like to to do a stylistic study professor e: yeah . phd d: and give you eh with the report eh from eh the the study from the the the session one session . professor e: yeah . yeah . phd d: and i i found that eh another thing . when eh eh i w i i was eh look at eh nnn , the difference speech file , um , for example , eh if eh we use the ehm the mixed file , to to transcribe , the the events and the words , i i saw that eh the eh speech signal , collected by the eh this kind of mike eh of this kind of mike , eh are different from the eh mixed signal eh , we eh collected by headphone . grad g: yep . phd d: and it 's right . professor e: yeah . grad g: right . phd d: but the problem is the following . the the the i i i knew that eh the signal eh , eh would be different , but eh the the problem is eh , eh we eh detected eh difference events in the speech file eh collected by by that mike uh qui compared with the mixed file . and so if when you transcribe eh only eh using the nnn the mixed file , it 's possible eh if you use the transcription to evaluate a different system , it 's possible you eh in the eh i and you use the eh speech file collected by the eh fet mike , to eh to nnn to do the experiments with the the system , professor e: mm - hmm . grad g: right . phd d: its possible to evaluate eh , eh or to consider eh acoustic events that which you marked eh in the mixed file , but eh they do n't appear in the eh speech signal eh collected by the by the mike . grad g: right . the the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . phd d: yeah . yeah . oh , it 's a good idea . it 's a good idea i think . grad g: so i agree that if someone wants to do speech event transcription , that the mixed signals here phd d: yeah . grad g: i mean , if i 'm tapping on the table , you it 's not gon na show up on any of the mikes , but it 's gon na show up rather loudly in the pzm . phd d: yeah . yeah . yeah . so and i i i say eh that eh , eh , or this eh only because eh i c i i in my opinion , it 's necessary to eh to eh to put the transcription on the speech file , collected by the objective signal . grad g: so . phd d: i mean the the the signal collected by the eh , the real mike in the future , in the prototype to to eh correct the initial eh segmentation eh with the eh real speech professor e: mm - hmm . the the the far - field , yeah . phd d: you have to to analyze you have to to process . because i i found a difference . professor e: yeah , well , just i mean , just in that that one s ten second , or whatever it was , example that adam had that that we we passed on to others a few months ago , there was that business where i g i guess it was adam and jane were talking at the same time and and uh , in the close - talking mikes you could n't hear the overlap , and in the distant mike you could . so yeah , it 's clear that if you wan na study if you wan na find all the places where there were overlap , it 's probably better to use a distant mike . phd f: that 's good . professor e: on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes , phd d: yeah . phd c: but why ca n't you use the combination of the close - talking mikes , time aligned ? professor e: so it 's grad g: if you use the combination of the close - talking mikes , you would hear jane interrupting me , but you would n't hear the paper rustling . and so if you 're interested in phd c: i i mean if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem , professor e: some { comment } of it 's masking masked . phd d: yeah . phd a: were you interrupting him or was he interrupting you ? professor e: right . phd c: right ? grad g: right . phd d: yeah . grad g: although the other issue is that the mixed close - talking mikes i mean , i 'm doing weird normalizations and things like that . phd c: but it 's known . phd d: yeah . phd c: i mean , the normalization you do is over the whole conversation grad g: yep . phd c: is n't it , over the whole meeting . grad g: right . yep . phd c: so if you wanted to study people overlapping people , that 's not a problem . phd d: i i i think eh i saw the nnn the eh but eh i eh i have eh any results . i i i saw the the speech file collected by eh the fet mike , and eh eh signal eh to eh to noise eh relation is eh low . it 's low . professor e: mm - hmm . phd d: it 's very low . you would comp if we compare it with eh the headphone . grad g: yep . phd d: and i i found that nnn that eh , ehm , pr probably , grad g: did did you phd d: i 'm not sure eh by the moment , but it 's it 's probably that eh a lot of eh , eh for example , in the overlapping zone , on eh in in several eh parts of the files where you you can find eh , eh eh , smooth eh eh speech eh from eh one eh eh talker in the in the meeting , professor e: mm - hmm . mm - hmm . phd d: it 's probably in in that eh in in those files you you can not find you can not process because eh it 's confused with with noise . professor e: mm - hmm . phd d: and there are a lot of i think . but i have to study with more detail . but eh my idea is to to process only nnn , this eh nnn , this kind of s of eh speech . because i think it 's more realistic . i 'm not sure it 's a good idea , but eh professor e: no i grad g: well , it 's more realistic but it 'll it 'll be a lot harder . phd d: yeah . professor e: well , it 'd be hard , but on the other hand as you point out , if your if i if if your concern is to get uh the overlapping people people 's speech , you will you will get that somewhat better . phd d: mm - hmm . yeah . professor e: um , are you making any use uh you were you were working with th the data that had already been transcribed . phd d: with by jane . professor e: does it uh yes . phd d: yeah . professor e: now um did you make any use of that ? see i was wondering cuz we st we have these ten hours of other stuff that is not yet transcribed . phd d: yeah . yeah . professor e: do you phd d: the the transcription by jane , t eh i eh , i i i want to use to to nnn , eh to put i i it 's a reference for me . but eh the transcription eh for example , i i do n't i i 'm not interested in the in the in the words , transcription words , eh transcribed eh eh in eh follow in the in the in the speech file , but eh eh jane eh for example eh put a mark eh at the beginning eh of each eh talker , in the in the meeting , um eh she she nnn includes information about the zone where eh there are eh there is an overlapping zone . but eh there is n't any any mark , time temporal mark , to to c eh to mmm e - heh , to label { comment } the beginning and the end of the of the professor e: mm - hmm . ok . right , so she is phd d: ta i 'm i i i think eh we need this information to professor e: right . so the twelve you you it took you twelve hours of course this included maybe some some time where you were learning about what what you wanted to do , but but uh , it took you something like twelve hours to mark the forty - five minutes , your grad g: twelve minutes . phd d: twelve minutes . professor e: s twelve minutes ! phd d: twelve minutes . twelve . professor e: i thought you did forty - five minutes of phd d: no , forty - five minutes is the is the session , all the session . postdoc b: oh . professor e: oh , you have n't done the whole session . phd d: yeah , all is the the session . professor e: this is just twelve minutes . phd d: tw - twelve hours of work to to segment eh and label eh twelve minutes from a session of part of f professor e: oh . so { comment } let me back up again . so the when you said there were three hundred speaker overlaps , phd d: yeah . professor e: that 's in twelve minutes ? phd d: no no no . i i consider all the all the session because eh i i count the nnn the nnn the overlappings marked by by jane , professor e: oh , ok . postdoc b: oh , i see . phd d: in in in in the fin in in the forty - five minutes . professor e: ok . so it 's three hundred in forty - five minutes , but you have you have time uh , uh marked twelve minute the the the um overlaps in twelve minutes of it . phd d: yeah . professor e: got it . phd f: so , can i ask can i ask whether you found uh , you know , how accurate uh jane 's uh uh labels were as far as grad g: well , not just the overlaps , everything . phd f: you know , did she miss some overlaps ? or did she n ? phd d: but , by by the moment , i i do n't compare , my my temporal mark with eh jane , but eh i i want to do it . because eh eh i per perhaps i have eh errors in the in the marks , i and if i i compare with eh jane , it 's probably i i i can correct and and and to get eh eh a more accurately eh eh transcription in the file . professor e: yeah . grad g: well , also jane jane was doing word level . phd d: yeah . professor e: yeah . grad g: so we were n't concerned with { comment } exactly when an overlap started and stopped . phd f: right . right . phd c: well , not only a word level , but actually phd d: well phd f: i 'm expect i 'm not expecting phd d: no , it 's phd c: i mean , you did n't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or grad g: right . professor e: mm - hmm . grad g: yep . postdoc b: well phd d: yeah . yeah . postdoc b: well , yeah , b yeah , i would say time bin . so my my goal is to get words with reference to a time bin , beginning and end point . phd c: yeah . phd d: yeah . phd c: right . phd d: yeah . postdoc b: and and sometimes , you know , it was like you could have an overlap where someone said something in the middle , phd d: yeah . postdoc b: but , yeah , w it just was n't important for our purposes to have it that i disrupt that unit in order to have , you know , a the words in the order in which they were spoken , it would have it would have been hard with the interface that we have . phd d: yeah . postdoc b: now , my a adam 's working on a of course , on a revised overlapping interface , phd d: uh - huh . grad g: right . phd d: i i i think it 's it 's a good eh work , postdoc b: but phd d: but eh i think we need eh eh more information . phd f: no , of course . postdoc b: yeah . phd f: i expect you to find more overlaps than than jane grad g: always need more for postdoc b: yeah . phd d: no , no . i i have to go to phd f: because you 're looking at it at a much more detailed level . phd d: i want eh i wanted to eh compare the the transcription . professor e: i have grad g: but if it takes sixty to one professor e: well , i but i have a suggestion about that . um , obviously this is very , very time - consuming , and you 're finding lots of things which i 'm sure are gon na be very interesting , but in the interests of making progress , uh might i s how how would it affect your time if you only marked speaker overlaps ? phd d: only . professor e: yes . phd d: yeah . professor e: do not mark any other events , phd d: uh - huh . professor e: but only mark speaker do you think that would speed it up quite a bit ? phd d: ok . ok . i i i i w i i wanted to professor e: do y do you think that would speed it up ? uh , speed up your your your marking ? phd d: nnn , i do n't understand very . professor e: it took you a long time to mark twelve minutes . phd d: yeah . oh , yeah , yeah . professor e: now , my suggestion was for the other thirty - three phd d: on - only to mark only to mark overlapping zone , but professor e: yeah , and my question is , if you did that , if you followed my suggestion , would it take much less time ? phd d: oh , yeah . sure . professor e: yeah ok . phd d: yeah sure . professor e: then i think it 's a good idea . phd d: sure sure . professor e: then i think it 's a good idea , because it phd d: sure , because i i need a lot of time to to put the label or to do that . yeah . professor e: yeah , i mean , we we know that there 's noise . grad g: and phd d: uh - huh . professor e: there 's there 's uh continual noise uh from fans and so forth , and there is uh more impulsive noise from uh taps and so forth phd d: yeah . professor e: and and something in between with paper rustling . we know that all that 's there and it 's a g worthwhile thing to study , but obviously it takes a lot of time to mark all of these things . phd d: yeah . professor e: whereas th i i would think that uh you we can study more or less as a distinct phenomenon the overlapping of people talking . phd d: uh - huh . ok . ok . professor e: so . then you can get the cuz you need if it 's three hundred uh i i it sounds like you probably only have fifty or sixty or seventy events right now that are really phd d: yeah . professor e: and and you need to have a lot more than that to have any kind of uh even visual sense of of what 's going on , much less any kind of reasonable statistics . grad g: right . phd c: now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the grad g: well , that 's that 's what i was gon na bring up . phd c: i mean , you should n't need to do this p completely by hand , professor e: um , ok , yeah . so let 's back up because you were n't here for an earlier conversation . phd c: right ? i 'm sorry . professor e: so the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as i mean there 's a bunch of things i mean , increased energy is - is sort of an obvious one . phd c: mm - hmm . in the far - field mike . professor e: yeah . phd c: oh , ok . professor e: um , and uh , it 's not obvious , i mean , you could you could do the dumbest thing and get get it ninety percent of the time . but when you start going past that and trying to do better , it 's not obvious what combination of features is gon na give you the you know , the right detector . so the idea is to have some ground truth first . and so the i the idea of the manual marking was to say `` ok this , i you know , it 's it 's really here `` . phd a: but i think liz is saying why not get it out of the transcripts ? phd c: what i mean is get it from the close - talking mikes . professor e: uh , yeah . phd c: a or ge get a first pass from those , professor e: we t we t w we t we talked about that . phd c: and then go through sort of it 'd be a lot faster probably to phd f: and you can grad g: yeah , that 's his , uh professor e: we we we talked about that . s but so it 's a bootstrapping thing and the thing is , phd c: yeah , i just professor e: the idea was , i we i i we thought it would be useful for him to look at the data anyway , and and then whatever he could mark would be helpful , phd c: right . professor e: and we could uh it 's a question of what you bootstrap from . you know , do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then then do your simple measurements , uh from the close - talking mike . i mean , even with the close - talking mike you 're not gon na get it right all the time . phd c: well , that 's what i wonder , because um or how bad it is , professor e: well phd c: be um , because that would be interesting grad g: i 'm working on a program to do that , and phd c: especially because the bottleneck is the transcription . right ? i mean , we 've got a lot more data than we have transcriptions for . we have the audio data , we have the close - talking mike , professor e: yeah . phd c: so i mean it seems like one kind of project that 's not perfect , but um , that you can get the training data for pretty quickly is , you know , if you infer form the close - talking mikes where the on - off points are of speech , professor e: right , we discussed that . phd c: you know , how can we detect that from a far - field ? grad g: and postdoc b: oh . grad g: i 've i 've written a program to do that , phd c: ok , i 'm sorry i missed the grad g: and it , uh professor e: it 's ok . grad g: and so but it 's it 's doing something very , very simple . it just takes a threshold , based on on the volume , phd c: uh - huh . phd f: or you can set the threshold low and then weed out the false alarms by hand . phd c: right , by hand . yeah . phd f: yeah . grad g: um , and then it does a median filter , and then it looks for runs . and , it seems to work , i 've i 'm sort of fiddling with the parameters , to get it to actually generate something , and i have n't i do n't what i 'm working on was working on was getting it to a form where we can import it into the user interface that we have , into transcriber . and so i told i said it would take about a day . i 've worked on it for about half a day , grad h: i have to go . grad g: so give me another half day and i we 'll have something we can play with . phd c: ok . professor e: see , this is where we really need the meeting recorder query stuff to be working , because we 've had these meetings and we 've had this discussion about this , and i 'm sort of remembering a little bit about what we decided , phd c: right . i 'm sorry . i just professor e: but i could n't remember all of it . phd c: it professor e: so , i think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when when he he gets his thing going , grad g: but professor e: uh , and phd c: well , it 's definitely good to have somebody look at it . i was just thinking as a way to speed up you know , the amount of postdoc b: mm - hmm . professor e: that was that was exactly the notion that that that we discussed . phd c: ok . grad g: thanks . postdoc b: another thing we discussed was um that phd c: it looks good . professor e: so . phd c: i 'll be in touch . thanks . professor e: s see ya . yeah . postdoc b: was that um there m there was this already a script i believe uh that dan had written , { comment } that uh handle bleedthrough , i mean cuz you have this this close you have contamination from other people who speak loudly . grad g: yeah , and i have n't tried using that . it would probably help the program that i 'm doing to first feed it through that . it 's a cross - correlation filter . so i i have n't tried that , but that if it it might be something it might be a good way of cleaning it up a little . postdoc b: so , some thought of maybe having yeah , having that be a preprocessor and then run it through yours . grad g: exactly . yep . professor e: but but that 's a refinement postdoc b: that 's what we were discussing . professor e: and i think we wan na see try the simple thing first , cuz you add this complex thing up uh afterwards that does something good y y yo you sort of wan na see what the simple thing does first . grad g: yep . professor e: but uh , having having somebody have some experience , again , with with uh with marking it from a human standpoint , we 're i mean , i do n't expect jose to to do it for uh f fifty hours of { comment } of speech , but i mean we { comment } if uh if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it . phd d: yeah . sure . sure . professor e: and when when uh adam was doing his automatic thing he could then compare to that and see what it was different . phd c: oh yeah , definitely . phd a: you know , i did i did uh something almost identical to this at one of my previous jobs , and it works pretty well . i mean , i almost exactly what you described , an energy detector with a median filter , you look for runs . and uh , you know , you can grad g: it seemed like the right thing to do . phd a: yeah . i mean , you you can get y i mean , you get them pretty close . grad g: that was with zero literature search . phd a: and so i think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to to do it . grad g: that 's good validation . phd a: yeah . postdoc b: is this proprietary ? phd a: uh . { comment } no . no . grad g: yeah , do you have a patent on it ? phd a: it was when i was working for the government . professor e: oh , then everybody owns it . it 's the people . postdoc b: well , i mean , is this something that we could just co - opt , or is it ? phd a: nah . postdoc b: no . ok . professor e: well , i i i he 's pretty close , anyway . i think i think it 's phd a: yeah , he 's it it does n't take a long time . postdoc b: right . i just thought if it was tried and true , then { comment } and he 's gone through additional levels of of development . grad g: just output . although if you if you have some parameters like what 's a good window size for the median filter phd a: oh ! { comment } i have to remember . i 'll think about it , and try to remember . phd f: and it might be different for government people . grad g: that 's alright . professor e: yeah , good enough for government work , as they say . phd c: they they phd a: di - dif different different bandwidth . phd f: they grad g: i was doing pretty short , you know , tenth of a second , { comment } sorts of numbers . phd f: ok . professor e: uh , i do n't know , it if if we want to uh so , uh , maybe we should move on to other other things in limited time . postdoc b: can i ask one question about his statistics ? so so in the tw twelve minutes , um , if we took three hundred and divided it by four , which is about the length of twelve minutes , i um , i 'd expect like there should be seventy - five overlaps . professor e: yeah . postdoc b: did you find uh more than seventy - five overlaps in that period , or ? phd d: more than ? postdoc b: more than how many overlaps in your twelve minutes ? phd d: how many ? eh , not @ @ i onl - only i i transcribe eh only twelve minutes from the professor e: yeah . phd d: but eh i i do n't co eh i do n't count eh the the overlap . postdoc b: the overlaps . ok . phd d: i consider i i the the nnn the the three hundred is eh considered only you your transcription . i have to to finish transcribing . so . grad g: i b i bet they 're more , because the beginning of the meeting had a lot more overlaps than than sort of the middle . phd d: yeah . grad g: middle or end . postdoc b: i 'm not sure . phd d: yeah . grad g: because i we 're we 're dealing with the uh , in the early meetings , we 're recording while we 're saying who 's talking on what microphone , { comment } and things like that , phd d: yeah . grad g: and that seems to be a lot of overlap . postdoc b: i think it 's an empirical question . phd d: yeah . postdoc b: i think we could find that out . phd d: yeah . grad g: yep . postdoc b: i 'm i 'm not sure that the beginning had more . professor e: so so i was gon na ask , i guess about any any other things that that that either of you wanted to talk about , especially since andreas is leaving in five minutes , that that you wan na go with . phd c: can i just ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz i 'm i wanted to get a feel for that to sort of be able to know what what can be done first and like how many meetings are we recording professor e: right so there 's this this there 's this forty - five minute piece that jane transcribed . phd c: and professor e: that piece was then uh sent to ibm so they could transcribe so we have some comparison point . then there 's s a larger piece that 's been recorded and uh put on cd - rom and sent uh to ibm . right ? and then we do n't know . phd c: how many meetings is that ? like how many grad g: what 's that ? professor e: that was about ten hours , and there was about phd c: t ten it 's like ten meetings or something ? uh - huh . grad g: yeah , something like that . and then then we phd a: ten meetings that have been sent to ibm ? phd c: and professor e: yeah . grad g: well , i have n't sent them yet because i was having this problem with the missing files . professor e: oh . oh , that 's right , that had those have not been sent . phd a: h how many total have we recorded now , altogether ? professor e: we 're saying about twelve hours . grad g: about twelve by now . twelve or thirteen . phd c: uh - huh . and we 're recording only this meeting , like continuously we 're only recording this one now ? or ? professor e: no . no , so the the that 's the that 's the biggest one uh , chunk so far , grad g: nope . phd a: it was the morning one . phd c: ok . professor e: but there 's at least one meeting recorded of uh the uh uh natural language guys . grad g: jerry . phd c: do they meet every week , professor e: and then there phd c: or every professor e: uh , they do . w w and we talked to them about recording some more and we 're going to , uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded , phd c: great . professor e: and we 're gon na start recording them . they 're they meet on tuesdays . we 're gon na start recording them next week . so actually , we 're gon na h start having a a pretty significant chunk and so , you know , adam 's sort of struggling with trying to get things to be less buggy , and come up quicker when they do crash and stuff things like that , now that uh the things are starting to happen . so right now , yeah , i th i 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that that amount is gon na grow uh so that the meeting meetings will probably ultimately i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , you know , twenty or thirty percent of it , not not not eighty or ninety . but . phd c: so there 's probably there 's three to four a week , grad g: that 's what we 're aiming for . phd c: that we 're aiming for . professor e: yeah . phd c: and they 're each about an hour or something . professor e: yeah , yeah . grad g: although yeah . we 'll find out tomorrow whether we can really do this or not . phd c: so ok . professor e: yeah and th the the other thing is i 'm not pos i 'm sort of thinking as we 've been through this a few times , that i really do n't know maybe you wan na do it once for the novelty , but i do n't know if in general we wan na have meetings that we record from outside this group do the digits . grad g: right . professor e: because it 's just an added bunch of weird stuff . phd c: yeah . professor e: and , you know , we we h we 're highly motivated . uh in fact , the morning group is really motivated cuz they 're working on connected digits , so it 's grad g: actually that 's something i wanted to ask , is i have a bunch of scripts to help with the transcription of the digits . professor e: yeah . grad g: we do n't have to hand - transcribe the digits because we 're reading them and i have those . phd c: right . professor e: yeah . grad g: and so i have some scripts that let you very quickly extract the sections of each utterance . but i have n't been ru i have n't been doing that . um , if i did that , is someone gon na be working on it ? professor e: uh , yeah , i i think definitely s so absolutely . grad g: i mean , is it something of interest ? professor e: yeah , whoever we have working on the acoustics for the meeting recorder are gon na start with that . grad g: ok . i mean , i i 'm i 'm interested in it , i just do n't have time to do it now . phd f: i was these meetings i 'm sure someone thought of this , but these this uh reading of the numbers would be extremely helpful to do um adaptation . grad g: so phd f: um . grad g: yep . yep . phd c: actually i have o grad g: i i would really like someone to do adaptation . phd f: mm - hmm . grad g: so if we got someone interested in that , i think it would be great for meeting recorder . professor e: well i mean , one of the things i wanted to do , uh , that i i talked to to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , grad g: since it 's the same people over and over . phd f: mm - hmm . professor e: to try to get rid of some of the effects of the the the far - field effects . um , i mean we have the party line has been that echo cancellation is not the right way to handle the situation phd f: mm - hmm . professor e: because people move around , and uh , if if it 's if it 's uh not a simple echo , like a cross - talk kind of echo , but it 's actually room acoustics , it 's it 's it 's you ca n't really do inversion , phd f: mm - hmm . professor e: and even echo cancellation is going to uh be something it may you someone may be moving enough that you are not able to adapt quickly and so the tack that we 've taken is more `` lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal `` . phd f: mm - hmm . professor e: uh , that 's the party line . but it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous . it 's good good to sort of test them , actually . and so we have n't had anybody try to do a good serious job on echo cancellation and we should know how well that can do . so that 's something i 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . um , there was a have been some nice talks recently by by lucent on on their b phd f: hmm . professor e: the block echo cancellation particularly appealed to me , uh you know , trying and change it sample by sample , but you have some reasonable sized blocks . { comment } and um , you know , th phd a: w what is the um the artifact you try to you 're trying to get rid of when you do that ? phd f: ciao . professor e: uh so it 's it you have a a direct uh uh , what 's the difference in if you were trying to construct a linear filter , that would um phd f: i 'm signing off . professor e: yeah . that would subtract off { comment } the um uh parts of the signal that were the aspects of the signal that were different between the close - talk and the distant . you know , so so uh um i guess in most echo cancellation yeah , so you given that um yeah , so you 're trying to so you 'd there 's a a distance between the close and the distant mikes so there 's a time delay there , and after the time delay , there 's these various reflections . and if you figure out well what 's the there 's a a least squares algorithm that adjusts itself adjusts the weight so that you try to subtract essentially to subtract off uh different uh different reflections . right ? so let 's take the simple case where you just had you had some uh some delay in a satellite connection or something and then there 's a there 's an echo . it comes back . and you want to adjust this filter so that it will maximally reduce the effect of this echo . phd a: so that would mean like if you were listening to the data that was recorded on one of those . uh , just the raw data , you would you might hear kind of an echo ? and and then this noise cancellation would get professor e: well , i 'm i 'm i 'm saying that 's a simplified version of what 's really happening . { comment } what 's really happening is well , when i 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , uh , the indirect sound that 's bounced around the room a number of times . ok ? so now , if you um try to r you to completely remove the effect of that is sort of impractical for a number of technical reasons , but i but not to try to completely remove it , that is , invert the the room response , but just to try to uh uh eliminate some of the the effect of some of the echos . um , a number of people have done this so that , say , if you 're talking to a speakerphone , uh it makes it more like it would be , if you were talking right up to it . so this is sort of the st the straight - forward approach . you say i i i want to use this uh this item but i want to subtract off various kinds of echos . so you construct a filter , and you have this this filtered version uh of the speech um gets uh uh gets subtracted off from the original speech . then you try to you try to minimize the energy in some sense . and so um uh with some constraints . phd a: kind of a clean up thing , that professor e: it 's a clean up thing . right . phd a: ok . professor e: so , echo cancelling is is , you know , commonly done in telephony , and and and it 's sort of the obvious thing to do in this situation if you if , you know , you 're gon na be talking some distance from a mike . phd a: when uh , i would have meetings with the folks in cambridge when i was at bbn over the phone , they had a um some kind of a special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . and then it was uh and then it would come on and it was very clear , professor e: yeah . phd a: you know . professor e: right . so it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . so um , uh anyway that 's that 's kind of a reasonable thing that i 'd like to have somebody try somebody look and and the digits would be a reasonable thing to do that with . i think that 'd be enough data plenty of data to do that with , and i for that sort of task you would n't care whether it was uh large vocabulary speech or anything . uh . um postdoc b: is brian kingsbury 's work related to that , or is it a different type of reverberation ? professor e: brian 's { comment } kingsbury 's work is an example of what we did f f from the opposite dogma . right ? which is what i was calling the `` party line `` , which is that uh doing that sort of thing is not really what we want . we want something more flexible , uh i i where people might change their position , and there might be , you know there 's also um oh yeah , noise . so the echo cancellation does not really allow for noise . it 's if you have a clean situation but you just have some delays , then we 'll figure out the right the right set of weights for your taps for your filter in order to produce the effect of those those echos . but um if there 's noise , then the very signal that it 's looking at is corrupted so that it 's decision about what the right you know , right right uh delays are is , uh is right delayed signal is is is uh is incorrect . and so , in a noisy situation , um , also in a in a situation that 's very reverberant { comment } with long reverberation times { comment } and really long delays , it 's it 's sort of typically impractical . so for those kind of reasons , and also a a c a complete inversion , if you actually i mentioned that it 's kind of hard to really do the inversion of the room acoustics . um , that 's difficult because um often times the the um the system transfer function is such that when it 's inverted you get something that 's unstable , and so , if you you do your estimate of what the system is , and then you try to invert it , you get a filter that actually uh , you know , rings , and and uh goes to infinity . so it 's so there 's there 's there 's that sort of technical reason , and the fact that things move , and there 's air currents i mean there 's all sorts of all sorts of reasons why it 's not really practical . so for all those kinds of reasons , uh we we we sort of um , concluded we did n't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which is n't really inversion , and um we decided to do this approach of taking uh , just picking uh features , which were uh will give you more something that was more stable , in the presence of , or absence of , room reverberation , and that 's what brian was trying to do . so , um , let me just say a couple things that i was i was gon na bring up . uh . let 's see . i guess you you actually already said this thing about the uh about the consent forms , which was that we now do n't have to so this was the human subjects folks who said this , { comment } or that that ? postdoc b: the a apparently i mean , we 're gon na do a revised form , of course . um but once a person has signed it once , then that 's valid for a certain number of meetings . she wanted me to actually estimate how many meetings and put that on the consent form . i told her that would be a little bit difficult to say . so i think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something . it wo n't be that many people who do it that often , but um just , you know , so long as they do n't forget that they 've done it , i guess . professor e: ok . um , back on the data thing , so there 's this sort of one hour , ten hour , a hundred hour sort of thing that that we have . we have we have an hour uh that that is transcribed , we have we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , uh by the end of the semester we 'll have , i do n't know , forty or fifty or something , if we if this really uh well , do we have that much ? phd c: not really . it 's three to four per week . professor e: let 's see , we have phd c: so that 's what you know , that professor e: uh eight weeks , uh is phd c: so that 's not a lot of hours . professor e: eight weeks times three hours is twenty - four , so that 's yeah , so like thirty thirty hours ? phd a: three three hours . phd c: yeah . i mean , is there i know this sounds tough but we 've got the room set up . um i was starting to think of some projects where you would use well , similar to what we talked about with uh energy detection on the close - talking mikes . there are a number of interesting questions that you can ask about how interactions happen in a meeting , that do n't require any transcription . so what are the patterns , the energy patterns over the meeting ? and i 'm really interested in this but we do n't have a whole lot of data . so i was thinking , you know , we 've got the room set up and you can always think of , also for political reasons , if icsi collected you know , two hundred hours , that looks different than forty hours , even if we do n't transcribe it ourselves , professor e: but i do n't think we 're gon na stop at the end of this semester . phd c: so professor e: right ? so , i th i think that if we are able to keep that up for a few months , we are gon na have more like a hundred hours . phd c: i mean , is there are there any other meetings here that we can record , especially meetings that have some kind of conflict in them { comment } or some kind of deci i mean , that are less well i do n't uh , that have some more emotional aspects to them , or strong grad g: we had some good ones earlier . phd c: there 's laughter , um i 'm talking more about strong differences of opinion meetings , maybe with manager types , or grad g: i think it 's hard to record those . phd c: to be allowed to record them ? postdoc b: it 's also likely that people will cancel out afterwards . phd c: ok . professor e: yeah , people will get postdoc b: but i but i wanted to raise the kpfa idea . phd c: ok . well , if there is , anyway . professor e: yeah , i was gon na mention that . grad g: oh , that 's a good idea . that 's that would be a good match . professor e: yeah . so yeah . so i i uh , i i 'd mentioned to adam , and that was another thing i was gon na talk uh , mention to them before { comment } that uh there 's uh it it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media . because , you know , we had talked before about the problem about using found data , { comment } that that uh it 's just set up however they have it set up and we do n't have any say about it and it 's typically one microphone , in a , uh , uh or and and so it does n't really give us the the the uh characteristics we want . um and so i do think we 're gon na continue recording here and record what we can . but um , it did occur to me that we could go to friends in broadcast media and say `` hey you have this panel show , or this you know , this discussion show , and um can you record multi - channel ? `` and uh they may be willing to record it uh with phd c: with lapel mikes or something ? professor e: well , they probably already use lapel , but they might be able to have it it would n't be that weird for them to have another mike that was somewhat distant . phd c: right . professor e: it would n't be exactly this setup , but it would be that sort of thing , and what we were gon na get from uw , you know , assuming they they they start recording , is n't als also is not going to be this exact setup . phd c: right . no , i think that 'd be great , if we can get more data . professor e: so , { comment } i i i i was thinking of looking into that . the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , { comment } uh that we could invite them to have like some of their { comment } record some of their shows here . postdoc b: wow ! phd c: well or the thing is , they 're not as averse to wearing one of these head - mount i mean , they 're on the radio , grad g: right , as we are . phd c: right ? so . { comment } um , i think that 'd be fantastic professor e: right . phd c: cuz those kinds of panels and those have interesting professor e: yeah . phd c: th - that 's an a side of style a style that we 're not collecting here , so it 'd be great . professor e: and and the i mean , the other side to it was the what which is where we were coming from i 'll i 'll talk to you more about it later { comment } is that is that there 's there 's uh the radio stations and television stations already have stuff worked out presumably , uh related to , you know , legal issues and and permissions and all that . i mean , they already do what they do do whatever they do . so it 's uh , it 's so it 's so it 's another source . so i think it 's something we should look into , you know , we 'll collect what we collect here hopefully they will collect more at uw also and um and maybe we have this other source . but yeah i think that it 's not unreasonable to aim at getting , you know , significantly in excess of a hundred hours . i mean , that was sort of our goal . the thing was , i was hoping that we could @ @ in the under this controlled situation we could at least collect , you know , thirty to fifty hours . and at the rate we 're going we 'll get pretty close to that i think this semester . and if we continue to collect some next semester , i think we should , uh phd c: right . yeah i was mostly trying to think , `` ok , if you start a project , within say a month , you know , how much data do you have to work with . and you you wan na s you wan na sort of fr freeze your your data for awhile so um right now and we do n't have the transcripts back yet from ibm right ? do oh , do we now ? professor e: well , we do n't even have it for this f you know , forty - five minutes , that was phd c: so um , not complaining , i was just trying to think , you know , what kinds of projects can you do now versus uh six months from now professor e: yeah . phd c: and they 're pretty different , because professor e: yeah . so i was thinking right now it 's sort of this exploratory stuff where you you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like , grad g: right . phd c: um right . right , right . professor e: and and and uh and meanwhile we collect , and it 's more like yeah , three months from now , or six months from now you can you can do a lot of other things . phd c: cuz i 'm not actually sure , just logistically that i can spend you know , i do n't wan na charge the time that i have on the project too early , before there 's enough data to make good use of the time . and that 's and especially with the student grad g: right . phd c: uh for instance this guy who seems professor e: yeah . phd c: uh anyway , i should n't say too much , but um if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will i have to work with , with that person . and so it 's professor e: i yeah , so i would think , exploratory things now . uh , three months from now um , i mean the transcriptions i think are a bit of an unknown cuz we have n't gotten those back yet as far as the timing , but i think as far as the collection , it does n't seem to me l like , uh , unreasonable to say that uh in january , you know , ro roughly uh which is roughly three months from now , we should have at least something like , you know , twenty - five , thirty hours . phd c: and we just do n't know about the transcription part of that , professor e: so that 's postdoc b: yeah , we need to i think that there 's a possibility that the transcript will need to be adjusted afterwards , phd c: so . i mean , it postdoc b: and uh es especially since these people wo n't be uh used to dealing with multi - channel uh transcriptions . phd c: right . professor e: yeah . postdoc b: so i think that we 'll need to adjust some and also if we wan na add things like um , well , more refined coding of overlaps , then definitely i think we should count on having an extra pass through . i wanted to ask another a a aspect of the data collection . there 'd be no reason why a person could n't get together several uh , you know , friends , and come and argue about a topic if they wanted to , right ? professor e: if they really have something they wan na talk about as opposed to something @ @ i mean , what we 're trying to stay away from was artificial constructions , but i think if it 's a real why not ? yeah . phd c: i mean , i 'm thinking , politically grad g: stage some political debates . postdoc b: you could do this , phd c: well yeah , postdoc b: you know . you could . phd c: or just if you 're if you ha if there are meetings here that happen that we can record even if we do n't um have them do the digits , { comment } or maybe have them do a shorter digit thing { comment } like if it was , you know , uh , one string of digits , or something , they 'd probably be willing to do . grad g: we do n't have to do the digits at all if we do n't want to . phd c: then , having the data is very valuable , cuz i think it 's um politically better for us to say we have this many hours of audio data , especially with the itr , if we put in a proposal on it . it 'll just look like icsi 's collected a lot more audio data . um , whether it 's transcribed or not um , is another issue , but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer . postdoc b: it seems like you could hold some meetings . grad g: yep . postdoc b: you know , you and maybe adam ? phd c: so . postdoc b: you you could you could maybe hold some additional meetings , if you wanted . phd a: would it help at all i mean , we 're already talking about sort of two levels of detail in meetings . one is uh um without doing the digits or , i guess the full - blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted stuff . phd c: need the close - talking mikes . phd a: you do , ok . phd c: i mean , absolutely , professor e: yeah . yeah . phd c: yeah . i 'm really scared grad g: it seems like it 's a big part of this corpus is to have the close - talking mikes . phd a: i see , ok . phd c: um or at least , like , me personally ? i would { comment } i could n't use that data . professor e: yeah . postdoc b: i agree . and mari also , phd c: um . postdoc b: we had this came up when she she was here . that 's important . phd c: so it 's a great idea , professor e: yeah , i i b by the by the way , i do n't think the transcriptions are actually , in the long run , such a big bottleneck . phd c: and if it were true than i would just do that , but it 's not that bad like the room is not the bottleneck , and we have enough time in the room , it 's getting the people to come in and put on the and get the setup going . professor e: i think the issue is just that we 're we 're blazing that path . right ? and and um d do you have any idea when when uh the you 'll be able to send uh the ten hours to them ? grad g: well , i 've been burning two c ds a day , which is about all i can do with the time i have . professor e: yeah . yeah . grad g: so it 'll be early next week . professor e: yeah , ok . so early next week we send it to them , and then then we check with them to see if they 've got it and we we start , you know asking about the timing for it . grad g: yep . professor e: so i think once they get it sorted out about how they 're gon na do it , which i think they 're pretty well along on , cuz they were able to read the files and so on . grad g: yep . professor e: right ? grad g: yeah , but professor e: well grad g: yeah , who knows where they are . phd a: have they ever responded to you ? grad g: nope . professor e: yeah , but you know , so they they they have you know , they 're volunteering their time and they have a lot of other things to do , phd c: what if grad g: yeah , you we ca n't complain . professor e: right ? but they but at any rate , they 'll i i think once they get that sorted out , they 're they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it , and uh i think it 's not going to be i do n't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , i think . it 's not going to be thirty grad g: yep . i think that 's probably true . phd c: really ? so it 's the amount of professor e: it 's it 's just getting it going . grad g: it 's pipeline , pipeline issues . phd c: right . what about these lunch meetings grad g: once the pipeline fills . phd c: i mean , i do n't know , if there 's any way without too much more overhead , even if we do n't ship it right away to ibm even if we just collect it here for awhile , { comment } to record you know , two or three more meeting a week , just to have the data , even if they 're um not doing the digits , but they do wear the headphones ? professor e: but the lunch meetings are pretty much one person getting up and phd c: no , i meant , um , sorry , the meetings where people eat their lunch downstairs , maybe they do n't wan na be recorded , but grad g: oh , and we 're just chatting ? phd c: just the ch the chatting . grad g: yeah , we have a lot of those . phd c: i actually i actually think that 's useful data , um the chatting , grad g: yeah , the problem with that is i would i think i would feel a little constrained to you know ? uh , some of the meetings phd c: but ok . you do n't wan na do it , cuz ok . grad g: you know , our `` soccer ball `` meeting ? phd c: alright . grad g: i guess none of you were there for our soccer ball meeting . phd c: alright , { comment } so i 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it . grad g: that was hilarious . professor e: yeah . well , we should also check with mari again , because they because they were really intending , you know , maybe just did n't happen , but they were really intending to be duplicating this in some level . so then that would double what we had . uh . and there 's a lot of different meetings at uw uh i mean really m a lot more { comment } than we have here right cuz we 're not right on campus , grad g: right . professor e: so . phd a: is the uh , notion of recording any of chuck 's meetings dead in the water , or is that still a possibility ? professor e: uh , they seem to have some problems with it . we can we can talk about that later . um , but , again , jerry is jerry 's open so i mean , we have two speech meetings , one uh network meeting , uh jerry was open to it but i i s one of the things that i think is a little a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably ca n't do it every week . you know ? i i i i think that that people are gon na feel uh are gon na feel a little bit constrained . now , it might get a little better if we do n't have them do the digits all the time . and the then so then they can just really sort of try to put the mikes on and then just charge in and grad g: yep . phd c: what if we give people you know , we cater a lunch in exchange for them having their meeting here or something ? postdoc b: well , you know , i i do think eating while you 're doing a meeting is going to be increasing the noise . phd c: ok . postdoc b: but i had another question , which is um , you know , in principle , w um , i know that you do n't want artificial topics , phd c: alright , alright , alright . postdoc b: but um it does seem to me that we might be able to get subjects from campus to come down and do something that would n't be too artificial . i mean , we could political discussions , or or something or other , phd c: no , definitely . postdoc b: and i you know , people who are because , you know , there 's also this constraint . we d it 's like , you know , the the uh goldibears goldi goldilocks , it 's like you do n't want meetings that are too large , but you do n't want meetings that are too small . and um a and it just seems like maybe we could exploit the subj human subject p p pool , in the positive sense of the word . phd a: well , even i mean , coming down from campus is sort of a big thing , but what about postdoc b: we could pay subjects . phd a: or what about people in the in the building ? phd c: yeah , i was thinking , there 's all these other peo phd a: i mean , there 's the state of california downstairs , and phd c: yeah . i mean grad g: i just really doubt that uh any of the state of california meetings would be recordable and then releasable to the general public . postdoc b: yeah . phd a: oh . phd c: mm - hmm . grad g: so i i mean i talked with some people at the haas business school who are i who are interested in speech recognition phd c: alright , well . grad g: and , they sort of hummed and hawed and said `` well maybe we could have meetings down here `` , but then i got email from them that said `` no , we decided we 're not really interested and we do n't wan na come down and hold meetings . `` so , i think it 's gon na be a problem to get people regularly . phd a: what about joachim , maybe he can professor e: but but we c but i think , you know , we get some scattered things from this and that . and i i d i do think that maybe we can get somewhere with the with the radio . phd c: mm - hmm . professor e: uh i i have better contacts in radio than in television , but phd a: you could get a lot of lively discussions from those radio ones . phd c: well , and they 're already they 're these things are already recorded , grad g: yep . professor e: yeah . phd c: we do n't have to ask them to even and i 'm not sure wh how they record it , but they must record from individual professor e: n well no , i 'm not talking about ones that are already recorded . i 'm talking about new ones phd c: why why not ? professor e: because because because we would be asking them to do something different . phd c: well , we can find out . i know for instance mark liberman was interested uh in in ldc getting data , uh , and professor e: right , that 's the found data idea . phd c: yeah . professor e: but what i 'm saying is uh if i talk to people that i know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike . phd c: mm - hmm . professor e: and u i think routinely they would not do this . so , since i 'm interested in the distant mike stuff , i wan na make sure that there is at least that somewhere phd c: right . great . ok . professor e: and uh but if we ask them to do that they might be intrigued enough by the idea that they uh might be e e willing to the i might be able to talk them into it . phd c: mm - hmm . grad g: um . we 're getting towards the end of our disk space , so we should think about trying to wrap up here . phd c: that 's a good way to end a meeting . professor e: ok . well i do n't why do n't we why d u why do n't we uh uh turn them turn grad g: ok , leave leave them on for a moment until i turn this off , cuz that 's when it crashed last time . postdoc b: oh . that 's good to know . professor e: turning off the microphone made it crash . well postdoc b: that 's good to know . professor e: ok .","output":"efforts by speaker mn005 are in progress to detect overlapping speech . for a single transcribed meeting , speaker mn005 reported approximately 300 cases of overlap . future work will involve manually deriving time marks from sections of overlapping speech for the same meeting , and then experimenting with different measures , e.g . energy increase , to determine a set of acoustically salient features for identifying speaker overlap ."},{"instruction":"what \u2019 s the current status of recordings and transcriptions ?","input":"professor e: so . ok . does n't look like it crashed . that 's great . grad g: so i think maybe what 's causing it to crash is i keep starting it and then stopping it to see if it 's working . and so i think starting it and then stopping it and starting it again causes it to crash . so , i wo n't do that anymore . postdoc b: and it looks like you 've found a way of uh mapping the location to the without having people have to give their names each time ? phd a: sounds like an initialization thing . postdoc b: i mean it 's like you have the so you know that grad g: no . postdoc b: i mean , are you going to write down that i sat here ? grad g: i 'm gon na collect the digit forms and write it down . postdoc b: ok . phd c: oh , ok . grad g: so so they should be right with what 's on the digit forms . ok , so i 'll go ahead and start with digits . u and i should say that uh , you just pau you just read each line an and then pause briefly . professor e: and start by giving the transcript number . phd a: tran phd d: transcript uh . ok , ok . phd a: oh sorry , go ahead . professor e: so uh , you see , don , the unbridled excitement of the work that we have on this project . grad h: ok . professor e: it 's just uh grad h: umh . professor e: uh , you know , it does n't seem like a bad idea to have { comment } that information . grad g: and i 'm surprised i sort of i 'm surprised i forgot that , professor e: yeah , i i 'd i think it 's some grad g: but uh i think that would be a good thing to add . after i just printed out a zillion of them . professor e: yeah , well , that 's um , so i i do have a a an agenda suggestion . uh , we i think the things that we talk about in this meeting uh tend to be a mixture of uh procedural uh mundane things and uh research points and um i was thinking i think it was a meeting a couple of weeks ago that we we spent much of the time talking about the mundane stuff cuz that 's easier to get out of the way and then we sort of drifted into the research and maybe five minutes into that andreas had to leave . so uh i 'm suggesting we turn it around and and uh sort of we have anybody has some mundane points that we could send an email later , uh hold them for a bit , and let 's talk about the the research - y kind of things . um , so um the one th one thing i know that we have on that is uh we had talked a a couple weeks before um uh about the uh the stuff you were doing with with uh um uh l l attempting to locate events , we had a little go around trying to figure out what you meant by `` events `` but i think , you know , what we had meant by `` events `` i guess was uh points of overlap between speakers . but i th i gather from our discussion a little earlier today that you also mean uh interruptions with something else phd d: yeah . professor e: like some other noise . phd d: uh - huh . yeah . professor e: yes ? you mean that as an event also . phd d: to professor e: so at any rate you were you 've you 've done some work on that phd d: right . professor e: and um then the other thing would be it might be nice to have a preliminary discussion of some of the other uh research uh areas that uh we 're thinking about doing . um , i think especially since you you have n't been in in these meetings for a little bit , maybe you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , uh and one of the things i know that also came up uh is some discussions that that uh that uh jane had with lokendra uh about some some some um uh work about i i i d i i do n't want to try to say cuz i i 'll say it wrong , but anyway some some potential collaboration there about about the about the working with these data . phd c: oh . sure . professor e: so . so , uh . grad g: you wan na just go around ? professor e: uh . well , i do n't know if we if this is sort of like everybody has something to contribute sort of thing , i think there 's just just a couple a couple people primarily um but um uh , wh why do n't actually i think that that last one i just said we could do fairly quickly so why do n't you you start with that . postdoc b: ok . shall i shall i just start ? ok . professor e: yeah , just explain what it was . postdoc b: um , so , uh , he was interested in the question of you know , relating to his to the research he presented recently , um of inference structures , and uh , the need to build in , um , this this sort of uh mechanism for understanding of language . and he gave the example in his talk about how um , e a i 'm remembering it just off the top of my head right now , but it 's something about how um , i `` joe slipped `` you know , `` john had washed the floor `` or something like that . and i do n't have it quite right , but that kind of thing , where you have to draw the inference that , ok , there 's this time sequence , but also the the the causal aspects of the uh floor and and how it might have been the cause of the fall and that um it was the other person who fell than the one who cleaned it and it { comment } these sorts of things . so , i looked through the transcript that we have so far , { comment } and um , fou identified a couple different types of things of that type and um , one of them was something like uh , during the course of the transcript , um um , w we had gone through the part where everyone said which channel they were on and which device they were on , and um , the question was raised `` well , should we restart the recording at this point ? `` and and dan ellis said , `` well , we 're just so far ahead of the game right now we really do n't need to `` . now , how would you interpret that without a lot of inference ? so , the inferences that are involved are things like , ok , so , how do you interpret `` ahead of the game `` ? you know . so it 's the it 's i what you what you int what you draw you know , the conclusions that you need to draw are that space is involved in recording , grad g: hmm , metaphorically . postdoc b: that um , i that i we have enough space , and he continues , like `` we 're so ahead of the game cuz now we have built - in downsampling `` . so you have to sort of get the idea that um , `` ahead of the game `` is sp speaking with respect to space limitations , that um that in fact downsampling is gaining us enough space , and that therefore we can keep the recording we 've done so far . but there are a lot of different things like that . grad g: so , do you think his interest is in using this as a data source , or training material , or what ? professor e: well , i i should maybe interject to say this started off with a discussion that i had with him , so um we were trying to think of ways that his interests could interact with ours grad g: mm - hmm . professor e: and um uh i thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with jane 's help , look into some of the data that we 're already have and see , is there anything to this at all ? grad g: mm - hmm . professor e: is there any point which you think that , you know , you could gain some advantage and some potential use for it . cuz it could be that you 'd look through it and you say `` well , this is just the wrong task for for him to pursue his `` grad g: wrong , yeah . professor e: and and uh i got the impression from your mail that in fact there was enough things like this just in the little sample that that you looked at that that it 's plausible at least . postdoc b: it 's possible . uh , he was he he you know we met and he was gon na go and uh you know , y look through them more systematically professor e: yeah . postdoc b: and then uh meet again . professor e: yeah . postdoc b: so it 's , you know , not a matter of a professor e: yeah . postdoc b: but , yeah , i think i think it was optimistic . professor e: so anyway , that 's that 's e a quite different thing from anything we 've talked about that , you know , might might might come out from some of this . phd c: but he can use text , basically . i mean , he 's talking about just using text postdoc b: that 's his major i mentioned several that w had to do with implications drawn from intonational contours phd c: pretty much , or ? postdoc b: and that was n't as directly relevant to what he 's doing . he 's interested in these these knowledge structures , phd c: ok . phd d: yeah , interesting . postdoc b: inferences that you draw i from professor e: i mean , he certainly could use text , but we were in fact looking to see if there is there is there something in common between our interest in meetings and his interest in in in this stuff . so . grad g: and i imagine that transcripts of speech i mean text that is speech probably has more of those than sort of prepared writing . i i do n't know whether it would or not , but it seems like it would . professor e: i do n't know , probably de probably depends on what the prepared writing was . but . postdoc b: yeah , i do n't think i would make that leap , because i in narratives , you know i mean , if you spell out everything in a narrative , it can be really tedious , grad g: mm - hmm . postdoc b: so . grad g: yeah , i 'm just thinking , you know , when you 're when you 're face to face , you have a lot of backchannel and and postdoc b: oh . that aspect . grad g: yeah . and so i think it 's just easier to do that sort of broad inference jumping if it 's face to face . i mean , so , if i just read that dan was saying `` we 're ahead of the game `` { comment } in that in that context , postdoc b: well yeah . grad g: i might not realize that he was talking about disk space as opposed to anything else . postdoc b: i you know , i i had several that had to do with backchannels and this was n't one of them . grad g: uh - huh . postdoc b: this this one really does um m make you leap from so he said , you know , `` we 're ahead of the game , w we have built - in downsampling `` . grad g: mm - hmm . postdoc b: and the inference , i if you had it written down , would be grad g: i guess it would be the same . postdoc b: uh - huh . but there are others that have backchannelling , it 's just he was less interested in those . phd f: can i sorry to interrupt . um , i f f f i 've @ @ { comment } d a minute uh , several minutes ago , i , like , briefly was was not listening and so who is `` he `` in this context ? phd c: yeah , there 's a lot of pronoun phd f: ok . so i was just realizing we 've you guys have been talking about `` he `` um for at least uh , i do n't know , three three four minutes without ever mentioning the person 's name again . phd c: i believe it . yeah . actually to make it worse , { comment } uh , morgan uses `` you `` and `` you `` phd f: so this is this is this is gon na be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort . grad g: it 's in my notes . phd c: with gaze and no identification , or i just wrote this down . yeah , actually . cuz morgan will say well , `` you had some ideas `` phd d: yeah . phd f: you just wrote this ? phd c: and he never said li - he looked grad g: well , i think he 's doing that intentionally , phd c: right , so it 's great . grad g: are n't you ? phd c: so this is really great phd f: right . phd c: because the thing is , because he 's looking at the per even for addressees in the conversation , phd d: yeah . phd f: mm - hmm . phd c: i bet you could pick that up in the acoustics . just because your gaze is also correlated with the directionality of your voice . professor e: uh - huh . could be . postdoc b: can we professor e: yeah . that would be tou grad g: oh , that would be interesting . phd c: yeah , so that , i mean , to even know um when phd d: yeah . phd c: yeah , if you have the p z ms you should be able to pick up what a person is looking at from their voice . grad g: well , especially with morgan , with the way we have the microphones arranged . i 'm sort of right on axis and it would be very hard to tell . phd c: right . grad g: uh . postdoc b: oh , but you 'd have the phd c: put morgan always like this postdoc b: you 'd have fainter phd c: and postdoc b: would n't you get fainter reception out here ? professor e: well , these grad g: sure , but i think if i 'm talking like this ? right now i 'm looking at jane and talking , now i 'm looking at chuck and talking , i do n't think the microphones would pick up that difference . phd c: but you do n't have this this problem . postdoc b: i see . phd c: morgan is the one who does this most . grad g: so if i 'm talking at you , or i 'm talking at you . professor e: i probably been affect no , i th i think i 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about `` oh gee is somebody going to say something bad ? `` and so on . grad g: lawyers . professor e: and so i so i 'm i 'm tending to stay away from people 's names even though uh postdoc b: i am too . phd c: even though you could pick up later on , just from the acoustics who you were t who you were looking at . postdoc b: i am too . grad g: and we did mention who `` he `` was . phd c: yeah . professor e: yeah . phd f: right , but i missed it . grad g: early in the conversation . phd f: but it was uh phd c: yeah , yeah . professor e: yeah . grad g: do sh - can i say professor e: yeah . no no , there 's phd f: yeah . grad g: or or is that just too sensitive ? professor e: no no , it is n't sensitive at all . postdoc b: well professor e: i was just i was just i was overreacting just because we 've been talking about it . postdoc b: and in fact , it is it is it is sensitive . phd c: no , but that it 's interesting . professor e: it 's ok to postdoc b: i i came up with something from the human subjects people that i wanted to mention . i mean , it fits into the m area of the mundane , but they did say you know , i asked her very specifically about this clause of how , um , you know , it says `` no individuals will be identified uh , `` in any publication using the data . `` ok , well , individuals being identified , let 's say you have a a snippet that says , `` joe s uh thinks such - and - such about about this field , but i think he 's wrongheaded . `` now i mean , we 're we 're gon na be careful not to have the `` wrongheaded `` part in there , but but you know , let 's say we say , you know , `` joe used to think so - and - so about this area , in his publication he says that but i think he 's changed his mind . `` or whatever . then the issue of of being able to trace joe , because we know he 's well - known in this field , and all this and and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive . professor e: b but i postdoc b: so i think it 's really really kind of adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wan na be able to have to remove ? professor e: yeah , well , there 's that . but i i mean i think also to some extent it 's just educating the human subjects people , in a way , because there 's if uh you know , there 's court transcripts , there 's there 's transcripts of radio shows i mean people say people 's names all the time . so i think it it ca n't be bad to say people 's names . it 's just that i i mean you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of of of slandering anybody , phd c: but , then it wo n't i mean , if we if we professor e: but grad g: it 's not a meeting . phd c: yeah . i mean we should do whatever 's natural in a meeting if if we were n't being recorded . professor e: yeah . right , so i so my behavior is probably not natural . phd c: `` if person x `` professor e: so . postdoc b: well , my feeling on it was that it was n't really important who said it , you know . professor e: yeah . phd f: well , if you ha since you have to um go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark grad g: well , we t we t we talked about this during the anon anonymization . phd f: right . grad g: if we wan na go through and extract from the audio and the written every time someone says a name . and i thought that our conclusion was that we did n't want to do that . professor e: yeah , we really ca n't . but a actually , i 'm sorry . i really would like to push finish this off . postdoc b: i understand . no i just i just was suggesting that it 's not a bad policy p potentially . professor e: so it 's postdoc b: so , we need to talk about this later . professor e: yeah , i di i did n't intend it an a policy though . postdoc b: uh - huh . professor e: it was it was just it was just unconscious well , semi - conscious behavior . i sorta knew i was doing it but it was phd f: well , i still do n't know who `` he `` is . professor e: i i do i do n't remember who `` he `` is . phd c: no , you have to say , you still do n't know who `` he `` is , with that prosody . professor e: ah . uh , we were talking about dan at one point { comment } and we were talking about lokendra at another point . postdoc b: yeah , depends on which one you mean . professor e: and i do n't i do n't remember which which part . phd f: oh . phd c: it 's ambiguous , so it 's ok . professor e: uh , i think grad g: well , the inference structures was lokendra . phd f: but no . the inference stuff was was was lokendra . professor e: yeah . yeah . yeah . phd f: ok . that makes sense , yeah . phd c: and the downsampling must have been dan . professor e: um grad g: yeah . professor e: good yeah . phd c: it 's an inference . professor e: yeah , you could do all these inferences , yeah . grad g: yeah . professor e: yeah . um , i i would like to move it into into uh what jose uh has been doing postdoc b: yeah . professor e: because he 's actually been doing something . phd d: uh - huh . ok . professor e: so . right . phd f: as opposed to the rest of us . phd d: well - { comment } ok . i i remind that me my first objective eh , in the project is to to study difference parameters to to find a a good solution to detect eh , the overlapping zone in eh speech recorded . but eh , tsk , { comment } ehhh { comment } in that way { comment } i i i begin to to study and to analyze the ehn the recorded speech eh the different session to to find and to locate and to mark eh the the different overlapping zone . and eh so eh i was eh i am transcribing the the first session and i i have found eh , eh one thousand acoustic events , eh besides the overlapping zones , eh i i i mean the eh breaths eh aspiration eh , eh , talk eh , eh , clap , eh { comment } i do n't know what is the different names eh you use to to name the the n speech phd a: nonspeech sounds ? phd d: yeah . grad g: oh , i do n't think we 've been doing it at that level of detail . so . phd d: yeah . eh , i i i do i do n't need to to to mmm to m to label the the different acoustic , but i prefer because eh i would like to to study if eh , i i will find eh , eh , a good eh parameters eh to detect overlapping i would like to to to test these parameters eh with the another eh , eh acoustic events , to nnn to eh to find what is the ehm the false eh , the false eh hypothesis eh , nnn , which eh are produced when we use the the ehm this eh parameter eh i mean pitch eh , eh , difference eh , feature grad g: mm - hmm . phd a: you know i think some of these um that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there . grad g: so it was phd d: yeah . phd a: i mean , if it 's a tapping sound , you would n't necessarily or , you know , something like that , it 'd be it might be hard to know that it was two separate events . phd d: yeah . yeah . yeah . yeah . grad g: well you were n't talking about just overlaps phd d: ye grad g: were you ? you were just talking about acoustic events . phd d: i i i i t i t i talk eh about eh acoustic events in general , grad g: someone starts , someone stops yeah . phd a: oh . phd d: but eh my my objective eh will be eh to study eh overlapping zone . grad g: mm - hmm . phd d: eh ? { comment } n eh in twelve minutes i found eh , eh one thousand acoustic events . professor e: how many overlaps were there uh in it ? no no , how many of them were the overlaps of speech , though ? phd d: how many ? eh almost eh three hundred eh in one session grad g: oh , god ! phd d: in five eh in forty - five minutes . phd a: three hundred overlapping speech phd d: alm - three hundred overlapping zone . grad g: ugh . phd c: overlapping speech . phd d: with the overlapping zone , overlapping speech speech what eh different duration . phd a: mm - hmm . professor e: sure . postdoc b: does this ? so if you had an overlap involving three people , how many times was that counted ? phd d: yeah , three people , two people . eh , um i would like to consider eh one people with difference noise eh in the background , be professor e: no no , but i think what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ? phd d: oh . oh . yeah . i consider one event eh for th for that eh for all the zone . this th i i i con i consider i consider eh an acoustic event , the overlapping zone , the period where three speaker or eh are talking together . grad g: well so let 's postdoc b: for grad g: so let 's say me and jane are talking at the same time , and then liz starts talking also over all of us . how many events would that be ? phd d: so - i do n't understand . grad g: so , two people are talking , { comment } and then a third person starts talking . phd d: yeah ? grad g: is there an event right here ? phd d: eh no . no no . for me is the overlapping zone , because because you you have s you have more one eh , more one voice eh , eh produced in a in in a moment . professor e: i see . grad g: so i if two or more people are talking . professor e: ok . yeah . so i think yeah . we just wanted to understand how you 're defining it . phd d: yeah . if professor e: so then , in the region between since there there is some continuous region , in between regions where there is only one person speaking . phd d: uh - huh . professor e: and one contiguous region like that you 're calling an event . phd d: uh - huh . professor e: is it are you calling the beginning or the end of it the event , phd d: yeah . professor e: or are you calling the entire length of it the event ? phd d: i consider the the , nnn the nnn , nnn eh , the entirety eh , eh , all all the time there were the voice has overlapped . professor e: ok . phd d: this is the idea . but eh i i do n't distinguish between the the numbers of eh speaker . uh , i 'm not considering eh the the ehm eh , the fact of eh , eh , for example , what did you say ? eh at first eh , eh two talkers are uh , eh speaking , and eh , eh a third person eh join to to that . for me , it 's eh it 's eh , all overlap zone , with eh several numbers of speakers is eh , eh the same acoustic event . wi - but uh , without any mark between the zone of the overlapping zone with two speakers eh speaking together , and the zone with the three speakers . postdoc b: that would j just be one . phd d: it one . one . postdoc b: ok . phd d: eh , with eh , a beginning mark and the ending mark . because eh for me , is the is the zone with eh some kind of eh distortion the spectral . professor e: got it . phd d: i do n't mind by the moment , by the moment . grad g: well , but but you could imagine that three people talking has a different spectral characteristic than two . phd d: i i do n't yeah , but eh but eh i have to study . { comment } what will happen in a general way , professor e: could . grad g: so . you had to start somewhere . professor e: yeah . we just w phd c: so there 's a lot of overlap . phd d: i i do n't know what eh will will happen with the grad g: yep . phd c: so . grad g: that 's a lot of overlap , phd d: yeah ? professor e: so again , that 's that 's three three hundred in forty - five minutes that are that are speakers , just speakers . grad g: yeah , for forty - five minutes . phd d: yeah . yeah . professor e: uh - huh . ok . yeah . postdoc b: but a a a th professor e: so that 's about eight per minute . postdoc b: but a thousand events in twelve minutes , that 's phd d: yeah , but yeah . phd c: but that can include taps . phd d: but professor e: uh . yeah . postdoc b: well , but a thousand taps in eight minutes is a l in twelve minutes is a lot . phd d: general . phd c: actually phd d: i i con i consider i consider acoustic events eh , the silent too . postdoc b: silent . grad g: silence starting or silence ending phd d: yeah , silent , ground to bec to detect eh because i consider acoustic event all the things are not eh speech . phd c: oh , ok . professor e: mm - hmm . phd a: oh . phd d: in ge in in in a general point of view . phd c: oh . professor e: ok , so how many of those thousand were silence ? phd c: alright . phd d: in the per phd f: not speech not speech or too much speech . phd d: too much speech . professor e: right . so how many of those thousand were silence , silent sections ? phd d: yeah . uh silent , i i i i do n't i i have n't the eh i i would like to to do a stylistic study professor e: yeah . phd d: and give you eh with the report eh from eh the the study from the the the session one session . professor e: yeah . yeah . phd d: and i i found that eh another thing . when eh eh i w i i was eh look at eh nnn , the difference speech file , um , for example , eh if eh we use the ehm the mixed file , to to transcribe , the the events and the words , i i saw that eh the eh speech signal , collected by the eh this kind of mike eh of this kind of mike , eh are different from the eh mixed signal eh , we eh collected by headphone . grad g: yep . phd d: and it 's right . professor e: yeah . grad g: right . phd d: but the problem is the following . the the the i i i knew that eh the signal eh , eh would be different , but eh the the problem is eh , eh we eh detected eh difference events in the speech file eh collected by by that mike uh qui compared with the mixed file . and so if when you transcribe eh only eh using the nnn the mixed file , it 's possible eh if you use the transcription to evaluate a different system , it 's possible you eh in the eh i and you use the eh speech file collected by the eh fet mike , to eh to nnn to do the experiments with the the system , professor e: mm - hmm . grad g: right . phd d: its possible to evaluate eh , eh or to consider eh acoustic events that which you marked eh in the mixed file , but eh they do n't appear in the eh speech signal eh collected by the by the mike . grad g: right . the the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . phd d: yeah . yeah . oh , it 's a good idea . it 's a good idea i think . grad g: so i agree that if someone wants to do speech event transcription , that the mixed signals here phd d: yeah . grad g: i mean , if i 'm tapping on the table , you it 's not gon na show up on any of the mikes , but it 's gon na show up rather loudly in the pzm . phd d: yeah . yeah . yeah . so and i i i say eh that eh , eh , or this eh only because eh i c i i in my opinion , it 's necessary to eh to eh to put the transcription on the speech file , collected by the objective signal . grad g: so . phd d: i mean the the the signal collected by the eh , the real mike in the future , in the prototype to to eh correct the initial eh segmentation eh with the eh real speech professor e: mm - hmm . the the the far - field , yeah . phd d: you have to to analyze you have to to process . because i i found a difference . professor e: yeah , well , just i mean , just in that that one s ten second , or whatever it was , example that adam had that that we we passed on to others a few months ago , there was that business where i g i guess it was adam and jane were talking at the same time and and uh , in the close - talking mikes you could n't hear the overlap , and in the distant mike you could . so yeah , it 's clear that if you wan na study if you wan na find all the places where there were overlap , it 's probably better to use a distant mike . phd f: that 's good . professor e: on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes , phd d: yeah . phd c: but why ca n't you use the combination of the close - talking mikes , time aligned ? professor e: so it 's grad g: if you use the combination of the close - talking mikes , you would hear jane interrupting me , but you would n't hear the paper rustling . and so if you 're interested in phd c: i i mean if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem , professor e: some { comment } of it 's masking masked . phd d: yeah . phd a: were you interrupting him or was he interrupting you ? professor e: right . phd c: right ? grad g: right . phd d: yeah . grad g: although the other issue is that the mixed close - talking mikes i mean , i 'm doing weird normalizations and things like that . phd c: but it 's known . phd d: yeah . phd c: i mean , the normalization you do is over the whole conversation grad g: yep . phd c: is n't it , over the whole meeting . grad g: right . yep . phd c: so if you wanted to study people overlapping people , that 's not a problem . phd d: i i i think eh i saw the nnn the eh but eh i eh i have eh any results . i i i saw the the speech file collected by eh the fet mike , and eh eh signal eh to eh to noise eh relation is eh low . it 's low . professor e: mm - hmm . phd d: it 's very low . you would comp if we compare it with eh the headphone . grad g: yep . phd d: and i i found that nnn that eh , ehm , pr probably , grad g: did did you phd d: i 'm not sure eh by the moment , but it 's it 's probably that eh a lot of eh , eh for example , in the overlapping zone , on eh in in several eh parts of the files where you you can find eh , eh eh , smooth eh eh speech eh from eh one eh eh talker in the in the meeting , professor e: mm - hmm . mm - hmm . phd d: it 's probably in in that eh in in those files you you can not find you can not process because eh it 's confused with with noise . professor e: mm - hmm . phd d: and there are a lot of i think . but i have to study with more detail . but eh my idea is to to process only nnn , this eh nnn , this kind of s of eh speech . because i think it 's more realistic . i 'm not sure it 's a good idea , but eh professor e: no i grad g: well , it 's more realistic but it 'll it 'll be a lot harder . phd d: yeah . professor e: well , it 'd be hard , but on the other hand as you point out , if your if i if if your concern is to get uh the overlapping people people 's speech , you will you will get that somewhat better . phd d: mm - hmm . yeah . professor e: um , are you making any use uh you were you were working with th the data that had already been transcribed . phd d: with by jane . professor e: does it uh yes . phd d: yeah . professor e: now um did you make any use of that ? see i was wondering cuz we st we have these ten hours of other stuff that is not yet transcribed . phd d: yeah . yeah . professor e: do you phd d: the the transcription by jane , t eh i eh , i i i want to use to to nnn , eh to put i i it 's a reference for me . but eh the transcription eh for example , i i do n't i i 'm not interested in the in the in the words , transcription words , eh transcribed eh eh in eh follow in the in the in the speech file , but eh eh jane eh for example eh put a mark eh at the beginning eh of each eh talker , in the in the meeting , um eh she she nnn includes information about the zone where eh there are eh there is an overlapping zone . but eh there is n't any any mark , time temporal mark , to to c eh to mmm e - heh , to label { comment } the beginning and the end of the of the professor e: mm - hmm . ok . right , so she is phd d: ta i 'm i i i think eh we need this information to professor e: right . so the twelve you you it took you twelve hours of course this included maybe some some time where you were learning about what what you wanted to do , but but uh , it took you something like twelve hours to mark the forty - five minutes , your grad g: twelve minutes . phd d: twelve minutes . professor e: s twelve minutes ! phd d: twelve minutes . twelve . professor e: i thought you did forty - five minutes of phd d: no , forty - five minutes is the is the session , all the session . postdoc b: oh . professor e: oh , you have n't done the whole session . phd d: yeah , all is the the session . professor e: this is just twelve minutes . phd d: tw - twelve hours of work to to segment eh and label eh twelve minutes from a session of part of f professor e: oh . so { comment } let me back up again . so the when you said there were three hundred speaker overlaps , phd d: yeah . professor e: that 's in twelve minutes ? phd d: no no no . i i consider all the all the session because eh i i count the nnn the nnn the overlappings marked by by jane , professor e: oh , ok . postdoc b: oh , i see . phd d: in in in in the fin in in the forty - five minutes . professor e: ok . so it 's three hundred in forty - five minutes , but you have you have time uh , uh marked twelve minute the the the um overlaps in twelve minutes of it . phd d: yeah . professor e: got it . phd f: so , can i ask can i ask whether you found uh , you know , how accurate uh jane 's uh uh labels were as far as grad g: well , not just the overlaps , everything . phd f: you know , did she miss some overlaps ? or did she n ? phd d: but , by by the moment , i i do n't compare , my my temporal mark with eh jane , but eh i i want to do it . because eh eh i per perhaps i have eh errors in the in the marks , i and if i i compare with eh jane , it 's probably i i i can correct and and and to get eh eh a more accurately eh eh transcription in the file . professor e: yeah . grad g: well , also jane jane was doing word level . phd d: yeah . professor e: yeah . grad g: so we were n't concerned with { comment } exactly when an overlap started and stopped . phd f: right . right . phd c: well , not only a word level , but actually phd d: well phd f: i 'm expect i 'm not expecting phd d: no , it 's phd c: i mean , you did n't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or grad g: right . professor e: mm - hmm . grad g: yep . postdoc b: well phd d: yeah . yeah . postdoc b: well , yeah , b yeah , i would say time bin . so my my goal is to get words with reference to a time bin , beginning and end point . phd c: yeah . phd d: yeah . phd c: right . phd d: yeah . postdoc b: and and sometimes , you know , it was like you could have an overlap where someone said something in the middle , phd d: yeah . postdoc b: but , yeah , w it just was n't important for our purposes to have it that i disrupt that unit in order to have , you know , a the words in the order in which they were spoken , it would have it would have been hard with the interface that we have . phd d: yeah . postdoc b: now , my a adam 's working on a of course , on a revised overlapping interface , phd d: uh - huh . grad g: right . phd d: i i i think it 's it 's a good eh work , postdoc b: but phd d: but eh i think we need eh eh more information . phd f: no , of course . postdoc b: yeah . phd f: i expect you to find more overlaps than than jane grad g: always need more for postdoc b: yeah . phd d: no , no . i i have to go to phd f: because you 're looking at it at a much more detailed level . phd d: i want eh i wanted to eh compare the the transcription . professor e: i have grad g: but if it takes sixty to one professor e: well , i but i have a suggestion about that . um , obviously this is very , very time - consuming , and you 're finding lots of things which i 'm sure are gon na be very interesting , but in the interests of making progress , uh might i s how how would it affect your time if you only marked speaker overlaps ? phd d: only . professor e: yes . phd d: yeah . professor e: do not mark any other events , phd d: uh - huh . professor e: but only mark speaker do you think that would speed it up quite a bit ? phd d: ok . ok . i i i i w i i wanted to professor e: do y do you think that would speed it up ? uh , speed up your your your marking ? phd d: nnn , i do n't understand very . professor e: it took you a long time to mark twelve minutes . phd d: yeah . oh , yeah , yeah . professor e: now , my suggestion was for the other thirty - three phd d: on - only to mark only to mark overlapping zone , but professor e: yeah , and my question is , if you did that , if you followed my suggestion , would it take much less time ? phd d: oh , yeah . sure . professor e: yeah ok . phd d: yeah sure . professor e: then i think it 's a good idea . phd d: sure sure . professor e: then i think it 's a good idea , because it phd d: sure , because i i need a lot of time to to put the label or to do that . yeah . professor e: yeah , i mean , we we know that there 's noise . grad g: and phd d: uh - huh . professor e: there 's there 's uh continual noise uh from fans and so forth , and there is uh more impulsive noise from uh taps and so forth phd d: yeah . professor e: and and something in between with paper rustling . we know that all that 's there and it 's a g worthwhile thing to study , but obviously it takes a lot of time to mark all of these things . phd d: yeah . professor e: whereas th i i would think that uh you we can study more or less as a distinct phenomenon the overlapping of people talking . phd d: uh - huh . ok . ok . professor e: so . then you can get the cuz you need if it 's three hundred uh i i it sounds like you probably only have fifty or sixty or seventy events right now that are really phd d: yeah . professor e: and and you need to have a lot more than that to have any kind of uh even visual sense of of what 's going on , much less any kind of reasonable statistics . grad g: right . phd c: now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the grad g: well , that 's that 's what i was gon na bring up . phd c: i mean , you should n't need to do this p completely by hand , professor e: um , ok , yeah . so let 's back up because you were n't here for an earlier conversation . phd c: right ? i 'm sorry . professor e: so the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as i mean there 's a bunch of things i mean , increased energy is - is sort of an obvious one . phd c: mm - hmm . in the far - field mike . professor e: yeah . phd c: oh , ok . professor e: um , and uh , it 's not obvious , i mean , you could you could do the dumbest thing and get get it ninety percent of the time . but when you start going past that and trying to do better , it 's not obvious what combination of features is gon na give you the you know , the right detector . so the idea is to have some ground truth first . and so the i the idea of the manual marking was to say `` ok this , i you know , it 's it 's really here `` . phd a: but i think liz is saying why not get it out of the transcripts ? phd c: what i mean is get it from the close - talking mikes . professor e: uh , yeah . phd c: a or ge get a first pass from those , professor e: we t we t w we t we talked about that . phd c: and then go through sort of it 'd be a lot faster probably to phd f: and you can grad g: yeah , that 's his , uh professor e: we we we talked about that . s but so it 's a bootstrapping thing and the thing is , phd c: yeah , i just professor e: the idea was , i we i i we thought it would be useful for him to look at the data anyway , and and then whatever he could mark would be helpful , phd c: right . professor e: and we could uh it 's a question of what you bootstrap from . you know , do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then then do your simple measurements , uh from the close - talking mike . i mean , even with the close - talking mike you 're not gon na get it right all the time . phd c: well , that 's what i wonder , because um or how bad it is , professor e: well phd c: be um , because that would be interesting grad g: i 'm working on a program to do that , and phd c: especially because the bottleneck is the transcription . right ? i mean , we 've got a lot more data than we have transcriptions for . we have the audio data , we have the close - talking mike , professor e: yeah . phd c: so i mean it seems like one kind of project that 's not perfect , but um , that you can get the training data for pretty quickly is , you know , if you infer form the close - talking mikes where the on - off points are of speech , professor e: right , we discussed that . phd c: you know , how can we detect that from a far - field ? grad g: and postdoc b: oh . grad g: i 've i 've written a program to do that , phd c: ok , i 'm sorry i missed the grad g: and it , uh professor e: it 's ok . grad g: and so but it 's it 's doing something very , very simple . it just takes a threshold , based on on the volume , phd c: uh - huh . phd f: or you can set the threshold low and then weed out the false alarms by hand . phd c: right , by hand . yeah . phd f: yeah . grad g: um , and then it does a median filter , and then it looks for runs . and , it seems to work , i 've i 'm sort of fiddling with the parameters , to get it to actually generate something , and i have n't i do n't what i 'm working on was working on was getting it to a form where we can import it into the user interface that we have , into transcriber . and so i told i said it would take about a day . i 've worked on it for about half a day , grad h: i have to go . grad g: so give me another half day and i we 'll have something we can play with . phd c: ok . professor e: see , this is where we really need the meeting recorder query stuff to be working , because we 've had these meetings and we 've had this discussion about this , and i 'm sort of remembering a little bit about what we decided , phd c: right . i 'm sorry . i just professor e: but i could n't remember all of it . phd c: it professor e: so , i think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when when he he gets his thing going , grad g: but professor e: uh , and phd c: well , it 's definitely good to have somebody look at it . i was just thinking as a way to speed up you know , the amount of postdoc b: mm - hmm . professor e: that was that was exactly the notion that that that we discussed . phd c: ok . grad g: thanks . postdoc b: another thing we discussed was um that phd c: it looks good . professor e: so . phd c: i 'll be in touch . thanks . professor e: s see ya . yeah . postdoc b: was that um there m there was this already a script i believe uh that dan had written , { comment } that uh handle bleedthrough , i mean cuz you have this this close you have contamination from other people who speak loudly . grad g: yeah , and i have n't tried using that . it would probably help the program that i 'm doing to first feed it through that . it 's a cross - correlation filter . so i i have n't tried that , but that if it it might be something it might be a good way of cleaning it up a little . postdoc b: so , some thought of maybe having yeah , having that be a preprocessor and then run it through yours . grad g: exactly . yep . professor e: but but that 's a refinement postdoc b: that 's what we were discussing . professor e: and i think we wan na see try the simple thing first , cuz you add this complex thing up uh afterwards that does something good y y yo you sort of wan na see what the simple thing does first . grad g: yep . professor e: but uh , having having somebody have some experience , again , with with uh with marking it from a human standpoint , we 're i mean , i do n't expect jose to to do it for uh f fifty hours of { comment } of speech , but i mean we { comment } if uh if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it . phd d: yeah . sure . sure . professor e: and when when uh adam was doing his automatic thing he could then compare to that and see what it was different . phd c: oh yeah , definitely . phd a: you know , i did i did uh something almost identical to this at one of my previous jobs , and it works pretty well . i mean , i almost exactly what you described , an energy detector with a median filter , you look for runs . and uh , you know , you can grad g: it seemed like the right thing to do . phd a: yeah . i mean , you you can get y i mean , you get them pretty close . grad g: that was with zero literature search . phd a: and so i think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to to do it . grad g: that 's good validation . phd a: yeah . postdoc b: is this proprietary ? phd a: uh . { comment } no . no . grad g: yeah , do you have a patent on it ? phd a: it was when i was working for the government . professor e: oh , then everybody owns it . it 's the people . postdoc b: well , i mean , is this something that we could just co - opt , or is it ? phd a: nah . postdoc b: no . ok . professor e: well , i i i he 's pretty close , anyway . i think i think it 's phd a: yeah , he 's it it does n't take a long time . postdoc b: right . i just thought if it was tried and true , then { comment } and he 's gone through additional levels of of development . grad g: just output . although if you if you have some parameters like what 's a good window size for the median filter phd a: oh ! { comment } i have to remember . i 'll think about it , and try to remember . phd f: and it might be different for government people . grad g: that 's alright . professor e: yeah , good enough for government work , as they say . phd c: they they phd a: di - dif different different bandwidth . phd f: they grad g: i was doing pretty short , you know , tenth of a second , { comment } sorts of numbers . phd f: ok . professor e: uh , i do n't know , it if if we want to uh so , uh , maybe we should move on to other other things in limited time . postdoc b: can i ask one question about his statistics ? so so in the tw twelve minutes , um , if we took three hundred and divided it by four , which is about the length of twelve minutes , i um , i 'd expect like there should be seventy - five overlaps . professor e: yeah . postdoc b: did you find uh more than seventy - five overlaps in that period , or ? phd d: more than ? postdoc b: more than how many overlaps in your twelve minutes ? phd d: how many ? eh , not @ @ i onl - only i i transcribe eh only twelve minutes from the professor e: yeah . phd d: but eh i i do n't co eh i do n't count eh the the overlap . postdoc b: the overlaps . ok . phd d: i consider i i the the nnn the the three hundred is eh considered only you your transcription . i have to to finish transcribing . so . grad g: i b i bet they 're more , because the beginning of the meeting had a lot more overlaps than than sort of the middle . phd d: yeah . grad g: middle or end . postdoc b: i 'm not sure . phd d: yeah . grad g: because i we 're we 're dealing with the uh , in the early meetings , we 're recording while we 're saying who 's talking on what microphone , { comment } and things like that , phd d: yeah . grad g: and that seems to be a lot of overlap . postdoc b: i think it 's an empirical question . phd d: yeah . postdoc b: i think we could find that out . phd d: yeah . grad g: yep . postdoc b: i 'm i 'm not sure that the beginning had more . professor e: so so i was gon na ask , i guess about any any other things that that that either of you wanted to talk about , especially since andreas is leaving in five minutes , that that you wan na go with . phd c: can i just ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz i 'm i wanted to get a feel for that to sort of be able to know what what can be done first and like how many meetings are we recording professor e: right so there 's this this there 's this forty - five minute piece that jane transcribed . phd c: and professor e: that piece was then uh sent to ibm so they could transcribe so we have some comparison point . then there 's s a larger piece that 's been recorded and uh put on cd - rom and sent uh to ibm . right ? and then we do n't know . phd c: how many meetings is that ? like how many grad g: what 's that ? professor e: that was about ten hours , and there was about phd c: t ten it 's like ten meetings or something ? uh - huh . grad g: yeah , something like that . and then then we phd a: ten meetings that have been sent to ibm ? phd c: and professor e: yeah . grad g: well , i have n't sent them yet because i was having this problem with the missing files . professor e: oh . oh , that 's right , that had those have not been sent . phd a: h how many total have we recorded now , altogether ? professor e: we 're saying about twelve hours . grad g: about twelve by now . twelve or thirteen . phd c: uh - huh . and we 're recording only this meeting , like continuously we 're only recording this one now ? or ? professor e: no . no , so the the that 's the that 's the biggest one uh , chunk so far , grad g: nope . phd a: it was the morning one . phd c: ok . professor e: but there 's at least one meeting recorded of uh the uh uh natural language guys . grad g: jerry . phd c: do they meet every week , professor e: and then there phd c: or every professor e: uh , they do . w w and we talked to them about recording some more and we 're going to , uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded , phd c: great . professor e: and we 're gon na start recording them . they 're they meet on tuesdays . we 're gon na start recording them next week . so actually , we 're gon na h start having a a pretty significant chunk and so , you know , adam 's sort of struggling with trying to get things to be less buggy , and come up quicker when they do crash and stuff things like that , now that uh the things are starting to happen . so right now , yeah , i th i 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that that amount is gon na grow uh so that the meeting meetings will probably ultimately i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , you know , twenty or thirty percent of it , not not not eighty or ninety . but . phd c: so there 's probably there 's three to four a week , grad g: that 's what we 're aiming for . phd c: that we 're aiming for . professor e: yeah . phd c: and they 're each about an hour or something . professor e: yeah , yeah . grad g: although yeah . we 'll find out tomorrow whether we can really do this or not . phd c: so ok . professor e: yeah and th the the other thing is i 'm not pos i 'm sort of thinking as we 've been through this a few times , that i really do n't know maybe you wan na do it once for the novelty , but i do n't know if in general we wan na have meetings that we record from outside this group do the digits . grad g: right . professor e: because it 's just an added bunch of weird stuff . phd c: yeah . professor e: and , you know , we we h we 're highly motivated . uh in fact , the morning group is really motivated cuz they 're working on connected digits , so it 's grad g: actually that 's something i wanted to ask , is i have a bunch of scripts to help with the transcription of the digits . professor e: yeah . grad g: we do n't have to hand - transcribe the digits because we 're reading them and i have those . phd c: right . professor e: yeah . grad g: and so i have some scripts that let you very quickly extract the sections of each utterance . but i have n't been ru i have n't been doing that . um , if i did that , is someone gon na be working on it ? professor e: uh , yeah , i i think definitely s so absolutely . grad g: i mean , is it something of interest ? professor e: yeah , whoever we have working on the acoustics for the meeting recorder are gon na start with that . grad g: ok . i mean , i i 'm i 'm interested in it , i just do n't have time to do it now . phd f: i was these meetings i 'm sure someone thought of this , but these this uh reading of the numbers would be extremely helpful to do um adaptation . grad g: so phd f: um . grad g: yep . yep . phd c: actually i have o grad g: i i would really like someone to do adaptation . phd f: mm - hmm . grad g: so if we got someone interested in that , i think it would be great for meeting recorder . professor e: well i mean , one of the things i wanted to do , uh , that i i talked to to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , grad g: since it 's the same people over and over . phd f: mm - hmm . professor e: to try to get rid of some of the effects of the the the far - field effects . um , i mean we have the party line has been that echo cancellation is not the right way to handle the situation phd f: mm - hmm . professor e: because people move around , and uh , if if it 's if it 's uh not a simple echo , like a cross - talk kind of echo , but it 's actually room acoustics , it 's it 's it 's you ca n't really do inversion , phd f: mm - hmm . professor e: and even echo cancellation is going to uh be something it may you someone may be moving enough that you are not able to adapt quickly and so the tack that we 've taken is more `` lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal `` . phd f: mm - hmm . professor e: uh , that 's the party line . but it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous . it 's good good to sort of test them , actually . and so we have n't had anybody try to do a good serious job on echo cancellation and we should know how well that can do . so that 's something i 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . um , there was a have been some nice talks recently by by lucent on on their b phd f: hmm . professor e: the block echo cancellation particularly appealed to me , uh you know , trying and change it sample by sample , but you have some reasonable sized blocks . { comment } and um , you know , th phd a: w what is the um the artifact you try to you 're trying to get rid of when you do that ? phd f: ciao . professor e: uh so it 's it you have a a direct uh uh , what 's the difference in if you were trying to construct a linear filter , that would um phd f: i 'm signing off . professor e: yeah . that would subtract off { comment } the um uh parts of the signal that were the aspects of the signal that were different between the close - talk and the distant . you know , so so uh um i guess in most echo cancellation yeah , so you given that um yeah , so you 're trying to so you 'd there 's a a distance between the close and the distant mikes so there 's a time delay there , and after the time delay , there 's these various reflections . and if you figure out well what 's the there 's a a least squares algorithm that adjusts itself adjusts the weight so that you try to subtract essentially to subtract off uh different uh different reflections . right ? so let 's take the simple case where you just had you had some uh some delay in a satellite connection or something and then there 's a there 's an echo . it comes back . and you want to adjust this filter so that it will maximally reduce the effect of this echo . phd a: so that would mean like if you were listening to the data that was recorded on one of those . uh , just the raw data , you would you might hear kind of an echo ? and and then this noise cancellation would get professor e: well , i 'm i 'm i 'm saying that 's a simplified version of what 's really happening . { comment } what 's really happening is well , when i 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , uh , the indirect sound that 's bounced around the room a number of times . ok ? so now , if you um try to r you to completely remove the effect of that is sort of impractical for a number of technical reasons , but i but not to try to completely remove it , that is , invert the the room response , but just to try to uh uh eliminate some of the the effect of some of the echos . um , a number of people have done this so that , say , if you 're talking to a speakerphone , uh it makes it more like it would be , if you were talking right up to it . so this is sort of the st the straight - forward approach . you say i i i want to use this uh this item but i want to subtract off various kinds of echos . so you construct a filter , and you have this this filtered version uh of the speech um gets uh uh gets subtracted off from the original speech . then you try to you try to minimize the energy in some sense . and so um uh with some constraints . phd a: kind of a clean up thing , that professor e: it 's a clean up thing . right . phd a: ok . professor e: so , echo cancelling is is , you know , commonly done in telephony , and and and it 's sort of the obvious thing to do in this situation if you if , you know , you 're gon na be talking some distance from a mike . phd a: when uh , i would have meetings with the folks in cambridge when i was at bbn over the phone , they had a um some kind of a special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . and then it was uh and then it would come on and it was very clear , professor e: yeah . phd a: you know . professor e: right . so it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . so um , uh anyway that 's that 's kind of a reasonable thing that i 'd like to have somebody try somebody look and and the digits would be a reasonable thing to do that with . i think that 'd be enough data plenty of data to do that with , and i for that sort of task you would n't care whether it was uh large vocabulary speech or anything . uh . um postdoc b: is brian kingsbury 's work related to that , or is it a different type of reverberation ? professor e: brian 's { comment } kingsbury 's work is an example of what we did f f from the opposite dogma . right ? which is what i was calling the `` party line `` , which is that uh doing that sort of thing is not really what we want . we want something more flexible , uh i i where people might change their position , and there might be , you know there 's also um oh yeah , noise . so the echo cancellation does not really allow for noise . it 's if you have a clean situation but you just have some delays , then we 'll figure out the right the right set of weights for your taps for your filter in order to produce the effect of those those echos . but um if there 's noise , then the very signal that it 's looking at is corrupted so that it 's decision about what the right you know , right right uh delays are is , uh is right delayed signal is is is uh is incorrect . and so , in a noisy situation , um , also in a in a situation that 's very reverberant { comment } with long reverberation times { comment } and really long delays , it 's it 's sort of typically impractical . so for those kind of reasons , and also a a c a complete inversion , if you actually i mentioned that it 's kind of hard to really do the inversion of the room acoustics . um , that 's difficult because um often times the the um the system transfer function is such that when it 's inverted you get something that 's unstable , and so , if you you do your estimate of what the system is , and then you try to invert it , you get a filter that actually uh , you know , rings , and and uh goes to infinity . so it 's so there 's there 's there 's that sort of technical reason , and the fact that things move , and there 's air currents i mean there 's all sorts of all sorts of reasons why it 's not really practical . so for all those kinds of reasons , uh we we we sort of um , concluded we did n't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which is n't really inversion , and um we decided to do this approach of taking uh , just picking uh features , which were uh will give you more something that was more stable , in the presence of , or absence of , room reverberation , and that 's what brian was trying to do . so , um , let me just say a couple things that i was i was gon na bring up . uh . let 's see . i guess you you actually already said this thing about the uh about the consent forms , which was that we now do n't have to so this was the human subjects folks who said this , { comment } or that that ? postdoc b: the a apparently i mean , we 're gon na do a revised form , of course . um but once a person has signed it once , then that 's valid for a certain number of meetings . she wanted me to actually estimate how many meetings and put that on the consent form . i told her that would be a little bit difficult to say . so i think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something . it wo n't be that many people who do it that often , but um just , you know , so long as they do n't forget that they 've done it , i guess . professor e: ok . um , back on the data thing , so there 's this sort of one hour , ten hour , a hundred hour sort of thing that that we have . we have we have an hour uh that that is transcribed , we have we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , uh by the end of the semester we 'll have , i do n't know , forty or fifty or something , if we if this really uh well , do we have that much ? phd c: not really . it 's three to four per week . professor e: let 's see , we have phd c: so that 's what you know , that professor e: uh eight weeks , uh is phd c: so that 's not a lot of hours . professor e: eight weeks times three hours is twenty - four , so that 's yeah , so like thirty thirty hours ? phd a: three three hours . phd c: yeah . i mean , is there i know this sounds tough but we 've got the room set up . um i was starting to think of some projects where you would use well , similar to what we talked about with uh energy detection on the close - talking mikes . there are a number of interesting questions that you can ask about how interactions happen in a meeting , that do n't require any transcription . so what are the patterns , the energy patterns over the meeting ? and i 'm really interested in this but we do n't have a whole lot of data . so i was thinking , you know , we 've got the room set up and you can always think of , also for political reasons , if icsi collected you know , two hundred hours , that looks different than forty hours , even if we do n't transcribe it ourselves , professor e: but i do n't think we 're gon na stop at the end of this semester . phd c: so professor e: right ? so , i th i think that if we are able to keep that up for a few months , we are gon na have more like a hundred hours . phd c: i mean , is there are there any other meetings here that we can record , especially meetings that have some kind of conflict in them { comment } or some kind of deci i mean , that are less well i do n't uh , that have some more emotional aspects to them , or strong grad g: we had some good ones earlier . phd c: there 's laughter , um i 'm talking more about strong differences of opinion meetings , maybe with manager types , or grad g: i think it 's hard to record those . phd c: to be allowed to record them ? postdoc b: it 's also likely that people will cancel out afterwards . phd c: ok . professor e: yeah , people will get postdoc b: but i but i wanted to raise the kpfa idea . phd c: ok . well , if there is , anyway . professor e: yeah , i was gon na mention that . grad g: oh , that 's a good idea . that 's that would be a good match . professor e: yeah . so yeah . so i i uh , i i 'd mentioned to adam , and that was another thing i was gon na talk uh , mention to them before { comment } that uh there 's uh it it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media . because , you know , we had talked before about the problem about using found data , { comment } that that uh it 's just set up however they have it set up and we do n't have any say about it and it 's typically one microphone , in a , uh , uh or and and so it does n't really give us the the the uh characteristics we want . um and so i do think we 're gon na continue recording here and record what we can . but um , it did occur to me that we could go to friends in broadcast media and say `` hey you have this panel show , or this you know , this discussion show , and um can you record multi - channel ? `` and uh they may be willing to record it uh with phd c: with lapel mikes or something ? professor e: well , they probably already use lapel , but they might be able to have it it would n't be that weird for them to have another mike that was somewhat distant . phd c: right . professor e: it would n't be exactly this setup , but it would be that sort of thing , and what we were gon na get from uw , you know , assuming they they they start recording , is n't als also is not going to be this exact setup . phd c: right . no , i think that 'd be great , if we can get more data . professor e: so , { comment } i i i i was thinking of looking into that . the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , { comment } uh that we could invite them to have like some of their { comment } record some of their shows here . postdoc b: wow ! phd c: well or the thing is , they 're not as averse to wearing one of these head - mount i mean , they 're on the radio , grad g: right , as we are . phd c: right ? so . { comment } um , i think that 'd be fantastic professor e: right . phd c: cuz those kinds of panels and those have interesting professor e: yeah . phd c: th - that 's an a side of style a style that we 're not collecting here , so it 'd be great . professor e: and and the i mean , the other side to it was the what which is where we were coming from i 'll i 'll talk to you more about it later { comment } is that is that there 's there 's uh the radio stations and television stations already have stuff worked out presumably , uh related to , you know , legal issues and and permissions and all that . i mean , they already do what they do do whatever they do . so it 's uh , it 's so it 's so it 's another source . so i think it 's something we should look into , you know , we 'll collect what we collect here hopefully they will collect more at uw also and um and maybe we have this other source . but yeah i think that it 's not unreasonable to aim at getting , you know , significantly in excess of a hundred hours . i mean , that was sort of our goal . the thing was , i was hoping that we could @ @ in the under this controlled situation we could at least collect , you know , thirty to fifty hours . and at the rate we 're going we 'll get pretty close to that i think this semester . and if we continue to collect some next semester , i think we should , uh phd c: right . yeah i was mostly trying to think , `` ok , if you start a project , within say a month , you know , how much data do you have to work with . and you you wan na s you wan na sort of fr freeze your your data for awhile so um right now and we do n't have the transcripts back yet from ibm right ? do oh , do we now ? professor e: well , we do n't even have it for this f you know , forty - five minutes , that was phd c: so um , not complaining , i was just trying to think , you know , what kinds of projects can you do now versus uh six months from now professor e: yeah . phd c: and they 're pretty different , because professor e: yeah . so i was thinking right now it 's sort of this exploratory stuff where you you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like , grad g: right . phd c: um right . right , right . professor e: and and and uh and meanwhile we collect , and it 's more like yeah , three months from now , or six months from now you can you can do a lot of other things . phd c: cuz i 'm not actually sure , just logistically that i can spend you know , i do n't wan na charge the time that i have on the project too early , before there 's enough data to make good use of the time . and that 's and especially with the student grad g: right . phd c: uh for instance this guy who seems professor e: yeah . phd c: uh anyway , i should n't say too much , but um if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will i have to work with , with that person . and so it 's professor e: i yeah , so i would think , exploratory things now . uh , three months from now um , i mean the transcriptions i think are a bit of an unknown cuz we have n't gotten those back yet as far as the timing , but i think as far as the collection , it does n't seem to me l like , uh , unreasonable to say that uh in january , you know , ro roughly uh which is roughly three months from now , we should have at least something like , you know , twenty - five , thirty hours . phd c: and we just do n't know about the transcription part of that , professor e: so that 's postdoc b: yeah , we need to i think that there 's a possibility that the transcript will need to be adjusted afterwards , phd c: so . i mean , it postdoc b: and uh es especially since these people wo n't be uh used to dealing with multi - channel uh transcriptions . phd c: right . professor e: yeah . postdoc b: so i think that we 'll need to adjust some and also if we wan na add things like um , well , more refined coding of overlaps , then definitely i think we should count on having an extra pass through . i wanted to ask another a a aspect of the data collection . there 'd be no reason why a person could n't get together several uh , you know , friends , and come and argue about a topic if they wanted to , right ? professor e: if they really have something they wan na talk about as opposed to something @ @ i mean , what we 're trying to stay away from was artificial constructions , but i think if it 's a real why not ? yeah . phd c: i mean , i 'm thinking , politically grad g: stage some political debates . postdoc b: you could do this , phd c: well yeah , postdoc b: you know . you could . phd c: or just if you 're if you ha if there are meetings here that happen that we can record even if we do n't um have them do the digits , { comment } or maybe have them do a shorter digit thing { comment } like if it was , you know , uh , one string of digits , or something , they 'd probably be willing to do . grad g: we do n't have to do the digits at all if we do n't want to . phd c: then , having the data is very valuable , cuz i think it 's um politically better for us to say we have this many hours of audio data , especially with the itr , if we put in a proposal on it . it 'll just look like icsi 's collected a lot more audio data . um , whether it 's transcribed or not um , is another issue , but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer . postdoc b: it seems like you could hold some meetings . grad g: yep . postdoc b: you know , you and maybe adam ? phd c: so . postdoc b: you you could you could maybe hold some additional meetings , if you wanted . phd a: would it help at all i mean , we 're already talking about sort of two levels of detail in meetings . one is uh um without doing the digits or , i guess the full - blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted stuff . phd c: need the close - talking mikes . phd a: you do , ok . phd c: i mean , absolutely , professor e: yeah . yeah . phd c: yeah . i 'm really scared grad g: it seems like it 's a big part of this corpus is to have the close - talking mikes . phd a: i see , ok . phd c: um or at least , like , me personally ? i would { comment } i could n't use that data . professor e: yeah . postdoc b: i agree . and mari also , phd c: um . postdoc b: we had this came up when she she was here . that 's important . phd c: so it 's a great idea , professor e: yeah , i i b by the by the way , i do n't think the transcriptions are actually , in the long run , such a big bottleneck . phd c: and if it were true than i would just do that , but it 's not that bad like the room is not the bottleneck , and we have enough time in the room , it 's getting the people to come in and put on the and get the setup going . professor e: i think the issue is just that we 're we 're blazing that path . right ? and and um d do you have any idea when when uh the you 'll be able to send uh the ten hours to them ? grad g: well , i 've been burning two c ds a day , which is about all i can do with the time i have . professor e: yeah . yeah . grad g: so it 'll be early next week . professor e: yeah , ok . so early next week we send it to them , and then then we check with them to see if they 've got it and we we start , you know asking about the timing for it . grad g: yep . professor e: so i think once they get it sorted out about how they 're gon na do it , which i think they 're pretty well along on , cuz they were able to read the files and so on . grad g: yep . professor e: right ? grad g: yeah , but professor e: well grad g: yeah , who knows where they are . phd a: have they ever responded to you ? grad g: nope . professor e: yeah , but you know , so they they they have you know , they 're volunteering their time and they have a lot of other things to do , phd c: what if grad g: yeah , you we ca n't complain . professor e: right ? but they but at any rate , they 'll i i think once they get that sorted out , they 're they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it , and uh i think it 's not going to be i do n't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , i think . it 's not going to be thirty grad g: yep . i think that 's probably true . phd c: really ? so it 's the amount of professor e: it 's it 's just getting it going . grad g: it 's pipeline , pipeline issues . phd c: right . what about these lunch meetings grad g: once the pipeline fills . phd c: i mean , i do n't know , if there 's any way without too much more overhead , even if we do n't ship it right away to ibm even if we just collect it here for awhile , { comment } to record you know , two or three more meeting a week , just to have the data , even if they 're um not doing the digits , but they do wear the headphones ? professor e: but the lunch meetings are pretty much one person getting up and phd c: no , i meant , um , sorry , the meetings where people eat their lunch downstairs , maybe they do n't wan na be recorded , but grad g: oh , and we 're just chatting ? phd c: just the ch the chatting . grad g: yeah , we have a lot of those . phd c: i actually i actually think that 's useful data , um the chatting , grad g: yeah , the problem with that is i would i think i would feel a little constrained to you know ? uh , some of the meetings phd c: but ok . you do n't wan na do it , cuz ok . grad g: you know , our `` soccer ball `` meeting ? phd c: alright . grad g: i guess none of you were there for our soccer ball meeting . phd c: alright , { comment } so i 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it . grad g: that was hilarious . professor e: yeah . well , we should also check with mari again , because they because they were really intending , you know , maybe just did n't happen , but they were really intending to be duplicating this in some level . so then that would double what we had . uh . and there 's a lot of different meetings at uw uh i mean really m a lot more { comment } than we have here right cuz we 're not right on campus , grad g: right . professor e: so . phd a: is the uh , notion of recording any of chuck 's meetings dead in the water , or is that still a possibility ? professor e: uh , they seem to have some problems with it . we can we can talk about that later . um , but , again , jerry is jerry 's open so i mean , we have two speech meetings , one uh network meeting , uh jerry was open to it but i i s one of the things that i think is a little a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably ca n't do it every week . you know ? i i i i think that that people are gon na feel uh are gon na feel a little bit constrained . now , it might get a little better if we do n't have them do the digits all the time . and the then so then they can just really sort of try to put the mikes on and then just charge in and grad g: yep . phd c: what if we give people you know , we cater a lunch in exchange for them having their meeting here or something ? postdoc b: well , you know , i i do think eating while you 're doing a meeting is going to be increasing the noise . phd c: ok . postdoc b: but i had another question , which is um , you know , in principle , w um , i know that you do n't want artificial topics , phd c: alright , alright , alright . postdoc b: but um it does seem to me that we might be able to get subjects from campus to come down and do something that would n't be too artificial . i mean , we could political discussions , or or something or other , phd c: no , definitely . postdoc b: and i you know , people who are because , you know , there 's also this constraint . we d it 's like , you know , the the uh goldibears goldi goldilocks , it 's like you do n't want meetings that are too large , but you do n't want meetings that are too small . and um a and it just seems like maybe we could exploit the subj human subject p p pool , in the positive sense of the word . phd a: well , even i mean , coming down from campus is sort of a big thing , but what about postdoc b: we could pay subjects . phd a: or what about people in the in the building ? phd c: yeah , i was thinking , there 's all these other peo phd a: i mean , there 's the state of california downstairs , and phd c: yeah . i mean grad g: i just really doubt that uh any of the state of california meetings would be recordable and then releasable to the general public . postdoc b: yeah . phd a: oh . phd c: mm - hmm . grad g: so i i mean i talked with some people at the haas business school who are i who are interested in speech recognition phd c: alright , well . grad g: and , they sort of hummed and hawed and said `` well maybe we could have meetings down here `` , but then i got email from them that said `` no , we decided we 're not really interested and we do n't wan na come down and hold meetings . `` so , i think it 's gon na be a problem to get people regularly . phd a: what about joachim , maybe he can professor e: but but we c but i think , you know , we get some scattered things from this and that . and i i d i do think that maybe we can get somewhere with the with the radio . phd c: mm - hmm . professor e: uh i i have better contacts in radio than in television , but phd a: you could get a lot of lively discussions from those radio ones . phd c: well , and they 're already they 're these things are already recorded , grad g: yep . professor e: yeah . phd c: we do n't have to ask them to even and i 'm not sure wh how they record it , but they must record from individual professor e: n well no , i 'm not talking about ones that are already recorded . i 'm talking about new ones phd c: why why not ? professor e: because because because we would be asking them to do something different . phd c: well , we can find out . i know for instance mark liberman was interested uh in in ldc getting data , uh , and professor e: right , that 's the found data idea . phd c: yeah . professor e: but what i 'm saying is uh if i talk to people that i know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike . phd c: mm - hmm . professor e: and u i think routinely they would not do this . so , since i 'm interested in the distant mike stuff , i wan na make sure that there is at least that somewhere phd c: right . great . ok . professor e: and uh but if we ask them to do that they might be intrigued enough by the idea that they uh might be e e willing to the i might be able to talk them into it . phd c: mm - hmm . grad g: um . we 're getting towards the end of our disk space , so we should think about trying to wrap up here . phd c: that 's a good way to end a meeting . professor e: ok . well i do n't why do n't we why d u why do n't we uh uh turn them turn grad g: ok , leave leave them on for a moment until i turn this off , cuz that 's when it crashed last time . postdoc b: oh . that 's good to know . professor e: turning off the microphone made it crash . well postdoc b: that 's good to know . professor e: ok .","output":"approximately 12-13 hours of meeting recorder data have been collected , roughly 45 minutes of which have been transcribed . additional meetings by other icsi research groups will be recorded . a suggestion was made that multi-channel data also be collected in cooperation with local media broadcasters , and that such events might be recorded live from icsi ."},{"instruction":"what was the future of data collection ?","input":"professor e: so . ok . does n't look like it crashed . that 's great . grad g: so i think maybe what 's causing it to crash is i keep starting it and then stopping it to see if it 's working . and so i think starting it and then stopping it and starting it again causes it to crash . so , i wo n't do that anymore . postdoc b: and it looks like you 've found a way of uh mapping the location to the without having people have to give their names each time ? phd a: sounds like an initialization thing . postdoc b: i mean it 's like you have the so you know that grad g: no . postdoc b: i mean , are you going to write down that i sat here ? grad g: i 'm gon na collect the digit forms and write it down . postdoc b: ok . phd c: oh , ok . grad g: so so they should be right with what 's on the digit forms . ok , so i 'll go ahead and start with digits . u and i should say that uh , you just pau you just read each line an and then pause briefly . professor e: and start by giving the transcript number . phd a: tran phd d: transcript uh . ok , ok . phd a: oh sorry , go ahead . professor e: so uh , you see , don , the unbridled excitement of the work that we have on this project . grad h: ok . professor e: it 's just uh grad h: umh . professor e: uh , you know , it does n't seem like a bad idea to have { comment } that information . grad g: and i 'm surprised i sort of i 'm surprised i forgot that , professor e: yeah , i i 'd i think it 's some grad g: but uh i think that would be a good thing to add . after i just printed out a zillion of them . professor e: yeah , well , that 's um , so i i do have a a an agenda suggestion . uh , we i think the things that we talk about in this meeting uh tend to be a mixture of uh procedural uh mundane things and uh research points and um i was thinking i think it was a meeting a couple of weeks ago that we we spent much of the time talking about the mundane stuff cuz that 's easier to get out of the way and then we sort of drifted into the research and maybe five minutes into that andreas had to leave . so uh i 'm suggesting we turn it around and and uh sort of we have anybody has some mundane points that we could send an email later , uh hold them for a bit , and let 's talk about the the research - y kind of things . um , so um the one th one thing i know that we have on that is uh we had talked a a couple weeks before um uh about the uh the stuff you were doing with with uh um uh l l attempting to locate events , we had a little go around trying to figure out what you meant by `` events `` but i think , you know , what we had meant by `` events `` i guess was uh points of overlap between speakers . but i th i gather from our discussion a little earlier today that you also mean uh interruptions with something else phd d: yeah . professor e: like some other noise . phd d: uh - huh . yeah . professor e: yes ? you mean that as an event also . phd d: to professor e: so at any rate you were you 've you 've done some work on that phd d: right . professor e: and um then the other thing would be it might be nice to have a preliminary discussion of some of the other uh research uh areas that uh we 're thinking about doing . um , i think especially since you you have n't been in in these meetings for a little bit , maybe you have some discussion of some of the p the plausible things to look at now that we 're starting to get data , uh and one of the things i know that also came up uh is some discussions that that uh that uh jane had with lokendra uh about some some some um uh work about i i i d i i do n't want to try to say cuz i i 'll say it wrong , but anyway some some potential collaboration there about about the about the working with these data . phd c: oh . sure . professor e: so . so , uh . grad g: you wan na just go around ? professor e: uh . well , i do n't know if we if this is sort of like everybody has something to contribute sort of thing , i think there 's just just a couple a couple people primarily um but um uh , wh why do n't actually i think that that last one i just said we could do fairly quickly so why do n't you you start with that . postdoc b: ok . shall i shall i just start ? ok . professor e: yeah , just explain what it was . postdoc b: um , so , uh , he was interested in the question of you know , relating to his to the research he presented recently , um of inference structures , and uh , the need to build in , um , this this sort of uh mechanism for understanding of language . and he gave the example in his talk about how um , e a i 'm remembering it just off the top of my head right now , but it 's something about how um , i `` joe slipped `` you know , `` john had washed the floor `` or something like that . and i do n't have it quite right , but that kind of thing , where you have to draw the inference that , ok , there 's this time sequence , but also the the the causal aspects of the uh floor and and how it might have been the cause of the fall and that um it was the other person who fell than the one who cleaned it and it { comment } these sorts of things . so , i looked through the transcript that we have so far , { comment } and um , fou identified a couple different types of things of that type and um , one of them was something like uh , during the course of the transcript , um um , w we had gone through the part where everyone said which channel they were on and which device they were on , and um , the question was raised `` well , should we restart the recording at this point ? `` and and dan ellis said , `` well , we 're just so far ahead of the game right now we really do n't need to `` . now , how would you interpret that without a lot of inference ? so , the inferences that are involved are things like , ok , so , how do you interpret `` ahead of the game `` ? you know . so it 's the it 's i what you what you int what you draw you know , the conclusions that you need to draw are that space is involved in recording , grad g: hmm , metaphorically . postdoc b: that um , i that i we have enough space , and he continues , like `` we 're so ahead of the game cuz now we have built - in downsampling `` . so you have to sort of get the idea that um , `` ahead of the game `` is sp speaking with respect to space limitations , that um that in fact downsampling is gaining us enough space , and that therefore we can keep the recording we 've done so far . but there are a lot of different things like that . grad g: so , do you think his interest is in using this as a data source , or training material , or what ? professor e: well , i i should maybe interject to say this started off with a discussion that i had with him , so um we were trying to think of ways that his interests could interact with ours grad g: mm - hmm . professor e: and um uh i thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with jane 's help , look into some of the data that we 're already have and see , is there anything to this at all ? grad g: mm - hmm . professor e: is there any point which you think that , you know , you could gain some advantage and some potential use for it . cuz it could be that you 'd look through it and you say `` well , this is just the wrong task for for him to pursue his `` grad g: wrong , yeah . professor e: and and uh i got the impression from your mail that in fact there was enough things like this just in the little sample that that you looked at that that it 's plausible at least . postdoc b: it 's possible . uh , he was he he you know we met and he was gon na go and uh you know , y look through them more systematically professor e: yeah . postdoc b: and then uh meet again . professor e: yeah . postdoc b: so it 's , you know , not a matter of a professor e: yeah . postdoc b: but , yeah , i think i think it was optimistic . professor e: so anyway , that 's that 's e a quite different thing from anything we 've talked about that , you know , might might might come out from some of this . phd c: but he can use text , basically . i mean , he 's talking about just using text postdoc b: that 's his major i mentioned several that w had to do with implications drawn from intonational contours phd c: pretty much , or ? postdoc b: and that was n't as directly relevant to what he 's doing . he 's interested in these these knowledge structures , phd c: ok . phd d: yeah , interesting . postdoc b: inferences that you draw i from professor e: i mean , he certainly could use text , but we were in fact looking to see if there is there is there something in common between our interest in meetings and his interest in in in this stuff . so . grad g: and i imagine that transcripts of speech i mean text that is speech probably has more of those than sort of prepared writing . i i do n't know whether it would or not , but it seems like it would . professor e: i do n't know , probably de probably depends on what the prepared writing was . but . postdoc b: yeah , i do n't think i would make that leap , because i in narratives , you know i mean , if you spell out everything in a narrative , it can be really tedious , grad g: mm - hmm . postdoc b: so . grad g: yeah , i 'm just thinking , you know , when you 're when you 're face to face , you have a lot of backchannel and and postdoc b: oh . that aspect . grad g: yeah . and so i think it 's just easier to do that sort of broad inference jumping if it 's face to face . i mean , so , if i just read that dan was saying `` we 're ahead of the game `` { comment } in that in that context , postdoc b: well yeah . grad g: i might not realize that he was talking about disk space as opposed to anything else . postdoc b: i you know , i i had several that had to do with backchannels and this was n't one of them . grad g: uh - huh . postdoc b: this this one really does um m make you leap from so he said , you know , `` we 're ahead of the game , w we have built - in downsampling `` . grad g: mm - hmm . postdoc b: and the inference , i if you had it written down , would be grad g: i guess it would be the same . postdoc b: uh - huh . but there are others that have backchannelling , it 's just he was less interested in those . phd f: can i sorry to interrupt . um , i f f f i 've @ @ { comment } d a minute uh , several minutes ago , i , like , briefly was was not listening and so who is `` he `` in this context ? phd c: yeah , there 's a lot of pronoun phd f: ok . so i was just realizing we 've you guys have been talking about `` he `` um for at least uh , i do n't know , three three four minutes without ever mentioning the person 's name again . phd c: i believe it . yeah . actually to make it worse , { comment } uh , morgan uses `` you `` and `` you `` phd f: so this is this is this is gon na be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort . grad g: it 's in my notes . phd c: with gaze and no identification , or i just wrote this down . yeah , actually . cuz morgan will say well , `` you had some ideas `` phd d: yeah . phd f: you just wrote this ? phd c: and he never said li - he looked grad g: well , i think he 's doing that intentionally , phd c: right , so it 's great . grad g: are n't you ? phd c: so this is really great phd f: right . phd c: because the thing is , because he 's looking at the per even for addressees in the conversation , phd d: yeah . phd f: mm - hmm . phd c: i bet you could pick that up in the acoustics . just because your gaze is also correlated with the directionality of your voice . professor e: uh - huh . could be . postdoc b: can we professor e: yeah . that would be tou grad g: oh , that would be interesting . phd c: yeah , so that , i mean , to even know um when phd d: yeah . phd c: yeah , if you have the p z ms you should be able to pick up what a person is looking at from their voice . grad g: well , especially with morgan , with the way we have the microphones arranged . i 'm sort of right on axis and it would be very hard to tell . phd c: right . grad g: uh . postdoc b: oh , but you 'd have the phd c: put morgan always like this postdoc b: you 'd have fainter phd c: and postdoc b: would n't you get fainter reception out here ? professor e: well , these grad g: sure , but i think if i 'm talking like this ? right now i 'm looking at jane and talking , now i 'm looking at chuck and talking , i do n't think the microphones would pick up that difference . phd c: but you do n't have this this problem . postdoc b: i see . phd c: morgan is the one who does this most . grad g: so if i 'm talking at you , or i 'm talking at you . professor e: i probably been affect no , i th i think i 've been affected by too many conversations where we were talking about lawyers and talking about and concerns about `` oh gee is somebody going to say something bad ? `` and so on . grad g: lawyers . professor e: and so i so i 'm i 'm tending to stay away from people 's names even though uh postdoc b: i am too . phd c: even though you could pick up later on , just from the acoustics who you were t who you were looking at . postdoc b: i am too . grad g: and we did mention who `` he `` was . phd c: yeah . professor e: yeah . phd f: right , but i missed it . grad g: early in the conversation . phd f: but it was uh phd c: yeah , yeah . professor e: yeah . grad g: do sh - can i say professor e: yeah . no no , there 's phd f: yeah . grad g: or or is that just too sensitive ? professor e: no no , it is n't sensitive at all . postdoc b: well professor e: i was just i was just i was overreacting just because we 've been talking about it . postdoc b: and in fact , it is it is it is sensitive . phd c: no , but that it 's interesting . professor e: it 's ok to postdoc b: i i came up with something from the human subjects people that i wanted to mention . i mean , it fits into the m area of the mundane , but they did say you know , i asked her very specifically about this clause of how , um , you know , it says `` no individuals will be identified uh , `` in any publication using the data . `` ok , well , individuals being identified , let 's say you have a a snippet that says , `` joe s uh thinks such - and - such about about this field , but i think he 's wrongheaded . `` now i mean , we 're we 're gon na be careful not to have the `` wrongheaded `` part in there , but but you know , let 's say we say , you know , `` joe used to think so - and - so about this area , in his publication he says that but i think he 's changed his mind . `` or whatever . then the issue of of being able to trace joe , because we know he 's well - known in this field , and all this and and tie it to the speaker , whose name was just mentioned a moment ago , can be sensitive . professor e: b but i postdoc b: so i think it 's really really kind of adaptive and wise to not mention names any more than we have to because if there 's a slanderous aspect to it , then how much to we wan na be able to have to remove ? professor e: yeah , well , there 's that . but i i mean i think also to some extent it 's just educating the human subjects people , in a way , because there 's if uh you know , there 's court transcripts , there 's there 's transcripts of radio shows i mean people say people 's names all the time . so i think it it ca n't be bad to say people 's names . it 's just that i i mean you 're right that there 's more poten if we never say anybody 's name , then there 's no chance of of of slandering anybody , phd c: but , then it wo n't i mean , if we if we professor e: but grad g: it 's not a meeting . phd c: yeah . i mean we should do whatever 's natural in a meeting if if we were n't being recorded . professor e: yeah . right , so i so my behavior is probably not natural . phd c: `` if person x `` professor e: so . postdoc b: well , my feeling on it was that it was n't really important who said it , you know . professor e: yeah . phd f: well , if you ha since you have to um go over the transcripts later anyway , you could make it one of the jobs of the people who do that to mark grad g: well , we t we t we talked about this during the anon anonymization . phd f: right . grad g: if we wan na go through and extract from the audio and the written every time someone says a name . and i thought that our conclusion was that we did n't want to do that . professor e: yeah , we really ca n't . but a actually , i 'm sorry . i really would like to push finish this off . postdoc b: i understand . no i just i just was suggesting that it 's not a bad policy p potentially . professor e: so it 's postdoc b: so , we need to talk about this later . professor e: yeah , i di i did n't intend it an a policy though . postdoc b: uh - huh . professor e: it was it was just it was just unconscious well , semi - conscious behavior . i sorta knew i was doing it but it was phd f: well , i still do n't know who `` he `` is . professor e: i i do i do n't remember who `` he `` is . phd c: no , you have to say , you still do n't know who `` he `` is , with that prosody . professor e: ah . uh , we were talking about dan at one point { comment } and we were talking about lokendra at another point . postdoc b: yeah , depends on which one you mean . professor e: and i do n't i do n't remember which which part . phd f: oh . phd c: it 's ambiguous , so it 's ok . professor e: uh , i think grad g: well , the inference structures was lokendra . phd f: but no . the inference stuff was was was lokendra . professor e: yeah . yeah . yeah . phd f: ok . that makes sense , yeah . phd c: and the downsampling must have been dan . professor e: um grad g: yeah . professor e: good yeah . phd c: it 's an inference . professor e: yeah , you could do all these inferences , yeah . grad g: yeah . professor e: yeah . um , i i would like to move it into into uh what jose uh has been doing postdoc b: yeah . professor e: because he 's actually been doing something . phd d: uh - huh . ok . professor e: so . right . phd f: as opposed to the rest of us . phd d: well - { comment } ok . i i remind that me my first objective eh , in the project is to to study difference parameters to to find a a good solution to detect eh , the overlapping zone in eh speech recorded . but eh , tsk , { comment } ehhh { comment } in that way { comment } i i i begin to to study and to analyze the ehn the recorded speech eh the different session to to find and to locate and to mark eh the the different overlapping zone . and eh so eh i was eh i am transcribing the the first session and i i have found eh , eh one thousand acoustic events , eh besides the overlapping zones , eh i i i mean the eh breaths eh aspiration eh , eh , talk eh , eh , clap , eh { comment } i do n't know what is the different names eh you use to to name the the n speech phd a: nonspeech sounds ? phd d: yeah . grad g: oh , i do n't think we 've been doing it at that level of detail . so . phd d: yeah . eh , i i i do i do n't need to to to mmm to m to label the the different acoustic , but i prefer because eh i would like to to study if eh , i i will find eh , eh , a good eh parameters eh to detect overlapping i would like to to to test these parameters eh with the another eh , eh acoustic events , to nnn to eh to find what is the ehm the false eh , the false eh hypothesis eh , nnn , which eh are produced when we use the the ehm this eh parameter eh i mean pitch eh , eh , difference eh , feature grad g: mm - hmm . phd a: you know i think some of these um that are the nonspeech overlapping events may be difficult even for humans to tell that there 's two there . grad g: so it was phd d: yeah . phd a: i mean , if it 's a tapping sound , you would n't necessarily or , you know , something like that , it 'd be it might be hard to know that it was two separate events . phd d: yeah . yeah . yeah . yeah . grad g: well you were n't talking about just overlaps phd d: ye grad g: were you ? you were just talking about acoustic events . phd d: i i i i t i t i talk eh about eh acoustic events in general , grad g: someone starts , someone stops yeah . phd a: oh . phd d: but eh my my objective eh will be eh to study eh overlapping zone . grad g: mm - hmm . phd d: eh ? { comment } n eh in twelve minutes i found eh , eh one thousand acoustic events . professor e: how many overlaps were there uh in it ? no no , how many of them were the overlaps of speech , though ? phd d: how many ? eh almost eh three hundred eh in one session grad g: oh , god ! phd d: in five eh in forty - five minutes . phd a: three hundred overlapping speech phd d: alm - three hundred overlapping zone . grad g: ugh . phd c: overlapping speech . phd d: with the overlapping zone , overlapping speech speech what eh different duration . phd a: mm - hmm . professor e: sure . postdoc b: does this ? so if you had an overlap involving three people , how many times was that counted ? phd d: yeah , three people , two people . eh , um i would like to consider eh one people with difference noise eh in the background , be professor e: no no , but i think what she 's asking is if at some particular for some particular stretch you had three people talking , instead of two , did you call that one event ? phd d: oh . oh . yeah . i consider one event eh for th for that eh for all the zone . this th i i i con i consider i consider eh an acoustic event , the overlapping zone , the period where three speaker or eh are talking together . grad g: well so let 's postdoc b: for grad g: so let 's say me and jane are talking at the same time , and then liz starts talking also over all of us . how many events would that be ? phd d: so - i do n't understand . grad g: so , two people are talking , { comment } and then a third person starts talking . phd d: yeah ? grad g: is there an event right here ? phd d: eh no . no no . for me is the overlapping zone , because because you you have s you have more one eh , more one voice eh , eh produced in a in in a moment . professor e: i see . grad g: so i if two or more people are talking . professor e: ok . yeah . so i think yeah . we just wanted to understand how you 're defining it . phd d: yeah . if professor e: so then , in the region between since there there is some continuous region , in between regions where there is only one person speaking . phd d: uh - huh . professor e: and one contiguous region like that you 're calling an event . phd d: uh - huh . professor e: is it are you calling the beginning or the end of it the event , phd d: yeah . professor e: or are you calling the entire length of it the event ? phd d: i consider the the , nnn the nnn , nnn eh , the entirety eh , eh , all all the time there were the voice has overlapped . professor e: ok . phd d: this is the idea . but eh i i do n't distinguish between the the numbers of eh speaker . uh , i 'm not considering eh the the ehm eh , the fact of eh , eh , for example , what did you say ? eh at first eh , eh two talkers are uh , eh speaking , and eh , eh a third person eh join to to that . for me , it 's eh it 's eh , all overlap zone , with eh several numbers of speakers is eh , eh the same acoustic event . wi - but uh , without any mark between the zone of the overlapping zone with two speakers eh speaking together , and the zone with the three speakers . postdoc b: that would j just be one . phd d: it one . one . postdoc b: ok . phd d: eh , with eh , a beginning mark and the ending mark . because eh for me , is the is the zone with eh some kind of eh distortion the spectral . professor e: got it . phd d: i do n't mind by the moment , by the moment . grad g: well , but but you could imagine that three people talking has a different spectral characteristic than two . phd d: i i do n't yeah , but eh but eh i have to study . { comment } what will happen in a general way , professor e: could . grad g: so . you had to start somewhere . professor e: yeah . we just w phd c: so there 's a lot of overlap . phd d: i i do n't know what eh will will happen with the grad g: yep . phd c: so . grad g: that 's a lot of overlap , phd d: yeah ? professor e: so again , that 's that 's three three hundred in forty - five minutes that are that are speakers , just speakers . grad g: yeah , for forty - five minutes . phd d: yeah . yeah . professor e: uh - huh . ok . yeah . postdoc b: but a a a th professor e: so that 's about eight per minute . postdoc b: but a thousand events in twelve minutes , that 's phd d: yeah , but yeah . phd c: but that can include taps . phd d: but professor e: uh . yeah . postdoc b: well , but a thousand taps in eight minutes is a l in twelve minutes is a lot . phd d: general . phd c: actually phd d: i i con i consider i consider acoustic events eh , the silent too . postdoc b: silent . grad g: silence starting or silence ending phd d: yeah , silent , ground to bec to detect eh because i consider acoustic event all the things are not eh speech . phd c: oh , ok . professor e: mm - hmm . phd a: oh . phd d: in ge in in in a general point of view . phd c: oh . professor e: ok , so how many of those thousand were silence ? phd c: alright . phd d: in the per phd f: not speech not speech or too much speech . phd d: too much speech . professor e: right . so how many of those thousand were silence , silent sections ? phd d: yeah . uh silent , i i i i do n't i i have n't the eh i i would like to to do a stylistic study professor e: yeah . phd d: and give you eh with the report eh from eh the the study from the the the session one session . professor e: yeah . yeah . phd d: and i i found that eh another thing . when eh eh i w i i was eh look at eh nnn , the difference speech file , um , for example , eh if eh we use the ehm the mixed file , to to transcribe , the the events and the words , i i saw that eh the eh speech signal , collected by the eh this kind of mike eh of this kind of mike , eh are different from the eh mixed signal eh , we eh collected by headphone . grad g: yep . phd d: and it 's right . professor e: yeah . grad g: right . phd d: but the problem is the following . the the the i i i knew that eh the signal eh , eh would be different , but eh the the problem is eh , eh we eh detected eh difference events in the speech file eh collected by by that mike uh qui compared with the mixed file . and so if when you transcribe eh only eh using the nnn the mixed file , it 's possible eh if you use the transcription to evaluate a different system , it 's possible you eh in the eh i and you use the eh speech file collected by the eh fet mike , to eh to nnn to do the experiments with the the system , professor e: mm - hmm . grad g: right . phd d: its possible to evaluate eh , eh or to consider eh acoustic events that which you marked eh in the mixed file , but eh they do n't appear in the eh speech signal eh collected by the by the mike . grad g: right . the the reason that i generated the mixed file was for ibm to do word level transcription , not speech event transcription . phd d: yeah . yeah . oh , it 's a good idea . it 's a good idea i think . grad g: so i agree that if someone wants to do speech event transcription , that the mixed signals here phd d: yeah . grad g: i mean , if i 'm tapping on the table , you it 's not gon na show up on any of the mikes , but it 's gon na show up rather loudly in the pzm . phd d: yeah . yeah . yeah . so and i i i say eh that eh , eh , or this eh only because eh i c i i in my opinion , it 's necessary to eh to eh to put the transcription on the speech file , collected by the objective signal . grad g: so . phd d: i mean the the the signal collected by the eh , the real mike in the future , in the prototype to to eh correct the initial eh segmentation eh with the eh real speech professor e: mm - hmm . the the the far - field , yeah . phd d: you have to to analyze you have to to process . because i i found a difference . professor e: yeah , well , just i mean , just in that that one s ten second , or whatever it was , example that adam had that that we we passed on to others a few months ago , there was that business where i g i guess it was adam and jane were talking at the same time and and uh , in the close - talking mikes you could n't hear the overlap , and in the distant mike you could . so yeah , it 's clear that if you wan na study if you wan na find all the places where there were overlap , it 's probably better to use a distant mike . phd f: that 's good . professor e: on the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes , phd d: yeah . phd c: but why ca n't you use the combination of the close - talking mikes , time aligned ? professor e: so it 's grad g: if you use the combination of the close - talking mikes , you would hear jane interrupting me , but you would n't hear the paper rustling . and so if you 're interested in phd c: i i mean if you 're interested in speakers overlapping other speakers and not the other kinds of nonspeech , that 's not a problem , professor e: some { comment } of it 's masking masked . phd d: yeah . phd a: were you interrupting him or was he interrupting you ? professor e: right . phd c: right ? grad g: right . phd d: yeah . grad g: although the other issue is that the mixed close - talking mikes i mean , i 'm doing weird normalizations and things like that . phd c: but it 's known . phd d: yeah . phd c: i mean , the normalization you do is over the whole conversation grad g: yep . phd c: is n't it , over the whole meeting . grad g: right . yep . phd c: so if you wanted to study people overlapping people , that 's not a problem . phd d: i i i think eh i saw the nnn the eh but eh i eh i have eh any results . i i i saw the the speech file collected by eh the fet mike , and eh eh signal eh to eh to noise eh relation is eh low . it 's low . professor e: mm - hmm . phd d: it 's very low . you would comp if we compare it with eh the headphone . grad g: yep . phd d: and i i found that nnn that eh , ehm , pr probably , grad g: did did you phd d: i 'm not sure eh by the moment , but it 's it 's probably that eh a lot of eh , eh for example , in the overlapping zone , on eh in in several eh parts of the files where you you can find eh , eh eh , smooth eh eh speech eh from eh one eh eh talker in the in the meeting , professor e: mm - hmm . mm - hmm . phd d: it 's probably in in that eh in in those files you you can not find you can not process because eh it 's confused with with noise . professor e: mm - hmm . phd d: and there are a lot of i think . but i have to study with more detail . but eh my idea is to to process only nnn , this eh nnn , this kind of s of eh speech . because i think it 's more realistic . i 'm not sure it 's a good idea , but eh professor e: no i grad g: well , it 's more realistic but it 'll it 'll be a lot harder . phd d: yeah . professor e: well , it 'd be hard , but on the other hand as you point out , if your if i if if your concern is to get uh the overlapping people people 's speech , you will you will get that somewhat better . phd d: mm - hmm . yeah . professor e: um , are you making any use uh you were you were working with th the data that had already been transcribed . phd d: with by jane . professor e: does it uh yes . phd d: yeah . professor e: now um did you make any use of that ? see i was wondering cuz we st we have these ten hours of other stuff that is not yet transcribed . phd d: yeah . yeah . professor e: do you phd d: the the transcription by jane , t eh i eh , i i i want to use to to nnn , eh to put i i it 's a reference for me . but eh the transcription eh for example , i i do n't i i 'm not interested in the in the in the words , transcription words , eh transcribed eh eh in eh follow in the in the in the speech file , but eh eh jane eh for example eh put a mark eh at the beginning eh of each eh talker , in the in the meeting , um eh she she nnn includes information about the zone where eh there are eh there is an overlapping zone . but eh there is n't any any mark , time temporal mark , to to c eh to mmm e - heh , to label { comment } the beginning and the end of the of the professor e: mm - hmm . ok . right , so she is phd d: ta i 'm i i i think eh we need this information to professor e: right . so the twelve you you it took you twelve hours of course this included maybe some some time where you were learning about what what you wanted to do , but but uh , it took you something like twelve hours to mark the forty - five minutes , your grad g: twelve minutes . phd d: twelve minutes . professor e: s twelve minutes ! phd d: twelve minutes . twelve . professor e: i thought you did forty - five minutes of phd d: no , forty - five minutes is the is the session , all the session . postdoc b: oh . professor e: oh , you have n't done the whole session . phd d: yeah , all is the the session . professor e: this is just twelve minutes . phd d: tw - twelve hours of work to to segment eh and label eh twelve minutes from a session of part of f professor e: oh . so { comment } let me back up again . so the when you said there were three hundred speaker overlaps , phd d: yeah . professor e: that 's in twelve minutes ? phd d: no no no . i i consider all the all the session because eh i i count the nnn the nnn the overlappings marked by by jane , professor e: oh , ok . postdoc b: oh , i see . phd d: in in in in the fin in in the forty - five minutes . professor e: ok . so it 's three hundred in forty - five minutes , but you have you have time uh , uh marked twelve minute the the the um overlaps in twelve minutes of it . phd d: yeah . professor e: got it . phd f: so , can i ask can i ask whether you found uh , you know , how accurate uh jane 's uh uh labels were as far as grad g: well , not just the overlaps , everything . phd f: you know , did she miss some overlaps ? or did she n ? phd d: but , by by the moment , i i do n't compare , my my temporal mark with eh jane , but eh i i want to do it . because eh eh i per perhaps i have eh errors in the in the marks , i and if i i compare with eh jane , it 's probably i i i can correct and and and to get eh eh a more accurately eh eh transcription in the file . professor e: yeah . grad g: well , also jane jane was doing word level . phd d: yeah . professor e: yeah . grad g: so we were n't concerned with { comment } exactly when an overlap started and stopped . phd f: right . right . phd c: well , not only a word level , but actually phd d: well phd f: i 'm expect i 'm not expecting phd d: no , it 's phd c: i mean , you did n't need to show the exact point of interruption , you just were showing at the level of the phrase or the level of the speech spurt , or grad g: right . professor e: mm - hmm . grad g: yep . postdoc b: well phd d: yeah . yeah . postdoc b: well , yeah , b yeah , i would say time bin . so my my goal is to get words with reference to a time bin , beginning and end point . phd c: yeah . phd d: yeah . phd c: right . phd d: yeah . postdoc b: and and sometimes , you know , it was like you could have an overlap where someone said something in the middle , phd d: yeah . postdoc b: but , yeah , w it just was n't important for our purposes to have it that i disrupt that unit in order to have , you know , a the words in the order in which they were spoken , it would have it would have been hard with the interface that we have . phd d: yeah . postdoc b: now , my a adam 's working on a of course , on a revised overlapping interface , phd d: uh - huh . grad g: right . phd d: i i i think it 's it 's a good eh work , postdoc b: but phd d: but eh i think we need eh eh more information . phd f: no , of course . postdoc b: yeah . phd f: i expect you to find more overlaps than than jane grad g: always need more for postdoc b: yeah . phd d: no , no . i i have to go to phd f: because you 're looking at it at a much more detailed level . phd d: i want eh i wanted to eh compare the the transcription . professor e: i have grad g: but if it takes sixty to one professor e: well , i but i have a suggestion about that . um , obviously this is very , very time - consuming , and you 're finding lots of things which i 'm sure are gon na be very interesting , but in the interests of making progress , uh might i s how how would it affect your time if you only marked speaker overlaps ? phd d: only . professor e: yes . phd d: yeah . professor e: do not mark any other events , phd d: uh - huh . professor e: but only mark speaker do you think that would speed it up quite a bit ? phd d: ok . ok . i i i i w i i wanted to professor e: do y do you think that would speed it up ? uh , speed up your your your marking ? phd d: nnn , i do n't understand very . professor e: it took you a long time to mark twelve minutes . phd d: yeah . oh , yeah , yeah . professor e: now , my suggestion was for the other thirty - three phd d: on - only to mark only to mark overlapping zone , but professor e: yeah , and my question is , if you did that , if you followed my suggestion , would it take much less time ? phd d: oh , yeah . sure . professor e: yeah ok . phd d: yeah sure . professor e: then i think it 's a good idea . phd d: sure sure . professor e: then i think it 's a good idea , because it phd d: sure , because i i need a lot of time to to put the label or to do that . yeah . professor e: yeah , i mean , we we know that there 's noise . grad g: and phd d: uh - huh . professor e: there 's there 's uh continual noise uh from fans and so forth , and there is uh more impulsive noise from uh taps and so forth phd d: yeah . professor e: and and something in between with paper rustling . we know that all that 's there and it 's a g worthwhile thing to study , but obviously it takes a lot of time to mark all of these things . phd d: yeah . professor e: whereas th i i would think that uh you we can study more or less as a distinct phenomenon the overlapping of people talking . phd d: uh - huh . ok . ok . professor e: so . then you can get the cuz you need if it 's three hundred uh i i it sounds like you probably only have fifty or sixty or seventy events right now that are really phd d: yeah . professor e: and and you need to have a lot more than that to have any kind of uh even visual sense of of what 's going on , much less any kind of reasonable statistics . grad g: right . phd c: now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the grad g: well , that 's that 's what i was gon na bring up . phd c: i mean , you should n't need to do this p completely by hand , professor e: um , ok , yeah . so let 's back up because you were n't here for an earlier conversation . phd c: right ? i 'm sorry . professor e: so the idea was that what he was going to be doing was experimenting with different measures such as the increase in energy , such as the energy in the lpc residuals , such as i mean there 's a bunch of things i mean , increased energy is - is sort of an obvious one . phd c: mm - hmm . in the far - field mike . professor e: yeah . phd c: oh , ok . professor e: um , and uh , it 's not obvious , i mean , you could you could do the dumbest thing and get get it ninety percent of the time . but when you start going past that and trying to do better , it 's not obvious what combination of features is gon na give you the you know , the right detector . so the idea is to have some ground truth first . and so the i the idea of the manual marking was to say `` ok this , i you know , it 's it 's really here `` . phd a: but i think liz is saying why not get it out of the transcripts ? phd c: what i mean is get it from the close - talking mikes . professor e: uh , yeah . phd c: a or ge get a first pass from those , professor e: we t we t w we t we talked about that . phd c: and then go through sort of it 'd be a lot faster probably to phd f: and you can grad g: yeah , that 's his , uh professor e: we we we talked about that . s but so it 's a bootstrapping thing and the thing is , phd c: yeah , i just professor e: the idea was , i we i i we thought it would be useful for him to look at the data anyway , and and then whatever he could mark would be helpful , phd c: right . professor e: and we could uh it 's a question of what you bootstrap from . you know , do you bootstrap from a simple measurement which is right most of the time and then you g do better , or do you bootstrap from some human being looking at it and then then do your simple measurements , uh from the close - talking mike . i mean , even with the close - talking mike you 're not gon na get it right all the time . phd c: well , that 's what i wonder , because um or how bad it is , professor e: well phd c: be um , because that would be interesting grad g: i 'm working on a program to do that , and phd c: especially because the bottleneck is the transcription . right ? i mean , we 've got a lot more data than we have transcriptions for . we have the audio data , we have the close - talking mike , professor e: yeah . phd c: so i mean it seems like one kind of project that 's not perfect , but um , that you can get the training data for pretty quickly is , you know , if you infer form the close - talking mikes where the on - off points are of speech , professor e: right , we discussed that . phd c: you know , how can we detect that from a far - field ? grad g: and postdoc b: oh . grad g: i 've i 've written a program to do that , phd c: ok , i 'm sorry i missed the grad g: and it , uh professor e: it 's ok . grad g: and so but it 's it 's doing something very , very simple . it just takes a threshold , based on on the volume , phd c: uh - huh . phd f: or you can set the threshold low and then weed out the false alarms by hand . phd c: right , by hand . yeah . phd f: yeah . grad g: um , and then it does a median filter , and then it looks for runs . and , it seems to work , i 've i 'm sort of fiddling with the parameters , to get it to actually generate something , and i have n't i do n't what i 'm working on was working on was getting it to a form where we can import it into the user interface that we have , into transcriber . and so i told i said it would take about a day . i 've worked on it for about half a day , grad h: i have to go . grad g: so give me another half day and i we 'll have something we can play with . phd c: ok . professor e: see , this is where we really need the meeting recorder query stuff to be working , because we 've had these meetings and we 've had this discussion about this , and i 'm sort of remembering a little bit about what we decided , phd c: right . i 'm sorry . i just professor e: but i could n't remember all of it . phd c: it professor e: so , i think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when when he he gets his thing going , grad g: but professor e: uh , and phd c: well , it 's definitely good to have somebody look at it . i was just thinking as a way to speed up you know , the amount of postdoc b: mm - hmm . professor e: that was that was exactly the notion that that that we discussed . phd c: ok . grad g: thanks . postdoc b: another thing we discussed was um that phd c: it looks good . professor e: so . phd c: i 'll be in touch . thanks . professor e: s see ya . yeah . postdoc b: was that um there m there was this already a script i believe uh that dan had written , { comment } that uh handle bleedthrough , i mean cuz you have this this close you have contamination from other people who speak loudly . grad g: yeah , and i have n't tried using that . it would probably help the program that i 'm doing to first feed it through that . it 's a cross - correlation filter . so i i have n't tried that , but that if it it might be something it might be a good way of cleaning it up a little . postdoc b: so , some thought of maybe having yeah , having that be a preprocessor and then run it through yours . grad g: exactly . yep . professor e: but but that 's a refinement postdoc b: that 's what we were discussing . professor e: and i think we wan na see try the simple thing first , cuz you add this complex thing up uh afterwards that does something good y y yo you sort of wan na see what the simple thing does first . grad g: yep . professor e: but uh , having having somebody have some experience , again , with with uh with marking it from a human standpoint , we 're i mean , i do n't expect jose to to do it for uh f fifty hours of { comment } of speech , but i mean we { comment } if uh if he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it . phd d: yeah . sure . sure . professor e: and when when uh adam was doing his automatic thing he could then compare to that and see what it was different . phd c: oh yeah , definitely . phd a: you know , i did i did uh something almost identical to this at one of my previous jobs , and it works pretty well . i mean , i almost exactly what you described , an energy detector with a median filter , you look for runs . and uh , you know , you can grad g: it seemed like the right thing to do . phd a: yeah . i mean , you you can get y i mean , you get them pretty close . grad g: that was with zero literature search . phd a: and so i think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to to do it . grad g: that 's good validation . phd a: yeah . postdoc b: is this proprietary ? phd a: uh . { comment } no . no . grad g: yeah , do you have a patent on it ? phd a: it was when i was working for the government . professor e: oh , then everybody owns it . it 's the people . postdoc b: well , i mean , is this something that we could just co - opt , or is it ? phd a: nah . postdoc b: no . ok . professor e: well , i i i he 's pretty close , anyway . i think i think it 's phd a: yeah , he 's it it does n't take a long time . postdoc b: right . i just thought if it was tried and true , then { comment } and he 's gone through additional levels of of development . grad g: just output . although if you if you have some parameters like what 's a good window size for the median filter phd a: oh ! { comment } i have to remember . i 'll think about it , and try to remember . phd f: and it might be different for government people . grad g: that 's alright . professor e: yeah , good enough for government work , as they say . phd c: they they phd a: di - dif different different bandwidth . phd f: they grad g: i was doing pretty short , you know , tenth of a second , { comment } sorts of numbers . phd f: ok . professor e: uh , i do n't know , it if if we want to uh so , uh , maybe we should move on to other other things in limited time . postdoc b: can i ask one question about his statistics ? so so in the tw twelve minutes , um , if we took three hundred and divided it by four , which is about the length of twelve minutes , i um , i 'd expect like there should be seventy - five overlaps . professor e: yeah . postdoc b: did you find uh more than seventy - five overlaps in that period , or ? phd d: more than ? postdoc b: more than how many overlaps in your twelve minutes ? phd d: how many ? eh , not @ @ i onl - only i i transcribe eh only twelve minutes from the professor e: yeah . phd d: but eh i i do n't co eh i do n't count eh the the overlap . postdoc b: the overlaps . ok . phd d: i consider i i the the nnn the the three hundred is eh considered only you your transcription . i have to to finish transcribing . so . grad g: i b i bet they 're more , because the beginning of the meeting had a lot more overlaps than than sort of the middle . phd d: yeah . grad g: middle or end . postdoc b: i 'm not sure . phd d: yeah . grad g: because i we 're we 're dealing with the uh , in the early meetings , we 're recording while we 're saying who 's talking on what microphone , { comment } and things like that , phd d: yeah . grad g: and that seems to be a lot of overlap . postdoc b: i think it 's an empirical question . phd d: yeah . postdoc b: i think we could find that out . phd d: yeah . grad g: yep . postdoc b: i 'm i 'm not sure that the beginning had more . professor e: so so i was gon na ask , i guess about any any other things that that that either of you wanted to talk about , especially since andreas is leaving in five minutes , that that you wan na go with . phd c: can i just ask about the data , like very straightforward question is where we are on the amount of data and the amount of transcribed data , just cuz i 'm i wanted to get a feel for that to sort of be able to know what what can be done first and like how many meetings are we recording professor e: right so there 's this this there 's this forty - five minute piece that jane transcribed . phd c: and professor e: that piece was then uh sent to ibm so they could transcribe so we have some comparison point . then there 's s a larger piece that 's been recorded and uh put on cd - rom and sent uh to ibm . right ? and then we do n't know . phd c: how many meetings is that ? like how many grad g: what 's that ? professor e: that was about ten hours , and there was about phd c: t ten it 's like ten meetings or something ? uh - huh . grad g: yeah , something like that . and then then we phd a: ten meetings that have been sent to ibm ? phd c: and professor e: yeah . grad g: well , i have n't sent them yet because i was having this problem with the missing files . professor e: oh . oh , that 's right , that had those have not been sent . phd a: h how many total have we recorded now , altogether ? professor e: we 're saying about twelve hours . grad g: about twelve by now . twelve or thirteen . phd c: uh - huh . and we 're recording only this meeting , like continuously we 're only recording this one now ? or ? professor e: no . no , so the the that 's the that 's the biggest one uh , chunk so far , grad g: nope . phd a: it was the morning one . phd c: ok . professor e: but there 's at least one meeting recorded of uh the uh uh natural language guys . grad g: jerry . phd c: do they meet every week , professor e: and then there phd c: or every professor e: uh , they do . w w and we talked to them about recording some more and we 're going to , uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded , phd c: great . professor e: and we 're gon na start recording them . they 're they meet on tuesdays . we 're gon na start recording them next week . so actually , we 're gon na h start having a a pretty significant chunk and so , you know , adam 's sort of struggling with trying to get things to be less buggy , and come up quicker when they do crash and stuff things like that , now that uh the things are starting to happen . so right now , yeah , i th i 'd say the data is predominantly meeting meetings , but there are scattered other meetings in it and that that amount is gon na grow uh so that the meeting meetings will probably ultimately i if we 're if we collect fifty or sixty hours , the meeting meetings it will probably be , you know , twenty or thirty percent of it , not not not eighty or ninety . but . phd c: so there 's probably there 's three to four a week , grad g: that 's what we 're aiming for . phd c: that we 're aiming for . professor e: yeah . phd c: and they 're each about an hour or something . professor e: yeah , yeah . grad g: although yeah . we 'll find out tomorrow whether we can really do this or not . phd c: so ok . professor e: yeah and th the the other thing is i 'm not pos i 'm sort of thinking as we 've been through this a few times , that i really do n't know maybe you wan na do it once for the novelty , but i do n't know if in general we wan na have meetings that we record from outside this group do the digits . grad g: right . professor e: because it 's just an added bunch of weird stuff . phd c: yeah . professor e: and , you know , we we h we 're highly motivated . uh in fact , the morning group is really motivated cuz they 're working on connected digits , so it 's grad g: actually that 's something i wanted to ask , is i have a bunch of scripts to help with the transcription of the digits . professor e: yeah . grad g: we do n't have to hand - transcribe the digits because we 're reading them and i have those . phd c: right . professor e: yeah . grad g: and so i have some scripts that let you very quickly extract the sections of each utterance . but i have n't been ru i have n't been doing that . um , if i did that , is someone gon na be working on it ? professor e: uh , yeah , i i think definitely s so absolutely . grad g: i mean , is it something of interest ? professor e: yeah , whoever we have working on the acoustics for the meeting recorder are gon na start with that . grad g: ok . i mean , i i 'm i 'm interested in it , i just do n't have time to do it now . phd f: i was these meetings i 'm sure someone thought of this , but these this uh reading of the numbers would be extremely helpful to do um adaptation . grad g: so phd f: um . grad g: yep . yep . phd c: actually i have o grad g: i i would really like someone to do adaptation . phd f: mm - hmm . grad g: so if we got someone interested in that , i think it would be great for meeting recorder . professor e: well i mean , one of the things i wanted to do , uh , that i i talked to to don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , grad g: since it 's the same people over and over . phd f: mm - hmm . professor e: to try to get rid of some of the effects of the the the far - field effects . um , i mean we have the party line has been that echo cancellation is not the right way to handle the situation phd f: mm - hmm . professor e: because people move around , and uh , if if it 's if it 's uh not a simple echo , like a cross - talk kind of echo , but it 's actually room acoustics , it 's it 's it 's you ca n't really do inversion , phd f: mm - hmm . professor e: and even echo cancellation is going to uh be something it may you someone may be moving enough that you are not able to adapt quickly and so the tack that we 've taken is more `` lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal `` . phd f: mm - hmm . professor e: uh , that 's the party line . but it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous . it 's good good to sort of test them , actually . and so we have n't had anybody try to do a good serious job on echo cancellation and we should know how well that can do . so that 's something i 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . um , there was a have been some nice talks recently by by lucent on on their b phd f: hmm . professor e: the block echo cancellation particularly appealed to me , uh you know , trying and change it sample by sample , but you have some reasonable sized blocks . { comment } and um , you know , th phd a: w what is the um the artifact you try to you 're trying to get rid of when you do that ? phd f: ciao . professor e: uh so it 's it you have a a direct uh uh , what 's the difference in if you were trying to construct a linear filter , that would um phd f: i 'm signing off . professor e: yeah . that would subtract off { comment } the um uh parts of the signal that were the aspects of the signal that were different between the close - talk and the distant . you know , so so uh um i guess in most echo cancellation yeah , so you given that um yeah , so you 're trying to so you 'd there 's a a distance between the close and the distant mikes so there 's a time delay there , and after the time delay , there 's these various reflections . and if you figure out well what 's the there 's a a least squares algorithm that adjusts itself adjusts the weight so that you try to subtract essentially to subtract off uh different uh different reflections . right ? so let 's take the simple case where you just had you had some uh some delay in a satellite connection or something and then there 's a there 's an echo . it comes back . and you want to adjust this filter so that it will maximally reduce the effect of this echo . phd a: so that would mean like if you were listening to the data that was recorded on one of those . uh , just the raw data , you would you might hear kind of an echo ? and and then this noise cancellation would get professor e: well , i 'm i 'm i 'm saying that 's a simplified version of what 's really happening . { comment } what 's really happening is well , when i 'm talking to you right now , you 're getting the direct sound from my speech , but you 're also getting , uh , the indirect sound that 's bounced around the room a number of times . ok ? so now , if you um try to r you to completely remove the effect of that is sort of impractical for a number of technical reasons , but i but not to try to completely remove it , that is , invert the the room response , but just to try to uh uh eliminate some of the the effect of some of the echos . um , a number of people have done this so that , say , if you 're talking to a speakerphone , uh it makes it more like it would be , if you were talking right up to it . so this is sort of the st the straight - forward approach . you say i i i want to use this uh this item but i want to subtract off various kinds of echos . so you construct a filter , and you have this this filtered version uh of the speech um gets uh uh gets subtracted off from the original speech . then you try to you try to minimize the energy in some sense . and so um uh with some constraints . phd a: kind of a clean up thing , that professor e: it 's a clean up thing . right . phd a: ok . professor e: so , echo cancelling is is , you know , commonly done in telephony , and and and it 's sort of the obvious thing to do in this situation if you if , you know , you 're gon na be talking some distance from a mike . phd a: when uh , i would have meetings with the folks in cambridge when i was at bbn over the phone , they had a um some kind of a special speaker phone and when they would first connect me , it would come on and we 'd hear all this noise . and then it was uh and then it would come on and it was very clear , professor e: yeah . phd a: you know . professor e: right . so it 's taking samples , it 's doing adaptation , it 's adjusting weights , and then it 's getting the sum . so um , uh anyway that 's that 's kind of a reasonable thing that i 'd like to have somebody try somebody look and and the digits would be a reasonable thing to do that with . i think that 'd be enough data plenty of data to do that with , and i for that sort of task you would n't care whether it was uh large vocabulary speech or anything . uh . um postdoc b: is brian kingsbury 's work related to that , or is it a different type of reverberation ? professor e: brian 's { comment } kingsbury 's work is an example of what we did f f from the opposite dogma . right ? which is what i was calling the `` party line `` , which is that uh doing that sort of thing is not really what we want . we want something more flexible , uh i i where people might change their position , and there might be , you know there 's also um oh yeah , noise . so the echo cancellation does not really allow for noise . it 's if you have a clean situation but you just have some delays , then we 'll figure out the right the right set of weights for your taps for your filter in order to produce the effect of those those echos . but um if there 's noise , then the very signal that it 's looking at is corrupted so that it 's decision about what the right you know , right right uh delays are is , uh is right delayed signal is is is uh is incorrect . and so , in a noisy situation , um , also in a in a situation that 's very reverberant { comment } with long reverberation times { comment } and really long delays , it 's it 's sort of typically impractical . so for those kind of reasons , and also a a c a complete inversion , if you actually i mentioned that it 's kind of hard to really do the inversion of the room acoustics . um , that 's difficult because um often times the the um the system transfer function is such that when it 's inverted you get something that 's unstable , and so , if you you do your estimate of what the system is , and then you try to invert it , you get a filter that actually uh , you know , rings , and and uh goes to infinity . so it 's so there 's there 's there 's that sort of technical reason , and the fact that things move , and there 's air currents i mean there 's all sorts of all sorts of reasons why it 's not really practical . so for all those kinds of reasons , uh we we we sort of um , concluded we did n't want to in do inversion , and we 're even pretty skeptical of echo cancellation , which is n't really inversion , and um we decided to do this approach of taking uh , just picking uh features , which were uh will give you more something that was more stable , in the presence of , or absence of , room reverberation , and that 's what brian was trying to do . so , um , let me just say a couple things that i was i was gon na bring up . uh . let 's see . i guess you you actually already said this thing about the uh about the consent forms , which was that we now do n't have to so this was the human subjects folks who said this , { comment } or that that ? postdoc b: the a apparently i mean , we 're gon na do a revised form , of course . um but once a person has signed it once , then that 's valid for a certain number of meetings . she wanted me to actually estimate how many meetings and put that on the consent form . i told her that would be a little bit difficult to say . so i think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something . it wo n't be that many people who do it that often , but um just , you know , so long as they do n't forget that they 've done it , i guess . professor e: ok . um , back on the data thing , so there 's this sort of one hour , ten hour , a hundred hour sort of thing that that we have . we have we have an hour uh that that is transcribed , we have we have twelve hours that 's recorded but not transcribed , and at the rate we 're going , uh by the end of the semester we 'll have , i do n't know , forty or fifty or something , if we if this really uh well , do we have that much ? phd c: not really . it 's three to four per week . professor e: let 's see , we have phd c: so that 's what you know , that professor e: uh eight weeks , uh is phd c: so that 's not a lot of hours . professor e: eight weeks times three hours is twenty - four , so that 's yeah , so like thirty thirty hours ? phd a: three three hours . phd c: yeah . i mean , is there i know this sounds tough but we 've got the room set up . um i was starting to think of some projects where you would use well , similar to what we talked about with uh energy detection on the close - talking mikes . there are a number of interesting questions that you can ask about how interactions happen in a meeting , that do n't require any transcription . so what are the patterns , the energy patterns over the meeting ? and i 'm really interested in this but we do n't have a whole lot of data . so i was thinking , you know , we 've got the room set up and you can always think of , also for political reasons , if icsi collected you know , two hundred hours , that looks different than forty hours , even if we do n't transcribe it ourselves , professor e: but i do n't think we 're gon na stop at the end of this semester . phd c: so professor e: right ? so , i th i think that if we are able to keep that up for a few months , we are gon na have more like a hundred hours . phd c: i mean , is there are there any other meetings here that we can record , especially meetings that have some kind of conflict in them { comment } or some kind of deci i mean , that are less well i do n't uh , that have some more emotional aspects to them , or strong grad g: we had some good ones earlier . phd c: there 's laughter , um i 'm talking more about strong differences of opinion meetings , maybe with manager types , or grad g: i think it 's hard to record those . phd c: to be allowed to record them ? postdoc b: it 's also likely that people will cancel out afterwards . phd c: ok . professor e: yeah , people will get postdoc b: but i but i wanted to raise the kpfa idea . phd c: ok . well , if there is , anyway . professor e: yeah , i was gon na mention that . grad g: oh , that 's a good idea . that 's that would be a good match . professor e: yeah . so yeah . so i i uh , i i 'd mentioned to adam , and that was another thing i was gon na talk uh , mention to them before { comment } that uh there 's uh it it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media . because , you know , we had talked before about the problem about using found data , { comment } that that uh it 's just set up however they have it set up and we do n't have any say about it and it 's typically one microphone , in a , uh , uh or and and so it does n't really give us the the the uh characteristics we want . um and so i do think we 're gon na continue recording here and record what we can . but um , it did occur to me that we could go to friends in broadcast media and say `` hey you have this panel show , or this you know , this discussion show , and um can you record multi - channel ? `` and uh they may be willing to record it uh with phd c: with lapel mikes or something ? professor e: well , they probably already use lapel , but they might be able to have it it would n't be that weird for them to have another mike that was somewhat distant . phd c: right . professor e: it would n't be exactly this setup , but it would be that sort of thing , and what we were gon na get from uw , you know , assuming they they they start recording , is n't als also is not going to be this exact setup . phd c: right . no , i think that 'd be great , if we can get more data . professor e: so , { comment } i i i i was thinking of looking into that . the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , { comment } uh that we could invite them to have like some of their { comment } record some of their shows here . postdoc b: wow ! phd c: well or the thing is , they 're not as averse to wearing one of these head - mount i mean , they 're on the radio , grad g: right , as we are . phd c: right ? so . { comment } um , i think that 'd be fantastic professor e: right . phd c: cuz those kinds of panels and those have interesting professor e: yeah . phd c: th - that 's an a side of style a style that we 're not collecting here , so it 'd be great . professor e: and and the i mean , the other side to it was the what which is where we were coming from i 'll i 'll talk to you more about it later { comment } is that is that there 's there 's uh the radio stations and television stations already have stuff worked out presumably , uh related to , you know , legal issues and and permissions and all that . i mean , they already do what they do do whatever they do . so it 's uh , it 's so it 's so it 's another source . so i think it 's something we should look into , you know , we 'll collect what we collect here hopefully they will collect more at uw also and um and maybe we have this other source . but yeah i think that it 's not unreasonable to aim at getting , you know , significantly in excess of a hundred hours . i mean , that was sort of our goal . the thing was , i was hoping that we could @ @ in the under this controlled situation we could at least collect , you know , thirty to fifty hours . and at the rate we 're going we 'll get pretty close to that i think this semester . and if we continue to collect some next semester , i think we should , uh phd c: right . yeah i was mostly trying to think , `` ok , if you start a project , within say a month , you know , how much data do you have to work with . and you you wan na s you wan na sort of fr freeze your your data for awhile so um right now and we do n't have the transcripts back yet from ibm right ? do oh , do we now ? professor e: well , we do n't even have it for this f you know , forty - five minutes , that was phd c: so um , not complaining , i was just trying to think , you know , what kinds of projects can you do now versus uh six months from now professor e: yeah . phd c: and they 're pretty different , because professor e: yeah . so i was thinking right now it 's sort of this exploratory stuff where you you look at the data , you use some primitive measures and get a feeling for what the scatter plots look like , grad g: right . phd c: um right . right , right . professor e: and and and uh and meanwhile we collect , and it 's more like yeah , three months from now , or six months from now you can you can do a lot of other things . phd c: cuz i 'm not actually sure , just logistically that i can spend you know , i do n't wan na charge the time that i have on the project too early , before there 's enough data to make good use of the time . and that 's and especially with the student grad g: right . phd c: uh for instance this guy who seems professor e: yeah . phd c: uh anyway , i should n't say too much , but um if someone came that was great and wanted to do some real work and they have to end by the end of this school year in the spring , how much data will i have to work with , with that person . and so it 's professor e: i yeah , so i would think , exploratory things now . uh , three months from now um , i mean the transcriptions i think are a bit of an unknown cuz we have n't gotten those back yet as far as the timing , but i think as far as the collection , it does n't seem to me l like , uh , unreasonable to say that uh in january , you know , ro roughly uh which is roughly three months from now , we should have at least something like , you know , twenty - five , thirty hours . phd c: and we just do n't know about the transcription part of that , professor e: so that 's postdoc b: yeah , we need to i think that there 's a possibility that the transcript will need to be adjusted afterwards , phd c: so . i mean , it postdoc b: and uh es especially since these people wo n't be uh used to dealing with multi - channel uh transcriptions . phd c: right . professor e: yeah . postdoc b: so i think that we 'll need to adjust some and also if we wan na add things like um , well , more refined coding of overlaps , then definitely i think we should count on having an extra pass through . i wanted to ask another a a aspect of the data collection . there 'd be no reason why a person could n't get together several uh , you know , friends , and come and argue about a topic if they wanted to , right ? professor e: if they really have something they wan na talk about as opposed to something @ @ i mean , what we 're trying to stay away from was artificial constructions , but i think if it 's a real why not ? yeah . phd c: i mean , i 'm thinking , politically grad g: stage some political debates . postdoc b: you could do this , phd c: well yeah , postdoc b: you know . you could . phd c: or just if you 're if you ha if there are meetings here that happen that we can record even if we do n't um have them do the digits , { comment } or maybe have them do a shorter digit thing { comment } like if it was , you know , uh , one string of digits , or something , they 'd probably be willing to do . grad g: we do n't have to do the digits at all if we do n't want to . phd c: then , having the data is very valuable , cuz i think it 's um politically better for us to say we have this many hours of audio data , especially with the itr , if we put in a proposal on it . it 'll just look like icsi 's collected a lot more audio data . um , whether it 's transcribed or not um , is another issue , but there 's there are research questions you can answer without the transcriptions , or at least that you can start to answer . postdoc b: it seems like you could hold some meetings . grad g: yep . postdoc b: you know , you and maybe adam ? phd c: so . postdoc b: you you could you could maybe hold some additional meetings , if you wanted . phd a: would it help at all i mean , we 're already talking about sort of two levels of detail in meetings . one is uh um without doing the digits or , i guess the full - blown one is where you do the digits , and everything , and then talk about doing it without digits , what if we had another level , just to collect data , which is without the headsets and we just did the table - mounted stuff . phd c: need the close - talking mikes . phd a: you do , ok . phd c: i mean , absolutely , professor e: yeah . yeah . phd c: yeah . i 'm really scared grad g: it seems like it 's a big part of this corpus is to have the close - talking mikes . phd a: i see , ok . phd c: um or at least , like , me personally ? i would { comment } i could n't use that data . professor e: yeah . postdoc b: i agree . and mari also , phd c: um . postdoc b: we had this came up when she she was here . that 's important . phd c: so it 's a great idea , professor e: yeah , i i b by the by the way , i do n't think the transcriptions are actually , in the long run , such a big bottleneck . phd c: and if it were true than i would just do that , but it 's not that bad like the room is not the bottleneck , and we have enough time in the room , it 's getting the people to come in and put on the and get the setup going . professor e: i think the issue is just that we 're we 're blazing that path . right ? and and um d do you have any idea when when uh the you 'll be able to send uh the ten hours to them ? grad g: well , i 've been burning two c ds a day , which is about all i can do with the time i have . professor e: yeah . yeah . grad g: so it 'll be early next week . professor e: yeah , ok . so early next week we send it to them , and then then we check with them to see if they 've got it and we we start , you know asking about the timing for it . grad g: yep . professor e: so i think once they get it sorted out about how they 're gon na do it , which i think they 're pretty well along on , cuz they were able to read the files and so on . grad g: yep . professor e: right ? grad g: yeah , but professor e: well grad g: yeah , who knows where they are . phd a: have they ever responded to you ? grad g: nope . professor e: yeah , but you know , so they they they have you know , they 're volunteering their time and they have a lot of other things to do , phd c: what if grad g: yeah , you we ca n't complain . professor e: right ? but they but at any rate , they 'll i i think once they get that sorted out , they 're they 're making cassettes there , then they 're handing it to someone who they who 's who is doing it , and uh i think it 's not going to be i do n't think it 's going to be that much more of a deal for them to do thirty hours then to do one hour , i think . it 's not going to be thirty grad g: yep . i think that 's probably true . phd c: really ? so it 's the amount of professor e: it 's it 's just getting it going . grad g: it 's pipeline , pipeline issues . phd c: right . what about these lunch meetings grad g: once the pipeline fills . phd c: i mean , i do n't know , if there 's any way without too much more overhead , even if we do n't ship it right away to ibm even if we just collect it here for awhile , { comment } to record you know , two or three more meeting a week , just to have the data , even if they 're um not doing the digits , but they do wear the headphones ? professor e: but the lunch meetings are pretty much one person getting up and phd c: no , i meant , um , sorry , the meetings where people eat their lunch downstairs , maybe they do n't wan na be recorded , but grad g: oh , and we 're just chatting ? phd c: just the ch the chatting . grad g: yeah , we have a lot of those . phd c: i actually i actually think that 's useful data , um the chatting , grad g: yeah , the problem with that is i would i think i would feel a little constrained to you know ? uh , some of the meetings phd c: but ok . you do n't wan na do it , cuz ok . grad g: you know , our `` soccer ball `` meeting ? phd c: alright . grad g: i guess none of you were there for our soccer ball meeting . phd c: alright , { comment } so i 'll just throw it out there , if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it . grad g: that was hilarious . professor e: yeah . well , we should also check with mari again , because they because they were really intending , you know , maybe just did n't happen , but they were really intending to be duplicating this in some level . so then that would double what we had . uh . and there 's a lot of different meetings at uw uh i mean really m a lot more { comment } than we have here right cuz we 're not right on campus , grad g: right . professor e: so . phd a: is the uh , notion of recording any of chuck 's meetings dead in the water , or is that still a possibility ? professor e: uh , they seem to have some problems with it . we can we can talk about that later . um , but , again , jerry is jerry 's open so i mean , we have two speech meetings , one uh network meeting , uh jerry was open to it but i i s one of the things that i think is a little a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably ca n't do it every week . you know ? i i i i think that that people are gon na feel uh are gon na feel a little bit constrained . now , it might get a little better if we do n't have them do the digits all the time . and the then so then they can just really sort of try to put the mikes on and then just charge in and grad g: yep . phd c: what if we give people you know , we cater a lunch in exchange for them having their meeting here or something ? postdoc b: well , you know , i i do think eating while you 're doing a meeting is going to be increasing the noise . phd c: ok . postdoc b: but i had another question , which is um , you know , in principle , w um , i know that you do n't want artificial topics , phd c: alright , alright , alright . postdoc b: but um it does seem to me that we might be able to get subjects from campus to come down and do something that would n't be too artificial . i mean , we could political discussions , or or something or other , phd c: no , definitely . postdoc b: and i you know , people who are because , you know , there 's also this constraint . we d it 's like , you know , the the uh goldibears goldi goldilocks , it 's like you do n't want meetings that are too large , but you do n't want meetings that are too small . and um a and it just seems like maybe we could exploit the subj human subject p p pool , in the positive sense of the word . phd a: well , even i mean , coming down from campus is sort of a big thing , but what about postdoc b: we could pay subjects . phd a: or what about people in the in the building ? phd c: yeah , i was thinking , there 's all these other peo phd a: i mean , there 's the state of california downstairs , and phd c: yeah . i mean grad g: i just really doubt that uh any of the state of california meetings would be recordable and then releasable to the general public . postdoc b: yeah . phd a: oh . phd c: mm - hmm . grad g: so i i mean i talked with some people at the haas business school who are i who are interested in speech recognition phd c: alright , well . grad g: and , they sort of hummed and hawed and said `` well maybe we could have meetings down here `` , but then i got email from them that said `` no , we decided we 're not really interested and we do n't wan na come down and hold meetings . `` so , i think it 's gon na be a problem to get people regularly . phd a: what about joachim , maybe he can professor e: but but we c but i think , you know , we get some scattered things from this and that . and i i d i do think that maybe we can get somewhere with the with the radio . phd c: mm - hmm . professor e: uh i i have better contacts in radio than in television , but phd a: you could get a lot of lively discussions from those radio ones . phd c: well , and they 're already they 're these things are already recorded , grad g: yep . professor e: yeah . phd c: we do n't have to ask them to even and i 'm not sure wh how they record it , but they must record from individual professor e: n well no , i 'm not talking about ones that are already recorded . i 'm talking about new ones phd c: why why not ? professor e: because because because we would be asking them to do something different . phd c: well , we can find out . i know for instance mark liberman was interested uh in in ldc getting data , uh , and professor e: right , that 's the found data idea . phd c: yeah . professor e: but what i 'm saying is uh if i talk to people that i know who do these th who produce these things we could ask them if they could record an extra channel , let 's say , of a distant mike . phd c: mm - hmm . professor e: and u i think routinely they would not do this . so , since i 'm interested in the distant mike stuff , i wan na make sure that there is at least that somewhere phd c: right . great . ok . professor e: and uh but if we ask them to do that they might be intrigued enough by the idea that they uh might be e e willing to the i might be able to talk them into it . phd c: mm - hmm . grad g: um . we 're getting towards the end of our disk space , so we should think about trying to wrap up here . phd c: that 's a good way to end a meeting . professor e: ok . well i do n't why do n't we why d u why do n't we uh uh turn them turn grad g: ok , leave leave them on for a moment until i turn this off , cuz that 's when it crashed last time . postdoc b: oh . that 's good to know . professor e: turning off the microphone made it crash . well postdoc b: that 's good to know . professor e: ok .","output":"the group aims to collect over 100 hours of meeting recorder data in total . speaker consent forms are being revised . it was suggested that subjects should sign a new consent form after 10 recording sessions ."},{"instruction":"what was the general discussion of the meeting ?","input":"grad b:  grad d: how many batteries do you go through ? grad b: thank you . professor c: alright . phd a: sure . professor c: good . yeah . ok so , let 's get started . nancy said she 's coming and that means she will be . um . my suggestion is that robert and johno sort of give us a report on last week 's adventures uh to start . so everybody knows there were these guys f uh from heidelber - uh , uh , actually from uh dfki uh , part of the german smartkom project , who were here for the week and , i think got a lot done . grad e: yeah , i think so too . um . the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like `` roman numeral one , am smarticus . `` it actually says , `` roemisch einz , am smarticus , `` grad b: ok . grad e: which means it 's just using a german sythesis module for english sentences . grad b: ok . grad e: so uh , professor c: it does n't know `` i `` . grad b: ok . grad e: um , the uh grad b: oh , am spartacus . `` grad d: `` i am sm - i am smarticus `` is what it 's saying . phd a: right . grad b: verstehe . ok . grad d: i gue grad e: the uh sythesis is just a question of um , hopefully it 's just a question of exchanging a couple of files , once we have them . and , um , it 's not going to be a problem because we decided to stick to the so - called concept to speech approach . so i 'm i 'm i 'm going backwards now , so `` synthesis `` is where you sort of make this uh , make these sounds , and `` concept to speech `` is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . grad b: mm - hmm . grad e: and , uh , johno learned how to write xml tags . uh , and did write the tree adjoining grammar for some some sentences . no , right ? grad d: yeah . grad e: yeah , for a couple grad d: so . bu - uh , i the way the uh , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to a er in xml and there 's a conversion system for different uh , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is uh , in a lisp - like the knowledge base is in a lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have a basically , a goal and it , you know , says `` ok , well i 'm gon na try to do the greet - the - person goal , grad b: mm - hmm . grad d: so it just starts uh , it binds some variables and it just decides to , you know , do some subscold . basically , it just means `` build the tree . `` grad b: ok . grad d: and then it passes the tree onto , uh , the ge the generation module . grad e: but i think that the point is that out of the twelve possible utterances that the german system can do , we 've already written the the syntax trees for three or four . grad d: we yeah . so , the syntax trees are very simple . it 's like most of the sentences in one tree , grad b: mm - hmm . grad d: and instead of , you know , breaking down to , like , small units and building back up , they basically took the sentences , and basically cut them in half , or you know , into thirds or something like that , and made trees out of those . and so uh , uh tilman wrote a little tool that you could take lisp notation and generate an xml , uh , tree . uh , s what do ca structure from the from the lisp . and so basically you just say , you know , `` noun goes to `` , you know , er , nah , i do n't re i 've never been good at those . so there 's like the vp goes to n and those things in lisp , and it will generate for you . grad b: ok . n , n , v yeah , ok . alright . grad e: and because we 're sticking to that structure , the synthesis module does n't need to be changed . so all that f fancy stuff , and the texas speech version of it , which is actually the simpler version , is gon na be done in october which is much too late for us . so . this way we we worked around that . the , uh the system , um i can show you the system . i actually want , at least , maybe , you should be able to start it on your own . if you wan na play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on on on seventeen modules before they actually can stomach it , anything . and send in a a a couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we do n't have here . grad b: mm - hmm . grad e: and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was a lot of engineering stuff . no science in there whatsoever , but it 's working now , and um , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation . grad d: why i had i did need to chan generate different trees than the german ones , mainly because you know like uh , the gerund in in german is automatically taken care of with just a regular verb , grad e: you have to switch it on . grad b: mm - hmm . grad d: so i 'd uh have to add `` am walking , `` grad b: ok . grad d: or i 'd have to add a little stem for the `` am `` , when i build the built the tree . grad b: ok . yeah , i noticed that um , that some of the examples they had , had you know , non - english word orders and so on , you know . and then all that good stuff . so . professor c: alright . grad d: yeah . grad b: like . professor c: so it might be worth , keith , you looking at this , grad b: yeah . professor c: um grad b: i i still do n't i still do n't really understand e like grad d: well tilman s grad b: i mean we sort of say , um you know , i i still do n't exactly understand sort of the information flow uh in in this thing , or what the modules are and so on . so , you know , like just that such - and - such module uh um decides that it wants to achieve the goal of greeting the user , and then magically it sort of s professor c: yeah grad b: i mean , how does it know which syntactic structure to pull out , and all that ? professor c: i thi yeah . so . i think it 's not worth going over in the group , grad b: r uh sure . professor c: but sort of when you get free and you have the time uh either robert or johno or i can walk you through it . grad b: yeah , soon . ok . professor c: and you can ask all the questions about how this all fits together . grad b: that 's fine . professor c: it 's eee { comment } messy but once you understand it you understand it . it 's it 's there 's nothing really complicated about it . grad b: ok . grad e: no . grad b: and i remember one thing that that came up in the talk last wednesday . um , was this , i i think he talked about the idea of like , um he was talking about these lexicalized uh , uh , tree adjoining grammars where you sort of for each word you , um grad d: ok , you know how to do it ? grad b: for each lexical item , the lexical entry says what all the uh trees are that it can appear in . and of course , that 's not v that 's the opposite of constructional . that 's , you know , that 's that 's hpsg or whatever . professor c: right . grad b: you know ? professor c: right . now , we 're we 're not committed for our research to do any of those things . grad b: yeah . mm - hmm . professor c: so uh we are committed for our funding . grad b: right . professor c: ok ? to uh grad b: make our stuff fit to that . professor c: yeah , to n no , to just get the dem get the demos they need . grad b: uh - huh . professor c: ok ? so between us all we have t to get th the demos they need . if it turns out we can also give them lots more than that by , you know , tapping into other things we do , that 's great . grad d: you should probably move the microphone closer to your face . grad b: mm - hmm . professor c: but i it turns out not to be in an any of the contracts grad d: there 's like a little the twisty thing , you can move it with . grad b: ok . professor c: and , s deliberately . so , the reason i 'd like you to understand uh what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with a question of `` could we fit this deeper stuff in there ? `` or something . you know what the hell we we 're talking about fitting in . grad b: right . ok . professor c: so it 's just , uh in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? uh , is there anything we can give back , beyond th the sort of minimum requirements ? but none of that has a short time fuse . grad b: ok . professor c: so th the demo the demo requirements for this fall are sort of taken care of as of later this week or something . and then so , it 's probably fifteen months or something until there 's another serious demo requirement . grad b: oh ok . professor c: that does n't mean we do n't think about it for fifteen months , grad b: right . professor c: but it means we can not think about it for six months . grad b: right , yeah . professor c: so . the plan for this summer uh , really is to step back from the applied project , grad e: right . professor c: keep the d keep the context open , but actually go after the basic issues . grad b: hmm . oh ok . professor c: and , so the idea is there 's this uh , other subgroup that 's worrying about formalizing the nota getting a notation . but sort of in parallel with that , uh , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , grad b: mm - hmm . professor c: but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . grad b: yeah . ok . got it . professor c: it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and stuff . grad b: yeah . professor c: and , i don i do n't want you f feeling that you have to somehow meet all these other constraints . grad b: right , ok . professor c: um . and similarly with the parsing , uh we 're gon na worry about parsing uh , the general case you know , construction parser for general constructions . and , if we need a cut - down version for something , or whatever , we 'll worry about that later . grad b: ok . professor c: so i 'd like to , for the summer turn into science mode . grad b: ok . professor c: and i assume that 's also , uh , your plan as well . grad b: so i mean , the the point is that like the meetings um so far that i 've been at have been sort of been geared towards this demo , professor c: right . yeah . yeah . grad b: and then that 's going to go away pretty soon . professor c: but but we we 're swit grad b: ok . professor c: right . grad b: and then we 'll sort of shift gears a fairly substantially , professor c: yeah . grad e: it 's professor c: yeah . grad b: huh ? professor c: yeah . grad e: it 's got . what i what i think is is a good idea that i can can show to anyone who 's interested , we can even make a sort of an internal demo , and i i show you what i do , grad b: mm - hmm . grad e: i speak into it and you hear it talk , grad b: ok . grad e: and i can sort of walk f through the information . so , this is like in half hour or forty - five minutes . just fun . grad b: ok . grad e: and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , sort of , give a sensible answer . grad b: right . ok . professor c: so , c sh we could set that up as actually an institute wide thing ? just give a talk in the big room , and and so peo people know what 's going on ? when you 're ready ? grad e: absolutely . professor c: yeah i mean , that 's the kind of thing that 's the level at which you know we can just li invite everybody and say `` this is a project that we 've been working on and here 's a demo version of it `` and stuff like that . grad b: yeah . grad e: ok . well d we we do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're grad b: uh - huh . professor c: indeed . grad e: yeah . ok . makes sense . professor c: but any so that e e it 's clear , then , i think . actually , roughly starting uh let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . grad b: yeah . ok . professor c: but uh starting next meeting i think we want to flip into this mode where uh . i mean there are a lot of issues , what 's the ontology look like , grad b: mm - hmm . professor c: you know what do the constructions look like , what 's the execution engine look like , mmm lots of things . grad b: mm - hmm . professor c: but , more focused on uh an idealized version than just getting the demo out . now before we do that , let 's get back in oh ! but , it 's still , i think , useful for you to understand the demo version enough , so that you can can see what what it is that that uh it might eventually get retro - fitted into or something . grad b: yeah . ok , right . professor c: and johno 's already done that , uh , looked at the dem uh the looked at the smartkom stuff . grad d: wa uh to some de uh what what part of th the smartkom stuff ? professor c: well , the parser , and that stuff . grad d: oh yeah yeah . professor c: ok . anyway . so , the trip the report on these the last we we sort of interrupted you guys telling us about what happened last week . grad b: yeah . it 's alright . grad e: um . well it was just amazing to to see uh how how instable the whole thing is , professor c: maybe you 're done , then . grad e: and if you just take the and i g i got the feeling that we are the only ones right now who have a running system . i do n't know what the guys in kaiserslautern have running because e the version that is , the full version that 's on the server d does not work . and you need to do a lot of stuff to make it work . and so it 's and even tilman and ralf sort of said `` yeah there never was a really working version that uh did it without th all the shortcuts that they built in for the uh october @ @ version `` . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , uh it was fun to some extent , but the uh the outcome that is sort of of scientific interest is that i think both ralf and tilman um , i know that they enjoyed it here , and they r they they liked , uh , a lot of the stuff they saw here , what what we have been thinking about , and they 're more than willing to to um , cooperate , by all means . and um , part of my responsibility is uh to use our internal `` group - ware `` server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and and generating and constructions w we we sort of uh put it in there and they put what they do in there and maybe we can even um , get some overlap , get some synergy out of that . and um , the , uh if i find someone at in eml that is interested in that , um i i may even think that we could look take constructions and and generate from them because the tree adjoining grammars that that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g - like stuff , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're of course definitely focused on the understanding , um , pipeline . professor c: anyth - any other { comment } uh repo visit reports sort of stories ? uh we so we now know i think , what the landscape is like . grad b: mm - hmm . professor c: and so we just push on and and uh , do what we need to do . and one of the things we need to do is the um , and this i think is relatively tight tightly constrained , is to finish up this belief - net stuff . so . uh . and i was going to switch to start talking about that unless there 're m other more general questions . ok so here 's where we are on the belief - net stuff as far as i understand it . um . going back i guess two weeks ago uh robert had laid out this belief - net , missing only the connections . right ? that is { comment } so , he 'd put all th all the dots down , and we went through this , and , i think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . yeah { comment } we may run across one or two more . but of course the connections were n't . so , uh bhaskara and i went off and looked at some technical questions about were certain operations sort of legitimate belief - net computations and was there some known problem with them or had someone already uh , solved you know how to do this and stuff . and so bhaskara tracked that down . the answer seems to be uh , `` no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do `` . and , so the current state of things is that , again , starting now , um we 'd like to actually get a running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and uh , he 's gon na leave us an inheritance , which is a uh hopefully a belief - net that does these things . and there 're two aspects to it , one of which is , you know , technical , getting the coding right , and making it run , and uh stuff like that . and the other is the actual semantics . ok ? what all you know , what are the considerations and how and what are the ways in which they relate . so he doe h he does n't need help from this group on the technical aspects or if he does uh we 'll do that separately . grad b: mm - hmm . professor c: but in terms of what are the decisions and stuff like that , that 's something that we all have to work out . is is that right ? i mean that 's that 's both you guys ' understanding of where we are ? grad e: absolutely . professor c: ok . grad g: so , i guess , um is there like a latest version of the belief - net of the proposed belief - net ? like grad e: we had um decided grad g: like grad e: um . well , no , we did n't decide . we wanted to look into maybe getting it , the visualization , a bit clearer , but i think if we do it , um , sort of a paper version of all the nodes and then the connections between them , that should suffice . grad g: mm - hmm . yeah , that should be fine . professor c: yeah i mean , that 's a separate problem . grad d: yeah , i professor c: we do in the long run wan na do better visualization and all that stuff . grad e: yeah . professor c: that 's separable , yeah . grad d: i did look into that , uh in terms of , you know , exploding the nodes out and down ag professor c: yep . right . grad d: javabayes does not support that . i can imagine a way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it , professor c: not not at this point . grad d: and i went through all the other packages on murph - kevin murphy 's page , professor c: right . grad d: and i could n't find the necessary mix of free and uh with the gui and , with this thing that we want . professor c: well , we can p if it 's if we can pay yeah . if you know it 's paying a thousand dollars or something we can do that . ok ? so so do n't view free as as a absolute constraint . grad d: ok . ok , so then i 'll go back and look at the ones on the list that professor c: ok . and you can ask kevin . grad e: but grad g: yeah . grad d: mmm . grad e: but grad g: yeah , the one that uh people seem to use is uh hugin or whatever ? professor c: hugin , yeah that 's free . grad g: how exp i do n't think it 's is it free ? because i 've seen it advertised in places so i it seems to professor c: uh , it may be free to academics . like i i do n't know . i have a co { comment } i have a copy { comment } that i l i downloaded . grad g: ok . professor c: so , at one point it was free . grad g: ok . professor c: uh but yo i noticed people do use hugin so um , grad d: how do you spell that ? professor c: hugin . grad f: why professor c: and bhaskara can give you a pointer . so then , in any case , um but paying a lit you know , if i if it 's uh probably for university , it 's it 's gon na be real cheap anyway . but um , you know , if it 's fifty thousand dollars we are n't gon na do it . i 'm mean , we have no need for that . grad e: i i also s would suggest not to d spend two weeks in in in changing the the javabayes code . professor c: no , grad b: yeah . professor c: he 's not gon na do that . grad d: ok . grad e: i i will send you a pointer to a java applet that does that , it 's sort of a fish - eye . you you have a node , and you click on it , and it shows you all the connections , grad d: mmm . grad e: and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that does n't work , it 's not a problem we we need to solve right now . what i 'm what my job is , i will , um , give you the input in terms of of the internal structure . maybe node by node , or something like this ? or should i collect it all grad g: mm - hmm . grad e: and professor c: does n't matter . grad g: um , just any like like sort of rough representation of the entire belief - net is probably best . grad e: ok . and um you 're gon na be around ? t again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ? grad g: yeah i mean , yeah , i can like i c um . this week i guess um , kind of i have a lot of projects and stuff but after that i will generally be more free . so yes , i might i can be around . and g i mean , generally if you email me also i can be around on other days . grad e: yeah . ok . professor c: yeah and this is not a crisis that i mean , you do , e everybody who 's a student should , you know do their work , get their c courses all in good shape and and and and then we 'll dig d dig down on this . grad e: yeah , that 's yeah . ok . no , that 's good . that means i have i h i can spend this week doing it . so . grad g: ok . grad b: how do you go about this process of deciding what these connections are ? i know that there 's an issue of how to weight the different things too , and stuff . right ? i mean do you just sort of guess and see if it sort of professor c: right . well there there there there 're two different things you do . grad e: it 's professor c: one is you design and the other is you learn . ok ? so uh what we 're gon na do initially is is do design , and , i if you will , guess . grad b: ok . professor c: ok . uh that is you know use your best knowledge of of the domain to uh , hypothesize what the dependencies are and stuff . grad b: right . ok . professor c: if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure grad b: yeah . professor c: and there are even techniques for learning the structure , although that takes a lot more data , and it 's not as @ @ and so forth and so on . so uh but for the limited amount of stuff we have for this particular exercise i think we 'll just design it . grad b: alright . grad e: yeah . fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and stuff . grad b: ok . grad e: so but this is the { comment } long run . grad b: yeah . grad e: but to solve our problems ag uh a mediocre design will do i think in the beginning . grad b: yeah , that 's right . yeah , oh , and by the way , speaking of data , um , are there i could swore uh , i could swear i saw it sitting on someone 's desk at some point , but is there a um a transcript of any of the , sort of , initial interactions of people with the with the system ? cuz you know , i 'm still sort of itching to to look at what look at the stuff , and see what people are saying . professor c: mm - hmm . yeah . yeah make yourself a note . so and and , of course keith would like the german as well as the english , so whatever you guys can get . grad e: the german . oh yeah , of course , german . yeah . professor c: yeah , the y your native language , right ? you remember that one . grad e: ok . that 's important , yeah . grad b: yeah , professor c: so he 'll get you some data . grad b: u ok . yeah , i mean i i sort of um found the uh , uh the audio of some of those , and um , it kind of sounded like i did n't want to trudge through that , you know . grad e: hmm . grad b: it was just strange , but . professor c: yep . grad e: we probably will not get those to describe because they were trial runs . grad b: oh yeah , ok . grad e: um , but uh that 's th but we have data in english and german already . grad b: ok , yeah , i mean . grad e: so . transcribed . i will send you that . ok . professor c: ok , so while we 're still at this sort of top level , anything else that we oughta talk about today ? grad e: ho - how was your thingy . grad b: oh , um , i just wanted to , uh , s like mention as an issue , um , you know last meeting i was n't here because i went to a linguistics colloquium on the fictive motion stuff , professor c: oh right . grad b: and that was pretty interesting and you know , i mean , seems to me that that will fairly obviously be of relevance to uh to what we 're doing here because you know people are likely to give descriptions like you know , `` what 's that thing uh right where you start to go up the hill , `` or something like that , you know , meaning a few feet up the hill or whatever from some reference point and all that stuff so i mean , i 'm sure in terms of you know , people trying to state locations or , you know , all that kind of stuff , this is gon na be very relevant . so , um , now that was the talk was about english versus japanese , um , which obviously the japanese does n't affect us directly , except that , um , some of the construction he 'd what he talked about was that you know in english we say things like th you know , `` your bike is parked across the street `` and we use these prepositional phrases , you know , `` well , if you were to move across the street you would be at the bike `` , but um in in japanese the the more conventionalized tendency is to use a sort of a description of `` where one has crossed to the river , there is a tree `` . um , and you know , you can actually say things like , um , `` there 's a tree where one has crossed the river , but no one has ever crossed the river `` , or something like that . so the idea is that this really is you know that 's supposed show that 's it 's really fictive and so on . but um but the point is that that kind of construction is also used in english , you know , like `` right where you start to go up the hill `` , or `` just when you get off the train `` , or something like that to uh , to indicate where something is . professor c: mmm . grad b: so we 'll have to think about professor c: so how much is that used in german ? grad e: um . the uh well i wa i was on a uh on a on a different sidetrack . professor c: oh , ok . grad e: i mean , the the deep map project which um is undergoing some renovation at at the moment , but this is a a three language project : german , english , japanese . grad b: ok . grad e: and um , we have a uh , uh i have taken care that we have the the japanese generation and stuff . and so i looked into uh spatial description . so we can generate spatial descriptions , how to get from a to b . and and information on objects , in german , english , and japanese . grad b: mm - hmm . grad e: and there is a huge uh project on spatial descriptions uh differences in spatial descriptions . well , if yo if you 're interested in that , so how how , i mean it does sort of go d all the way down to the conceptual level to some extent . grad b: ok . grad e: so . um . professor c: so , where is this huge project ? grad e: it 's kleist . it 's the uh bielefeld generation of uh spatial descriptions and whatever . professor c: mm - hmm . grad e:  professor c: well , that may be another thing that keith wants to look at . grad b: ok . grad e: but um , i i think we should leave japanese constructions maybe outside of the scope for for now , grad b: yeah . grad e: but um definitely it 's interesting to look at at cross the bordered there . professor c: mm - hmm . phd a: are are you going to p pay any attention to the relative position of of the direction relative relative to the speaker ? for example , there are some differences between hebrew and english . we can say um `` park in front of the car `` as you come beh you drive behind the car . in hebrew it means `` park behind the car `` , because to follow the car is defined as it faces you . grad e: mm - hmm . intrinsic , yeah . phd a: while in english , front of the car is the absolute front of the car . grad b: ok . phd a: so . grad b: right , so the canonical direction of motion determines where the front is . phd a: right . right . grad b: ok . phd a: so , i i i is german uh closer to to e uh , uh , uh , uh to e i mean uh grad e: mm - hmm . phd a: i do n't think it it 's related to syntax , though , so it may be entirely different . grad e: um , as a matter of fact professor c: no , it 's not . grad b: right . phd a: yeah . grad e: um . did you ever get to look at the the rou paper that i sent you on the on that problem in english and german ? grad b: i think grad e: carroll , ninety - three . um . i there is a a study on the differences between english and german on exactly that problem . phd a: hmm . grad e: so it 's they actually say `` the monkey in front of the car , where 's the monkey ? `` grad b: mm - hmm . grad e: and , um , they found statistically very significant differences in english and german , so i i i it might be , since there are only a finite number of ways of doing it , that that german might be more like hebrew in that respect . grad b: hmm . grad e: the solution they proposed was that it was due to syntactic factors . phd a: that but it was n't was grad e: that syntactic facto factors do do play a role there , wh whether you 're more likely , you know , to develop uh , choices that lead you towards using uh intrinsic versus extrinsic reference frames . phd a: right . mm - hmm . right . grad b: i mean , it seems to me that you can get both in in english depending o professor c: hmm . grad b: you know , like , `` in front of the car `` could you know like , here 's the car sideways to me in between me and the car or something 's in front of the car , or whatever . i could see that , professor c: absolutely . grad b: but but anyway , so you know , i mean , this was this was a a very good talk on those kinds of issues and so on . so uh . grad e: i can also give you uh , a pointer to a paper of mine which is the the ultimate taxonomy of reference frames . grad b: alright ! cool ! grad e: so . professor c: oh . grad e: i 'm the only person in the world who actually knows how it works . professor c: oh . grad e: not really . professor c: great . no , i 've not seen that . phd a: what do you mean . um . `` reference frames `` ? grad e: it 's called a phd a: uh uh grad e: it 's it 's spatial reference frames . you actually have only um . if you wan na have a this is usually um i should there should be an `` l `` , though . well actually you have only have two choices . you can either do a two - point or a three - point which is you you 're familiar with th with the `` origo `` ? where that 's the center `` origo `` is the center of the f frame of reference . grad b: hmm . grad e: and then you have the reference object and the object to be localized . grad b: hmm . phd a: mm - hmm . grad e: ok ? in some cases the origo is the same as the reference object . professor c: so that would be `` origin `` in english , grad f: this was like grad b: the origin . phd a: right grad b: yeah . professor c: right ? grad e: `` origo `` is a terminus technikus . in that sense , that 's even used in the english literature . `` origo . `` grad b: oh , ok . i never heard it . professor c: alright . phd a: ok . grad b: ok . grad e: and um , so , this video tape is in front of me . grad b: mm - hmm . grad e: i 'm the origo and i 'm also the reference object . grad b: mm - hmm . phd a: right . grad e: those are two - point . professor c: mm - hmm . grad e: and three - point relations is if something has an intrinsic front side like this chair then your f shoe is behind the chair . professor c: yeah . grad b: mm - hmm . grad e: and , reference object and um . no , from from my point of view your shoe is left of the chair . grad b: right . you you can actually say things like , um , `` it 's behind the tree from me `` or something like that , i think , in in in certain circumstances in english , right ? as sort of `` from where i 'm standing it would appear that `` grad e: yeah . yeah . so , grad f: looks a little bit like reichenbach for time . professor c: yeah , it sounds like it , does n't it , grad b: yeah . professor c: yeah . grad f: it 's a lot like it . grad e: and then and then here you grad f: um . grad e: on this scale , you have it either be ego or allocentric . professor c: mm - hmm . grad e: and that 's { comment } that 's basically it . so . egocentric two - point , egocentric three - point , or you can have allocentric . grad b: oh , ok . grad e: so , `` as seen from the church , the town hall is right of that um , fire station `` . aa - huh { comment } it 's hardly ever used but it 's w phd a: i 'd love to see it if you if you have a copy kind of . uh . grad b: yeah . professor c: yeah . i see this is this is getting into ami 's thing . phd a: here grad b: mm - hmm . professor c: he 's he 's very interested in that . grad e: ok . professor c: so . grad b: me too . professor c: uh . yeah . well , why do n't you just put it on the web page ? there 's this edu right ? grad e: yeah it 's or or just yeah . professor c: or a link to it . grad e: it 's also all on my my home page at eml . it 's called `` an anatomy of a spatial description `` . professor c: just grad e: but i 'll send that link . phd a: ok , great . professor c: maybe just put a link on . yeah . grad e: yep . professor c: by the way , there something that i did n't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach . grad e: yep . grad b: huh . professor c: so there 's there 's uh all this linguistic stuff about you know , near and far , or yon and and so forth . grad b: mm - hmm . professor c: so this is all this is there 's this linguistic facts . but apparently , the uh . here 's the way the findings go . that , you know they do mri , and and if you 're uh got something within reach then there 's one of your areas lights up , and if something 's out of reach uh a different one . but here 's the the amazing result , um , they say . you get someone with a with a deficit so that they have a perfectly normal ability at distance things . so the s typical task is subdivision . so there 's a a line on the wall over there , and you give them a laser pointer , and you say , `` where 's the midpoint ? `` and they do fine . if you give them the line , and they have to touch it , they ca n't . there 's just that part of the brain is n't functioning , so they ca n't do that . here 's the real experiment . the same thing on the wall , you give them a laser , `` where is it ? `` , grad b: mm - hmm . professor c: they do it . give them a stick , long stick , and say `` do it `` , they ca n't do it . so there 's a remapping of distant space into nearby space . phd a: right . so they doubled the the end the end of this grad f: because it 's within reach now ? grad b: yeah , professor c: it 's not within reach and you use the within - reach uh , mechanism . grad b: yeah . grad f: oh . wow . grad b: circuits . phd a: right . professor c: so i 'll d i 'll dig you up this reference . grad b: that 's cool . professor c: and so this doe this is , uh first of all , it explains something that i 've always wondered about and i 'll do this this test on you guys as well . so . uh . how - i have had an experience , not often , but a certain number of times , when , for example , i 'm working with a tool , a screwdriver or something , for a long time , i start feeling the tip directly . not indirectly , but you actually can feel the tip . grad b: yeah yeah . professor c: and people who are uh accomplished violinists and stuff like that , claim they also have this kind of thing where you get a direct sensation of , physical sensation , of the end affector . grad b: yeah . what 's going on at the end of the tool , phd a: the ext the the the extension , grad b: yeah . professor c: huh ? grad b: what 's going on at the end of the tool , or whatever . professor c: yeah , within phd a: right . professor c: huh ? phd a: the extension of of your hand , right . professor c: yeah , right . have you hav y h had this ? phd a: the i i think so . i mean i i it 's not exactly the th same thing , but but s it it it 's getting close to that . grad b: yeah . grad f: w what does it feel like ? professor c: oh i it feels like your as if your uh neurons had extended themselves out to this tool , and you 're feeling forces on it and so forth and and you deal directly with it . phd a: i once i i was playing you know with those um uh devices that allow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something grad b: oh , ok . professor c: right , yeah yeah yeah . yeah . phd a: and there 's a correspondence between professor c: yeah . phd a: so i played with it . after a while , you do n't feel the difference anymore . i i mean it 's kind of grad b: mm - hmm . professor c: yeah , right . phd a: very kind of you stop back and suddenly it goes away and you have to kind of work again to recapture it , but yeah . grad b: yeah . professor c: right , yeah , so anyway , so so this was the first actual experimental evidence i 'd seen that was consistent with this anecdotal stuff . grad b: that 's cool . professor c: and of course it makes a lovely def uh story about why languages uh , make this distinction . of course there are behavioral differences too . things you can reach are really quite different than things you ca n't . grad b: yeah . professor c: but there seems to be an actu really deep embodied neural difference . and i this is , um so . in addition to the e grad e: this is more proximal - distal . professor c: yeah uh exactly . so in addition to e ego and allocentric uh which appear all over the place , you also apparently have this proximal - distal thing which is very deeply uh embedded . s grad e: well , dan montello sort of , he he does the uh uh th the cognitive map world , down in santa barbara . and he he always talks about these he he already well i probably most likely without knowing this this evidence uh is talking about these small scale spaces that you can manipulate versus large scale environmental spaces . professor c: yeah . well there 's there 's uh been a lot of behavioral things o on this , but that was the first neur neuro - physiological thing i saw . anyway yeah , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , right ? and so these issues about uh , reference , and spatial { comment } reference , discourse reference , uh - uh - uh - uh { comment } all this sort of stuff , uh , deixis which is part of what you were talking about , grad b: mm - hmm . mm - hmm . professor c: um so , all of this stuff is coming up essentially starting now . so we got ta do all this . so there 's that . and then there 's also a set of system things that come up . so `` ok , we 're not using their system . that means we need our system . `` grad b: mm - hmm . professor c: right ? grad b: yeah . professor c: it it follows . and so , uh , in addition to the business about just getting the linguistics right , and the formalism and stuff , we 're actually gon na build something and uh , johno is point person on the parser , analyzer , whatever that is , and we 're gon na start on that in parallel with the um , the grammar stuff . grad b: alright . professor c: but to do that we 're gon na need to make some decisions like ontology , so , um and so this is another thing where we 're gon na , you know , have to get involved and make s relatively early i think , make some decisions on uh , `` is there an ontology api that that `` there 's a sort of standard way of getting things from ontologies and we build the parser and stuff around that , or is there a particular ontology that we 're gon na standardize on , and if so for example , is there something that we can use there . i does uh either the uh smartkom project or one of the projects at eml have something that we can just p pull out , for that . uh , so there are gon na be some some some things like that , which are not science but system . but we are n't gon na ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually uh build some of it . and how much we build , and and so forth . grad b: i professor c: uh . part of it , if it works right , is wh it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that um , there 's a good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , grad b: ok . professor c: and of course it 's only w in both cases it 's only one piece of a bigger system . grad b: mm - hmm . professor c: but it would be nice if that piece were exactly the same piece . grad b: right . professor c: it was just this uh construction analyzer . and so we think we think we have a shot at at that . grad b: ok . professor c: so . the for so . to to come full circle on that , this formalization task , ok ? is trying to get the formalism into into a shape where it can actually uh grad b: yeah . be of use to someone who 's trying to do this , right ? professor c: d well , yeah , where it actually is is covers the whole range of things . and the the the the thing that got mark into the worst trouble is he had a very ambitious thing he was trying to do , and he insisted on trying to do it with a limited set of mechanisms . it turned out , inherently not to cover the space . grad b: ok . professor c: and it just it was just terribly frustrating for him , grad b: yeah . professor c: and he seemed fully committed to both sides of this i i irreconcilable thing . grad b: i see . right . professor c: and . uh . johno is much more pragmatic . grad b: ok . good to know . professor c: uh . huh ? is this is true , is it not ? grad d: yes . professor c: ok . so there 's you know sort of , yeah , deep , really deep , emotional commitment to a certain theory being uh , complete . grad b: oh , ok . grad f: you do n't have a hidden purist streak ? grad d: oh no . professor c: we - well it has n't it it certainly has n't been observed , in any case . grad f: ok . just checking . grad d: no sir . grad b: alright . professor c: um . now , you do , but that 's ok . uh . so . for for grad b: cuz i do n't have to implement anything . professor c: exactly right . exactly . grad f: i have a problem , then . it 's so . whether i do depends on whether i 'm talking to him or him probably . phd a: hmm . grad b: yeah , right . professor c: right . why a actually , uh , the thing is , you you do but , th the thing you have to im implement is so small that uh . grad f: which meeting i 'm in . it 's ok to be purist within that context . professor c: within that , yeah , grad f: yes , professor c: and uh , it 's a and still , i think , you know , get something done . grad f: good . grad b: cool ! professor c: but to try to do something upscale and purist particularly if if um what you 're purist about does n't actually work , is real hard . grad f: yay . grad b: mm - hmm . yeah . professor c: ok . and then the other thing is while we 're doing this uh robert 's gon na pick a piece of this space , phd a: it 's possible yeah . grad b: ok . professor c: ok , uh , for his absentee thesis . i think you all know that that you can just , in germany almost just send in your thesis . grad b: just a drive up . ca - chuk ! phd a: um professor c: yeah right . grad b: there you go . professor c: ok . grad e: the - th there there 's a drive - in thesis uh sh joint over in saarbruecken . grad b: exactly . drive through , yeah . professor c: it costs a lot . the the amount you put in your credit card and as well . but , uh , but anyway , so , uh , that 's um , also got ta be worked out , hopefully over the next few weeks , so that that it becomes clear uh , what piece uh , robert wants to jump into . and , while we 're at this level , uh , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . grad b: ok . professor c: so , de uh . and her name is eva . grad b: ok . professor c: it really is . nobody believed th th that grad f: yeah , i thought it had to be a joke , of your part , you know professor c: yeah . grad f: like { comment } `` johno made it up , i 'm sure . `` grad g: is this person someone who 's in first - year this year , professor c: no , first year coming . grad g: or professor c: so , she 's she 's now out here she 's moved , and she 'll be a student as of then . grad g: ok . professor c: and probably she 'll pick up from you on the belief - net stuff , so sh she 'll be chasing you down and stuff like that . grad g: ok . professor c: uh . grad e: document . grad g: right . professor c: uh , against all traditions . and actually i talked today to a uh undergraduate who wants to do an honors thesis on this . uh grad f: someone from the class ? professor c: no , interestingly enough . grad f: we always get these people who are not in the class , who professor c: some of th some of them , yeah . grad f: it 's interesting . professor c: so anyway , uh , but uh she 's another one of these ones with a three point nine average and so forth and so on . grad b: mm - hmm . professor c: uh , so , um , i 've give i 've given her some things to read . so we 'll see how this goes . oh there 's yet another one of the incoming first { comment } incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . um , anyway , so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gon na make sense to have this be separate from the other bigger effort with the formalization stuff or not , i 'm not sure . it partly depends on w what your thesis turns out to be and how that goes . s so , we 'll see . and then , ami , you can decide , you know , how much time you wan na put into it and uh , it it 's beginning to take shap shape , phd a: ok . professor c: so uh and , phd a: right professor c: i think you will find that if you want to look technically at some of the your traditional questions in this light , uh keith , who 's buil building constructions , will be quite happy to uh see what , you know , you envision as the issues and the problems and um , how they might uh get reflected in constructions . grad b: sure . professor c: i suspect that 's right . grad b: yeah . yeah . phd a: i i may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but uh , after that or before that . professor c: ok , fine . and , um , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in in the neighborhood . phd a: right . yeah be uh actu actually i 'm invited to do some consulting with a bank in geneva which has an affiliation with a research institute in geneva , which i forgot the name of . professor c: yeah . yep . e o do y phd a: yeah . professor c: well , we we 're connected to uh there 's a there 's a a very significant connection between we 'll we 'll go through this , phd a: yeah . professor c: icsi and epfl , which is the , uh it 's the fr ge - germany 's got two big technical institutes . there 's one in in zurich , phd a: mm - hmm . professor c: e t and then there 's one , the french speaking one , in lausanne , grad b: oh , so in switzerland . professor c: ok ? which is uh e p phd a: great . professor c: f l . so find out who they are associated with in geneva . phd a: right . professor c: probably we 're connected to them . phd a: great . i 'll let you know . s i 'll send you email . professor c: ok . yeah , and so anyway we c uh we can m undoubtedly get ami uh to give a talk at uh eml or something like that . while he 's in in uh grad e: hmm . uh . i i think the one you you gave here a couple of weeks ago would be of interest there , too . phd a: sure , yeah . professor c: a lot of interest . actually , either place , dfki or uh yeah , so , and and if there is a book , that you 'll be building up some audience for it . phd a: yeah . right . professor c: and you 'll get feedback from these guys . phd a: great , yeah . professor c: cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . phd a: cool . professor c: ok . so , uh , unless we wan na start digging into the uh the belief - net and the decisions now , which would be fine , it 's probably grad e: i i tho it 's probably better if i come next week with the um version o point nine of the structure . professor c: ok . so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying `` here 's what we think we understand , here are the things we think we do n't understand `` . and that we as a group will try to to finish it . what i 'd like to do is shoot f for finishing all this next monday . grad g: sure . professor c: ok ? uh , `` these are the decisions `` i do n't think we 're gon na get lots more information . it 's a design problem . grad b: mm - hmm . professor c: you know . we grad g: yeah . professor c: yeah . and let 's come up with a first cut at what this should look like . and then finish it up . grad b: ok . professor c: does that so make sense ? grad b: ok . grad e: and um , the the sem semester will be over next week but then you have projects for one more week to come ? grad g: no , i i think i 'll be done everything by this uh by the end of this week . grad e: same with you ? no . grad d: nnn . this well , i 've i have projects , but then the my prof professor of one of my classes also wa has a final that he 's giving us . and he 's giving us five days to do it which means it going to be hard . grad b: yeah . professor c: yeah . oh . is it a take - home final ? who 's doing this ? grad d: yeah . aikin , alex , yeah . professor c: yeah , figured . that would have been i my guess . grad g: hmm . professor c: right . um , but anyway , yeah . grad b: pretty soon . grad e: ok . professor c: ok , so i guess that 's grad d: so , the seventeenth will definitely be the last day , like it or not for me . professor c: right . right . so let 's do this , and then we we well there 's gon na be some separate co these guys are talking , uh we have a group on the formalization , uh nancy and johno and i are gon na talk about parsers . so there 're various kinds of uh grad b: ok . professor c: of course , nothing gets done even in a meeting of seven people , grad b: right . professor c: right ? so , um , two or three people is the size in which actual work gets done . grad e: mmm . grad b: yeah . professor c: so we 'll do that . great . oh , the other thing we wan na do is catch up with uh , ellen and see what she 's doing because the um image schemas are going to be um , an important pa grad b: yeah . quite relevant , yeah . professor c: we we want those , grad b: yeah , oh yeah . professor c: right ? and we want them formalized and stuff like that . grad b: yeah . professor c: so let me let me make a note to do that . grad b: ok . yeah , i 'm actually probably going to be in contact with her uh pretty soon anyway because of various of us students were going to have a reading group about precisely that sort of thing over the summer , grad d: ok . professor c: oh right ! right right right ! grad b: so . professor c: that 's great ! yeah , i i shweta mentioned that , although she said it 's a secret . grad b: ok . grad d: hi grad b: right , no faculty ! professor c: th - the faculty are n't faculty are n't supposed to know . grad d: wednesday 's much better for me , yeah . professor c: but um , i 'm sufficiently clueless that i count as a grad b: yeah , right . it 's as if we did n't tell anyone at all , grad d: bhaskara . grad b: right .","output":"the meeting discussed various topics such as data collection and updates on the german parser . they discussed xml modifications and future thoughts on the ontology . additionally , object representations will include an eva vector . this can be incorporated in the database entry for a particular building or inherited from the ontology of the building type . the actual number of the inputs can create a combinatorial explosion when setting the probabilities . in any case , further to fulfilling the basic requirements ( translating the parser and the generator into english ) , the project is entirely open-ended in terms of focus of research ."},{"instruction":"what was the general discussion of the meeting ?","input":"grad b:  grad d: how many batteries do you go through ? grad b: thank you . professor c: alright . phd a: sure . professor c: good . yeah . ok so , let 's get started . nancy said she 's coming and that means she will be . um . my suggestion is that robert and johno sort of give us a report on last week 's adventures uh to start . so everybody knows there were these guys f uh from heidelber - uh , uh , actually from uh dfki uh , part of the german smartkom project , who were here for the week and , i think got a lot done . grad e: yeah , i think so too . um . the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like `` roman numeral one , am smarticus . `` it actually says , `` roemisch einz , am smarticus , `` grad b: ok . grad e: which means it 's just using a german sythesis module for english sentences . grad b: ok . grad e: so uh , professor c: it does n't know `` i `` . grad b: ok . grad e: um , the uh grad b: oh , am spartacus . `` grad d: `` i am sm - i am smarticus `` is what it 's saying . phd a: right . grad b: verstehe . ok . grad d: i gue grad e: the uh sythesis is just a question of um , hopefully it 's just a question of exchanging a couple of files , once we have them . and , um , it 's not going to be a problem because we decided to stick to the so - called concept to speech approach . so i 'm i 'm i 'm going backwards now , so `` synthesis `` is where you sort of make this uh , make these sounds , and `` concept to speech `` is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . grad b: mm - hmm . grad e: and , uh , johno learned how to write xml tags . uh , and did write the tree adjoining grammar for some some sentences . no , right ? grad d: yeah . grad e: yeah , for a couple grad d: so . bu - uh , i the way the uh , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to a er in xml and there 's a conversion system for different uh , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is uh , in a lisp - like the knowledge base is in a lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have a basically , a goal and it , you know , says `` ok , well i 'm gon na try to do the greet - the - person goal , grad b: mm - hmm . grad d: so it just starts uh , it binds some variables and it just decides to , you know , do some subscold . basically , it just means `` build the tree . `` grad b: ok . grad d: and then it passes the tree onto , uh , the ge the generation module . grad e: but i think that the point is that out of the twelve possible utterances that the german system can do , we 've already written the the syntax trees for three or four . grad d: we yeah . so , the syntax trees are very simple . it 's like most of the sentences in one tree , grad b: mm - hmm . grad d: and instead of , you know , breaking down to , like , small units and building back up , they basically took the sentences , and basically cut them in half , or you know , into thirds or something like that , and made trees out of those . and so uh , uh tilman wrote a little tool that you could take lisp notation and generate an xml , uh , tree . uh , s what do ca structure from the from the lisp . and so basically you just say , you know , `` noun goes to `` , you know , er , nah , i do n't re i 've never been good at those . so there 's like the vp goes to n and those things in lisp , and it will generate for you . grad b: ok . n , n , v yeah , ok . alright . grad e: and because we 're sticking to that structure , the synthesis module does n't need to be changed . so all that f fancy stuff , and the texas speech version of it , which is actually the simpler version , is gon na be done in october which is much too late for us . so . this way we we worked around that . the , uh the system , um i can show you the system . i actually want , at least , maybe , you should be able to start it on your own . if you wan na play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on on on seventeen modules before they actually can stomach it , anything . and send in a a a couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we do n't have here . grad b: mm - hmm . grad e: and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was a lot of engineering stuff . no science in there whatsoever , but it 's working now , and um , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation . grad d: why i had i did need to chan generate different trees than the german ones , mainly because you know like uh , the gerund in in german is automatically taken care of with just a regular verb , grad e: you have to switch it on . grad b: mm - hmm . grad d: so i 'd uh have to add `` am walking , `` grad b: ok . grad d: or i 'd have to add a little stem for the `` am `` , when i build the built the tree . grad b: ok . yeah , i noticed that um , that some of the examples they had , had you know , non - english word orders and so on , you know . and then all that good stuff . so . professor c: alright . grad d: yeah . grad b: like . professor c: so it might be worth , keith , you looking at this , grad b: yeah . professor c: um grad b: i i still do n't i still do n't really understand e like grad d: well tilman s grad b: i mean we sort of say , um you know , i i still do n't exactly understand sort of the information flow uh in in this thing , or what the modules are and so on . so , you know , like just that such - and - such module uh um decides that it wants to achieve the goal of greeting the user , and then magically it sort of s professor c: yeah grad b: i mean , how does it know which syntactic structure to pull out , and all that ? professor c: i thi yeah . so . i think it 's not worth going over in the group , grad b: r uh sure . professor c: but sort of when you get free and you have the time uh either robert or johno or i can walk you through it . grad b: yeah , soon . ok . professor c: and you can ask all the questions about how this all fits together . grad b: that 's fine . professor c: it 's eee { comment } messy but once you understand it you understand it . it 's it 's there 's nothing really complicated about it . grad b: ok . grad e: no . grad b: and i remember one thing that that came up in the talk last wednesday . um , was this , i i think he talked about the idea of like , um he was talking about these lexicalized uh , uh , tree adjoining grammars where you sort of for each word you , um grad d: ok , you know how to do it ? grad b: for each lexical item , the lexical entry says what all the uh trees are that it can appear in . and of course , that 's not v that 's the opposite of constructional . that 's , you know , that 's that 's hpsg or whatever . professor c: right . grad b: you know ? professor c: right . now , we 're we 're not committed for our research to do any of those things . grad b: yeah . mm - hmm . professor c: so uh we are committed for our funding . grad b: right . professor c: ok ? to uh grad b: make our stuff fit to that . professor c: yeah , to n no , to just get the dem get the demos they need . grad b: uh - huh . professor c: ok ? so between us all we have t to get th the demos they need . if it turns out we can also give them lots more than that by , you know , tapping into other things we do , that 's great . grad d: you should probably move the microphone closer to your face . grad b: mm - hmm . professor c: but i it turns out not to be in an any of the contracts grad d: there 's like a little the twisty thing , you can move it with . grad b: ok . professor c: and , s deliberately . so , the reason i 'd like you to understand uh what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with a question of `` could we fit this deeper stuff in there ? `` or something . you know what the hell we we 're talking about fitting in . grad b: right . ok . professor c: so it 's just , uh in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? uh , is there anything we can give back , beyond th the sort of minimum requirements ? but none of that has a short time fuse . grad b: ok . professor c: so th the demo the demo requirements for this fall are sort of taken care of as of later this week or something . and then so , it 's probably fifteen months or something until there 's another serious demo requirement . grad b: oh ok . professor c: that does n't mean we do n't think about it for fifteen months , grad b: right . professor c: but it means we can not think about it for six months . grad b: right , yeah . professor c: so . the plan for this summer uh , really is to step back from the applied project , grad e: right . professor c: keep the d keep the context open , but actually go after the basic issues . grad b: hmm . oh ok . professor c: and , so the idea is there 's this uh , other subgroup that 's worrying about formalizing the nota getting a notation . but sort of in parallel with that , uh , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , grad b: mm - hmm . professor c: but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . grad b: yeah . ok . got it . professor c: it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and stuff . grad b: yeah . professor c: and , i don i do n't want you f feeling that you have to somehow meet all these other constraints . grad b: right , ok . professor c: um . and similarly with the parsing , uh we 're gon na worry about parsing uh , the general case you know , construction parser for general constructions . and , if we need a cut - down version for something , or whatever , we 'll worry about that later . grad b: ok . professor c: so i 'd like to , for the summer turn into science mode . grad b: ok . professor c: and i assume that 's also , uh , your plan as well . grad b: so i mean , the the point is that like the meetings um so far that i 've been at have been sort of been geared towards this demo , professor c: right . yeah . yeah . grad b: and then that 's going to go away pretty soon . professor c: but but we we 're swit grad b: ok . professor c: right . grad b: and then we 'll sort of shift gears a fairly substantially , professor c: yeah . grad e: it 's professor c: yeah . grad b: huh ? professor c: yeah . grad e: it 's got . what i what i think is is a good idea that i can can show to anyone who 's interested , we can even make a sort of an internal demo , and i i show you what i do , grad b: mm - hmm . grad e: i speak into it and you hear it talk , grad b: ok . grad e: and i can sort of walk f through the information . so , this is like in half hour or forty - five minutes . just fun . grad b: ok . grad e: and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , sort of , give a sensible answer . grad b: right . ok . professor c: so , c sh we could set that up as actually an institute wide thing ? just give a talk in the big room , and and so peo people know what 's going on ? when you 're ready ? grad e: absolutely . professor c: yeah i mean , that 's the kind of thing that 's the level at which you know we can just li invite everybody and say `` this is a project that we 've been working on and here 's a demo version of it `` and stuff like that . grad b: yeah . grad e: ok . well d we we do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're grad b: uh - huh . professor c: indeed . grad e: yeah . ok . makes sense . professor c: but any so that e e it 's clear , then , i think . actually , roughly starting uh let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . grad b: yeah . ok . professor c: but uh starting next meeting i think we want to flip into this mode where uh . i mean there are a lot of issues , what 's the ontology look like , grad b: mm - hmm . professor c: you know what do the constructions look like , what 's the execution engine look like , mmm lots of things . grad b: mm - hmm . professor c: but , more focused on uh an idealized version than just getting the demo out . now before we do that , let 's get back in oh ! but , it 's still , i think , useful for you to understand the demo version enough , so that you can can see what what it is that that uh it might eventually get retro - fitted into or something . grad b: yeah . ok , right . professor c: and johno 's already done that , uh , looked at the dem uh the looked at the smartkom stuff . grad d: wa uh to some de uh what what part of th the smartkom stuff ? professor c: well , the parser , and that stuff . grad d: oh yeah yeah . professor c: ok . anyway . so , the trip the report on these the last we we sort of interrupted you guys telling us about what happened last week . grad b: yeah . it 's alright . grad e: um . well it was just amazing to to see uh how how instable the whole thing is , professor c: maybe you 're done , then . grad e: and if you just take the and i g i got the feeling that we are the only ones right now who have a running system . i do n't know what the guys in kaiserslautern have running because e the version that is , the full version that 's on the server d does not work . and you need to do a lot of stuff to make it work . and so it 's and even tilman and ralf sort of said `` yeah there never was a really working version that uh did it without th all the shortcuts that they built in for the uh october @ @ version `` . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , uh it was fun to some extent , but the uh the outcome that is sort of of scientific interest is that i think both ralf and tilman um , i know that they enjoyed it here , and they r they they liked , uh , a lot of the stuff they saw here , what what we have been thinking about , and they 're more than willing to to um , cooperate , by all means . and um , part of my responsibility is uh to use our internal `` group - ware `` server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and and generating and constructions w we we sort of uh put it in there and they put what they do in there and maybe we can even um , get some overlap , get some synergy out of that . and um , the , uh if i find someone at in eml that is interested in that , um i i may even think that we could look take constructions and and generate from them because the tree adjoining grammars that that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g - like stuff , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're of course definitely focused on the understanding , um , pipeline . professor c: anyth - any other { comment } uh repo visit reports sort of stories ? uh we so we now know i think , what the landscape is like . grad b: mm - hmm . professor c: and so we just push on and and uh , do what we need to do . and one of the things we need to do is the um , and this i think is relatively tight tightly constrained , is to finish up this belief - net stuff . so . uh . and i was going to switch to start talking about that unless there 're m other more general questions . ok so here 's where we are on the belief - net stuff as far as i understand it . um . going back i guess two weeks ago uh robert had laid out this belief - net , missing only the connections . right ? that is { comment } so , he 'd put all th all the dots down , and we went through this , and , i think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . yeah { comment } we may run across one or two more . but of course the connections were n't . so , uh bhaskara and i went off and looked at some technical questions about were certain operations sort of legitimate belief - net computations and was there some known problem with them or had someone already uh , solved you know how to do this and stuff . and so bhaskara tracked that down . the answer seems to be uh , `` no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do `` . and , so the current state of things is that , again , starting now , um we 'd like to actually get a running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and uh , he 's gon na leave us an inheritance , which is a uh hopefully a belief - net that does these things . and there 're two aspects to it , one of which is , you know , technical , getting the coding right , and making it run , and uh stuff like that . and the other is the actual semantics . ok ? what all you know , what are the considerations and how and what are the ways in which they relate . so he doe h he does n't need help from this group on the technical aspects or if he does uh we 'll do that separately . grad b: mm - hmm . professor c: but in terms of what are the decisions and stuff like that , that 's something that we all have to work out . is is that right ? i mean that 's that 's both you guys ' understanding of where we are ? grad e: absolutely . professor c: ok . grad g: so , i guess , um is there like a latest version of the belief - net of the proposed belief - net ? like grad e: we had um decided grad g: like grad e: um . well , no , we did n't decide . we wanted to look into maybe getting it , the visualization , a bit clearer , but i think if we do it , um , sort of a paper version of all the nodes and then the connections between them , that should suffice . grad g: mm - hmm . yeah , that should be fine . professor c: yeah i mean , that 's a separate problem . grad d: yeah , i professor c: we do in the long run wan na do better visualization and all that stuff . grad e: yeah . professor c: that 's separable , yeah . grad d: i did look into that , uh in terms of , you know , exploding the nodes out and down ag professor c: yep . right . grad d: javabayes does not support that . i can imagine a way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it , professor c: not not at this point . grad d: and i went through all the other packages on murph - kevin murphy 's page , professor c: right . grad d: and i could n't find the necessary mix of free and uh with the gui and , with this thing that we want . professor c: well , we can p if it 's if we can pay yeah . if you know it 's paying a thousand dollars or something we can do that . ok ? so so do n't view free as as a absolute constraint . grad d: ok . ok , so then i 'll go back and look at the ones on the list that professor c: ok . and you can ask kevin . grad e: but grad g: yeah . grad d: mmm . grad e: but grad g: yeah , the one that uh people seem to use is uh hugin or whatever ? professor c: hugin , yeah that 's free . grad g: how exp i do n't think it 's is it free ? because i 've seen it advertised in places so i it seems to professor c: uh , it may be free to academics . like i i do n't know . i have a co { comment } i have a copy { comment } that i l i downloaded . grad g: ok . professor c: so , at one point it was free . grad g: ok . professor c: uh but yo i noticed people do use hugin so um , grad d: how do you spell that ? professor c: hugin . grad f: why professor c: and bhaskara can give you a pointer . so then , in any case , um but paying a lit you know , if i if it 's uh probably for university , it 's it 's gon na be real cheap anyway . but um , you know , if it 's fifty thousand dollars we are n't gon na do it . i 'm mean , we have no need for that . grad e: i i also s would suggest not to d spend two weeks in in in changing the the javabayes code . professor c: no , grad b: yeah . professor c: he 's not gon na do that . grad d: ok . grad e: i i will send you a pointer to a java applet that does that , it 's sort of a fish - eye . you you have a node , and you click on it , and it shows you all the connections , grad d: mmm . grad e: and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that does n't work , it 's not a problem we we need to solve right now . what i 'm what my job is , i will , um , give you the input in terms of of the internal structure . maybe node by node , or something like this ? or should i collect it all grad g: mm - hmm . grad e: and professor c: does n't matter . grad g: um , just any like like sort of rough representation of the entire belief - net is probably best . grad e: ok . and um you 're gon na be around ? t again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ? grad g: yeah i mean , yeah , i can like i c um . this week i guess um , kind of i have a lot of projects and stuff but after that i will generally be more free . so yes , i might i can be around . and g i mean , generally if you email me also i can be around on other days . grad e: yeah . ok . professor c: yeah and this is not a crisis that i mean , you do , e everybody who 's a student should , you know do their work , get their c courses all in good shape and and and and then we 'll dig d dig down on this . grad e: yeah , that 's yeah . ok . no , that 's good . that means i have i h i can spend this week doing it . so . grad g: ok . grad b: how do you go about this process of deciding what these connections are ? i know that there 's an issue of how to weight the different things too , and stuff . right ? i mean do you just sort of guess and see if it sort of professor c: right . well there there there there 're two different things you do . grad e: it 's professor c: one is you design and the other is you learn . ok ? so uh what we 're gon na do initially is is do design , and , i if you will , guess . grad b: ok . professor c: ok . uh that is you know use your best knowledge of of the domain to uh , hypothesize what the dependencies are and stuff . grad b: right . ok . professor c: if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure grad b: yeah . professor c: and there are even techniques for learning the structure , although that takes a lot more data , and it 's not as @ @ and so forth and so on . so uh but for the limited amount of stuff we have for this particular exercise i think we 'll just design it . grad b: alright . grad e: yeah . fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and stuff . grad b: ok . grad e: so but this is the { comment } long run . grad b: yeah . grad e: but to solve our problems ag uh a mediocre design will do i think in the beginning . grad b: yeah , that 's right . yeah , oh , and by the way , speaking of data , um , are there i could swore uh , i could swear i saw it sitting on someone 's desk at some point , but is there a um a transcript of any of the , sort of , initial interactions of people with the with the system ? cuz you know , i 'm still sort of itching to to look at what look at the stuff , and see what people are saying . professor c: mm - hmm . yeah . yeah make yourself a note . so and and , of course keith would like the german as well as the english , so whatever you guys can get . grad e: the german . oh yeah , of course , german . yeah . professor c: yeah , the y your native language , right ? you remember that one . grad e: ok . that 's important , yeah . grad b: yeah , professor c: so he 'll get you some data . grad b: u ok . yeah , i mean i i sort of um found the uh , uh the audio of some of those , and um , it kind of sounded like i did n't want to trudge through that , you know . grad e: hmm . grad b: it was just strange , but . professor c: yep . grad e: we probably will not get those to describe because they were trial runs . grad b: oh yeah , ok . grad e: um , but uh that 's th but we have data in english and german already . grad b: ok , yeah , i mean . grad e: so . transcribed . i will send you that . ok . professor c: ok , so while we 're still at this sort of top level , anything else that we oughta talk about today ? grad e: ho - how was your thingy . grad b: oh , um , i just wanted to , uh , s like mention as an issue , um , you know last meeting i was n't here because i went to a linguistics colloquium on the fictive motion stuff , professor c: oh right . grad b: and that was pretty interesting and you know , i mean , seems to me that that will fairly obviously be of relevance to uh to what we 're doing here because you know people are likely to give descriptions like you know , `` what 's that thing uh right where you start to go up the hill , `` or something like that , you know , meaning a few feet up the hill or whatever from some reference point and all that stuff so i mean , i 'm sure in terms of you know , people trying to state locations or , you know , all that kind of stuff , this is gon na be very relevant . so , um , now that was the talk was about english versus japanese , um , which obviously the japanese does n't affect us directly , except that , um , some of the construction he 'd what he talked about was that you know in english we say things like th you know , `` your bike is parked across the street `` and we use these prepositional phrases , you know , `` well , if you were to move across the street you would be at the bike `` , but um in in japanese the the more conventionalized tendency is to use a sort of a description of `` where one has crossed to the river , there is a tree `` . um , and you know , you can actually say things like , um , `` there 's a tree where one has crossed the river , but no one has ever crossed the river `` , or something like that . so the idea is that this really is you know that 's supposed show that 's it 's really fictive and so on . but um but the point is that that kind of construction is also used in english , you know , like `` right where you start to go up the hill `` , or `` just when you get off the train `` , or something like that to uh , to indicate where something is . professor c: mmm . grad b: so we 'll have to think about professor c: so how much is that used in german ? grad e: um . the uh well i wa i was on a uh on a on a different sidetrack . professor c: oh , ok . grad e: i mean , the the deep map project which um is undergoing some renovation at at the moment , but this is a a three language project : german , english , japanese . grad b: ok . grad e: and um , we have a uh , uh i have taken care that we have the the japanese generation and stuff . and so i looked into uh spatial description . so we can generate spatial descriptions , how to get from a to b . and and information on objects , in german , english , and japanese . grad b: mm - hmm . grad e: and there is a huge uh project on spatial descriptions uh differences in spatial descriptions . well , if yo if you 're interested in that , so how how , i mean it does sort of go d all the way down to the conceptual level to some extent . grad b: ok . grad e: so . um . professor c: so , where is this huge project ? grad e: it 's kleist . it 's the uh bielefeld generation of uh spatial descriptions and whatever . professor c: mm - hmm . grad e:  professor c: well , that may be another thing that keith wants to look at . grad b: ok . grad e: but um , i i think we should leave japanese constructions maybe outside of the scope for for now , grad b: yeah . grad e: but um definitely it 's interesting to look at at cross the bordered there . professor c: mm - hmm . phd a: are are you going to p pay any attention to the relative position of of the direction relative relative to the speaker ? for example , there are some differences between hebrew and english . we can say um `` park in front of the car `` as you come beh you drive behind the car . in hebrew it means `` park behind the car `` , because to follow the car is defined as it faces you . grad e: mm - hmm . intrinsic , yeah . phd a: while in english , front of the car is the absolute front of the car . grad b: ok . phd a: so . grad b: right , so the canonical direction of motion determines where the front is . phd a: right . right . grad b: ok . phd a: so , i i i is german uh closer to to e uh , uh , uh , uh to e i mean uh grad e: mm - hmm . phd a: i do n't think it it 's related to syntax , though , so it may be entirely different . grad e: um , as a matter of fact professor c: no , it 's not . grad b: right . phd a: yeah . grad e: um . did you ever get to look at the the rou paper that i sent you on the on that problem in english and german ? grad b: i think grad e: carroll , ninety - three . um . i there is a a study on the differences between english and german on exactly that problem . phd a: hmm . grad e: so it 's they actually say `` the monkey in front of the car , where 's the monkey ? `` grad b: mm - hmm . grad e: and , um , they found statistically very significant differences in english and german , so i i i it might be , since there are only a finite number of ways of doing it , that that german might be more like hebrew in that respect . grad b: hmm . grad e: the solution they proposed was that it was due to syntactic factors . phd a: that but it was n't was grad e: that syntactic facto factors do do play a role there , wh whether you 're more likely , you know , to develop uh , choices that lead you towards using uh intrinsic versus extrinsic reference frames . phd a: right . mm - hmm . right . grad b: i mean , it seems to me that you can get both in in english depending o professor c: hmm . grad b: you know , like , `` in front of the car `` could you know like , here 's the car sideways to me in between me and the car or something 's in front of the car , or whatever . i could see that , professor c: absolutely . grad b: but but anyway , so you know , i mean , this was this was a a very good talk on those kinds of issues and so on . so uh . grad e: i can also give you uh , a pointer to a paper of mine which is the the ultimate taxonomy of reference frames . grad b: alright ! cool ! grad e: so . professor c: oh . grad e: i 'm the only person in the world who actually knows how it works . professor c: oh . grad e: not really . professor c: great . no , i 've not seen that . phd a: what do you mean . um . `` reference frames `` ? grad e: it 's called a phd a: uh uh grad e: it 's it 's spatial reference frames . you actually have only um . if you wan na have a this is usually um i should there should be an `` l `` , though . well actually you have only have two choices . you can either do a two - point or a three - point which is you you 're familiar with th with the `` origo `` ? where that 's the center `` origo `` is the center of the f frame of reference . grad b: hmm . grad e: and then you have the reference object and the object to be localized . grad b: hmm . phd a: mm - hmm . grad e: ok ? in some cases the origo is the same as the reference object . professor c: so that would be `` origin `` in english , grad f: this was like grad b: the origin . phd a: right grad b: yeah . professor c: right ? grad e: `` origo `` is a terminus technikus . in that sense , that 's even used in the english literature . `` origo . `` grad b: oh , ok . i never heard it . professor c: alright . phd a: ok . grad b: ok . grad e: and um , so , this video tape is in front of me . grad b: mm - hmm . grad e: i 'm the origo and i 'm also the reference object . grad b: mm - hmm . phd a: right . grad e: those are two - point . professor c: mm - hmm . grad e: and three - point relations is if something has an intrinsic front side like this chair then your f shoe is behind the chair . professor c: yeah . grad b: mm - hmm . grad e: and , reference object and um . no , from from my point of view your shoe is left of the chair . grad b: right . you you can actually say things like , um , `` it 's behind the tree from me `` or something like that , i think , in in in certain circumstances in english , right ? as sort of `` from where i 'm standing it would appear that `` grad e: yeah . yeah . so , grad f: looks a little bit like reichenbach for time . professor c: yeah , it sounds like it , does n't it , grad b: yeah . professor c: yeah . grad f: it 's a lot like it . grad e: and then and then here you grad f: um . grad e: on this scale , you have it either be ego or allocentric . professor c: mm - hmm . grad e: and that 's { comment } that 's basically it . so . egocentric two - point , egocentric three - point , or you can have allocentric . grad b: oh , ok . grad e: so , `` as seen from the church , the town hall is right of that um , fire station `` . aa - huh { comment } it 's hardly ever used but it 's w phd a: i 'd love to see it if you if you have a copy kind of . uh . grad b: yeah . professor c: yeah . i see this is this is getting into ami 's thing . phd a: here grad b: mm - hmm . professor c: he 's he 's very interested in that . grad e: ok . professor c: so . grad b: me too . professor c: uh . yeah . well , why do n't you just put it on the web page ? there 's this edu right ? grad e: yeah it 's or or just yeah . professor c: or a link to it . grad e: it 's also all on my my home page at eml . it 's called `` an anatomy of a spatial description `` . professor c: just grad e: but i 'll send that link . phd a: ok , great . professor c: maybe just put a link on . yeah . grad e: yep . professor c: by the way , there something that i did n't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach . grad e: yep . grad b: huh . professor c: so there 's there 's uh all this linguistic stuff about you know , near and far , or yon and and so forth . grad b: mm - hmm . professor c: so this is all this is there 's this linguistic facts . but apparently , the uh . here 's the way the findings go . that , you know they do mri , and and if you 're uh got something within reach then there 's one of your areas lights up , and if something 's out of reach uh a different one . but here 's the the amazing result , um , they say . you get someone with a with a deficit so that they have a perfectly normal ability at distance things . so the s typical task is subdivision . so there 's a a line on the wall over there , and you give them a laser pointer , and you say , `` where 's the midpoint ? `` and they do fine . if you give them the line , and they have to touch it , they ca n't . there 's just that part of the brain is n't functioning , so they ca n't do that . here 's the real experiment . the same thing on the wall , you give them a laser , `` where is it ? `` , grad b: mm - hmm . professor c: they do it . give them a stick , long stick , and say `` do it `` , they ca n't do it . so there 's a remapping of distant space into nearby space . phd a: right . so they doubled the the end the end of this grad f: because it 's within reach now ? grad b: yeah , professor c: it 's not within reach and you use the within - reach uh , mechanism . grad b: yeah . grad f: oh . wow . grad b: circuits . phd a: right . professor c: so i 'll d i 'll dig you up this reference . grad b: that 's cool . professor c: and so this doe this is , uh first of all , it explains something that i 've always wondered about and i 'll do this this test on you guys as well . so . uh . how - i have had an experience , not often , but a certain number of times , when , for example , i 'm working with a tool , a screwdriver or something , for a long time , i start feeling the tip directly . not indirectly , but you actually can feel the tip . grad b: yeah yeah . professor c: and people who are uh accomplished violinists and stuff like that , claim they also have this kind of thing where you get a direct sensation of , physical sensation , of the end affector . grad b: yeah . what 's going on at the end of the tool , phd a: the ext the the the extension , grad b: yeah . professor c: huh ? grad b: what 's going on at the end of the tool , or whatever . professor c: yeah , within phd a: right . professor c: huh ? phd a: the extension of of your hand , right . professor c: yeah , right . have you hav y h had this ? phd a: the i i think so . i mean i i it 's not exactly the th same thing , but but s it it it 's getting close to that . grad b: yeah . grad f: w what does it feel like ? professor c: oh i it feels like your as if your uh neurons had extended themselves out to this tool , and you 're feeling forces on it and so forth and and you deal directly with it . phd a: i once i i was playing you know with those um uh devices that allow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something grad b: oh , ok . professor c: right , yeah yeah yeah . yeah . phd a: and there 's a correspondence between professor c: yeah . phd a: so i played with it . after a while , you do n't feel the difference anymore . i i mean it 's kind of grad b: mm - hmm . professor c: yeah , right . phd a: very kind of you stop back and suddenly it goes away and you have to kind of work again to recapture it , but yeah . grad b: yeah . professor c: right , yeah , so anyway , so so this was the first actual experimental evidence i 'd seen that was consistent with this anecdotal stuff . grad b: that 's cool . professor c: and of course it makes a lovely def uh story about why languages uh , make this distinction . of course there are behavioral differences too . things you can reach are really quite different than things you ca n't . grad b: yeah . professor c: but there seems to be an actu really deep embodied neural difference . and i this is , um so . in addition to the e grad e: this is more proximal - distal . professor c: yeah uh exactly . so in addition to e ego and allocentric uh which appear all over the place , you also apparently have this proximal - distal thing which is very deeply uh embedded . s grad e: well , dan montello sort of , he he does the uh uh th the cognitive map world , down in santa barbara . and he he always talks about these he he already well i probably most likely without knowing this this evidence uh is talking about these small scale spaces that you can manipulate versus large scale environmental spaces . professor c: yeah . well there 's there 's uh been a lot of behavioral things o on this , but that was the first neur neuro - physiological thing i saw . anyway yeah , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , right ? and so these issues about uh , reference , and spatial { comment } reference , discourse reference , uh - uh - uh - uh { comment } all this sort of stuff , uh , deixis which is part of what you were talking about , grad b: mm - hmm . mm - hmm . professor c: um so , all of this stuff is coming up essentially starting now . so we got ta do all this . so there 's that . and then there 's also a set of system things that come up . so `` ok , we 're not using their system . that means we need our system . `` grad b: mm - hmm . professor c: right ? grad b: yeah . professor c: it it follows . and so , uh , in addition to the business about just getting the linguistics right , and the formalism and stuff , we 're actually gon na build something and uh , johno is point person on the parser , analyzer , whatever that is , and we 're gon na start on that in parallel with the um , the grammar stuff . grad b: alright . professor c: but to do that we 're gon na need to make some decisions like ontology , so , um and so this is another thing where we 're gon na , you know , have to get involved and make s relatively early i think , make some decisions on uh , `` is there an ontology api that that `` there 's a sort of standard way of getting things from ontologies and we build the parser and stuff around that , or is there a particular ontology that we 're gon na standardize on , and if so for example , is there something that we can use there . i does uh either the uh smartkom project or one of the projects at eml have something that we can just p pull out , for that . uh , so there are gon na be some some some things like that , which are not science but system . but we are n't gon na ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually uh build some of it . and how much we build , and and so forth . grad b: i professor c: uh . part of it , if it works right , is wh it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that um , there 's a good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , grad b: ok . professor c: and of course it 's only w in both cases it 's only one piece of a bigger system . grad b: mm - hmm . professor c: but it would be nice if that piece were exactly the same piece . grad b: right . professor c: it was just this uh construction analyzer . and so we think we think we have a shot at at that . grad b: ok . professor c: so . the for so . to to come full circle on that , this formalization task , ok ? is trying to get the formalism into into a shape where it can actually uh grad b: yeah . be of use to someone who 's trying to do this , right ? professor c: d well , yeah , where it actually is is covers the whole range of things . and the the the the thing that got mark into the worst trouble is he had a very ambitious thing he was trying to do , and he insisted on trying to do it with a limited set of mechanisms . it turned out , inherently not to cover the space . grad b: ok . professor c: and it just it was just terribly frustrating for him , grad b: yeah . professor c: and he seemed fully committed to both sides of this i i irreconcilable thing . grad b: i see . right . professor c: and . uh . johno is much more pragmatic . grad b: ok . good to know . professor c: uh . huh ? is this is true , is it not ? grad d: yes . professor c: ok . so there 's you know sort of , yeah , deep , really deep , emotional commitment to a certain theory being uh , complete . grad b: oh , ok . grad f: you do n't have a hidden purist streak ? grad d: oh no . professor c: we - well it has n't it it certainly has n't been observed , in any case . grad f: ok . just checking . grad d: no sir . grad b: alright . professor c: um . now , you do , but that 's ok . uh . so . for for grad b: cuz i do n't have to implement anything . professor c: exactly right . exactly . grad f: i have a problem , then . it 's so . whether i do depends on whether i 'm talking to him or him probably . phd a: hmm . grad b: yeah , right . professor c: right . why a actually , uh , the thing is , you you do but , th the thing you have to im implement is so small that uh . grad f: which meeting i 'm in . it 's ok to be purist within that context . professor c: within that , yeah , grad f: yes , professor c: and uh , it 's a and still , i think , you know , get something done . grad f: good . grad b: cool ! professor c: but to try to do something upscale and purist particularly if if um what you 're purist about does n't actually work , is real hard . grad f: yay . grad b: mm - hmm . yeah . professor c: ok . and then the other thing is while we 're doing this uh robert 's gon na pick a piece of this space , phd a: it 's possible yeah . grad b: ok . professor c: ok , uh , for his absentee thesis . i think you all know that that you can just , in germany almost just send in your thesis . grad b: just a drive up . ca - chuk ! phd a: um professor c: yeah right . grad b: there you go . professor c: ok . grad e: the - th there there 's a drive - in thesis uh sh joint over in saarbruecken . grad b: exactly . drive through , yeah . professor c: it costs a lot . the the amount you put in your credit card and as well . but , uh , but anyway , so , uh , that 's um , also got ta be worked out , hopefully over the next few weeks , so that that it becomes clear uh , what piece uh , robert wants to jump into . and , while we 're at this level , uh , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . grad b: ok . professor c: so , de uh . and her name is eva . grad b: ok . professor c: it really is . nobody believed th th that grad f: yeah , i thought it had to be a joke , of your part , you know professor c: yeah . grad f: like { comment } `` johno made it up , i 'm sure . `` grad g: is this person someone who 's in first - year this year , professor c: no , first year coming . grad g: or professor c: so , she 's she 's now out here she 's moved , and she 'll be a student as of then . grad g: ok . professor c: and probably she 'll pick up from you on the belief - net stuff , so sh she 'll be chasing you down and stuff like that . grad g: ok . professor c: uh . grad e: document . grad g: right . professor c: uh , against all traditions . and actually i talked today to a uh undergraduate who wants to do an honors thesis on this . uh grad f: someone from the class ? professor c: no , interestingly enough . grad f: we always get these people who are not in the class , who professor c: some of th some of them , yeah . grad f: it 's interesting . professor c: so anyway , uh , but uh she 's another one of these ones with a three point nine average and so forth and so on . grad b: mm - hmm . professor c: uh , so , um , i 've give i 've given her some things to read . so we 'll see how this goes . oh there 's yet another one of the incoming first { comment } incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . um , anyway , so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gon na make sense to have this be separate from the other bigger effort with the formalization stuff or not , i 'm not sure . it partly depends on w what your thesis turns out to be and how that goes . s so , we 'll see . and then , ami , you can decide , you know , how much time you wan na put into it and uh , it it 's beginning to take shap shape , phd a: ok . professor c: so uh and , phd a: right professor c: i think you will find that if you want to look technically at some of the your traditional questions in this light , uh keith , who 's buil building constructions , will be quite happy to uh see what , you know , you envision as the issues and the problems and um , how they might uh get reflected in constructions . grad b: sure . professor c: i suspect that 's right . grad b: yeah . yeah . phd a: i i may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but uh , after that or before that . professor c: ok , fine . and , um , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in in the neighborhood . phd a: right . yeah be uh actu actually i 'm invited to do some consulting with a bank in geneva which has an affiliation with a research institute in geneva , which i forgot the name of . professor c: yeah . yep . e o do y phd a: yeah . professor c: well , we we 're connected to uh there 's a there 's a a very significant connection between we 'll we 'll go through this , phd a: yeah . professor c: icsi and epfl , which is the , uh it 's the fr ge - germany 's got two big technical institutes . there 's one in in zurich , phd a: mm - hmm . professor c: e t and then there 's one , the french speaking one , in lausanne , grad b: oh , so in switzerland . professor c: ok ? which is uh e p phd a: great . professor c: f l . so find out who they are associated with in geneva . phd a: right . professor c: probably we 're connected to them . phd a: great . i 'll let you know . s i 'll send you email . professor c: ok . yeah , and so anyway we c uh we can m undoubtedly get ami uh to give a talk at uh eml or something like that . while he 's in in uh grad e: hmm . uh . i i think the one you you gave here a couple of weeks ago would be of interest there , too . phd a: sure , yeah . professor c: a lot of interest . actually , either place , dfki or uh yeah , so , and and if there is a book , that you 'll be building up some audience for it . phd a: yeah . right . professor c: and you 'll get feedback from these guys . phd a: great , yeah . professor c: cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . phd a: cool . professor c: ok . so , uh , unless we wan na start digging into the uh the belief - net and the decisions now , which would be fine , it 's probably grad e: i i tho it 's probably better if i come next week with the um version o point nine of the structure . professor c: ok . so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying `` here 's what we think we understand , here are the things we think we do n't understand `` . and that we as a group will try to to finish it . what i 'd like to do is shoot f for finishing all this next monday . grad g: sure . professor c: ok ? uh , `` these are the decisions `` i do n't think we 're gon na get lots more information . it 's a design problem . grad b: mm - hmm . professor c: you know . we grad g: yeah . professor c: yeah . and let 's come up with a first cut at what this should look like . and then finish it up . grad b: ok . professor c: does that so make sense ? grad b: ok . grad e: and um , the the sem semester will be over next week but then you have projects for one more week to come ? grad g: no , i i think i 'll be done everything by this uh by the end of this week . grad e: same with you ? no . grad d: nnn . this well , i 've i have projects , but then the my prof professor of one of my classes also wa has a final that he 's giving us . and he 's giving us five days to do it which means it going to be hard . grad b: yeah . professor c: yeah . oh . is it a take - home final ? who 's doing this ? grad d: yeah . aikin , alex , yeah . professor c: yeah , figured . that would have been i my guess . grad g: hmm . professor c: right . um , but anyway , yeah . grad b: pretty soon . grad e: ok . professor c: ok , so i guess that 's grad d: so , the seventeenth will definitely be the last day , like it or not for me . professor c: right . right . so let 's do this , and then we we well there 's gon na be some separate co these guys are talking , uh we have a group on the formalization , uh nancy and johno and i are gon na talk about parsers . so there 're various kinds of uh grad b: ok . professor c: of course , nothing gets done even in a meeting of seven people , grad b: right . professor c: right ? so , um , two or three people is the size in which actual work gets done . grad e: mmm . grad b: yeah . professor c: so we 'll do that . great . oh , the other thing we wan na do is catch up with uh , ellen and see what she 's doing because the um image schemas are going to be um , an important pa grad b: yeah . quite relevant , yeah . professor c: we we want those , grad b: yeah , oh yeah . professor c: right ? and we want them formalized and stuff like that . grad b: yeah . professor c: so let me let me make a note to do that . grad b: ok . yeah , i 'm actually probably going to be in contact with her uh pretty soon anyway because of various of us students were going to have a reading group about precisely that sort of thing over the summer , grad d: ok . professor c: oh right ! right right right ! grad b: so . professor c: that 's great ! yeah , i i shweta mentioned that , although she said it 's a secret . grad b: ok . grad d: hi grad b: right , no faculty ! professor c: th - the faculty are n't faculty are n't supposed to know . grad d: wednesday 's much better for me , yeah . professor c: but um , i 'm sufficiently clueless that i count as a grad b: yeah , right . it 's as if we did n't tell anyone at all , grad d: bhaskara . grad b: right .","output":"the translation of smartkom to english is in its final stages . the variety of linguistic conventions seem to develop around an ego\/allo-centric and a proximal\/distal paradigm . from an engineering perspective , the belief-net for the ave task should be completed within a few weeks . since the whole system is going to be re-designed , there are major decisions to be taken regarding the parser and the ontology , as well as what can be re-used from past eml projects . in parallel , another team is working on formalisation and notation . finally , more ideas are expected to come from students and their research ."},{"instruction":"what were the problems encountered with smartkom system ?","input":"grad b:  grad d: how many batteries do you go through ? grad b: thank you . professor c: alright . phd a: sure . professor c: good . yeah . ok so , let 's get started . nancy said she 's coming and that means she will be . um . my suggestion is that robert and johno sort of give us a report on last week 's adventures uh to start . so everybody knows there were these guys f uh from heidelber - uh , uh , actually from uh dfki uh , part of the german smartkom project , who were here for the week and , i think got a lot done . grad e: yeah , i think so too . um . the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like `` roman numeral one , am smarticus . `` it actually says , `` roemisch einz , am smarticus , `` grad b: ok . grad e: which means it 's just using a german sythesis module for english sentences . grad b: ok . grad e: so uh , professor c: it does n't know `` i `` . grad b: ok . grad e: um , the uh grad b: oh , am spartacus . `` grad d: `` i am sm - i am smarticus `` is what it 's saying . phd a: right . grad b: verstehe . ok . grad d: i gue grad e: the uh sythesis is just a question of um , hopefully it 's just a question of exchanging a couple of files , once we have them . and , um , it 's not going to be a problem because we decided to stick to the so - called concept to speech approach . so i 'm i 'm i 'm going backwards now , so `` synthesis `` is where you sort of make this uh , make these sounds , and `` concept to speech `` is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . grad b: mm - hmm . grad e: and , uh , johno learned how to write xml tags . uh , and did write the tree adjoining grammar for some some sentences . no , right ? grad d: yeah . grad e: yeah , for a couple grad d: so . bu - uh , i the way the uh , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to a er in xml and there 's a conversion system for different uh , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is uh , in a lisp - like the knowledge base is in a lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have a basically , a goal and it , you know , says `` ok , well i 'm gon na try to do the greet - the - person goal , grad b: mm - hmm . grad d: so it just starts uh , it binds some variables and it just decides to , you know , do some subscold . basically , it just means `` build the tree . `` grad b: ok . grad d: and then it passes the tree onto , uh , the ge the generation module . grad e: but i think that the point is that out of the twelve possible utterances that the german system can do , we 've already written the the syntax trees for three or four . grad d: we yeah . so , the syntax trees are very simple . it 's like most of the sentences in one tree , grad b: mm - hmm . grad d: and instead of , you know , breaking down to , like , small units and building back up , they basically took the sentences , and basically cut them in half , or you know , into thirds or something like that , and made trees out of those . and so uh , uh tilman wrote a little tool that you could take lisp notation and generate an xml , uh , tree . uh , s what do ca structure from the from the lisp . and so basically you just say , you know , `` noun goes to `` , you know , er , nah , i do n't re i 've never been good at those . so there 's like the vp goes to n and those things in lisp , and it will generate for you . grad b: ok . n , n , v yeah , ok . alright . grad e: and because we 're sticking to that structure , the synthesis module does n't need to be changed . so all that f fancy stuff , and the texas speech version of it , which is actually the simpler version , is gon na be done in october which is much too late for us . so . this way we we worked around that . the , uh the system , um i can show you the system . i actually want , at least , maybe , you should be able to start it on your own . if you wan na play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on on on seventeen modules before they actually can stomach it , anything . and send in a a a couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we do n't have here . grad b: mm - hmm . grad e: and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was a lot of engineering stuff . no science in there whatsoever , but it 's working now , and um , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation . grad d: why i had i did need to chan generate different trees than the german ones , mainly because you know like uh , the gerund in in german is automatically taken care of with just a regular verb , grad e: you have to switch it on . grad b: mm - hmm . grad d: so i 'd uh have to add `` am walking , `` grad b: ok . grad d: or i 'd have to add a little stem for the `` am `` , when i build the built the tree . grad b: ok . yeah , i noticed that um , that some of the examples they had , had you know , non - english word orders and so on , you know . and then all that good stuff . so . professor c: alright . grad d: yeah . grad b: like . professor c: so it might be worth , keith , you looking at this , grad b: yeah . professor c: um grad b: i i still do n't i still do n't really understand e like grad d: well tilman s grad b: i mean we sort of say , um you know , i i still do n't exactly understand sort of the information flow uh in in this thing , or what the modules are and so on . so , you know , like just that such - and - such module uh um decides that it wants to achieve the goal of greeting the user , and then magically it sort of s professor c: yeah grad b: i mean , how does it know which syntactic structure to pull out , and all that ? professor c: i thi yeah . so . i think it 's not worth going over in the group , grad b: r uh sure . professor c: but sort of when you get free and you have the time uh either robert or johno or i can walk you through it . grad b: yeah , soon . ok . professor c: and you can ask all the questions about how this all fits together . grad b: that 's fine . professor c: it 's eee { comment } messy but once you understand it you understand it . it 's it 's there 's nothing really complicated about it . grad b: ok . grad e: no . grad b: and i remember one thing that that came up in the talk last wednesday . um , was this , i i think he talked about the idea of like , um he was talking about these lexicalized uh , uh , tree adjoining grammars where you sort of for each word you , um grad d: ok , you know how to do it ? grad b: for each lexical item , the lexical entry says what all the uh trees are that it can appear in . and of course , that 's not v that 's the opposite of constructional . that 's , you know , that 's that 's hpsg or whatever . professor c: right . grad b: you know ? professor c: right . now , we 're we 're not committed for our research to do any of those things . grad b: yeah . mm - hmm . professor c: so uh we are committed for our funding . grad b: right . professor c: ok ? to uh grad b: make our stuff fit to that . professor c: yeah , to n no , to just get the dem get the demos they need . grad b: uh - huh . professor c: ok ? so between us all we have t to get th the demos they need . if it turns out we can also give them lots more than that by , you know , tapping into other things we do , that 's great . grad d: you should probably move the microphone closer to your face . grad b: mm - hmm . professor c: but i it turns out not to be in an any of the contracts grad d: there 's like a little the twisty thing , you can move it with . grad b: ok . professor c: and , s deliberately . so , the reason i 'd like you to understand uh what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with a question of `` could we fit this deeper stuff in there ? `` or something . you know what the hell we we 're talking about fitting in . grad b: right . ok . professor c: so it 's just , uh in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? uh , is there anything we can give back , beyond th the sort of minimum requirements ? but none of that has a short time fuse . grad b: ok . professor c: so th the demo the demo requirements for this fall are sort of taken care of as of later this week or something . and then so , it 's probably fifteen months or something until there 's another serious demo requirement . grad b: oh ok . professor c: that does n't mean we do n't think about it for fifteen months , grad b: right . professor c: but it means we can not think about it for six months . grad b: right , yeah . professor c: so . the plan for this summer uh , really is to step back from the applied project , grad e: right . professor c: keep the d keep the context open , but actually go after the basic issues . grad b: hmm . oh ok . professor c: and , so the idea is there 's this uh , other subgroup that 's worrying about formalizing the nota getting a notation . but sort of in parallel with that , uh , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , grad b: mm - hmm . professor c: but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . grad b: yeah . ok . got it . professor c: it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and stuff . grad b: yeah . professor c: and , i don i do n't want you f feeling that you have to somehow meet all these other constraints . grad b: right , ok . professor c: um . and similarly with the parsing , uh we 're gon na worry about parsing uh , the general case you know , construction parser for general constructions . and , if we need a cut - down version for something , or whatever , we 'll worry about that later . grad b: ok . professor c: so i 'd like to , for the summer turn into science mode . grad b: ok . professor c: and i assume that 's also , uh , your plan as well . grad b: so i mean , the the point is that like the meetings um so far that i 've been at have been sort of been geared towards this demo , professor c: right . yeah . yeah . grad b: and then that 's going to go away pretty soon . professor c: but but we we 're swit grad b: ok . professor c: right . grad b: and then we 'll sort of shift gears a fairly substantially , professor c: yeah . grad e: it 's professor c: yeah . grad b: huh ? professor c: yeah . grad e: it 's got . what i what i think is is a good idea that i can can show to anyone who 's interested , we can even make a sort of an internal demo , and i i show you what i do , grad b: mm - hmm . grad e: i speak into it and you hear it talk , grad b: ok . grad e: and i can sort of walk f through the information . so , this is like in half hour or forty - five minutes . just fun . grad b: ok . grad e: and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , sort of , give a sensible answer . grad b: right . ok . professor c: so , c sh we could set that up as actually an institute wide thing ? just give a talk in the big room , and and so peo people know what 's going on ? when you 're ready ? grad e: absolutely . professor c: yeah i mean , that 's the kind of thing that 's the level at which you know we can just li invite everybody and say `` this is a project that we 've been working on and here 's a demo version of it `` and stuff like that . grad b: yeah . grad e: ok . well d we we do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're grad b: uh - huh . professor c: indeed . grad e: yeah . ok . makes sense . professor c: but any so that e e it 's clear , then , i think . actually , roughly starting uh let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . grad b: yeah . ok . professor c: but uh starting next meeting i think we want to flip into this mode where uh . i mean there are a lot of issues , what 's the ontology look like , grad b: mm - hmm . professor c: you know what do the constructions look like , what 's the execution engine look like , mmm lots of things . grad b: mm - hmm . professor c: but , more focused on uh an idealized version than just getting the demo out . now before we do that , let 's get back in oh ! but , it 's still , i think , useful for you to understand the demo version enough , so that you can can see what what it is that that uh it might eventually get retro - fitted into or something . grad b: yeah . ok , right . professor c: and johno 's already done that , uh , looked at the dem uh the looked at the smartkom stuff . grad d: wa uh to some de uh what what part of th the smartkom stuff ? professor c: well , the parser , and that stuff . grad d: oh yeah yeah . professor c: ok . anyway . so , the trip the report on these the last we we sort of interrupted you guys telling us about what happened last week . grad b: yeah . it 's alright . grad e: um . well it was just amazing to to see uh how how instable the whole thing is , professor c: maybe you 're done , then . grad e: and if you just take the and i g i got the feeling that we are the only ones right now who have a running system . i do n't know what the guys in kaiserslautern have running because e the version that is , the full version that 's on the server d does not work . and you need to do a lot of stuff to make it work . and so it 's and even tilman and ralf sort of said `` yeah there never was a really working version that uh did it without th all the shortcuts that they built in for the uh october @ @ version `` . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , uh it was fun to some extent , but the uh the outcome that is sort of of scientific interest is that i think both ralf and tilman um , i know that they enjoyed it here , and they r they they liked , uh , a lot of the stuff they saw here , what what we have been thinking about , and they 're more than willing to to um , cooperate , by all means . and um , part of my responsibility is uh to use our internal `` group - ware `` server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and and generating and constructions w we we sort of uh put it in there and they put what they do in there and maybe we can even um , get some overlap , get some synergy out of that . and um , the , uh if i find someone at in eml that is interested in that , um i i may even think that we could look take constructions and and generate from them because the tree adjoining grammars that that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g - like stuff , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're of course definitely focused on the understanding , um , pipeline . professor c: anyth - any other { comment } uh repo visit reports sort of stories ? uh we so we now know i think , what the landscape is like . grad b: mm - hmm . professor c: and so we just push on and and uh , do what we need to do . and one of the things we need to do is the um , and this i think is relatively tight tightly constrained , is to finish up this belief - net stuff . so . uh . and i was going to switch to start talking about that unless there 're m other more general questions . ok so here 's where we are on the belief - net stuff as far as i understand it . um . going back i guess two weeks ago uh robert had laid out this belief - net , missing only the connections . right ? that is { comment } so , he 'd put all th all the dots down , and we went through this , and , i think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . yeah { comment } we may run across one or two more . but of course the connections were n't . so , uh bhaskara and i went off and looked at some technical questions about were certain operations sort of legitimate belief - net computations and was there some known problem with them or had someone already uh , solved you know how to do this and stuff . and so bhaskara tracked that down . the answer seems to be uh , `` no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do `` . and , so the current state of things is that , again , starting now , um we 'd like to actually get a running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and uh , he 's gon na leave us an inheritance , which is a uh hopefully a belief - net that does these things . and there 're two aspects to it , one of which is , you know , technical , getting the coding right , and making it run , and uh stuff like that . and the other is the actual semantics . ok ? what all you know , what are the considerations and how and what are the ways in which they relate . so he doe h he does n't need help from this group on the technical aspects or if he does uh we 'll do that separately . grad b: mm - hmm . professor c: but in terms of what are the decisions and stuff like that , that 's something that we all have to work out . is is that right ? i mean that 's that 's both you guys ' understanding of where we are ? grad e: absolutely . professor c: ok . grad g: so , i guess , um is there like a latest version of the belief - net of the proposed belief - net ? like grad e: we had um decided grad g: like grad e: um . well , no , we did n't decide . we wanted to look into maybe getting it , the visualization , a bit clearer , but i think if we do it , um , sort of a paper version of all the nodes and then the connections between them , that should suffice . grad g: mm - hmm . yeah , that should be fine . professor c: yeah i mean , that 's a separate problem . grad d: yeah , i professor c: we do in the long run wan na do better visualization and all that stuff . grad e: yeah . professor c: that 's separable , yeah . grad d: i did look into that , uh in terms of , you know , exploding the nodes out and down ag professor c: yep . right . grad d: javabayes does not support that . i can imagine a way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it , professor c: not not at this point . grad d: and i went through all the other packages on murph - kevin murphy 's page , professor c: right . grad d: and i could n't find the necessary mix of free and uh with the gui and , with this thing that we want . professor c: well , we can p if it 's if we can pay yeah . if you know it 's paying a thousand dollars or something we can do that . ok ? so so do n't view free as as a absolute constraint . grad d: ok . ok , so then i 'll go back and look at the ones on the list that professor c: ok . and you can ask kevin . grad e: but grad g: yeah . grad d: mmm . grad e: but grad g: yeah , the one that uh people seem to use is uh hugin or whatever ? professor c: hugin , yeah that 's free . grad g: how exp i do n't think it 's is it free ? because i 've seen it advertised in places so i it seems to professor c: uh , it may be free to academics . like i i do n't know . i have a co { comment } i have a copy { comment } that i l i downloaded . grad g: ok . professor c: so , at one point it was free . grad g: ok . professor c: uh but yo i noticed people do use hugin so um , grad d: how do you spell that ? professor c: hugin . grad f: why professor c: and bhaskara can give you a pointer . so then , in any case , um but paying a lit you know , if i if it 's uh probably for university , it 's it 's gon na be real cheap anyway . but um , you know , if it 's fifty thousand dollars we are n't gon na do it . i 'm mean , we have no need for that . grad e: i i also s would suggest not to d spend two weeks in in in changing the the javabayes code . professor c: no , grad b: yeah . professor c: he 's not gon na do that . grad d: ok . grad e: i i will send you a pointer to a java applet that does that , it 's sort of a fish - eye . you you have a node , and you click on it , and it shows you all the connections , grad d: mmm . grad e: and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that does n't work , it 's not a problem we we need to solve right now . what i 'm what my job is , i will , um , give you the input in terms of of the internal structure . maybe node by node , or something like this ? or should i collect it all grad g: mm - hmm . grad e: and professor c: does n't matter . grad g: um , just any like like sort of rough representation of the entire belief - net is probably best . grad e: ok . and um you 're gon na be around ? t again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ? grad g: yeah i mean , yeah , i can like i c um . this week i guess um , kind of i have a lot of projects and stuff but after that i will generally be more free . so yes , i might i can be around . and g i mean , generally if you email me also i can be around on other days . grad e: yeah . ok . professor c: yeah and this is not a crisis that i mean , you do , e everybody who 's a student should , you know do their work , get their c courses all in good shape and and and and then we 'll dig d dig down on this . grad e: yeah , that 's yeah . ok . no , that 's good . that means i have i h i can spend this week doing it . so . grad g: ok . grad b: how do you go about this process of deciding what these connections are ? i know that there 's an issue of how to weight the different things too , and stuff . right ? i mean do you just sort of guess and see if it sort of professor c: right . well there there there there 're two different things you do . grad e: it 's professor c: one is you design and the other is you learn . ok ? so uh what we 're gon na do initially is is do design , and , i if you will , guess . grad b: ok . professor c: ok . uh that is you know use your best knowledge of of the domain to uh , hypothesize what the dependencies are and stuff . grad b: right . ok . professor c: if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure grad b: yeah . professor c: and there are even techniques for learning the structure , although that takes a lot more data , and it 's not as @ @ and so forth and so on . so uh but for the limited amount of stuff we have for this particular exercise i think we 'll just design it . grad b: alright . grad e: yeah . fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and stuff . grad b: ok . grad e: so but this is the { comment } long run . grad b: yeah . grad e: but to solve our problems ag uh a mediocre design will do i think in the beginning . grad b: yeah , that 's right . yeah , oh , and by the way , speaking of data , um , are there i could swore uh , i could swear i saw it sitting on someone 's desk at some point , but is there a um a transcript of any of the , sort of , initial interactions of people with the with the system ? cuz you know , i 'm still sort of itching to to look at what look at the stuff , and see what people are saying . professor c: mm - hmm . yeah . yeah make yourself a note . so and and , of course keith would like the german as well as the english , so whatever you guys can get . grad e: the german . oh yeah , of course , german . yeah . professor c: yeah , the y your native language , right ? you remember that one . grad e: ok . that 's important , yeah . grad b: yeah , professor c: so he 'll get you some data . grad b: u ok . yeah , i mean i i sort of um found the uh , uh the audio of some of those , and um , it kind of sounded like i did n't want to trudge through that , you know . grad e: hmm . grad b: it was just strange , but . professor c: yep . grad e: we probably will not get those to describe because they were trial runs . grad b: oh yeah , ok . grad e: um , but uh that 's th but we have data in english and german already . grad b: ok , yeah , i mean . grad e: so . transcribed . i will send you that . ok . professor c: ok , so while we 're still at this sort of top level , anything else that we oughta talk about today ? grad e: ho - how was your thingy . grad b: oh , um , i just wanted to , uh , s like mention as an issue , um , you know last meeting i was n't here because i went to a linguistics colloquium on the fictive motion stuff , professor c: oh right . grad b: and that was pretty interesting and you know , i mean , seems to me that that will fairly obviously be of relevance to uh to what we 're doing here because you know people are likely to give descriptions like you know , `` what 's that thing uh right where you start to go up the hill , `` or something like that , you know , meaning a few feet up the hill or whatever from some reference point and all that stuff so i mean , i 'm sure in terms of you know , people trying to state locations or , you know , all that kind of stuff , this is gon na be very relevant . so , um , now that was the talk was about english versus japanese , um , which obviously the japanese does n't affect us directly , except that , um , some of the construction he 'd what he talked about was that you know in english we say things like th you know , `` your bike is parked across the street `` and we use these prepositional phrases , you know , `` well , if you were to move across the street you would be at the bike `` , but um in in japanese the the more conventionalized tendency is to use a sort of a description of `` where one has crossed to the river , there is a tree `` . um , and you know , you can actually say things like , um , `` there 's a tree where one has crossed the river , but no one has ever crossed the river `` , or something like that . so the idea is that this really is you know that 's supposed show that 's it 's really fictive and so on . but um but the point is that that kind of construction is also used in english , you know , like `` right where you start to go up the hill `` , or `` just when you get off the train `` , or something like that to uh , to indicate where something is . professor c: mmm . grad b: so we 'll have to think about professor c: so how much is that used in german ? grad e: um . the uh well i wa i was on a uh on a on a different sidetrack . professor c: oh , ok . grad e: i mean , the the deep map project which um is undergoing some renovation at at the moment , but this is a a three language project : german , english , japanese . grad b: ok . grad e: and um , we have a uh , uh i have taken care that we have the the japanese generation and stuff . and so i looked into uh spatial description . so we can generate spatial descriptions , how to get from a to b . and and information on objects , in german , english , and japanese . grad b: mm - hmm . grad e: and there is a huge uh project on spatial descriptions uh differences in spatial descriptions . well , if yo if you 're interested in that , so how how , i mean it does sort of go d all the way down to the conceptual level to some extent . grad b: ok . grad e: so . um . professor c: so , where is this huge project ? grad e: it 's kleist . it 's the uh bielefeld generation of uh spatial descriptions and whatever . professor c: mm - hmm . grad e:  professor c: well , that may be another thing that keith wants to look at . grad b: ok . grad e: but um , i i think we should leave japanese constructions maybe outside of the scope for for now , grad b: yeah . grad e: but um definitely it 's interesting to look at at cross the bordered there . professor c: mm - hmm . phd a: are are you going to p pay any attention to the relative position of of the direction relative relative to the speaker ? for example , there are some differences between hebrew and english . we can say um `` park in front of the car `` as you come beh you drive behind the car . in hebrew it means `` park behind the car `` , because to follow the car is defined as it faces you . grad e: mm - hmm . intrinsic , yeah . phd a: while in english , front of the car is the absolute front of the car . grad b: ok . phd a: so . grad b: right , so the canonical direction of motion determines where the front is . phd a: right . right . grad b: ok . phd a: so , i i i is german uh closer to to e uh , uh , uh , uh to e i mean uh grad e: mm - hmm . phd a: i do n't think it it 's related to syntax , though , so it may be entirely different . grad e: um , as a matter of fact professor c: no , it 's not . grad b: right . phd a: yeah . grad e: um . did you ever get to look at the the rou paper that i sent you on the on that problem in english and german ? grad b: i think grad e: carroll , ninety - three . um . i there is a a study on the differences between english and german on exactly that problem . phd a: hmm . grad e: so it 's they actually say `` the monkey in front of the car , where 's the monkey ? `` grad b: mm - hmm . grad e: and , um , they found statistically very significant differences in english and german , so i i i it might be , since there are only a finite number of ways of doing it , that that german might be more like hebrew in that respect . grad b: hmm . grad e: the solution they proposed was that it was due to syntactic factors . phd a: that but it was n't was grad e: that syntactic facto factors do do play a role there , wh whether you 're more likely , you know , to develop uh , choices that lead you towards using uh intrinsic versus extrinsic reference frames . phd a: right . mm - hmm . right . grad b: i mean , it seems to me that you can get both in in english depending o professor c: hmm . grad b: you know , like , `` in front of the car `` could you know like , here 's the car sideways to me in between me and the car or something 's in front of the car , or whatever . i could see that , professor c: absolutely . grad b: but but anyway , so you know , i mean , this was this was a a very good talk on those kinds of issues and so on . so uh . grad e: i can also give you uh , a pointer to a paper of mine which is the the ultimate taxonomy of reference frames . grad b: alright ! cool ! grad e: so . professor c: oh . grad e: i 'm the only person in the world who actually knows how it works . professor c: oh . grad e: not really . professor c: great . no , i 've not seen that . phd a: what do you mean . um . `` reference frames `` ? grad e: it 's called a phd a: uh uh grad e: it 's it 's spatial reference frames . you actually have only um . if you wan na have a this is usually um i should there should be an `` l `` , though . well actually you have only have two choices . you can either do a two - point or a three - point which is you you 're familiar with th with the `` origo `` ? where that 's the center `` origo `` is the center of the f frame of reference . grad b: hmm . grad e: and then you have the reference object and the object to be localized . grad b: hmm . phd a: mm - hmm . grad e: ok ? in some cases the origo is the same as the reference object . professor c: so that would be `` origin `` in english , grad f: this was like grad b: the origin . phd a: right grad b: yeah . professor c: right ? grad e: `` origo `` is a terminus technikus . in that sense , that 's even used in the english literature . `` origo . `` grad b: oh , ok . i never heard it . professor c: alright . phd a: ok . grad b: ok . grad e: and um , so , this video tape is in front of me . grad b: mm - hmm . grad e: i 'm the origo and i 'm also the reference object . grad b: mm - hmm . phd a: right . grad e: those are two - point . professor c: mm - hmm . grad e: and three - point relations is if something has an intrinsic front side like this chair then your f shoe is behind the chair . professor c: yeah . grad b: mm - hmm . grad e: and , reference object and um . no , from from my point of view your shoe is left of the chair . grad b: right . you you can actually say things like , um , `` it 's behind the tree from me `` or something like that , i think , in in in certain circumstances in english , right ? as sort of `` from where i 'm standing it would appear that `` grad e: yeah . yeah . so , grad f: looks a little bit like reichenbach for time . professor c: yeah , it sounds like it , does n't it , grad b: yeah . professor c: yeah . grad f: it 's a lot like it . grad e: and then and then here you grad f: um . grad e: on this scale , you have it either be ego or allocentric . professor c: mm - hmm . grad e: and that 's { comment } that 's basically it . so . egocentric two - point , egocentric three - point , or you can have allocentric . grad b: oh , ok . grad e: so , `` as seen from the church , the town hall is right of that um , fire station `` . aa - huh { comment } it 's hardly ever used but it 's w phd a: i 'd love to see it if you if you have a copy kind of . uh . grad b: yeah . professor c: yeah . i see this is this is getting into ami 's thing . phd a: here grad b: mm - hmm . professor c: he 's he 's very interested in that . grad e: ok . professor c: so . grad b: me too . professor c: uh . yeah . well , why do n't you just put it on the web page ? there 's this edu right ? grad e: yeah it 's or or just yeah . professor c: or a link to it . grad e: it 's also all on my my home page at eml . it 's called `` an anatomy of a spatial description `` . professor c: just grad e: but i 'll send that link . phd a: ok , great . professor c: maybe just put a link on . yeah . grad e: yep . professor c: by the way , there something that i did n't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach . grad e: yep . grad b: huh . professor c: so there 's there 's uh all this linguistic stuff about you know , near and far , or yon and and so forth . grad b: mm - hmm . professor c: so this is all this is there 's this linguistic facts . but apparently , the uh . here 's the way the findings go . that , you know they do mri , and and if you 're uh got something within reach then there 's one of your areas lights up , and if something 's out of reach uh a different one . but here 's the the amazing result , um , they say . you get someone with a with a deficit so that they have a perfectly normal ability at distance things . so the s typical task is subdivision . so there 's a a line on the wall over there , and you give them a laser pointer , and you say , `` where 's the midpoint ? `` and they do fine . if you give them the line , and they have to touch it , they ca n't . there 's just that part of the brain is n't functioning , so they ca n't do that . here 's the real experiment . the same thing on the wall , you give them a laser , `` where is it ? `` , grad b: mm - hmm . professor c: they do it . give them a stick , long stick , and say `` do it `` , they ca n't do it . so there 's a remapping of distant space into nearby space . phd a: right . so they doubled the the end the end of this grad f: because it 's within reach now ? grad b: yeah , professor c: it 's not within reach and you use the within - reach uh , mechanism . grad b: yeah . grad f: oh . wow . grad b: circuits . phd a: right . professor c: so i 'll d i 'll dig you up this reference . grad b: that 's cool . professor c: and so this doe this is , uh first of all , it explains something that i 've always wondered about and i 'll do this this test on you guys as well . so . uh . how - i have had an experience , not often , but a certain number of times , when , for example , i 'm working with a tool , a screwdriver or something , for a long time , i start feeling the tip directly . not indirectly , but you actually can feel the tip . grad b: yeah yeah . professor c: and people who are uh accomplished violinists and stuff like that , claim they also have this kind of thing where you get a direct sensation of , physical sensation , of the end affector . grad b: yeah . what 's going on at the end of the tool , phd a: the ext the the the extension , grad b: yeah . professor c: huh ? grad b: what 's going on at the end of the tool , or whatever . professor c: yeah , within phd a: right . professor c: huh ? phd a: the extension of of your hand , right . professor c: yeah , right . have you hav y h had this ? phd a: the i i think so . i mean i i it 's not exactly the th same thing , but but s it it it 's getting close to that . grad b: yeah . grad f: w what does it feel like ? professor c: oh i it feels like your as if your uh neurons had extended themselves out to this tool , and you 're feeling forces on it and so forth and and you deal directly with it . phd a: i once i i was playing you know with those um uh devices that allow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something grad b: oh , ok . professor c: right , yeah yeah yeah . yeah . phd a: and there 's a correspondence between professor c: yeah . phd a: so i played with it . after a while , you do n't feel the difference anymore . i i mean it 's kind of grad b: mm - hmm . professor c: yeah , right . phd a: very kind of you stop back and suddenly it goes away and you have to kind of work again to recapture it , but yeah . grad b: yeah . professor c: right , yeah , so anyway , so so this was the first actual experimental evidence i 'd seen that was consistent with this anecdotal stuff . grad b: that 's cool . professor c: and of course it makes a lovely def uh story about why languages uh , make this distinction . of course there are behavioral differences too . things you can reach are really quite different than things you ca n't . grad b: yeah . professor c: but there seems to be an actu really deep embodied neural difference . and i this is , um so . in addition to the e grad e: this is more proximal - distal . professor c: yeah uh exactly . so in addition to e ego and allocentric uh which appear all over the place , you also apparently have this proximal - distal thing which is very deeply uh embedded . s grad e: well , dan montello sort of , he he does the uh uh th the cognitive map world , down in santa barbara . and he he always talks about these he he already well i probably most likely without knowing this this evidence uh is talking about these small scale spaces that you can manipulate versus large scale environmental spaces . professor c: yeah . well there 's there 's uh been a lot of behavioral things o on this , but that was the first neur neuro - physiological thing i saw . anyway yeah , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , right ? and so these issues about uh , reference , and spatial { comment } reference , discourse reference , uh - uh - uh - uh { comment } all this sort of stuff , uh , deixis which is part of what you were talking about , grad b: mm - hmm . mm - hmm . professor c: um so , all of this stuff is coming up essentially starting now . so we got ta do all this . so there 's that . and then there 's also a set of system things that come up . so `` ok , we 're not using their system . that means we need our system . `` grad b: mm - hmm . professor c: right ? grad b: yeah . professor c: it it follows . and so , uh , in addition to the business about just getting the linguistics right , and the formalism and stuff , we 're actually gon na build something and uh , johno is point person on the parser , analyzer , whatever that is , and we 're gon na start on that in parallel with the um , the grammar stuff . grad b: alright . professor c: but to do that we 're gon na need to make some decisions like ontology , so , um and so this is another thing where we 're gon na , you know , have to get involved and make s relatively early i think , make some decisions on uh , `` is there an ontology api that that `` there 's a sort of standard way of getting things from ontologies and we build the parser and stuff around that , or is there a particular ontology that we 're gon na standardize on , and if so for example , is there something that we can use there . i does uh either the uh smartkom project or one of the projects at eml have something that we can just p pull out , for that . uh , so there are gon na be some some some things like that , which are not science but system . but we are n't gon na ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually uh build some of it . and how much we build , and and so forth . grad b: i professor c: uh . part of it , if it works right , is wh it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that um , there 's a good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , grad b: ok . professor c: and of course it 's only w in both cases it 's only one piece of a bigger system . grad b: mm - hmm . professor c: but it would be nice if that piece were exactly the same piece . grad b: right . professor c: it was just this uh construction analyzer . and so we think we think we have a shot at at that . grad b: ok . professor c: so . the for so . to to come full circle on that , this formalization task , ok ? is trying to get the formalism into into a shape where it can actually uh grad b: yeah . be of use to someone who 's trying to do this , right ? professor c: d well , yeah , where it actually is is covers the whole range of things . and the the the the thing that got mark into the worst trouble is he had a very ambitious thing he was trying to do , and he insisted on trying to do it with a limited set of mechanisms . it turned out , inherently not to cover the space . grad b: ok . professor c: and it just it was just terribly frustrating for him , grad b: yeah . professor c: and he seemed fully committed to both sides of this i i irreconcilable thing . grad b: i see . right . professor c: and . uh . johno is much more pragmatic . grad b: ok . good to know . professor c: uh . huh ? is this is true , is it not ? grad d: yes . professor c: ok . so there 's you know sort of , yeah , deep , really deep , emotional commitment to a certain theory being uh , complete . grad b: oh , ok . grad f: you do n't have a hidden purist streak ? grad d: oh no . professor c: we - well it has n't it it certainly has n't been observed , in any case . grad f: ok . just checking . grad d: no sir . grad b: alright . professor c: um . now , you do , but that 's ok . uh . so . for for grad b: cuz i do n't have to implement anything . professor c: exactly right . exactly . grad f: i have a problem , then . it 's so . whether i do depends on whether i 'm talking to him or him probably . phd a: hmm . grad b: yeah , right . professor c: right . why a actually , uh , the thing is , you you do but , th the thing you have to im implement is so small that uh . grad f: which meeting i 'm in . it 's ok to be purist within that context . professor c: within that , yeah , grad f: yes , professor c: and uh , it 's a and still , i think , you know , get something done . grad f: good . grad b: cool ! professor c: but to try to do something upscale and purist particularly if if um what you 're purist about does n't actually work , is real hard . grad f: yay . grad b: mm - hmm . yeah . professor c: ok . and then the other thing is while we 're doing this uh robert 's gon na pick a piece of this space , phd a: it 's possible yeah . grad b: ok . professor c: ok , uh , for his absentee thesis . i think you all know that that you can just , in germany almost just send in your thesis . grad b: just a drive up . ca - chuk ! phd a: um professor c: yeah right . grad b: there you go . professor c: ok . grad e: the - th there there 's a drive - in thesis uh sh joint over in saarbruecken . grad b: exactly . drive through , yeah . professor c: it costs a lot . the the amount you put in your credit card and as well . but , uh , but anyway , so , uh , that 's um , also got ta be worked out , hopefully over the next few weeks , so that that it becomes clear uh , what piece uh , robert wants to jump into . and , while we 're at this level , uh , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . grad b: ok . professor c: so , de uh . and her name is eva . grad b: ok . professor c: it really is . nobody believed th th that grad f: yeah , i thought it had to be a joke , of your part , you know professor c: yeah . grad f: like { comment } `` johno made it up , i 'm sure . `` grad g: is this person someone who 's in first - year this year , professor c: no , first year coming . grad g: or professor c: so , she 's she 's now out here she 's moved , and she 'll be a student as of then . grad g: ok . professor c: and probably she 'll pick up from you on the belief - net stuff , so sh she 'll be chasing you down and stuff like that . grad g: ok . professor c: uh . grad e: document . grad g: right . professor c: uh , against all traditions . and actually i talked today to a uh undergraduate who wants to do an honors thesis on this . uh grad f: someone from the class ? professor c: no , interestingly enough . grad f: we always get these people who are not in the class , who professor c: some of th some of them , yeah . grad f: it 's interesting . professor c: so anyway , uh , but uh she 's another one of these ones with a three point nine average and so forth and so on . grad b: mm - hmm . professor c: uh , so , um , i 've give i 've given her some things to read . so we 'll see how this goes . oh there 's yet another one of the incoming first { comment } incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . um , anyway , so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gon na make sense to have this be separate from the other bigger effort with the formalization stuff or not , i 'm not sure . it partly depends on w what your thesis turns out to be and how that goes . s so , we 'll see . and then , ami , you can decide , you know , how much time you wan na put into it and uh , it it 's beginning to take shap shape , phd a: ok . professor c: so uh and , phd a: right professor c: i think you will find that if you want to look technically at some of the your traditional questions in this light , uh keith , who 's buil building constructions , will be quite happy to uh see what , you know , you envision as the issues and the problems and um , how they might uh get reflected in constructions . grad b: sure . professor c: i suspect that 's right . grad b: yeah . yeah . phd a: i i may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but uh , after that or before that . professor c: ok , fine . and , um , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in in the neighborhood . phd a: right . yeah be uh actu actually i 'm invited to do some consulting with a bank in geneva which has an affiliation with a research institute in geneva , which i forgot the name of . professor c: yeah . yep . e o do y phd a: yeah . professor c: well , we we 're connected to uh there 's a there 's a a very significant connection between we 'll we 'll go through this , phd a: yeah . professor c: icsi and epfl , which is the , uh it 's the fr ge - germany 's got two big technical institutes . there 's one in in zurich , phd a: mm - hmm . professor c: e t and then there 's one , the french speaking one , in lausanne , grad b: oh , so in switzerland . professor c: ok ? which is uh e p phd a: great . professor c: f l . so find out who they are associated with in geneva . phd a: right . professor c: probably we 're connected to them . phd a: great . i 'll let you know . s i 'll send you email . professor c: ok . yeah , and so anyway we c uh we can m undoubtedly get ami uh to give a talk at uh eml or something like that . while he 's in in uh grad e: hmm . uh . i i think the one you you gave here a couple of weeks ago would be of interest there , too . phd a: sure , yeah . professor c: a lot of interest . actually , either place , dfki or uh yeah , so , and and if there is a book , that you 'll be building up some audience for it . phd a: yeah . right . professor c: and you 'll get feedback from these guys . phd a: great , yeah . professor c: cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . phd a: cool . professor c: ok . so , uh , unless we wan na start digging into the uh the belief - net and the decisions now , which would be fine , it 's probably grad e: i i tho it 's probably better if i come next week with the um version o point nine of the structure . professor c: ok . so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying `` here 's what we think we understand , here are the things we think we do n't understand `` . and that we as a group will try to to finish it . what i 'd like to do is shoot f for finishing all this next monday . grad g: sure . professor c: ok ? uh , `` these are the decisions `` i do n't think we 're gon na get lots more information . it 's a design problem . grad b: mm - hmm . professor c: you know . we grad g: yeah . professor c: yeah . and let 's come up with a first cut at what this should look like . and then finish it up . grad b: ok . professor c: does that so make sense ? grad b: ok . grad e: and um , the the sem semester will be over next week but then you have projects for one more week to come ? grad g: no , i i think i 'll be done everything by this uh by the end of this week . grad e: same with you ? no . grad d: nnn . this well , i 've i have projects , but then the my prof professor of one of my classes also wa has a final that he 's giving us . and he 's giving us five days to do it which means it going to be hard . grad b: yeah . professor c: yeah . oh . is it a take - home final ? who 's doing this ? grad d: yeah . aikin , alex , yeah . professor c: yeah , figured . that would have been i my guess . grad g: hmm . professor c: right . um , but anyway , yeah . grad b: pretty soon . grad e: ok . professor c: ok , so i guess that 's grad d: so , the seventeenth will definitely be the last day , like it or not for me . professor c: right . right . so let 's do this , and then we we well there 's gon na be some separate co these guys are talking , uh we have a group on the formalization , uh nancy and johno and i are gon na talk about parsers . so there 're various kinds of uh grad b: ok . professor c: of course , nothing gets done even in a meeting of seven people , grad b: right . professor c: right ? so , um , two or three people is the size in which actual work gets done . grad e: mmm . grad b: yeah . professor c: so we 'll do that . great . oh , the other thing we wan na do is catch up with uh , ellen and see what she 's doing because the um image schemas are going to be um , an important pa grad b: yeah . quite relevant , yeah . professor c: we we want those , grad b: yeah , oh yeah . professor c: right ? and we want them formalized and stuff like that . grad b: yeah . professor c: so let me let me make a note to do that . grad b: ok . yeah , i 'm actually probably going to be in contact with her uh pretty soon anyway because of various of us students were going to have a reading group about precisely that sort of thing over the summer , grad d: ok . professor c: oh right ! right right right ! grad b: so . professor c: that 's great ! yeah , i i shweta mentioned that , although she said it 's a secret . grad b: ok . grad d: hi grad b: right , no faculty ! professor c: th - the faculty are n't faculty are n't supposed to know . grad d: wednesday 's much better for me , yeah . professor c: but um , i 'm sufficiently clueless that i count as a grad b: yeah , right . it 's as if we did n't tell anyone at all , grad d: bhaskara . grad b: right .","output":"the translation of smartkom to english is in its final stages . the synthesis module will be the last one to do , after the english syntax trees are completed . the system is still buggy and unstable , but it will soon be ready for a demonstration ."},{"instruction":"what demos would the system be involved in ?","input":"grad b:  grad d: how many batteries do you go through ? grad b: thank you . professor c: alright . phd a: sure . professor c: good . yeah . ok so , let 's get started . nancy said she 's coming and that means she will be . um . my suggestion is that robert and johno sort of give us a report on last week 's adventures uh to start . so everybody knows there were these guys f uh from heidelber - uh , uh , actually from uh dfki uh , part of the german smartkom project , who were here for the week and , i think got a lot done . grad e: yeah , i think so too . um . the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like `` roman numeral one , am smarticus . `` it actually says , `` roemisch einz , am smarticus , `` grad b: ok . grad e: which means it 's just using a german sythesis module for english sentences . grad b: ok . grad e: so uh , professor c: it does n't know `` i `` . grad b: ok . grad e: um , the uh grad b: oh , am spartacus . `` grad d: `` i am sm - i am smarticus `` is what it 's saying . phd a: right . grad b: verstehe . ok . grad d: i gue grad e: the uh sythesis is just a question of um , hopefully it 's just a question of exchanging a couple of files , once we have them . and , um , it 's not going to be a problem because we decided to stick to the so - called concept to speech approach . so i 'm i 'm i 'm going backwards now , so `` synthesis `` is where you sort of make this uh , make these sounds , and `` concept to speech `` is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . grad b: mm - hmm . grad e: and , uh , johno learned how to write xml tags . uh , and did write the tree adjoining grammar for some some sentences . no , right ? grad d: yeah . grad e: yeah , for a couple grad d: so . bu - uh , i the way the uh , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to a er in xml and there 's a conversion system for different uh , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is uh , in a lisp - like the knowledge base is in a lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have a basically , a goal and it , you know , says `` ok , well i 'm gon na try to do the greet - the - person goal , grad b: mm - hmm . grad d: so it just starts uh , it binds some variables and it just decides to , you know , do some subscold . basically , it just means `` build the tree . `` grad b: ok . grad d: and then it passes the tree onto , uh , the ge the generation module . grad e: but i think that the point is that out of the twelve possible utterances that the german system can do , we 've already written the the syntax trees for three or four . grad d: we yeah . so , the syntax trees are very simple . it 's like most of the sentences in one tree , grad b: mm - hmm . grad d: and instead of , you know , breaking down to , like , small units and building back up , they basically took the sentences , and basically cut them in half , or you know , into thirds or something like that , and made trees out of those . and so uh , uh tilman wrote a little tool that you could take lisp notation and generate an xml , uh , tree . uh , s what do ca structure from the from the lisp . and so basically you just say , you know , `` noun goes to `` , you know , er , nah , i do n't re i 've never been good at those . so there 's like the vp goes to n and those things in lisp , and it will generate for you . grad b: ok . n , n , v yeah , ok . alright . grad e: and because we 're sticking to that structure , the synthesis module does n't need to be changed . so all that f fancy stuff , and the texas speech version of it , which is actually the simpler version , is gon na be done in october which is much too late for us . so . this way we we worked around that . the , uh the system , um i can show you the system . i actually want , at least , maybe , you should be able to start it on your own . if you wan na play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on on on seventeen modules before they actually can stomach it , anything . and send in a a a couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we do n't have here . grad b: mm - hmm . grad e: and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was a lot of engineering stuff . no science in there whatsoever , but it 's working now , and um , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation . grad d: why i had i did need to chan generate different trees than the german ones , mainly because you know like uh , the gerund in in german is automatically taken care of with just a regular verb , grad e: you have to switch it on . grad b: mm - hmm . grad d: so i 'd uh have to add `` am walking , `` grad b: ok . grad d: or i 'd have to add a little stem for the `` am `` , when i build the built the tree . grad b: ok . yeah , i noticed that um , that some of the examples they had , had you know , non - english word orders and so on , you know . and then all that good stuff . so . professor c: alright . grad d: yeah . grad b: like . professor c: so it might be worth , keith , you looking at this , grad b: yeah . professor c: um grad b: i i still do n't i still do n't really understand e like grad d: well tilman s grad b: i mean we sort of say , um you know , i i still do n't exactly understand sort of the information flow uh in in this thing , or what the modules are and so on . so , you know , like just that such - and - such module uh um decides that it wants to achieve the goal of greeting the user , and then magically it sort of s professor c: yeah grad b: i mean , how does it know which syntactic structure to pull out , and all that ? professor c: i thi yeah . so . i think it 's not worth going over in the group , grad b: r uh sure . professor c: but sort of when you get free and you have the time uh either robert or johno or i can walk you through it . grad b: yeah , soon . ok . professor c: and you can ask all the questions about how this all fits together . grad b: that 's fine . professor c: it 's eee { comment } messy but once you understand it you understand it . it 's it 's there 's nothing really complicated about it . grad b: ok . grad e: no . grad b: and i remember one thing that that came up in the talk last wednesday . um , was this , i i think he talked about the idea of like , um he was talking about these lexicalized uh , uh , tree adjoining grammars where you sort of for each word you , um grad d: ok , you know how to do it ? grad b: for each lexical item , the lexical entry says what all the uh trees are that it can appear in . and of course , that 's not v that 's the opposite of constructional . that 's , you know , that 's that 's hpsg or whatever . professor c: right . grad b: you know ? professor c: right . now , we 're we 're not committed for our research to do any of those things . grad b: yeah . mm - hmm . professor c: so uh we are committed for our funding . grad b: right . professor c: ok ? to uh grad b: make our stuff fit to that . professor c: yeah , to n no , to just get the dem get the demos they need . grad b: uh - huh . professor c: ok ? so between us all we have t to get th the demos they need . if it turns out we can also give them lots more than that by , you know , tapping into other things we do , that 's great . grad d: you should probably move the microphone closer to your face . grad b: mm - hmm . professor c: but i it turns out not to be in an any of the contracts grad d: there 's like a little the twisty thing , you can move it with . grad b: ok . professor c: and , s deliberately . so , the reason i 'd like you to understand uh what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with a question of `` could we fit this deeper stuff in there ? `` or something . you know what the hell we we 're talking about fitting in . grad b: right . ok . professor c: so it 's just , uh in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? uh , is there anything we can give back , beyond th the sort of minimum requirements ? but none of that has a short time fuse . grad b: ok . professor c: so th the demo the demo requirements for this fall are sort of taken care of as of later this week or something . and then so , it 's probably fifteen months or something until there 's another serious demo requirement . grad b: oh ok . professor c: that does n't mean we do n't think about it for fifteen months , grad b: right . professor c: but it means we can not think about it for six months . grad b: right , yeah . professor c: so . the plan for this summer uh , really is to step back from the applied project , grad e: right . professor c: keep the d keep the context open , but actually go after the basic issues . grad b: hmm . oh ok . professor c: and , so the idea is there 's this uh , other subgroup that 's worrying about formalizing the nota getting a notation . but sort of in parallel with that , uh , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , grad b: mm - hmm . professor c: but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . grad b: yeah . ok . got it . professor c: it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and stuff . grad b: yeah . professor c: and , i don i do n't want you f feeling that you have to somehow meet all these other constraints . grad b: right , ok . professor c: um . and similarly with the parsing , uh we 're gon na worry about parsing uh , the general case you know , construction parser for general constructions . and , if we need a cut - down version for something , or whatever , we 'll worry about that later . grad b: ok . professor c: so i 'd like to , for the summer turn into science mode . grad b: ok . professor c: and i assume that 's also , uh , your plan as well . grad b: so i mean , the the point is that like the meetings um so far that i 've been at have been sort of been geared towards this demo , professor c: right . yeah . yeah . grad b: and then that 's going to go away pretty soon . professor c: but but we we 're swit grad b: ok . professor c: right . grad b: and then we 'll sort of shift gears a fairly substantially , professor c: yeah . grad e: it 's professor c: yeah . grad b: huh ? professor c: yeah . grad e: it 's got . what i what i think is is a good idea that i can can show to anyone who 's interested , we can even make a sort of an internal demo , and i i show you what i do , grad b: mm - hmm . grad e: i speak into it and you hear it talk , grad b: ok . grad e: and i can sort of walk f through the information . so , this is like in half hour or forty - five minutes . just fun . grad b: ok . grad e: and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , sort of , give a sensible answer . grad b: right . ok . professor c: so , c sh we could set that up as actually an institute wide thing ? just give a talk in the big room , and and so peo people know what 's going on ? when you 're ready ? grad e: absolutely . professor c: yeah i mean , that 's the kind of thing that 's the level at which you know we can just li invite everybody and say `` this is a project that we 've been working on and here 's a demo version of it `` and stuff like that . grad b: yeah . grad e: ok . well d we we do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're grad b: uh - huh . professor c: indeed . grad e: yeah . ok . makes sense . professor c: but any so that e e it 's clear , then , i think . actually , roughly starting uh let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . grad b: yeah . ok . professor c: but uh starting next meeting i think we want to flip into this mode where uh . i mean there are a lot of issues , what 's the ontology look like , grad b: mm - hmm . professor c: you know what do the constructions look like , what 's the execution engine look like , mmm lots of things . grad b: mm - hmm . professor c: but , more focused on uh an idealized version than just getting the demo out . now before we do that , let 's get back in oh ! but , it 's still , i think , useful for you to understand the demo version enough , so that you can can see what what it is that that uh it might eventually get retro - fitted into or something . grad b: yeah . ok , right . professor c: and johno 's already done that , uh , looked at the dem uh the looked at the smartkom stuff . grad d: wa uh to some de uh what what part of th the smartkom stuff ? professor c: well , the parser , and that stuff . grad d: oh yeah yeah . professor c: ok . anyway . so , the trip the report on these the last we we sort of interrupted you guys telling us about what happened last week . grad b: yeah . it 's alright . grad e: um . well it was just amazing to to see uh how how instable the whole thing is , professor c: maybe you 're done , then . grad e: and if you just take the and i g i got the feeling that we are the only ones right now who have a running system . i do n't know what the guys in kaiserslautern have running because e the version that is , the full version that 's on the server d does not work . and you need to do a lot of stuff to make it work . and so it 's and even tilman and ralf sort of said `` yeah there never was a really working version that uh did it without th all the shortcuts that they built in for the uh october @ @ version `` . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , uh it was fun to some extent , but the uh the outcome that is sort of of scientific interest is that i think both ralf and tilman um , i know that they enjoyed it here , and they r they they liked , uh , a lot of the stuff they saw here , what what we have been thinking about , and they 're more than willing to to um , cooperate , by all means . and um , part of my responsibility is uh to use our internal `` group - ware `` server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and and generating and constructions w we we sort of uh put it in there and they put what they do in there and maybe we can even um , get some overlap , get some synergy out of that . and um , the , uh if i find someone at in eml that is interested in that , um i i may even think that we could look take constructions and and generate from them because the tree adjoining grammars that that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g - like stuff , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're of course definitely focused on the understanding , um , pipeline . professor c: anyth - any other { comment } uh repo visit reports sort of stories ? uh we so we now know i think , what the landscape is like . grad b: mm - hmm . professor c: and so we just push on and and uh , do what we need to do . and one of the things we need to do is the um , and this i think is relatively tight tightly constrained , is to finish up this belief - net stuff . so . uh . and i was going to switch to start talking about that unless there 're m other more general questions . ok so here 's where we are on the belief - net stuff as far as i understand it . um . going back i guess two weeks ago uh robert had laid out this belief - net , missing only the connections . right ? that is { comment } so , he 'd put all th all the dots down , and we went through this , and , i think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . yeah { comment } we may run across one or two more . but of course the connections were n't . so , uh bhaskara and i went off and looked at some technical questions about were certain operations sort of legitimate belief - net computations and was there some known problem with them or had someone already uh , solved you know how to do this and stuff . and so bhaskara tracked that down . the answer seems to be uh , `` no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do `` . and , so the current state of things is that , again , starting now , um we 'd like to actually get a running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and uh , he 's gon na leave us an inheritance , which is a uh hopefully a belief - net that does these things . and there 're two aspects to it , one of which is , you know , technical , getting the coding right , and making it run , and uh stuff like that . and the other is the actual semantics . ok ? what all you know , what are the considerations and how and what are the ways in which they relate . so he doe h he does n't need help from this group on the technical aspects or if he does uh we 'll do that separately . grad b: mm - hmm . professor c: but in terms of what are the decisions and stuff like that , that 's something that we all have to work out . is is that right ? i mean that 's that 's both you guys ' understanding of where we are ? grad e: absolutely . professor c: ok . grad g: so , i guess , um is there like a latest version of the belief - net of the proposed belief - net ? like grad e: we had um decided grad g: like grad e: um . well , no , we did n't decide . we wanted to look into maybe getting it , the visualization , a bit clearer , but i think if we do it , um , sort of a paper version of all the nodes and then the connections between them , that should suffice . grad g: mm - hmm . yeah , that should be fine . professor c: yeah i mean , that 's a separate problem . grad d: yeah , i professor c: we do in the long run wan na do better visualization and all that stuff . grad e: yeah . professor c: that 's separable , yeah . grad d: i did look into that , uh in terms of , you know , exploding the nodes out and down ag professor c: yep . right . grad d: javabayes does not support that . i can imagine a way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it , professor c: not not at this point . grad d: and i went through all the other packages on murph - kevin murphy 's page , professor c: right . grad d: and i could n't find the necessary mix of free and uh with the gui and , with this thing that we want . professor c: well , we can p if it 's if we can pay yeah . if you know it 's paying a thousand dollars or something we can do that . ok ? so so do n't view free as as a absolute constraint . grad d: ok . ok , so then i 'll go back and look at the ones on the list that professor c: ok . and you can ask kevin . grad e: but grad g: yeah . grad d: mmm . grad e: but grad g: yeah , the one that uh people seem to use is uh hugin or whatever ? professor c: hugin , yeah that 's free . grad g: how exp i do n't think it 's is it free ? because i 've seen it advertised in places so i it seems to professor c: uh , it may be free to academics . like i i do n't know . i have a co { comment } i have a copy { comment } that i l i downloaded . grad g: ok . professor c: so , at one point it was free . grad g: ok . professor c: uh but yo i noticed people do use hugin so um , grad d: how do you spell that ? professor c: hugin . grad f: why professor c: and bhaskara can give you a pointer . so then , in any case , um but paying a lit you know , if i if it 's uh probably for university , it 's it 's gon na be real cheap anyway . but um , you know , if it 's fifty thousand dollars we are n't gon na do it . i 'm mean , we have no need for that . grad e: i i also s would suggest not to d spend two weeks in in in changing the the javabayes code . professor c: no , grad b: yeah . professor c: he 's not gon na do that . grad d: ok . grad e: i i will send you a pointer to a java applet that does that , it 's sort of a fish - eye . you you have a node , and you click on it , and it shows you all the connections , grad d: mmm . grad e: and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that does n't work , it 's not a problem we we need to solve right now . what i 'm what my job is , i will , um , give you the input in terms of of the internal structure . maybe node by node , or something like this ? or should i collect it all grad g: mm - hmm . grad e: and professor c: does n't matter . grad g: um , just any like like sort of rough representation of the entire belief - net is probably best . grad e: ok . and um you 're gon na be around ? t again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ? grad g: yeah i mean , yeah , i can like i c um . this week i guess um , kind of i have a lot of projects and stuff but after that i will generally be more free . so yes , i might i can be around . and g i mean , generally if you email me also i can be around on other days . grad e: yeah . ok . professor c: yeah and this is not a crisis that i mean , you do , e everybody who 's a student should , you know do their work , get their c courses all in good shape and and and and then we 'll dig d dig down on this . grad e: yeah , that 's yeah . ok . no , that 's good . that means i have i h i can spend this week doing it . so . grad g: ok . grad b: how do you go about this process of deciding what these connections are ? i know that there 's an issue of how to weight the different things too , and stuff . right ? i mean do you just sort of guess and see if it sort of professor c: right . well there there there there 're two different things you do . grad e: it 's professor c: one is you design and the other is you learn . ok ? so uh what we 're gon na do initially is is do design , and , i if you will , guess . grad b: ok . professor c: ok . uh that is you know use your best knowledge of of the domain to uh , hypothesize what the dependencies are and stuff . grad b: right . ok . professor c: if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure grad b: yeah . professor c: and there are even techniques for learning the structure , although that takes a lot more data , and it 's not as @ @ and so forth and so on . so uh but for the limited amount of stuff we have for this particular exercise i think we 'll just design it . grad b: alright . grad e: yeah . fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and stuff . grad b: ok . grad e: so but this is the { comment } long run . grad b: yeah . grad e: but to solve our problems ag uh a mediocre design will do i think in the beginning . grad b: yeah , that 's right . yeah , oh , and by the way , speaking of data , um , are there i could swore uh , i could swear i saw it sitting on someone 's desk at some point , but is there a um a transcript of any of the , sort of , initial interactions of people with the with the system ? cuz you know , i 'm still sort of itching to to look at what look at the stuff , and see what people are saying . professor c: mm - hmm . yeah . yeah make yourself a note . so and and , of course keith would like the german as well as the english , so whatever you guys can get . grad e: the german . oh yeah , of course , german . yeah . professor c: yeah , the y your native language , right ? you remember that one . grad e: ok . that 's important , yeah . grad b: yeah , professor c: so he 'll get you some data . grad b: u ok . yeah , i mean i i sort of um found the uh , uh the audio of some of those , and um , it kind of sounded like i did n't want to trudge through that , you know . grad e: hmm . grad b: it was just strange , but . professor c: yep . grad e: we probably will not get those to describe because they were trial runs . grad b: oh yeah , ok . grad e: um , but uh that 's th but we have data in english and german already . grad b: ok , yeah , i mean . grad e: so . transcribed . i will send you that . ok . professor c: ok , so while we 're still at this sort of top level , anything else that we oughta talk about today ? grad e: ho - how was your thingy . grad b: oh , um , i just wanted to , uh , s like mention as an issue , um , you know last meeting i was n't here because i went to a linguistics colloquium on the fictive motion stuff , professor c: oh right . grad b: and that was pretty interesting and you know , i mean , seems to me that that will fairly obviously be of relevance to uh to what we 're doing here because you know people are likely to give descriptions like you know , `` what 's that thing uh right where you start to go up the hill , `` or something like that , you know , meaning a few feet up the hill or whatever from some reference point and all that stuff so i mean , i 'm sure in terms of you know , people trying to state locations or , you know , all that kind of stuff , this is gon na be very relevant . so , um , now that was the talk was about english versus japanese , um , which obviously the japanese does n't affect us directly , except that , um , some of the construction he 'd what he talked about was that you know in english we say things like th you know , `` your bike is parked across the street `` and we use these prepositional phrases , you know , `` well , if you were to move across the street you would be at the bike `` , but um in in japanese the the more conventionalized tendency is to use a sort of a description of `` where one has crossed to the river , there is a tree `` . um , and you know , you can actually say things like , um , `` there 's a tree where one has crossed the river , but no one has ever crossed the river `` , or something like that . so the idea is that this really is you know that 's supposed show that 's it 's really fictive and so on . but um but the point is that that kind of construction is also used in english , you know , like `` right where you start to go up the hill `` , or `` just when you get off the train `` , or something like that to uh , to indicate where something is . professor c: mmm . grad b: so we 'll have to think about professor c: so how much is that used in german ? grad e: um . the uh well i wa i was on a uh on a on a different sidetrack . professor c: oh , ok . grad e: i mean , the the deep map project which um is undergoing some renovation at at the moment , but this is a a three language project : german , english , japanese . grad b: ok . grad e: and um , we have a uh , uh i have taken care that we have the the japanese generation and stuff . and so i looked into uh spatial description . so we can generate spatial descriptions , how to get from a to b . and and information on objects , in german , english , and japanese . grad b: mm - hmm . grad e: and there is a huge uh project on spatial descriptions uh differences in spatial descriptions . well , if yo if you 're interested in that , so how how , i mean it does sort of go d all the way down to the conceptual level to some extent . grad b: ok . grad e: so . um . professor c: so , where is this huge project ? grad e: it 's kleist . it 's the uh bielefeld generation of uh spatial descriptions and whatever . professor c: mm - hmm . grad e:  professor c: well , that may be another thing that keith wants to look at . grad b: ok . grad e: but um , i i think we should leave japanese constructions maybe outside of the scope for for now , grad b: yeah . grad e: but um definitely it 's interesting to look at at cross the bordered there . professor c: mm - hmm . phd a: are are you going to p pay any attention to the relative position of of the direction relative relative to the speaker ? for example , there are some differences between hebrew and english . we can say um `` park in front of the car `` as you come beh you drive behind the car . in hebrew it means `` park behind the car `` , because to follow the car is defined as it faces you . grad e: mm - hmm . intrinsic , yeah . phd a: while in english , front of the car is the absolute front of the car . grad b: ok . phd a: so . grad b: right , so the canonical direction of motion determines where the front is . phd a: right . right . grad b: ok . phd a: so , i i i is german uh closer to to e uh , uh , uh , uh to e i mean uh grad e: mm - hmm . phd a: i do n't think it it 's related to syntax , though , so it may be entirely different . grad e: um , as a matter of fact professor c: no , it 's not . grad b: right . phd a: yeah . grad e: um . did you ever get to look at the the rou paper that i sent you on the on that problem in english and german ? grad b: i think grad e: carroll , ninety - three . um . i there is a a study on the differences between english and german on exactly that problem . phd a: hmm . grad e: so it 's they actually say `` the monkey in front of the car , where 's the monkey ? `` grad b: mm - hmm . grad e: and , um , they found statistically very significant differences in english and german , so i i i it might be , since there are only a finite number of ways of doing it , that that german might be more like hebrew in that respect . grad b: hmm . grad e: the solution they proposed was that it was due to syntactic factors . phd a: that but it was n't was grad e: that syntactic facto factors do do play a role there , wh whether you 're more likely , you know , to develop uh , choices that lead you towards using uh intrinsic versus extrinsic reference frames . phd a: right . mm - hmm . right . grad b: i mean , it seems to me that you can get both in in english depending o professor c: hmm . grad b: you know , like , `` in front of the car `` could you know like , here 's the car sideways to me in between me and the car or something 's in front of the car , or whatever . i could see that , professor c: absolutely . grad b: but but anyway , so you know , i mean , this was this was a a very good talk on those kinds of issues and so on . so uh . grad e: i can also give you uh , a pointer to a paper of mine which is the the ultimate taxonomy of reference frames . grad b: alright ! cool ! grad e: so . professor c: oh . grad e: i 'm the only person in the world who actually knows how it works . professor c: oh . grad e: not really . professor c: great . no , i 've not seen that . phd a: what do you mean . um . `` reference frames `` ? grad e: it 's called a phd a: uh uh grad e: it 's it 's spatial reference frames . you actually have only um . if you wan na have a this is usually um i should there should be an `` l `` , though . well actually you have only have two choices . you can either do a two - point or a three - point which is you you 're familiar with th with the `` origo `` ? where that 's the center `` origo `` is the center of the f frame of reference . grad b: hmm . grad e: and then you have the reference object and the object to be localized . grad b: hmm . phd a: mm - hmm . grad e: ok ? in some cases the origo is the same as the reference object . professor c: so that would be `` origin `` in english , grad f: this was like grad b: the origin . phd a: right grad b: yeah . professor c: right ? grad e: `` origo `` is a terminus technikus . in that sense , that 's even used in the english literature . `` origo . `` grad b: oh , ok . i never heard it . professor c: alright . phd a: ok . grad b: ok . grad e: and um , so , this video tape is in front of me . grad b: mm - hmm . grad e: i 'm the origo and i 'm also the reference object . grad b: mm - hmm . phd a: right . grad e: those are two - point . professor c: mm - hmm . grad e: and three - point relations is if something has an intrinsic front side like this chair then your f shoe is behind the chair . professor c: yeah . grad b: mm - hmm . grad e: and , reference object and um . no , from from my point of view your shoe is left of the chair . grad b: right . you you can actually say things like , um , `` it 's behind the tree from me `` or something like that , i think , in in in certain circumstances in english , right ? as sort of `` from where i 'm standing it would appear that `` grad e: yeah . yeah . so , grad f: looks a little bit like reichenbach for time . professor c: yeah , it sounds like it , does n't it , grad b: yeah . professor c: yeah . grad f: it 's a lot like it . grad e: and then and then here you grad f: um . grad e: on this scale , you have it either be ego or allocentric . professor c: mm - hmm . grad e: and that 's { comment } that 's basically it . so . egocentric two - point , egocentric three - point , or you can have allocentric . grad b: oh , ok . grad e: so , `` as seen from the church , the town hall is right of that um , fire station `` . aa - huh { comment } it 's hardly ever used but it 's w phd a: i 'd love to see it if you if you have a copy kind of . uh . grad b: yeah . professor c: yeah . i see this is this is getting into ami 's thing . phd a: here grad b: mm - hmm . professor c: he 's he 's very interested in that . grad e: ok . professor c: so . grad b: me too . professor c: uh . yeah . well , why do n't you just put it on the web page ? there 's this edu right ? grad e: yeah it 's or or just yeah . professor c: or a link to it . grad e: it 's also all on my my home page at eml . it 's called `` an anatomy of a spatial description `` . professor c: just grad e: but i 'll send that link . phd a: ok , great . professor c: maybe just put a link on . yeah . grad e: yep . professor c: by the way , there something that i did n't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach . grad e: yep . grad b: huh . professor c: so there 's there 's uh all this linguistic stuff about you know , near and far , or yon and and so forth . grad b: mm - hmm . professor c: so this is all this is there 's this linguistic facts . but apparently , the uh . here 's the way the findings go . that , you know they do mri , and and if you 're uh got something within reach then there 's one of your areas lights up , and if something 's out of reach uh a different one . but here 's the the amazing result , um , they say . you get someone with a with a deficit so that they have a perfectly normal ability at distance things . so the s typical task is subdivision . so there 's a a line on the wall over there , and you give them a laser pointer , and you say , `` where 's the midpoint ? `` and they do fine . if you give them the line , and they have to touch it , they ca n't . there 's just that part of the brain is n't functioning , so they ca n't do that . here 's the real experiment . the same thing on the wall , you give them a laser , `` where is it ? `` , grad b: mm - hmm . professor c: they do it . give them a stick , long stick , and say `` do it `` , they ca n't do it . so there 's a remapping of distant space into nearby space . phd a: right . so they doubled the the end the end of this grad f: because it 's within reach now ? grad b: yeah , professor c: it 's not within reach and you use the within - reach uh , mechanism . grad b: yeah . grad f: oh . wow . grad b: circuits . phd a: right . professor c: so i 'll d i 'll dig you up this reference . grad b: that 's cool . professor c: and so this doe this is , uh first of all , it explains something that i 've always wondered about and i 'll do this this test on you guys as well . so . uh . how - i have had an experience , not often , but a certain number of times , when , for example , i 'm working with a tool , a screwdriver or something , for a long time , i start feeling the tip directly . not indirectly , but you actually can feel the tip . grad b: yeah yeah . professor c: and people who are uh accomplished violinists and stuff like that , claim they also have this kind of thing where you get a direct sensation of , physical sensation , of the end affector . grad b: yeah . what 's going on at the end of the tool , phd a: the ext the the the extension , grad b: yeah . professor c: huh ? grad b: what 's going on at the end of the tool , or whatever . professor c: yeah , within phd a: right . professor c: huh ? phd a: the extension of of your hand , right . professor c: yeah , right . have you hav y h had this ? phd a: the i i think so . i mean i i it 's not exactly the th same thing , but but s it it it 's getting close to that . grad b: yeah . grad f: w what does it feel like ? professor c: oh i it feels like your as if your uh neurons had extended themselves out to this tool , and you 're feeling forces on it and so forth and and you deal directly with it . phd a: i once i i was playing you know with those um uh devices that allow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something grad b: oh , ok . professor c: right , yeah yeah yeah . yeah . phd a: and there 's a correspondence between professor c: yeah . phd a: so i played with it . after a while , you do n't feel the difference anymore . i i mean it 's kind of grad b: mm - hmm . professor c: yeah , right . phd a: very kind of you stop back and suddenly it goes away and you have to kind of work again to recapture it , but yeah . grad b: yeah . professor c: right , yeah , so anyway , so so this was the first actual experimental evidence i 'd seen that was consistent with this anecdotal stuff . grad b: that 's cool . professor c: and of course it makes a lovely def uh story about why languages uh , make this distinction . of course there are behavioral differences too . things you can reach are really quite different than things you ca n't . grad b: yeah . professor c: but there seems to be an actu really deep embodied neural difference . and i this is , um so . in addition to the e grad e: this is more proximal - distal . professor c: yeah uh exactly . so in addition to e ego and allocentric uh which appear all over the place , you also apparently have this proximal - distal thing which is very deeply uh embedded . s grad e: well , dan montello sort of , he he does the uh uh th the cognitive map world , down in santa barbara . and he he always talks about these he he already well i probably most likely without knowing this this evidence uh is talking about these small scale spaces that you can manipulate versus large scale environmental spaces . professor c: yeah . well there 's there 's uh been a lot of behavioral things o on this , but that was the first neur neuro - physiological thing i saw . anyway yeah , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , right ? and so these issues about uh , reference , and spatial { comment } reference , discourse reference , uh - uh - uh - uh { comment } all this sort of stuff , uh , deixis which is part of what you were talking about , grad b: mm - hmm . mm - hmm . professor c: um so , all of this stuff is coming up essentially starting now . so we got ta do all this . so there 's that . and then there 's also a set of system things that come up . so `` ok , we 're not using their system . that means we need our system . `` grad b: mm - hmm . professor c: right ? grad b: yeah . professor c: it it follows . and so , uh , in addition to the business about just getting the linguistics right , and the formalism and stuff , we 're actually gon na build something and uh , johno is point person on the parser , analyzer , whatever that is , and we 're gon na start on that in parallel with the um , the grammar stuff . grad b: alright . professor c: but to do that we 're gon na need to make some decisions like ontology , so , um and so this is another thing where we 're gon na , you know , have to get involved and make s relatively early i think , make some decisions on uh , `` is there an ontology api that that `` there 's a sort of standard way of getting things from ontologies and we build the parser and stuff around that , or is there a particular ontology that we 're gon na standardize on , and if so for example , is there something that we can use there . i does uh either the uh smartkom project or one of the projects at eml have something that we can just p pull out , for that . uh , so there are gon na be some some some things like that , which are not science but system . but we are n't gon na ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually uh build some of it . and how much we build , and and so forth . grad b: i professor c: uh . part of it , if it works right , is wh it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that um , there 's a good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , grad b: ok . professor c: and of course it 's only w in both cases it 's only one piece of a bigger system . grad b: mm - hmm . professor c: but it would be nice if that piece were exactly the same piece . grad b: right . professor c: it was just this uh construction analyzer . and so we think we think we have a shot at at that . grad b: ok . professor c: so . the for so . to to come full circle on that , this formalization task , ok ? is trying to get the formalism into into a shape where it can actually uh grad b: yeah . be of use to someone who 's trying to do this , right ? professor c: d well , yeah , where it actually is is covers the whole range of things . and the the the the thing that got mark into the worst trouble is he had a very ambitious thing he was trying to do , and he insisted on trying to do it with a limited set of mechanisms . it turned out , inherently not to cover the space . grad b: ok . professor c: and it just it was just terribly frustrating for him , grad b: yeah . professor c: and he seemed fully committed to both sides of this i i irreconcilable thing . grad b: i see . right . professor c: and . uh . johno is much more pragmatic . grad b: ok . good to know . professor c: uh . huh ? is this is true , is it not ? grad d: yes . professor c: ok . so there 's you know sort of , yeah , deep , really deep , emotional commitment to a certain theory being uh , complete . grad b: oh , ok . grad f: you do n't have a hidden purist streak ? grad d: oh no . professor c: we - well it has n't it it certainly has n't been observed , in any case . grad f: ok . just checking . grad d: no sir . grad b: alright . professor c: um . now , you do , but that 's ok . uh . so . for for grad b: cuz i do n't have to implement anything . professor c: exactly right . exactly . grad f: i have a problem , then . it 's so . whether i do depends on whether i 'm talking to him or him probably . phd a: hmm . grad b: yeah , right . professor c: right . why a actually , uh , the thing is , you you do but , th the thing you have to im implement is so small that uh . grad f: which meeting i 'm in . it 's ok to be purist within that context . professor c: within that , yeah , grad f: yes , professor c: and uh , it 's a and still , i think , you know , get something done . grad f: good . grad b: cool ! professor c: but to try to do something upscale and purist particularly if if um what you 're purist about does n't actually work , is real hard . grad f: yay . grad b: mm - hmm . yeah . professor c: ok . and then the other thing is while we 're doing this uh robert 's gon na pick a piece of this space , phd a: it 's possible yeah . grad b: ok . professor c: ok , uh , for his absentee thesis . i think you all know that that you can just , in germany almost just send in your thesis . grad b: just a drive up . ca - chuk ! phd a: um professor c: yeah right . grad b: there you go . professor c: ok . grad e: the - th there there 's a drive - in thesis uh sh joint over in saarbruecken . grad b: exactly . drive through , yeah . professor c: it costs a lot . the the amount you put in your credit card and as well . but , uh , but anyway , so , uh , that 's um , also got ta be worked out , hopefully over the next few weeks , so that that it becomes clear uh , what piece uh , robert wants to jump into . and , while we 're at this level , uh , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . grad b: ok . professor c: so , de uh . and her name is eva . grad b: ok . professor c: it really is . nobody believed th th that grad f: yeah , i thought it had to be a joke , of your part , you know professor c: yeah . grad f: like { comment } `` johno made it up , i 'm sure . `` grad g: is this person someone who 's in first - year this year , professor c: no , first year coming . grad g: or professor c: so , she 's she 's now out here she 's moved , and she 'll be a student as of then . grad g: ok . professor c: and probably she 'll pick up from you on the belief - net stuff , so sh she 'll be chasing you down and stuff like that . grad g: ok . professor c: uh . grad e: document . grad g: right . professor c: uh , against all traditions . and actually i talked today to a uh undergraduate who wants to do an honors thesis on this . uh grad f: someone from the class ? professor c: no , interestingly enough . grad f: we always get these people who are not in the class , who professor c: some of th some of them , yeah . grad f: it 's interesting . professor c: so anyway , uh , but uh she 's another one of these ones with a three point nine average and so forth and so on . grad b: mm - hmm . professor c: uh , so , um , i 've give i 've given her some things to read . so we 'll see how this goes . oh there 's yet another one of the incoming first { comment } incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . um , anyway , so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gon na make sense to have this be separate from the other bigger effort with the formalization stuff or not , i 'm not sure . it partly depends on w what your thesis turns out to be and how that goes . s so , we 'll see . and then , ami , you can decide , you know , how much time you wan na put into it and uh , it it 's beginning to take shap shape , phd a: ok . professor c: so uh and , phd a: right professor c: i think you will find that if you want to look technically at some of the your traditional questions in this light , uh keith , who 's buil building constructions , will be quite happy to uh see what , you know , you envision as the issues and the problems and um , how they might uh get reflected in constructions . grad b: sure . professor c: i suspect that 's right . grad b: yeah . yeah . phd a: i i may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but uh , after that or before that . professor c: ok , fine . and , um , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in in the neighborhood . phd a: right . yeah be uh actu actually i 'm invited to do some consulting with a bank in geneva which has an affiliation with a research institute in geneva , which i forgot the name of . professor c: yeah . yep . e o do y phd a: yeah . professor c: well , we we 're connected to uh there 's a there 's a a very significant connection between we 'll we 'll go through this , phd a: yeah . professor c: icsi and epfl , which is the , uh it 's the fr ge - germany 's got two big technical institutes . there 's one in in zurich , phd a: mm - hmm . professor c: e t and then there 's one , the french speaking one , in lausanne , grad b: oh , so in switzerland . professor c: ok ? which is uh e p phd a: great . professor c: f l . so find out who they are associated with in geneva . phd a: right . professor c: probably we 're connected to them . phd a: great . i 'll let you know . s i 'll send you email . professor c: ok . yeah , and so anyway we c uh we can m undoubtedly get ami uh to give a talk at uh eml or something like that . while he 's in in uh grad e: hmm . uh . i i think the one you you gave here a couple of weeks ago would be of interest there , too . phd a: sure , yeah . professor c: a lot of interest . actually , either place , dfki or uh yeah , so , and and if there is a book , that you 'll be building up some audience for it . phd a: yeah . right . professor c: and you 'll get feedback from these guys . phd a: great , yeah . professor c: cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . phd a: cool . professor c: ok . so , uh , unless we wan na start digging into the uh the belief - net and the decisions now , which would be fine , it 's probably grad e: i i tho it 's probably better if i come next week with the um version o point nine of the structure . professor c: ok . so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying `` here 's what we think we understand , here are the things we think we do n't understand `` . and that we as a group will try to to finish it . what i 'd like to do is shoot f for finishing all this next monday . grad g: sure . professor c: ok ? uh , `` these are the decisions `` i do n't think we 're gon na get lots more information . it 's a design problem . grad b: mm - hmm . professor c: you know . we grad g: yeah . professor c: yeah . and let 's come up with a first cut at what this should look like . and then finish it up . grad b: ok . professor c: does that so make sense ? grad b: ok . grad e: and um , the the sem semester will be over next week but then you have projects for one more week to come ? grad g: no , i i think i 'll be done everything by this uh by the end of this week . grad e: same with you ? no . grad d: nnn . this well , i 've i have projects , but then the my prof professor of one of my classes also wa has a final that he 's giving us . and he 's giving us five days to do it which means it going to be hard . grad b: yeah . professor c: yeah . oh . is it a take - home final ? who 's doing this ? grad d: yeah . aikin , alex , yeah . professor c: yeah , figured . that would have been i my guess . grad g: hmm . professor c: right . um , but anyway , yeah . grad b: pretty soon . grad e: ok . professor c: ok , so i guess that 's grad d: so , the seventeenth will definitely be the last day , like it or not for me . professor c: right . right . so let 's do this , and then we we well there 's gon na be some separate co these guys are talking , uh we have a group on the formalization , uh nancy and johno and i are gon na talk about parsers . so there 're various kinds of uh grad b: ok . professor c: of course , nothing gets done even in a meeting of seven people , grad b: right . professor c: right ? so , um , two or three people is the size in which actual work gets done . grad e: mmm . grad b: yeah . professor c: so we 'll do that . great . oh , the other thing we wan na do is catch up with uh , ellen and see what she 's doing because the um image schemas are going to be um , an important pa grad b: yeah . quite relevant , yeah . professor c: we we want those , grad b: yeah , oh yeah . professor c: right ? and we want them formalized and stuff like that . grad b: yeah . professor c: so let me let me make a note to do that . grad b: ok . yeah , i 'm actually probably going to be in contact with her uh pretty soon anyway because of various of us students were going to have a reading group about precisely that sort of thing over the summer , grad d: ok . professor c: oh right ! right right right ! grad b: so . professor c: that 's great ! yeah , i i shweta mentioned that , although she said it 's a secret . grad b: ok . grad d: hi grad b: right , no faculty ! professor c: th - the faculty are n't faculty are n't supposed to know . grad d: wednesday 's much better for me , yeah . professor c: but um , i 'm sufficiently clueless that i count as a grad b: yeah , right . it 's as if we did n't tell anyone at all , grad d: bhaskara . grad b: right .","output":"the final english smartkom demo will be presented to the whole institute once the system is de-bugged and stabilised ."},{"instruction":"what would happen after the demo ?","input":"grad b:  grad d: how many batteries do you go through ? grad b: thank you . professor c: alright . phd a: sure . professor c: good . yeah . ok so , let 's get started . nancy said she 's coming and that means she will be . um . my suggestion is that robert and johno sort of give us a report on last week 's adventures uh to start . so everybody knows there were these guys f uh from heidelber - uh , uh , actually from uh dfki uh , part of the german smartkom project , who were here for the week and , i think got a lot done . grad e: yeah , i think so too . um . the we got to the point where we can now speak into the smartkom system , and it 'll go all the way through and then say something like `` roman numeral one , am smarticus . `` it actually says , `` roemisch einz , am smarticus , `` grad b: ok . grad e: which means it 's just using a german sythesis module for english sentences . grad b: ok . grad e: so uh , professor c: it does n't know `` i `` . grad b: ok . grad e: um , the uh grad b: oh , am spartacus . `` grad d: `` i am sm - i am smarticus `` is what it 's saying . phd a: right . grad b: verstehe . ok . grad d: i gue grad e: the uh sythesis is just a question of um , hopefully it 's just a question of exchanging a couple of files , once we have them . and , um , it 's not going to be a problem because we decided to stick to the so - called concept to speech approach . so i 'm i 'm i 'm going backwards now , so `` synthesis `` is where you sort of make this uh , make these sounds , and `` concept to speech `` is feeding into this synthesis module giving it what needs to be said , and the whole syntactic structure so it can pronounce things better , presumably . then , just with text to speech . grad b: mm - hmm . grad e: and , uh , johno learned how to write xml tags . uh , and did write the tree adjoining grammar for some some sentences . no , right ? grad d: yeah . grad e: yeah , for a couple grad d: so . bu - uh , i the way the uh , the dialogue manager works is it dumps out what it wants to know , or what it wants to tell the person , to a er in xml and there 's a conversion system for different uh , to go from xml to something else . and th so , the knowledge base for the system , that generates the syntasti syntactic structures for the ge generation is uh , in a lisp - like the knowledge base is in a lisp - like form . and then the thing that actually builds these syntactic structures is something based on prolog . so , you have a basically , a goal and it , you know , says `` ok , well i 'm gon na try to do the greet - the - person goal , grad b: mm - hmm . grad d: so it just starts uh , it binds some variables and it just decides to , you know , do some subscold . basically , it just means `` build the tree . `` grad b: ok . grad d: and then it passes the tree onto , uh , the ge the generation module . grad e: but i think that the point is that out of the twelve possible utterances that the german system can do , we 've already written the the syntax trees for three or four . grad d: we yeah . so , the syntax trees are very simple . it 's like most of the sentences in one tree , grad b: mm - hmm . grad d: and instead of , you know , breaking down to , like , small units and building back up , they basically took the sentences , and basically cut them in half , or you know , into thirds or something like that , and made trees out of those . and so uh , uh tilman wrote a little tool that you could take lisp notation and generate an xml , uh , tree . uh , s what do ca structure from the from the lisp . and so basically you just say , you know , `` noun goes to `` , you know , er , nah , i do n't re i 've never been good at those . so there 's like the vp goes to n and those things in lisp , and it will generate for you . grad b: ok . n , n , v yeah , ok . alright . grad e: and because we 're sticking to that structure , the synthesis module does n't need to be changed . so all that f fancy stuff , and the texas speech version of it , which is actually the simpler version , is gon na be done in october which is much too late for us . so . this way we we worked around that . the , uh the system , um i can show you the system . i actually want , at least , maybe , you should be able to start it on your own . if you wan na play around with it , in th in the future . right now it 's brittle and you need to ch start it up and then make ts twenty changes on on on on seventeen modules before they actually can stomach it , anything . and send in a a a couple of side queries on some dummy center set - up program so that it actually works because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we do n't have here . grad b: mm - hmm . grad e: and so we 're doing it via mouse , but the whole system was designed to work with this thing and it was it was a lot of engineering stuff . no science in there whatsoever , but it 's working now , and um , that 's the good news . so everything else actually did prove to be language independent except for the parsing and the generation . grad d: why i had i did need to chan generate different trees than the german ones , mainly because you know like uh , the gerund in in german is automatically taken care of with just a regular verb , grad e: you have to switch it on . grad b: mm - hmm . grad d: so i 'd uh have to add `` am walking , `` grad b: ok . grad d: or i 'd have to add a little stem for the `` am `` , when i build the built the tree . grad b: ok . yeah , i noticed that um , that some of the examples they had , had you know , non - english word orders and so on , you know . and then all that good stuff . so . professor c: alright . grad d: yeah . grad b: like . professor c: so it might be worth , keith , you looking at this , grad b: yeah . professor c: um grad b: i i still do n't i still do n't really understand e like grad d: well tilman s grad b: i mean we sort of say , um you know , i i still do n't exactly understand sort of the information flow uh in in this thing , or what the modules are and so on . so , you know , like just that such - and - such module uh um decides that it wants to achieve the goal of greeting the user , and then magically it sort of s professor c: yeah grad b: i mean , how does it know which syntactic structure to pull out , and all that ? professor c: i thi yeah . so . i think it 's not worth going over in the group , grad b: r uh sure . professor c: but sort of when you get free and you have the time uh either robert or johno or i can walk you through it . grad b: yeah , soon . ok . professor c: and you can ask all the questions about how this all fits together . grad b: that 's fine . professor c: it 's eee { comment } messy but once you understand it you understand it . it 's it 's there 's nothing really complicated about it . grad b: ok . grad e: no . grad b: and i remember one thing that that came up in the talk last wednesday . um , was this , i i think he talked about the idea of like , um he was talking about these lexicalized uh , uh , tree adjoining grammars where you sort of for each word you , um grad d: ok , you know how to do it ? grad b: for each lexical item , the lexical entry says what all the uh trees are that it can appear in . and of course , that 's not v that 's the opposite of constructional . that 's , you know , that 's that 's hpsg or whatever . professor c: right . grad b: you know ? professor c: right . now , we 're we 're not committed for our research to do any of those things . grad b: yeah . mm - hmm . professor c: so uh we are committed for our funding . grad b: right . professor c: ok ? to uh grad b: make our stuff fit to that . professor c: yeah , to n no , to just get the dem get the demos they need . grad b: uh - huh . professor c: ok ? so between us all we have t to get th the demos they need . if it turns out we can also give them lots more than that by , you know , tapping into other things we do , that 's great . grad d: you should probably move the microphone closer to your face . grad b: mm - hmm . professor c: but i it turns out not to be in an any of the contracts grad d: there 's like a little the twisty thing , you can move it with . grad b: ok . professor c: and , s deliberately . so , the reason i 'd like you to understand uh what 's going on in this demo system is not because it 's important to the research . it 's just for closure . so that if we come up with a question of `` could we fit this deeper stuff in there ? `` or something . you know what the hell we we 're talking about fitting in . grad b: right . ok . professor c: so it 's just , uh in the sam same actually with the rest of us we just need to really understand what 's there . is there anything we can make use of ? uh , is there anything we can give back , beyond th the sort of minimum requirements ? but none of that has a short time fuse . grad b: ok . professor c: so th the demo the demo requirements for this fall are sort of taken care of as of later this week or something . and then so , it 's probably fifteen months or something until there 's another serious demo requirement . grad b: oh ok . professor c: that does n't mean we do n't think about it for fifteen months , grad b: right . professor c: but it means we can not think about it for six months . grad b: right , yeah . professor c: so . the plan for this summer uh , really is to step back from the applied project , grad e: right . professor c: keep the d keep the context open , but actually go after the basic issues . grad b: hmm . oh ok . professor c: and , so the idea is there 's this uh , other subgroup that 's worrying about formalizing the nota getting a notation . but sort of in parallel with that , uh , the hope is tha in particularly you will work on constructions in english ge - and german for this domain , grad b: mm - hmm . professor c: but y not worry about parsing them or fitting them into smartkom or any of the other anything lik any other constraints for the time being . grad b: yeah . ok . got it . professor c: it 's hard enough to get it semantically and syntactically right and then and get the constructions in their form and stuff . grad b: yeah . professor c: and , i don i do n't want you f feeling that you have to somehow meet all these other constraints . grad b: right , ok . professor c: um . and similarly with the parsing , uh we 're gon na worry about parsing uh , the general case you know , construction parser for general constructions . and , if we need a cut - down version for something , or whatever , we 'll worry about that later . grad b: ok . professor c: so i 'd like to , for the summer turn into science mode . grad b: ok . professor c: and i assume that 's also , uh , your plan as well . grad b: so i mean , the the point is that like the meetings um so far that i 've been at have been sort of been geared towards this demo , professor c: right . yeah . yeah . grad b: and then that 's going to go away pretty soon . professor c: but but we we 're swit grad b: ok . professor c: right . grad b: and then we 'll sort of shift gears a fairly substantially , professor c: yeah . grad e: it 's professor c: yeah . grad b: huh ? professor c: yeah . grad e: it 's got . what i what i think is is a good idea that i can can show to anyone who 's interested , we can even make a sort of an internal demo , and i i show you what i do , grad b: mm - hmm . grad e: i speak into it and you hear it talk , grad b: ok . grad e: and i can sort of walk f through the information . so , this is like in half hour or forty - five minutes . just fun . grad b: ok . grad e: and so you when somebody on the streets com comes up to you and asks you what is smartkom so you can , sort of , give a sensible answer . grad b: right . ok . professor c: so , c sh we could set that up as actually an institute wide thing ? just give a talk in the big room , and and so peo people know what 's going on ? when you 're ready ? grad e: absolutely . professor c: yeah i mean , that 's the kind of thing that 's the level at which you know we can just li invite everybody and say `` this is a project that we 've been working on and here 's a demo version of it `` and stuff like that . grad b: yeah . grad e: ok . well d we we do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're grad b: uh - huh . professor c: indeed . grad e: yeah . ok . makes sense . professor c: but any so that e e it 's clear , then , i think . actually , roughly starting uh let 's say , nex next meeting , cuz this meeting we have one other thing to tie up besides the trip report . grad b: yeah . ok . professor c: but uh starting next meeting i think we want to flip into this mode where uh . i mean there are a lot of issues , what 's the ontology look like , grad b: mm - hmm . professor c: you know what do the constructions look like , what 's the execution engine look like , mmm lots of things . grad b: mm - hmm . professor c: but , more focused on uh an idealized version than just getting the demo out . now before we do that , let 's get back in oh ! but , it 's still , i think , useful for you to understand the demo version enough , so that you can can see what what it is that that uh it might eventually get retro - fitted into or something . grad b: yeah . ok , right . professor c: and johno 's already done that , uh , looked at the dem uh the looked at the smartkom stuff . grad d: wa uh to some de uh what what part of th the smartkom stuff ? professor c: well , the parser , and that stuff . grad d: oh yeah yeah . professor c: ok . anyway . so , the trip the report on these the last we we sort of interrupted you guys telling us about what happened last week . grad b: yeah . it 's alright . grad e: um . well it was just amazing to to see uh how how instable the whole thing is , professor c: maybe you 're done , then . grad e: and if you just take the and i g i got the feeling that we are the only ones right now who have a running system . i do n't know what the guys in kaiserslautern have running because e the version that is , the full version that 's on the server d does not work . and you need to do a lot of stuff to make it work . and so it 's and even tilman and ralf sort of said `` yeah there never was a really working version that uh did it without th all the shortcuts that they built in for the uh october @ @ version `` . so we 're actually maybe ahead of the system gruppe by now , the system the integration group . and it was , uh it was fun to some extent , but the uh the outcome that is sort of of scientific interest is that i think both ralf and tilman um , i know that they enjoyed it here , and they r they they liked , uh , a lot of the stuff they saw here , what what we have been thinking about , and they 're more than willing to to um , cooperate , by all means . and um , part of my responsibility is uh to use our internal `` group - ware `` server at eml , make that open to all of us and them , so that whatever we discuss in terms of parsing and and generating and constructions w we we sort of uh put it in there and they put what they do in there and maybe we can even um , get some overlap , get some synergy out of that . and um , the , uh if i find someone at in eml that is interested in that , um i i may even think that we could look take constructions and and generate from them because the tree adjoining grammars that that tilman is using is as you said nothing but a mathematical formalism . and you can just do anything with it , whether it 's syntactic trees , h p s g - like stuff , or whether it 's construction . so if you ever get to the generation side of constructing things and there might be something of interest there , but in the moment we 're of course definitely focused on the understanding , um , pipeline . professor c: anyth - any other { comment } uh repo visit reports sort of stories ? uh we so we now know i think , what the landscape is like . grad b: mm - hmm . professor c: and so we just push on and and uh , do what we need to do . and one of the things we need to do is the um , and this i think is relatively tight tightly constrained , is to finish up this belief - net stuff . so . uh . and i was going to switch to start talking about that unless there 're m other more general questions . ok so here 's where we are on the belief - net stuff as far as i understand it . um . going back i guess two weeks ago uh robert had laid out this belief - net , missing only the connections . right ? that is { comment } so , he 'd put all th all the dots down , and we went through this , and , i think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there . yeah { comment } we may run across one or two more . but of course the connections were n't . so , uh bhaskara and i went off and looked at some technical questions about were certain operations sort of legitimate belief - net computations and was there some known problem with them or had someone already uh , solved you know how to do this and stuff . and so bhaskara tracked that down . the answer seems to be uh , `` no , no one has done it , but yes it 's a perfectly reasonable thing to do if that 's what you set out to do `` . and , so the current state of things is that , again , starting now , um we 'd like to actually get a running belief - net for this particular subdomain done in the next few weeks . so bhaskara is switching projects as of the first of june , and uh , he 's gon na leave us an inheritance , which is a uh hopefully a belief - net that does these things . and there 're two aspects to it , one of which is , you know , technical , getting the coding right , and making it run , and uh stuff like that . and the other is the actual semantics . ok ? what all you know , what are the considerations and how and what are the ways in which they relate . so he doe h he does n't need help from this group on the technical aspects or if he does uh we 'll do that separately . grad b: mm - hmm . professor c: but in terms of what are the decisions and stuff like that , that 's something that we all have to work out . is is that right ? i mean that 's that 's both you guys ' understanding of where we are ? grad e: absolutely . professor c: ok . grad g: so , i guess , um is there like a latest version of the belief - net of the proposed belief - net ? like grad e: we had um decided grad g: like grad e: um . well , no , we did n't decide . we wanted to look into maybe getting it , the visualization , a bit clearer , but i think if we do it , um , sort of a paper version of all the nodes and then the connections between them , that should suffice . grad g: mm - hmm . yeah , that should be fine . professor c: yeah i mean , that 's a separate problem . grad d: yeah , i professor c: we do in the long run wan na do better visualization and all that stuff . grad e: yeah . professor c: that 's separable , yeah . grad d: i did look into that , uh in terms of , you know , exploding the nodes out and down ag professor c: yep . right . grad d: javabayes does not support that . i can imagine a way of hacking at the code to do that . it 'd probably take two weeks or so to actually go through and do it , professor c: not not at this point . grad d: and i went through all the other packages on murph - kevin murphy 's page , professor c: right . grad d: and i could n't find the necessary mix of free and uh with the gui and , with this thing that we want . professor c: well , we can p if it 's if we can pay yeah . if you know it 's paying a thousand dollars or something we can do that . ok ? so so do n't view free as as a absolute constraint . grad d: ok . ok , so then i 'll go back and look at the ones on the list that professor c: ok . and you can ask kevin . grad e: but grad g: yeah . grad d: mmm . grad e: but grad g: yeah , the one that uh people seem to use is uh hugin or whatever ? professor c: hugin , yeah that 's free . grad g: how exp i do n't think it 's is it free ? because i 've seen it advertised in places so i it seems to professor c: uh , it may be free to academics . like i i do n't know . i have a co { comment } i have a copy { comment } that i l i downloaded . grad g: ok . professor c: so , at one point it was free . grad g: ok . professor c: uh but yo i noticed people do use hugin so um , grad d: how do you spell that ? professor c: hugin . grad f: why professor c: and bhaskara can give you a pointer . so then , in any case , um but paying a lit you know , if i if it 's uh probably for university , it 's it 's gon na be real cheap anyway . but um , you know , if it 's fifty thousand dollars we are n't gon na do it . i 'm mean , we have no need for that . grad e: i i also s would suggest not to d spend two weeks in in in changing the the javabayes code . professor c: no , grad b: yeah . professor c: he 's not gon na do that . grad d: ok . grad e: i i will send you a pointer to a java applet that does that , it 's sort of a fish - eye . you you have a node , and you click on it , and it shows you all the connections , grad d: mmm . grad e: and then if you click on something else that moves away , that goes into the middle . and maybe there is an easy way of interfacing those two . if that does n't work , it 's not a problem we we need to solve right now . what i 'm what my job is , i will , um , give you the input in terms of of the internal structure . maybe node by node , or something like this ? or should i collect it all grad g: mm - hmm . grad e: and professor c: does n't matter . grad g: um , just any like like sort of rough representation of the entire belief - net is probably best . grad e: ok . and um you 're gon na be around ? t again , always tuesdays and thursdays afternoon - ish ? as usual ? or will that change ? grad g: yeah i mean , yeah , i can like i c um . this week i guess um , kind of i have a lot of projects and stuff but after that i will generally be more free . so yes , i might i can be around . and g i mean , generally if you email me also i can be around on other days . grad e: yeah . ok . professor c: yeah and this is not a crisis that i mean , you do , e everybody who 's a student should , you know do their work , get their c courses all in good shape and and and and then we 'll dig d dig down on this . grad e: yeah , that 's yeah . ok . no , that 's good . that means i have i h i can spend this week doing it . so . grad g: ok . grad b: how do you go about this process of deciding what these connections are ? i know that there 's an issue of how to weight the different things too , and stuff . right ? i mean do you just sort of guess and see if it sort of professor c: right . well there there there there 're two different things you do . grad e: it 's professor c: one is you design and the other is you learn . ok ? so uh what we 're gon na do initially is is do design , and , i if you will , guess . grad b: ok . professor c: ok . uh that is you know use your best knowledge of of the domain to uh , hypothesize what the dependencies are and stuff . grad b: right . ok . professor c: if it 's done right , and if you have data then , there are techniques for learning the numbers given the structure grad b: yeah . professor c: and there are even techniques for learning the structure , although that takes a lot more data , and it 's not as @ @ and so forth and so on . so uh but for the limited amount of stuff we have for this particular exercise i think we 'll just design it . grad b: alright . grad e: yeah . fo - hopefully as time passes we 'll get more and more data from heidelberg and from people actually using it and stuff . grad b: ok . grad e: so but this is the { comment } long run . grad b: yeah . grad e: but to solve our problems ag uh a mediocre design will do i think in the beginning . grad b: yeah , that 's right . yeah , oh , and by the way , speaking of data , um , are there i could swore uh , i could swear i saw it sitting on someone 's desk at some point , but is there a um a transcript of any of the , sort of , initial interactions of people with the with the system ? cuz you know , i 'm still sort of itching to to look at what look at the stuff , and see what people are saying . professor c: mm - hmm . yeah . yeah make yourself a note . so and and , of course keith would like the german as well as the english , so whatever you guys can get . grad e: the german . oh yeah , of course , german . yeah . professor c: yeah , the y your native language , right ? you remember that one . grad e: ok . that 's important , yeah . grad b: yeah , professor c: so he 'll get you some data . grad b: u ok . yeah , i mean i i sort of um found the uh , uh the audio of some of those , and um , it kind of sounded like i did n't want to trudge through that , you know . grad e: hmm . grad b: it was just strange , but . professor c: yep . grad e: we probably will not get those to describe because they were trial runs . grad b: oh yeah , ok . grad e: um , but uh that 's th but we have data in english and german already . grad b: ok , yeah , i mean . grad e: so . transcribed . i will send you that . ok . professor c: ok , so while we 're still at this sort of top level , anything else that we oughta talk about today ? grad e: ho - how was your thingy . grad b: oh , um , i just wanted to , uh , s like mention as an issue , um , you know last meeting i was n't here because i went to a linguistics colloquium on the fictive motion stuff , professor c: oh right . grad b: and that was pretty interesting and you know , i mean , seems to me that that will fairly obviously be of relevance to uh to what we 're doing here because you know people are likely to give descriptions like you know , `` what 's that thing uh right where you start to go up the hill , `` or something like that , you know , meaning a few feet up the hill or whatever from some reference point and all that stuff so i mean , i 'm sure in terms of you know , people trying to state locations or , you know , all that kind of stuff , this is gon na be very relevant . so , um , now that was the talk was about english versus japanese , um , which obviously the japanese does n't affect us directly , except that , um , some of the construction he 'd what he talked about was that you know in english we say things like th you know , `` your bike is parked across the street `` and we use these prepositional phrases , you know , `` well , if you were to move across the street you would be at the bike `` , but um in in japanese the the more conventionalized tendency is to use a sort of a description of `` where one has crossed to the river , there is a tree `` . um , and you know , you can actually say things like , um , `` there 's a tree where one has crossed the river , but no one has ever crossed the river `` , or something like that . so the idea is that this really is you know that 's supposed show that 's it 's really fictive and so on . but um but the point is that that kind of construction is also used in english , you know , like `` right where you start to go up the hill `` , or `` just when you get off the train `` , or something like that to uh , to indicate where something is . professor c: mmm . grad b: so we 'll have to think about professor c: so how much is that used in german ? grad e: um . the uh well i wa i was on a uh on a on a different sidetrack . professor c: oh , ok . grad e: i mean , the the deep map project which um is undergoing some renovation at at the moment , but this is a a three language project : german , english , japanese . grad b: ok . grad e: and um , we have a uh , uh i have taken care that we have the the japanese generation and stuff . and so i looked into uh spatial description . so we can generate spatial descriptions , how to get from a to b . and and information on objects , in german , english , and japanese . grad b: mm - hmm . grad e: and there is a huge uh project on spatial descriptions uh differences in spatial descriptions . well , if yo if you 're interested in that , so how how , i mean it does sort of go d all the way down to the conceptual level to some extent . grad b: ok . grad e: so . um . professor c: so , where is this huge project ? grad e: it 's kleist . it 's the uh bielefeld generation of uh spatial descriptions and whatever . professor c: mm - hmm . grad e:  professor c: well , that may be another thing that keith wants to look at . grad b: ok . grad e: but um , i i think we should leave japanese constructions maybe outside of the scope for for now , grad b: yeah . grad e: but um definitely it 's interesting to look at at cross the bordered there . professor c: mm - hmm . phd a: are are you going to p pay any attention to the relative position of of the direction relative relative to the speaker ? for example , there are some differences between hebrew and english . we can say um `` park in front of the car `` as you come beh you drive behind the car . in hebrew it means `` park behind the car `` , because to follow the car is defined as it faces you . grad e: mm - hmm . intrinsic , yeah . phd a: while in english , front of the car is the absolute front of the car . grad b: ok . phd a: so . grad b: right , so the canonical direction of motion determines where the front is . phd a: right . right . grad b: ok . phd a: so , i i i is german uh closer to to e uh , uh , uh , uh to e i mean uh grad e: mm - hmm . phd a: i do n't think it it 's related to syntax , though , so it may be entirely different . grad e: um , as a matter of fact professor c: no , it 's not . grad b: right . phd a: yeah . grad e: um . did you ever get to look at the the rou paper that i sent you on the on that problem in english and german ? grad b: i think grad e: carroll , ninety - three . um . i there is a a study on the differences between english and german on exactly that problem . phd a: hmm . grad e: so it 's they actually say `` the monkey in front of the car , where 's the monkey ? `` grad b: mm - hmm . grad e: and , um , they found statistically very significant differences in english and german , so i i i it might be , since there are only a finite number of ways of doing it , that that german might be more like hebrew in that respect . grad b: hmm . grad e: the solution they proposed was that it was due to syntactic factors . phd a: that but it was n't was grad e: that syntactic facto factors do do play a role there , wh whether you 're more likely , you know , to develop uh , choices that lead you towards using uh intrinsic versus extrinsic reference frames . phd a: right . mm - hmm . right . grad b: i mean , it seems to me that you can get both in in english depending o professor c: hmm . grad b: you know , like , `` in front of the car `` could you know like , here 's the car sideways to me in between me and the car or something 's in front of the car , or whatever . i could see that , professor c: absolutely . grad b: but but anyway , so you know , i mean , this was this was a a very good talk on those kinds of issues and so on . so uh . grad e: i can also give you uh , a pointer to a paper of mine which is the the ultimate taxonomy of reference frames . grad b: alright ! cool ! grad e: so . professor c: oh . grad e: i 'm the only person in the world who actually knows how it works . professor c: oh . grad e: not really . professor c: great . no , i 've not seen that . phd a: what do you mean . um . `` reference frames `` ? grad e: it 's called a phd a: uh uh grad e: it 's it 's spatial reference frames . you actually have only um . if you wan na have a this is usually um i should there should be an `` l `` , though . well actually you have only have two choices . you can either do a two - point or a three - point which is you you 're familiar with th with the `` origo `` ? where that 's the center `` origo `` is the center of the f frame of reference . grad b: hmm . grad e: and then you have the reference object and the object to be localized . grad b: hmm . phd a: mm - hmm . grad e: ok ? in some cases the origo is the same as the reference object . professor c: so that would be `` origin `` in english , grad f: this was like grad b: the origin . phd a: right grad b: yeah . professor c: right ? grad e: `` origo `` is a terminus technikus . in that sense , that 's even used in the english literature . `` origo . `` grad b: oh , ok . i never heard it . professor c: alright . phd a: ok . grad b: ok . grad e: and um , so , this video tape is in front of me . grad b: mm - hmm . grad e: i 'm the origo and i 'm also the reference object . grad b: mm - hmm . phd a: right . grad e: those are two - point . professor c: mm - hmm . grad e: and three - point relations is if something has an intrinsic front side like this chair then your f shoe is behind the chair . professor c: yeah . grad b: mm - hmm . grad e: and , reference object and um . no , from from my point of view your shoe is left of the chair . grad b: right . you you can actually say things like , um , `` it 's behind the tree from me `` or something like that , i think , in in in certain circumstances in english , right ? as sort of `` from where i 'm standing it would appear that `` grad e: yeah . yeah . so , grad f: looks a little bit like reichenbach for time . professor c: yeah , it sounds like it , does n't it , grad b: yeah . professor c: yeah . grad f: it 's a lot like it . grad e: and then and then here you grad f: um . grad e: on this scale , you have it either be ego or allocentric . professor c: mm - hmm . grad e: and that 's { comment } that 's basically it . so . egocentric two - point , egocentric three - point , or you can have allocentric . grad b: oh , ok . grad e: so , `` as seen from the church , the town hall is right of that um , fire station `` . aa - huh { comment } it 's hardly ever used but it 's w phd a: i 'd love to see it if you if you have a copy kind of . uh . grad b: yeah . professor c: yeah . i see this is this is getting into ami 's thing . phd a: here grad b: mm - hmm . professor c: he 's he 's very interested in that . grad e: ok . professor c: so . grad b: me too . professor c: uh . yeah . well , why do n't you just put it on the web page ? there 's this edu right ? grad e: yeah it 's or or just yeah . professor c: or a link to it . grad e: it 's also all on my my home page at eml . it 's called `` an anatomy of a spatial description `` . professor c: just grad e: but i 'll send that link . phd a: ok , great . professor c: maybe just put a link on . yeah . grad e: yep . professor c: by the way , there something that i did n't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach . grad e: yep . grad b: huh . professor c: so there 's there 's uh all this linguistic stuff about you know , near and far , or yon and and so forth . grad b: mm - hmm . professor c: so this is all this is there 's this linguistic facts . but apparently , the uh . here 's the way the findings go . that , you know they do mri , and and if you 're uh got something within reach then there 's one of your areas lights up , and if something 's out of reach uh a different one . but here 's the the amazing result , um , they say . you get someone with a with a deficit so that they have a perfectly normal ability at distance things . so the s typical task is subdivision . so there 's a a line on the wall over there , and you give them a laser pointer , and you say , `` where 's the midpoint ? `` and they do fine . if you give them the line , and they have to touch it , they ca n't . there 's just that part of the brain is n't functioning , so they ca n't do that . here 's the real experiment . the same thing on the wall , you give them a laser , `` where is it ? `` , grad b: mm - hmm . professor c: they do it . give them a stick , long stick , and say `` do it `` , they ca n't do it . so there 's a remapping of distant space into nearby space . phd a: right . so they doubled the the end the end of this grad f: because it 's within reach now ? grad b: yeah , professor c: it 's not within reach and you use the within - reach uh , mechanism . grad b: yeah . grad f: oh . wow . grad b: circuits . phd a: right . professor c: so i 'll d i 'll dig you up this reference . grad b: that 's cool . professor c: and so this doe this is , uh first of all , it explains something that i 've always wondered about and i 'll do this this test on you guys as well . so . uh . how - i have had an experience , not often , but a certain number of times , when , for example , i 'm working with a tool , a screwdriver or something , for a long time , i start feeling the tip directly . not indirectly , but you actually can feel the tip . grad b: yeah yeah . professor c: and people who are uh accomplished violinists and stuff like that , claim they also have this kind of thing where you get a direct sensation of , physical sensation , of the end affector . grad b: yeah . what 's going on at the end of the tool , phd a: the ext the the the extension , grad b: yeah . professor c: huh ? grad b: what 's going on at the end of the tool , or whatever . professor c: yeah , within phd a: right . professor c: huh ? phd a: the extension of of your hand , right . professor c: yeah , right . have you hav y h had this ? phd a: the i i think so . i mean i i it 's not exactly the th same thing , but but s it it it 's getting close to that . grad b: yeah . grad f: w what does it feel like ? professor c: oh i it feels like your as if your uh neurons had extended themselves out to this tool , and you 're feeling forces on it and so forth and and you deal directly with it . phd a: i once i i was playing you know with those um uh devices that allow you to manipulate objects when it 's dangerous to get close ? so you can insert your hand something grad b: oh , ok . professor c: right , yeah yeah yeah . yeah . phd a: and there 's a correspondence between professor c: yeah . phd a: so i played with it . after a while , you do n't feel the difference anymore . i i mean it 's kind of grad b: mm - hmm . professor c: yeah , right . phd a: very kind of you stop back and suddenly it goes away and you have to kind of work again to recapture it , but yeah . grad b: yeah . professor c: right , yeah , so anyway , so so this was the first actual experimental evidence i 'd seen that was consistent with this anecdotal stuff . grad b: that 's cool . professor c: and of course it makes a lovely def uh story about why languages uh , make this distinction . of course there are behavioral differences too . things you can reach are really quite different than things you ca n't . grad b: yeah . professor c: but there seems to be an actu really deep embodied neural difference . and i this is , um so . in addition to the e grad e: this is more proximal - distal . professor c: yeah uh exactly . so in addition to e ego and allocentric uh which appear all over the place , you also apparently have this proximal - distal thing which is very deeply uh embedded . s grad e: well , dan montello sort of , he he does the uh uh th the cognitive map world , down in santa barbara . and he he always talks about these he he already well i probably most likely without knowing this this evidence uh is talking about these small scale spaces that you can manipulate versus large scale environmental spaces . professor c: yeah . well there 's there 's uh been a lot of behavioral things o on this , but that was the first neur neuro - physiological thing i saw . anyway yeah , so we 'll we 'll look at this . and . so , all of these issues now are now starting to come up . so , now we 're now done with demos . we 're starting to do science , right ? and so these issues about uh , reference , and spatial { comment } reference , discourse reference , uh - uh - uh - uh { comment } all this sort of stuff , uh , deixis which is part of what you were talking about , grad b: mm - hmm . mm - hmm . professor c: um so , all of this stuff is coming up essentially starting now . so we got ta do all this . so there 's that . and then there 's also a set of system things that come up . so `` ok , we 're not using their system . that means we need our system . `` grad b: mm - hmm . professor c: right ? grad b: yeah . professor c: it it follows . and so , uh , in addition to the business about just getting the linguistics right , and the formalism and stuff , we 're actually gon na build something and uh , johno is point person on the parser , analyzer , whatever that is , and we 're gon na start on that in parallel with the um , the grammar stuff . grad b: alright . professor c: but to do that we 're gon na need to make some decisions like ontology , so , um and so this is another thing where we 're gon na , you know , have to get involved and make s relatively early i think , make some decisions on uh , `` is there an ontology api that that `` there 's a sort of standard way of getting things from ontologies and we build the parser and stuff around that , or is there a particular ontology that we 're gon na standardize on , and if so for example , is there something that we can use there . i does uh either the uh smartkom project or one of the projects at eml have something that we can just p pull out , for that . uh , so there are gon na be some some some things like that , which are not science but system . but we are n't gon na ignore those cuz we 're we 're not only going the plan is not only to lay out this thing , but to actually uh build some of it . and how much we build , and and so forth . grad b: i professor c: uh . part of it , if it works right , is wh it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling . so . it 's always been out of phase but it now seems that um , there 's a good shot at that . so we 've talked about it , and the hope is that we can make these things the same thing , grad b: ok . professor c: and of course it 's only w in both cases it 's only one piece of a bigger system . grad b: mm - hmm . professor c: but it would be nice if that piece were exactly the same piece . grad b: right . professor c: it was just this uh construction analyzer . and so we think we think we have a shot at at that . grad b: ok . professor c: so . the for so . to to come full circle on that , this formalization task , ok ? is trying to get the formalism into into a shape where it can actually uh grad b: yeah . be of use to someone who 's trying to do this , right ? professor c: d well , yeah , where it actually is is covers the whole range of things . and the the the the thing that got mark into the worst trouble is he had a very ambitious thing he was trying to do , and he insisted on trying to do it with a limited set of mechanisms . it turned out , inherently not to cover the space . grad b: ok . professor c: and it just it was just terribly frustrating for him , grad b: yeah . professor c: and he seemed fully committed to both sides of this i i irreconcilable thing . grad b: i see . right . professor c: and . uh . johno is much more pragmatic . grad b: ok . good to know . professor c: uh . huh ? is this is true , is it not ? grad d: yes . professor c: ok . so there 's you know sort of , yeah , deep , really deep , emotional commitment to a certain theory being uh , complete . grad b: oh , ok . grad f: you do n't have a hidden purist streak ? grad d: oh no . professor c: we - well it has n't it it certainly has n't been observed , in any case . grad f: ok . just checking . grad d: no sir . grad b: alright . professor c: um . now , you do , but that 's ok . uh . so . for for grad b: cuz i do n't have to implement anything . professor c: exactly right . exactly . grad f: i have a problem , then . it 's so . whether i do depends on whether i 'm talking to him or him probably . phd a: hmm . grad b: yeah , right . professor c: right . why a actually , uh , the thing is , you you do but , th the thing you have to im implement is so small that uh . grad f: which meeting i 'm in . it 's ok to be purist within that context . professor c: within that , yeah , grad f: yes , professor c: and uh , it 's a and still , i think , you know , get something done . grad f: good . grad b: cool ! professor c: but to try to do something upscale and purist particularly if if um what you 're purist about does n't actually work , is real hard . grad f: yay . grad b: mm - hmm . yeah . professor c: ok . and then the other thing is while we 're doing this uh robert 's gon na pick a piece of this space , phd a: it 's possible yeah . grad b: ok . professor c: ok , uh , for his absentee thesis . i think you all know that that you can just , in germany almost just send in your thesis . grad b: just a drive up . ca - chuk ! phd a: um professor c: yeah right . grad b: there you go . professor c: ok . grad e: the - th there there 's a drive - in thesis uh sh joint over in saarbruecken . grad b: exactly . drive through , yeah . professor c: it costs a lot . the the amount you put in your credit card and as well . but , uh , but anyway , so , uh , that 's um , also got ta be worked out , hopefully over the next few weeks , so that that it becomes clear uh , what piece uh , robert wants to jump into . and , while we 're at this level , uh , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft . grad b: ok . professor c: so , de uh . and her name is eva . grad b: ok . professor c: it really is . nobody believed th th that grad f: yeah , i thought it had to be a joke , of your part , you know professor c: yeah . grad f: like { comment } `` johno made it up , i 'm sure . `` grad g: is this person someone who 's in first - year this year , professor c: no , first year coming . grad g: or professor c: so , she 's she 's now out here she 's moved , and she 'll be a student as of then . grad g: ok . professor c: and probably she 'll pick up from you on the belief - net stuff , so sh she 'll be chasing you down and stuff like that . grad g: ok . professor c: uh . grad e: document . grad g: right . professor c: uh , against all traditions . and actually i talked today to a uh undergraduate who wants to do an honors thesis on this . uh grad f: someone from the class ? professor c: no , interestingly enough . grad f: we always get these people who are not in the class , who professor c: some of th some of them , yeah . grad f: it 's interesting . professor c: so anyway , uh , but uh she 's another one of these ones with a three point nine average and so forth and so on . grad b: mm - hmm . professor c: uh , so , um , i 've give i 've given her some things to read . so we 'll see how this goes . oh there 's yet another one of the incoming first { comment } incoming first - year graduate students who 's expressed interest , so we 'll see how that goes . um , anyway , so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts . we 'll see whether it 's gon na make sense to have this be separate from the other bigger effort with the formalization stuff or not , i 'm not sure . it partly depends on w what your thesis turns out to be and how that goes . s so , we 'll see . and then , ami , you can decide , you know , how much time you wan na put into it and uh , it it 's beginning to take shap shape , phd a: ok . professor c: so uh and , phd a: right professor c: i think you will find that if you want to look technically at some of the your traditional questions in this light , uh keith , who 's buil building constructions , will be quite happy to uh see what , you know , you envision as the issues and the problems and um , how they might uh get reflected in constructions . grad b: sure . professor c: i suspect that 's right . grad b: yeah . yeah . phd a: i i may have to go to switzerland for in june or beginning of july for between two weeks and four weeks , but uh , after that or before that . professor c: ok , fine . and , um , if it 's useful we can probably arrange for you to drop by and visit either at heidelberg or at the german ai center , while you 're in in the neighborhood . phd a: right . yeah be uh actu actually i 'm invited to do some consulting with a bank in geneva which has an affiliation with a research institute in geneva , which i forgot the name of . professor c: yeah . yep . e o do y phd a: yeah . professor c: well , we we 're connected to uh there 's a there 's a a very significant connection between we 'll we 'll go through this , phd a: yeah . professor c: icsi and epfl , which is the , uh it 's the fr ge - germany 's got two big technical institutes . there 's one in in zurich , phd a: mm - hmm . professor c: e t and then there 's one , the french speaking one , in lausanne , grad b: oh , so in switzerland . professor c: ok ? which is uh e p phd a: great . professor c: f l . so find out who they are associated with in geneva . phd a: right . professor c: probably we 're connected to them . phd a: great . i 'll let you know . s i 'll send you email . professor c: ok . yeah , and so anyway we c uh we can m undoubtedly get ami uh to give a talk at uh eml or something like that . while he 's in in uh grad e: hmm . uh . i i think the one you you gave here a couple of weeks ago would be of interest there , too . phd a: sure , yeah . professor c: a lot of interest . actually , either place , dfki or uh yeah , so , and and if there is a book , that you 'll be building up some audience for it . phd a: yeah . right . professor c: and you 'll get feedback from these guys . phd a: great , yeah . professor c: cuz they 've actually these dfki guys have done as much as anyone over the last decade in trying to build them . so we 'll set that up . phd a: cool . professor c: ok . so , uh , unless we wan na start digging into the uh the belief - net and the decisions now , which would be fine , it 's probably grad e: i i tho it 's probably better if i come next week with the um version o point nine of the structure . professor c: ok . so , how about if you two guys between now and next week come up with something that is partially proposal , and partially questions , saying `` here 's what we think we understand , here are the things we think we do n't understand `` . and that we as a group will try to to finish it . what i 'd like to do is shoot f for finishing all this next monday . grad g: sure . professor c: ok ? uh , `` these are the decisions `` i do n't think we 're gon na get lots more information . it 's a design problem . grad b: mm - hmm . professor c: you know . we grad g: yeah . professor c: yeah . and let 's come up with a first cut at what this should look like . and then finish it up . grad b: ok . professor c: does that so make sense ? grad b: ok . grad e: and um , the the sem semester will be over next week but then you have projects for one more week to come ? grad g: no , i i think i 'll be done everything by this uh by the end of this week . grad e: same with you ? no . grad d: nnn . this well , i 've i have projects , but then the my prof professor of one of my classes also wa has a final that he 's giving us . and he 's giving us five days to do it which means it going to be hard . grad b: yeah . professor c: yeah . oh . is it a take - home final ? who 's doing this ? grad d: yeah . aikin , alex , yeah . professor c: yeah , figured . that would have been i my guess . grad g: hmm . professor c: right . um , but anyway , yeah . grad b: pretty soon . grad e: ok . professor c: ok , so i guess that 's grad d: so , the seventeenth will definitely be the last day , like it or not for me . professor c: right . right . so let 's do this , and then we we well there 's gon na be some separate co these guys are talking , uh we have a group on the formalization , uh nancy and johno and i are gon na talk about parsers . so there 're various kinds of uh grad b: ok . professor c: of course , nothing gets done even in a meeting of seven people , grad b: right . professor c: right ? so , um , two or three people is the size in which actual work gets done . grad e: mmm . grad b: yeah . professor c: so we 'll do that . great . oh , the other thing we wan na do is catch up with uh , ellen and see what she 's doing because the um image schemas are going to be um , an important pa grad b: yeah . quite relevant , yeah . professor c: we we want those , grad b: yeah , oh yeah . professor c: right ? and we want them formalized and stuff like that . grad b: yeah . professor c: so let me let me make a note to do that . grad b: ok . yeah , i 'm actually probably going to be in contact with her uh pretty soon anyway because of various of us students were going to have a reading group about precisely that sort of thing over the summer , grad d: ok . professor c: oh right ! right right right ! grad b: so . professor c: that 's great ! yeah , i i shweta mentioned that , although she said it 's a secret . grad b: ok . grad d: hi grad b: right , no faculty ! professor c: th - the faculty are n't faculty are n't supposed to know . grad d: wednesday 's much better for me , yeah . professor c: but um , i 'm sufficiently clueless that i count as a grad b: yeah , right . it 's as if we did n't tell anyone at all , grad d: bhaskara . grad b: right .","output":"after the demo , the focus of research can switch towards purely scientific goals , including issues on ontology , deep semantic constructions , execution engines etc . moreover , a new system will be designed for the project and at least some parts of it should be built ."},{"instruction":"summarize the whole meeting","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"the meeting was about a computer based navigation system that will be used to conduct linguistic experiments on navigational terminology and intentionality , and it was simultaneously being recorded for another project . the navigational interface allows people to walk around a place and perform basic actions , like entering a building . its goal is to understand what people intend to do based on granular linguistic features . the experimental set up is that people talk to a human assistant who controls the program in an attempt to complete a certain task . to study intentionality , the team will determine important linguistic features and use a bayes model to see if they can predict the intention based on utterances ."},{"instruction":"summarize the discussion about setting up the recording equipment","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"one of the graduate students is working on building the pda of the future . the idea is to be able to record meetings for personal use and then query them for pertinent information . the data collection will be anonymized to a large extent , but not so much that the meeting does not represent a real scenario . this meeting will be one of the recorded meetings ."},{"instruction":"what did c think about setting up the recording equipment ?","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"c began by asking some questions about the recording procedure and wanted to know what excising utterances from the transcript would look like . c asked several questions to that end but clarified that the source of inquiry was curiosity and nothing more . additionally , c wanted a to explain to the meeting participants what the experiment was for ."},{"instruction":"what did a think about setting up the recording equipment ?","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"a noted that all participants will have to sign a consent form and read out digits and requested that microphones be kept away from the mouth to minimize breathing sounds . a also mentioned that people will be anonymized in the transcript . a explained that the goal was to eventually be able to query meetings for information ."},{"instruction":"summarize the discussion about the experimental setup of the computer navigation system","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"the computer navigation system will work as follows . the subject of the experiment will familiarize themselves with information about a city . then , they will be introduced to an advanced navigation system through which they can navigate the city , and they will be given several tasks , like buying stamps . the navigation system will crash , and the subject will be connected to a human operator . then , the human operator will control the system based on the subject 's requests as the subject tries to complete their tasks . both sides , the assistant and the subject , will be recorded for data collection purposes ."},{"instruction":"what did b think about the experimental setup of the computer navigation system ?","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"b explained that the subject of the experiment will first be given texts about a city , so they can familiarize themselves with foreign terms . then , they will be introduced to a computer navigation system with which they can navigate the city and provided with a set of tasks to complete . then , the computer system will crash , including the gps , so the person will not even know where they are , and the human operator will assist them . to find their location , the subject will have to provide visual information to the human operator . b also thought that creating movies of walking would require a lot of technical effort but later claimed that it may be worth it . b clarified that the goal was to see how people communicate in such a scenario ."},{"instruction":"what did d think about the experimental setup of the computer navigation system ?","input":"grad e: i guess . grad a: ok , we 're on . so just make sure that th your wireless mike is on , if you 're wearing a wireless . grad e: check one . check one . grad a: and you should be able to see which one which one you 're on by , uh , watching the little bars change . grad b: so , which is my bar ? mah ! number one . grad a: yep . grad e: sibilance . sibilance . grad a: so , actually , if you guys wan na go ahead and read digits now , as long as you 've signed the consent form , that 's alright . grad e: are we supposed to read digits at the same time ? grad a: no . no . grad e: oh , ok . grad a: each individually . we 're talking about doing all at the same time but i think cognitively that would be really difficult . to try to read them while everyone else is . grad e: everyone would need extreme focus . grad a: so , when you 're reading the digit strings , the first thing to do is just say which transcript you 're on . professor c: other way . we m we may wind up with ver we we may need versions of all this garbage . grad b: for our stuff . yeah . professor c: yeah . grad a: um . so the first thing you 'd wan na do is just say which transcript you 're on . professor c: yeah . grad a: so . you can see the transcript ? there 's two large number strings on the digits ? so you would just read that one . and then you read each line with a small pause between the lines . and the pause is just so the person transcribing it can tell where one line ends and the other begins . and i 'll give i 'll read the digit strings first , so can see how that goes . um . again , i 'm not sure how much i should talk about stuff before everyone 's here . professor c: mmm . well , we have one more coming . grad a: ok . well , why do n't i go ahead and read digit strings and then we can go on from there . professor c: ok . well , we can start doing it . grad a: thanks . so , uh , just also a note on wearing the microphones . all of you look like you 're doing it reasonably correctly , but you want it about two thumb widths away from your mouth , and then , at the corner . and that 's so that you minimize breath sounds , so that when you 're breathing , you do n't breathe into the mike . um . yeah , that 's good . and uh so , everyone needs to fill out , only once , the speaker form and the consent form . and the short form i mean , you should read the consent form , but uh , the thing to notice is that we will give you an opportunity to edit a all the transcripts . so , if you say things and you do n't want them to be released to the general public , which , these will be available at some point to anyone who wants them , uh , you 'll be given an opportunity by email , uh , to bleep out any portions you do n't like . um . on the speaker form just fill out as much of the information as you can . if you 're not exactly sure about the region , we 're not exactly sure either . so , do n't worry too much about it . the it 's just self rating . um . and i think that 's about it . i mean , should i do you want me to talk at all about why we 're doing this and what this project is ? professor c: um , yeah . grad a: or ? professor c: no . there was there was let 's see . oh grad e: does nancy know that we 're meeting in here ? grad b: i sent an email . professor c: she got an emai she was notified . grad e: oh yeah , she got an e yeah , yeah . professor c: whether she knows is another question . um . so are the people going to be identified by name ? grad a: well , what we 're gon na we 'll anonymize it in the transcript . um , but not in the audio . professor c: right . grad a: so the professor c: ok . so , then in terms of people worrying about , uh , excising things from the transcript , it 's unlikely . since it it does is n't attributed . oh , i see , but the a but the but the grad a: right , so if i said , `` oh , hi jerry , how are you ? `` , we 're not gon na go through and cancel out the `` jerry `` s . professor c: yeah . sure . grad a: um , so we will go through and , in the speaker id tags there 'll be , you know , m - one o seven , m - one o eight . professor c: right . grad a: um , but uh , professor c: right . grad a: um , it w uh , i do n't know a good way of doing it on the audio , and still have people who are doing discourse research be able to use the data . professor c: ok . mm - hmm . no , i i was n't complaining , grad a: yep . professor c: i just wanted to understand . grad a: right . professor c: ok . grad b: well , we can make up aliases for each of us . grad a: yeah , i mean , whatever you wan na do is fine , professor c: right . grad f: ok . grad a: but we find that we want the meeting to be as natural as possible . so , we 're trying to do real meetings . professor c: ok . grad a: and so we do n't wan na have to do aliases professor c: right . grad a: and we do n't want people to be editing what they say . grad b: right . grad a: so i think that it 's better just as a pro post - process to edit out every time you bash microsoft . professor c: right . grad b: mm - hmm . grad a: you know ? professor c: right . um , ok . so why do n't you tell us briefly grad a: ok . so th professor c: your give give your e normal schpiel . grad a: um . so this is the project is called meeting recorder and there are lots of different aspects of the project . um . so my particular interest is in the pda of the future . this is a mock - up of one . yes , we do believe the pda of the future will be made of wood . um . { comment } the idea is that you 'd be able to put a pda at the table at an impromptu meeting , and record it , and then be able to do querying and retrieval later on , on the meeting . so that 's my particular interest , is a portable device to do m uh , information retrieval on meetings . other people are interested in other aspects of meetings . um . so the first step on that , in any of these , is to collect some data . and so what we wanted is a room that 's instrumented with both the table top microphones , and these are very high quality pressure zone mikes , as well as the close talking mikes . what the close talk ng talking mikes gives us is some ground truth , gives us , um , high quality audio , um , especially for people who are n't interested in the acoustic parts of this corpus . so , for people who are more interested in language , we did n't want to penalize them by having only the far field mikes available . and then also , um , it 's a very , very hard task in terms of speech recognition . um . and so , uh , on the far field mikes we can expect very low recognition results . so we wanted the near field mikes to at least isolate the difference between the two . so that 's why we 're recording in parallel with the close talking and the far field at the same time . and then , all these channels are recorded simultaneously and framed synchronously so that you can also do things like , um , beam - forming on all the microphones and do research like that . our intention is to release this data to the public , um , probably through f through a body like the ldc . and , uh , just make it as a generally available corpus . um . there 's other work going on in meeting recording . so , we 're we 're working with sri , with uw , um . nist has started an effort which will include video . we 're not including video , obviously . and uh and then also , um , a small amount of assistance from ibm . is also involved . um . oh , and the digit strings , this is just a more constrained task . um . so because the general environment is so challenging , we decided to to do at least one set of digit strings to give ourselves something easier . and it 's exactly the same digit strings as in ti - digits , which is a common connected digits corpus . so we 'll have some , um , comparison to be able to be made . professor c: ok . grad a: anything else ? professor c: no . grad a: ok , so when the l last person comes in , just have them wear a wireless . it should be on already . um . either one of those . and uh , read the digit strings and and fill out the forms . so , the most important form is the consent form , so just be s be sure everyone signs that , if they consent . grad b: i 'm sure it 's pretty usual for meetings that people come late , grad a: yeah . grad b: so you will have to leave what you set . grad a: right . and uh , just give me a call , which , my number 's up there when your meeting is over . professor c: yep . grad a: and i 'm going to leave the mike here but it 's n uh , but i 'm not gon na be on so do n't have them use this one . it 'll just be sitting here . grad b: input ? yeah . there we go . professor c: by the way , adam , we will be using the , uh , screen as well . grad b: yep . professor c: so , you know . wow ! organization . so you guys who got email about this oh f uh , friday or something about what we 're up to . grad e: no . grad f: no . grad b: i got it . grad e: what was the nature of the email ? professor c: oh , this was about um , inferring intentions from features in context , and the words , like `` s go to see `` , or `` visit `` , or some grad b: wel - we i uh i i professor c: you did n't get it ? grad e: i do n't think i did . professor c: i guess these g have got better filters . cuz i sent it to everybody . you just blew it off . grad e: ah . professor c: ok . grad b: it 's really simple though . so this is the idea . um . we could pursue , um , if we thought it 's it 's worth it but , uh , i think we we will agree on that , um , to come up with a with a sort of very , very first crude prototype , and do some implementation work , and do some some research , and some modeling . so the idea is if you want to go somewhere , um , and focus on that object down oh , i can actually walk with this . this is nice . down here . that 's the powder - tower . now , um , we found in our , uh , data and from experiments , that there 's three things you can do . um , you can walk this way , and come really , really close to it . and touch it . but you can not enter or do anything else . unless you 're interested in rock climbing , it wo n't do you no good standing there . it 's just a dark alley . but you can touch it . if you want to actually go up or into the tower , you have to go this way , and then through some buildings and up some stairs and so forth . if you actually want to see the tower , and that 's what actually most people want to do , is just have a good look of it , take a picture for the family , { comment } you have to go this way , and go up here . and there you have a vre really view it exploded , the during the thirty years - war . really uh , interesting sight . and um , these uh these lines are , um , paths , grad e: mmm . grad b: or so that 's ab er , i the street network of our geographic information system . and you can tell that we deliberately cut out this part . because otherwise we could n't get our gis system to take to lead people this way . it would always use the closest point to the object , and then the tourists would be faced , you know , in front of a wall , but it would do them absolutely no good . so , what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , take a picture of it . or maybe you actually want to come as close as possible to the building . for whatever reason that may be . grad e: what 's it what 's it made out of ? grad b: um , r red limestone . grad e: so maybe you would wan na touch it . grad b: yeah , maybe you would want to touch it . um . okay , i this , um these intentions , we w w we could , if we want to , call it the the vista mode , where we just want to eh s get the overview or look at it , the enter mode , and the , well , tango mode . i always come up with with silly names . so this `` tango `` means , literally translated , `` to touch `` . so but sometimes the the tango mode is really relevant in the in the sense that , um , if you want to , uh if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building . consider , for example , the post office in chicago , a building so large that it has its own zip code . so the entrance could be miles away from the closest point . so sometimes it m m m makes sense maybe to d to distinguish there . so , um , i 've looked , uh , through twenty some uh , i did n't look through all the data . um , and there there 's uh , a lot more different ways in people uh , the ways people phrase how to g get if they want to get to a certain place . and sometimes here it 's b it 's a little bit more obvious um . maybe i should go back a couple of steps and go through the professor c: no , ok come in , sit down . if you grab yourself a microphone . grad b: you need to sign some stuff and read some digits . professor c: well , you can sign afterwards . grad b: o or later . grad e: you have to al also have to read some digits . professor c: afterwards . grad d: ok . { comment } ok . afterwards is fine . grad b: they are uncomfortable . mm - hmm . grad d: really small ? ok . i see . ok . grad b: yep . grad d: thank you . grad b: ok , but that was our idea . professor c: and it it it it it also has to be switched on , nance . grad b: is i i think grad e: no , that one 's already on , i thought he said . professor c: it 's on ? ok , good . grad d: ok . it 's on . grad e: yeah . grad b: ok . that was the idea . um , people , when they w when they want to go to a building , sometimes they just want to look at it . sometimes they want to enter it . and sometimes they want to get really close to it . that 's something we found . it 's just a truism . and the places where you will lead them for these intentions are sometimes ex in incredibly different . i i gave an example where the point where you end up if you want to look at it is completely different from where if you want to enter it . so , this is sort of how people may , uh may phrase those requests to a a a mock - up system at least that 's the way they did it . and we get tons of of these `` how do i get to `` , `` i want to go to `` , but also , `` give me directions to `` , and `` i would like to see `` . and um , what we can sort of do , if we look closer a closer at the the data that was the wrong one . um , we can look at some factors that may make a difference . first of all , very important , and um , that i 've completely forgot that when we talked . this is of course a crucial factor , `` what type of object is it ? `` so , some buildings you just do n't want to take pictures of . or very rarely . but you usually want to enter them . some objects are more picturesque , and you more f more highly photographed . then of course the the actual phrases may give us some idea of what the person wants . um . sometimes i found in the uh , looking at the data , in a superficial way , i found some s sort of modifiers that that m may also give us a hint , um , `` i 'm trying to get to `` nuh ? `` i need to get to `` . sort of hints to the fact that you 're not really sightseeing and and just f there for pleasure and so forth and so on . and this leads us straight to the context which also should be considered . that whatever it is you 're doing at the moment may also inter influence the interpretation of of a phrase . so , this is , uh , really uh , uh , uh my suggestion is really simple . we start with , um now , let me , uh , say one more thing . what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so , basically all of these things will result in the same xml m - three - l structure . sort of action `` go `` , and then an object . grad d: mm - hmm . grad b: yeah ? and a source . so it 's it 's it 's way too crude to d capture those differences in intentions . so , i thought , `` mmm ! maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` where we can start it and n sort of look `` ok , we need , we gon na get those m - three - l structures . the crude , undifferentiated parse . interpreted input . we may need additional part of speech , or maybe just some information on the verb , and modifiers , auxiliaries . we 'll see . and i will try to to sort of come up with a list of factors that we need to get out of there , and maybe we want to get a g switch for the context . so this is not something which we can actually monitor , now , but just is something we can set . and then you can all imagine sort of a a constrained satisfaction program , depending on on what , um , comes out . we want to have an a structure resulting if we feed it through a belief - net or or something along those lines . we 'd get an inferred intention , we we produce a structure that differentiates between the vista , the enter , and the , um , tango mode . which i think we maybe want to ignore . but . that 's my idea . it 's up for discussion . we can change all of it , any bit of it . throw it all away . grad f: now @ @ this email that you sent , actually . professor c: what ? grad f: now i remember the email . professor c: ok . grad e: huh . still , i have no recollection whatsoever of the email . i 'll have to go back and check . professor c: not important . so , what is important is that we understand what the proposed task is . and , the the i uh , robert and i talked about this some on friday . and we think it 's well - formed . so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain . grad f: so , where exactly is the , uh , deeper understanding being done ? like i mean , s is it before the bayes - net ? is it , uh professor c: well , it 's the it 's it 's always all of it . so , in general it 's always going to be , the answer is , everywhere . uh , so the notion is that , uh , this is n't real deep . but it 's deep enough that you can distinguish between these th three quite different kinds of , uh , going to see some tourist thing . and , so that 's that 's the quote `` deep `` that we 're trying to get at . and , robert 's point is that the current front - end does n't give you any way to not only does n't it do it , but it also does n't give you enough information to do it . it is n't like , if you just took what the front - end gives you , and used some clever inference algorithm on it , you would be able to figure out which of these is going on . so , uh , and this is bu - i in general it 's gon na be true of any kind of deep understanding , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , and they got ta be combined . and , my idea on how to combine them is with a belief - net , although it may turn out that t some totally different thing is gon na work better . um , the idea would be that you , uh , take your you 're editing your slide ? grad b: yeah . as i a sort of , as i get ideas , uh w uh . professor c: oh . grad b: so , discourse i i i thought about that . of course that needs to sort of go in there . professor c: oh . i 'm sorry . ok . so . this is minutes taking minutes as we go , in his in his own way . grad b: yep . professor c: um , but the p the anyway . so the thing is , i uh , d naively speaking , you 've you 've got a for this little task , a belief - net , which is going to have as output , the conditional pr probability of one of three things , that the person wants to uh , to view it , to enter it , or to tango with it . um . so that the the output of the belief - net is pretty well formed . and , then the inputs are going to be these kinds of things . and , then the question is there are two questions is , uh , one , where do you get this i { comment } information from , and two , what 's the structure of the belief - net ? so what are the conditional probabilities of this , that , and the other , given these things ? and you probably need intermediate nodes . i we do n't know what they are yet . so it may well be that , uh , for example , that , uh , knowing whether oh , another thing you want is some information abou i think , about the time of day . now , they may wan na call that part of context . grad b: mm - hmm . professor c: but the time of day matters a lot . and , if things are obviously closed , then , you grad b: people wo n't want to enter it . professor c: pe - people do n't wan na enter them . and , if it 's not obvious , you may want to actually uh , point out to people that it 's closed you know , what they 're g going to is closed and they do n't have the option of entering it . grad b: s b professor c: so another thing that can come up , and will come up as soon as you get serious about this is , that another option of course is to have a more of a dialogue . so if someone says something you could ask them . grad e: yeah . professor c: ok . and now , one thing you could do is always ask them , but that 's boring . and it also w it also be a pain for the person using it . so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . ask them which one you want . `` ok . but that 's , um , not what we 're gon na do . grad b: but maybe that 's a false state of the system , that it 's too close to call . professor c: oh yeah . you want the you want the ability to a you want the ability to ask , but what you do n't wan na do is onl build a system that always asks every time , and i that 's not getting at the scientific problem , grad b: mm - hmm . professor c: and it 's in general you 're you know , it 's gon na be much more complex than that . a this is purposely a really simple case . grad b: yeah . professor c: so , uh yeah . grad b: i have one more point to to bhaskara 's question . um , i think also the the the deep understanding part of it is is going to be in there to the extent that we um , want it in terms of our modeling . we can start , you know , basic from human beings , model that , its motions , going , walking , seeing , we can mem model all of that and then compose whatever inferences o we make out of these really conceptual primitives . that will be extremely deep in the in in in my understanding . professor c: yeah . s so so the way that might come up , if you wan na suppose you wanted to do that , you might say , `` um , as an intermediate step in your belief - net , is there a source - path - goal schema involved ? `` ok ? and if so , uh , is there a focus on the goal ? or is there a focus on the path ? or something . and that could be , uh , one of the conditiona you know , th the in some piece of the belief - net , that could be the the appropriate thing to enter . grad f: so , where would we extract that information from ? from the m - three - l ? professor c: no . no . see , the m - three - l is not gon na give th what he was saying is , the m - three - l does not have any of that . all it has is some really crude stuff saying , `` a person wants to go to a place . `` grad f: right . grad e: the m - three - l is the old smartkom output ? professor c: right . m - three well , m - three - l itself refers to multimedia mark - up language . grad e: ok . it 's just a language . right , yeah . professor c: so we have th w we we we have to have a better w way of referring to grad b: the parser output ? professor c: mm - hmm . grad b: `` analyzed speech `` i think it 's what they call it , professor c: yeah . the well , ok . grad b: really , oder professor c: yeah . grad b: o th no , actually , intention lattices is what we 're gon na get . professor c: is - i but they c they call it intention lattice , but tha grad b: in - in a intention lattice k hypothesis . professor c: anyway . grad b: they call it intention hypotheses . professor c: right . so , th they 're gon na give us some cr uh or we can assume that y you get this crude information . about intention , and that 's all they 're going to provide . and they do n't give you the kind of object , they do n't give you any discourse history , if you want to keep that you have to keep it somewhere else . grad b: well , they keep it . we have to request it . professor c: right . grad b: nuh ? but it 's not in there . professor c: well , they they kee they keep it by their lights . grad b: hmm . professor c: it may it may or may not be what what we want . grad b: yeah , or i professor c: yeah . grad e: so , if someone says , `` i wan na touch the side of the powder - tower `` , that would basically , we need to pop up tango mode and the and the directions ? professor c: if i if yeah , if it got as simple as that , yeah . grad e: yeah . professor c: but it would n't . grad e: ok . but that does n't necessarily but we 'd have to infer a source - path - goal to some degree for touching the side , right ? grad b: well uh , th the there is a p a point there if i understand you . correct ? um , because um , sometimes people just say things this you find very often . `` where is the city hall ? `` and this do they do n't wan na sh see it on a map , or they do n't wan na know it 's five hundred yards away from you , or that it 's to the your north . they wan na go there . that 's what they say , is , `` where is it ? `` . where is that damn thing ? grad e: and the parser would output grad b: well , that 's a a question mark . sh a lot of parsers , um , just , uh that 's way beyond their scope , is of interpreting that . you know ? but um , still outcome w the outcome will be some form of structure , with the town hall and maybe saying it 's a wh focus on the town hall . but to interpret it , grad d: mm - hmm . grad b: you know ? somebody else has to do that job later . professor c: yeah . grad e: i 'm just trying to figure out what the smartkom system would output , depending on these things . grad b: um , it will probably tell you how far away it is , at least that 's that 's even what deep map does . it tells you how far away it is , and and shows it to you on a map . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know where where it is . grad d: people no might not be able to infer that either , right ? like the fact like , i could imagine if someone came up to me and asked , `` where 's the city hall ? `` , i might say , g ar `` are you trying to get there ? `` because how i describe um , t its location uh , p probably depend on whether i think i should give them , you know , directions now , or say , you know , whatever , `` it 's half a mile away `` or something like that . grad b: mm - hmm . it 's a granularity factor , professor c: yeah . grad b: because where people ask you , `` where is new york ? `` , you will tell them it 's on the east coast . grad d: uh - huh . yeah . exactly . right . right . grad b: y y eh you wo n't tell them how to get there , ft you know , take that bus to the airport and blah - blah - blah . grad d: yeah . grad b: but if it 's the post office , you will tell them how to get there . grad d: right . mm - hmm . grad b: so th they have done some interesting experiments on that in hamburg as well . grad d: right . grad b: so . grad d: right . professor c: but i go go back to the the uh , th grad b: so i w this is `` onto `` is is knowledge about buildings , professor c: yeah , that slide . grad b: their opening times , and then t coupled with time of day , um , this should you know . grad d: so that context was like , um , their presumed purpose context , i like business or travel , as well as the utterance context , like , `` i 'm now standing at this place at this time `` . professor c: yeah , well i think we ought to d a as we have all along , d we we 've been distu distinguishing between situational context , which is what you have as context , and discourse context , grad b: mm - hmm . professor c: which you have as dh , grad b: nuh . professor c: i do n't know what the h means . grad b: history . discourse history . yeah . professor c: ok . whatever . so we can work out terminology later . grad b: yep . professor c: so , they 're they 're quite distinct . i mean , you need them both , but they 're quite distinct . and , so what we were talking about doing , a a as a first shot , is not doing any of the linguistics . except to find out what seems to be useful . so , the the the reason the belief - net is in blue , is the notion would be uh , this may be a bad dis bad idea , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , given these we have all these transcripts and we 're able to , by hand , extract the features to put in the belief - net . saying , `` aha ! here 're the things which , if you get them out of out of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` and if to actually do that , build it , um you know , run it y y run it on the data where you hand - transcribe the parameters . and see how that goes . if that goes well , then we can start worrying about how we would extract them . so where would you get this information ? and , expand it to to other things like this . but if we ca n't do that , then we 're in trouble . i mean th th i i if you ca n't do this task , um grad b: we need a different , uh , engine . machine , i mean . professor c: uh , uh , yeah , or something . well it i i if it if it 's the belief - nets , we we 'll switch to you know , logic or some terrible thing , but i do n't think that 's gon na be the case . i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . the real issue is , do what are the factors involved in determining this ? and i do n't know . grad b: hmm . but , only w professor c: hold on a s hold on a second . grad b: muh . professor c: so , i know . uh , uh , is it clear what 's going on here ? grad f: yep . grad d: um , i missed the beginning , but , um i guess could you back to the slide , the previous one ? so , is it that it 's , um these are all factors that uh , a these are the ones that you said that we are going to ignore now ? or that we want to take into account ? you were saying n professor c: take them into account . but but you do n't worry about h grad d: take the the linguistic factors too . oh , how to extract these features . professor c: how to extract them . so , f let 's find out which ones we need first , grad d: ok . got it . professor c: and grad d: ok . and and it 's clear from the data , um , like , sorta the correct answer in each case . professor c: no . grad d: but l grad b: no . but grad d: ok . professor c: let 's go back to th let 's go back to the the the slide of data . grad d: that 's that 's the thing i 'm curious ab grad b: um grad d: like do we know from the data wh which ok . so grad b: not from that data . but , um , since we are designing a a a an , compared to this , even bigger data collection effort , { comment } um , we will definitely take care to put it in there , grad d: mm - hmm . mm - hmm . grad b: in some shape , way , form over the other , grad d: mm - hmm . professor c: yeah . grad b: to see whether we can , then , get sort of empirically validated data . grad d: right . grad b: um , from this , we can sometimes , you know an and that 's that but that is n't that what we need for a belief - net anyhow ? is sort of s sometimes when people want to just see it , they phrase it more like this ? but it does n't exclude anybody from phrasing it totally differently , even if they still grad d: mm - hmm . right . grad b: you know ? grad d: right . grad b: but then other factors may come into play that change the outcome of their belief - net . so , um , this is exactly what grad d: right . grad b: because y you can never be sure . and i 'm sure even i the most , sort of , deliberate data collection experiment will never give you data that say , `` well , if it 's phrased like that , the intention is this . `` grad d: sure . grad b: you know , because then , uh , you grad d: u u i mean , the only way you could get that is if you were to give th the x subjects a task . right ? where you have where your , uh , current goal is to grad b: we yeah ! that 's what we 're doing . grad d:  grad b: but but we will still get the phrasing all over the place . grad d: so that 's what you want ? ok . so you will know . grad b: i 'm sure that , you know professor c: yeah . grad d: mm - hmm . the no , that 's fine . i guess , it 's just knowing the intention from the experimental subject . professor c: yeah . grad b: mm - hmm . professor c: from that task , yeah . so , uh , i think you all know this , but we are going to actually use this little room grad d:  professor c: and start recording subjects probably within a month or something . so , this is not any lo any of you guys ' worry , except that we may want to push that effort to get information we need . so our job is to figure out how to solve these problems . if it turns out that we need data of a certain sort , then the sort of data collection branch can be , uh , asked to do that . and one of the reasons why we 're recording the meeting for these guys is cuz we want their help when we d we start doing uh , recording of subjects . so , yeah y you 're absolutely right , though . no , you you will not have , and there it is , and , uh but you know , y y the , um grad d: and i think the other concern that has come up before , too , is if it 's um i do n't know if this was collected what situation this data was collected in . was it is it the one that you showed in your talk ? like people grad b: no , no . no . grad d: but ok . so was this , like , someone actually mobile , like s using a device ? grad b: uh , n no , no not i it was mobile but not not with a w a real wizard system . so there were never answers . grad d: uh - huh . ok . ok . but , is it i guess i do n't know the situation of of collecting th the data of , like here you could imagine them being walking around the city . as like one situation . and then you have all sorts of other c situational context factors that would influence w how to interpret , like you said , the scope and things like that . grad b: mm - hmm . grad d: if they 're doing it in a you know , `` i 'm sitting here with a map and asking questions `` , i i would imagine that the data would be really different . um , so it 's just grad b: yeah . but it was never th th the goal of that data collection to to serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , grad d: mm - hmm . grad b: there was n there was no label , grad d: mm - hmm . grad b: you know , intention a , intention b , intention c . grad d: right . grad b: or task a , b , c . um i 'm sure we can produce some if we need it , um , that that will help us along those lines . grad d: mm - hmm . grad b: but , you know , you got ta leave something for other people to model . so , to finding out what , you know , situational con what the contextual factors of the situation really are , you know is an interesting s interesting thing . grad d: mm - hmm . mm - hmm . grad b: u u sort of i 'm , at the moment , curious and i 'm i 'm s w want to approach it from the end where we can s sort of start with this toy system that we can play around with , grad d: mm - hmm . grad b: so that we get a clearer notion of what input we need for that , grad d: mm - hmm . grad b: what suffices and what does n't . and then we can start worrying about where to get this input , what what do we need , you know ultimately once we are all experts in changing that parser , for example , maybe , there 's just a couple three things we need to do and then we get more whatever , part of speech and more construction - type - like stuff out of it . grad d: mm - hmm . hmm . grad b: it 's a m pragmatic approach , uh , at the moment . grad e: how exactly does the data collection work ? do they have a map , and then you give them a scenario of some sort ? grad b: ok . imagine you 're the the subject . you 're gon na be in here , and somebody and and you see , uh , either th the three - d model , or uh , a quicktime animation of standing u in a square in heidelberg . so you actually see that . um . the uh , um , first thing is you have to read a text about heidelberg . so , just off a textbook , uh , tourist guide , to familiarize , uh , yourself with that sort of odd - sounding german street names , like fischergasse and so forth . so that 's part one . part two is , you 're told that this huge new , wonderful computer system exists , that can y tell you everything you want to know , and it understands you completely . and so you 're gon na pick up that phone , dial a number , and you get a certain amount of tasks that you have to solve . first you have to know find out how to get to that place , maybe with the intention of buying stamps in there . maybe so , the next task is to get to a certain place and take a picture for your grandchild . the third one is to get information on the history of an object . the fourth one and then the g system breaks down . it crashes , and grad d: a at the third ? right then ? grad b: after the third task . grad d: ok . grad b: and then or after the fourth . some find @ @ { comment } forget that for now . and then , a human operator comes on , and and exp apologizes that the system has crashed , but , you know , urges you to continue , you know ? now with a human operator . and so , you have basically the same tasks again , just with different objects , and you go through it again , and that was it . oh , and one one little bit w and uh , the computer you are you are being told the computer system knows exactly where you are , via gps . when the human operator comes on , um , that person does not know . so the gps is crashed as well . so the person first has to ask you `` where are you ? `` . and so you have to do some s tell the person sort of where you are , depending on what you see there . um , this is a a a a a bit that i d i do n't think we did we discuss that bit ? uh , i just sort of squeezed that in now . but it 's something , uh , that would provide some very interesting data for some people i know . so . grad d: so , in the display you can oh , you said that you cou you might have a display that shows , like , the grad b: yeah . a additionally , y you have a a a sort of a map type display . grad d: a w your perspective ? sort of ? grad b: uh , two - d . grad d: and so , as you grad b: n grad d: oh , two - d . ok . grad b: two - d . grad d: so as you move through it that 's - they just track it on the for themselves grad b: yeah . b y you do n't that 's grad d: there . grad b: i do n't know . i but y i do n't think you really move , sort of . grad d: ok . so grad b: yeah ? i mean that would be an an an enormous technical effort , unless we would we can show it walks to , you know . we can have movies of walking , you walking through through heidelberg , and u ultimately arriving there . grad d: mm - hmm . grad b: maybe we wan na do that . yeah . grad d: uh , i was just trying to figure out how how ambitious the system is . grad b: the map was sort of intended to you want to go to that place . you know , and it 's sort of there . grad d: mm - hmm . grad b: and you see the label of the name so we get those names , pronunciation stuff , and so forth , and we can change that . grad d: mm - hmm . mm - hmm . so your tasks do n't require you to i mean , uh yo you 're told so when your task is , i do n't know , `` go buy stamps `` or something like that ? so , do you have to respond ? or does your uh , what are you ste what are you supposed to be telling the system ? like , w what you 're doing now ? or grad b: well , we 'll see what people do . grad d: there 's no ok , so it 's just like , `` let 's figure out what they would say under the circumstances `` . grad b: yeah , and and we will record both sides . i mean , we will record the wi - the wizard grad d: uh - huh . grad b: i mean , in both cases it 's gon na be a human , in the computer , and in the operator case . grad d: uh - huh . grad b: and we will re there will be some dialogue , you know ? so , you first have to do this , and that , grad d: yep . grad b: and and grad d: mm - hmm . grad b: see wh what they say . we can ins instruct the , uh , wizard in how expressive and talkative he should be . but um , maybe the maybe what you 're suggesting is what you 're suggesting that it might be too poor , the data , if we sort of limit it to this ping pong one t uh , task results in a question and then there 's an answer and that 's the end of the task ? you wan na m have it more more steps , sort of ? grad d: yeah , i i do n't know how much direction is given to the subject about what their interaction i mean , th they 're unfamiliar w with interacting with the system . grad b: mm - hmm . grad d: all they know is it 's this great system that could do s stuff . grad b: mm - hmm . professor c: oh yeah , but to some extent this is a different discussion . grad d: right ? so professor c: ok ? so . uh , we we have to have this discussion of th the experiment , and the data collection , and all that sorta stuff grad d: uh - huh . professor c: and we do have , um , a student who is a candidate for wizard . uh , she 's gon na get in touch with me . it 's a student of eve 's . fey , fey ? spelled fey . do you do you grad d: oh , fey parrill . professor c: you know her ? grad d: yeah . uh - huh . professor c: ok . sh - is sh grad d: she started taking the class last year and then did n't um , you know , did n't continue . i g she 's a g professor c: she 's graduated . grad d: is she an undergradua she is a graduate , ok . professor c: yeah . grad d: yeah , i m i know her very , very briefly . i know she was inter you know , interested in aspect and stuff like that . professor c: ok . so , anyway , she 's looking for some more part time work w while she 's waiting actually for graduate school . and she 'll be in touch . so we may have someone , uh , to do this , and she 's got you know , some background in in all this stuff . and is a linguist st and , so so . that 's so , nancy , we 'll have an at some point we 'll have another discussion on exactly wha t t you know , how that 's gon na go . grad d: mm - hmm . professor c: and um , jane , but also , uh , liz have offered to help us do this , uh , data collection and design and stuff . grad d: mm - hmm . mmm . professor c: so , when we get to that we 'll have some people doing it that know what they 're doing . grad d: ok . i guess the reason i was asking about the sort of the de the details of this kind of thing is that , um , it 's one thing to collect data for , i do n't know , speech recognition or various other tasks that have pretty c clear correct answers , but with intention um , obviously , as you point out , there 's a lot of di other factors and i 'm not really sure , um , how how e the question of how to make it a t appropriate toy version of that um , it 's ju it 's just hard . so , i mean , obviously it 's a grad e: yeah , uh , actually i guess that was my question . is the intention implicit in the scenario that 's given ? like , do the grad d: it is , if they have these tasks that they 're supposed to grad e: yeah , i just was n't sure to what level of detail the task was . grad d: to to give yeah , grad b: mm - hmm . grad d: uh grad b: n no one is , at the moment . grad d: right . right . grad e: ok . professor c: so , we that 's part of what we 'll have to figure out . grad d: right . professor c: but , uh , grad d: mm - hmm . professor c: the the problem that i was tr gon na try to focus on today was , let 's suppose by magic you could collect dialogues in which , one way or the other , you were able to , uh , figure out both the intention , and set the context , and know what language was used . so let 's suppose that we can get that kind of data . um . the issue is , can we find a way to , basically , featurize it so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely . grad d: w what are the t three intentions ? is it to go there , to see it , and grad b: to come as close as possible to it . professor c: th - the terminology we 're using is to grad d: yeah , it 's @ @ . professor c: go back . to v grad d: ok . professor c: to view it . ok ? to enter it . now those it seems to me those are cl you c you have no trouble with those being distinct . `` take a picture of it `` you you might well want to be a really rather different place than entering it . grad d: mm - hmm . mm - hmm . professor c: and , for an object that 's at all big , uh , sort of getting to the nearest part of it uh , could be quite different than either of those . grad d: mm - hmm . mm - hmm . mm - hmm . professor c: just sort of grad d: ok , so now i understand the referent of tango mode . i did n't get that before . grad e: see , i would have thought it was more of a waltz . grad b: s to `` waltz `` it ? grad d: yeah , like , how close are you gon na be ? professor c: well . grad d: like , tango 's really close . grad e: yeah , cuz a tango yeah . professor c: well , anyway . so grad f: all these so , like , the question is how what features can like , do you wan na try to extract from , say , the parse or whatever ? professor c: right . grad f: like , the presence of a word or the presence of a certain uh , stem , or certain construction or whatever . professor c: right . is there a construction , or the kind of object , or w uh , anything else that 's in the si it 's either in the in the s the discourse itself or in the context . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature . now , how you determine that is another issue . but fo for the current problem , it would just be , `` ok , if you can be sure that it 's a tourist , versus a businessman , versus a native , `` or something , uh , that would give you a lot of discriminatory power and then just have a little section in your belief - net that said , `` pppt ! `` though sin f in the short run , you 'd set them , grad f: mm - hmm . professor c: and see ho how it worked , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . grad f: right . so , how should what 's the uh , plan ? like , how should we go about figuring out these professor c: ok . so , first of all is , uh , do e either of you guys , you got a favorite belief - net that you 've , you know , played with ? javabayes or something ? grad f: oh . no , not really . professor c: ok . well , anyway . f get one . ok ? so y so one of th one of the things we wan na do is actually , uh , pick a package , does n't matter which one , uh , presumably one that 's got good interactive abilities , cuz a lot of what we 're gon na be d you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . d w these are not gon na get big in in the foreseeable future . but we do want one in which it 's easy to interact with and , uh , modify . because i that 's a lot of what it 's gon na be , is , um , playing with this . and probably one in which it 's easy to have , um , what amounts to transcript files . so that if if we have all these cases ok ? so we make up cases that have these features , ok , and then you 'd like to be able to say , `` ok , here 's a bunch of cases `` there 're even ones tha that you can do learning ok ? so you have all their cases and and their results and you have a algorithms to go through and run around trying to set the the probabilities for you . um , probably that 's not worth it . i mean , my guess is we are n't gon na have enough data that 's good enough to make the these data fitting ones worth it , but i do n't know . so i would say you guy the first task for you two guys is to um , pick a package . ok , and you wan na it s you know , the standard things you want it stable , you want it yeah , @ @ . and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on . grad b: an - nuh . professor c: but it what i like about it is it 's very concrete . ok ? we we have a we know what the outcomes are gon na be , and we have some some data that 's loose , we can use our own intuition , and see how hard it is , and , importantly , what intermediate nodes we think we need . so it if it turns out that just , thinking about the problem , you come up with things you really need to you know , this is the kind of thing that is , you know , an intermediate little piece in your belief - net . that 'd be really interesting . grad e: mm - hmm . grad b: and it and it may serve as a platform for a person , maybe me , or whoever , who is interested in doing some linguistic analysis . i mean , w we have the for - framenet group here , and we can see what they have found out about those concepts already , that are contained in the data , um , you know , to come up with a nice little set of features and um , maybe even means of s uh , extracting them . and and that altogether could also be uh , become a nice paper that 's going to be published somewhere , if we sit down and write it . and um when you said javabayes belief - net you were talking about ones that run on coffee ? or that are in the program language java ? professor c: no , th it turns out that there is a , uh the new end of java libraries . ok , and it turns out one called grad b: mmm . ok . professor c: which is one that fair people around here use a fair amount . i have no idea whether that 's the obvious advantage of that is that you can then , relatively easily , get all the other java packages for guis or whatever else you might want to do . grad b: mm - hmm . professor c: so that i that 's i think why a lot of people doing research use that . but it may not be i have no idea whether that 's the best choice an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets . so , uh , grad d: there 's the m tool kit that um , kevin murphy has developed , professor c: right . it 's ok . grad d: which might be useful too . grad f: right . professor c: so , yeah , kevin would be a good person to start with . grad d: and it 's available matlab code . professor c: nancy knows him well . i do n't know i do n't know whether you guys have met kevin yet or not , grad b: mm - hmm . professor c: but , uh grad f: yeah , i know him . grad b: but i but since we all probably are pretty sure that , um , the professor c: yeah . grad b: for example , this th th the dialogue history is is um , producing xml documents . m - three - l of course is xml . and the ontology that um , uh the student is is constructing for me back in in eml is in oil and that 's also in xml . and so that 's where a lot of knowledge about bakeries , about hotels , about castles and stuff is gon na come from . professor c: mm - hmm . yeah . grad b: um , so , if it has that io capability and if it 's a java package , it will definitely be able we can couple . professor c: yeah . so , yeah , we 're sort of committed to xml as the kind of , uh , interchange . but that 's , you know , not a big deal . grad b: who is n't , nuh ? professor c: so , in terms of of interchanging in and out of any module we build , it 'll be xml . and if you 're going off to queries to the ontology , for example , you 'll have to deal with its interface . but that 's that 's fine an and um , all of these things have been built with much bigger projects than this in mind . so they they have worked very hard . it 's kind of blackboards and multi - wave blackboards and ways of interchanging and registering your a and so forth . so , that i do n't think is even worth us worrying about just yet . i mean if we can get the core of the thing to work , in a way that we 're comfortable with , then we ca we can get in and out of it with , uh , xml , um , little descriptors . i believe . grad b: hmm . yeah . yeah , i like , for example , the what you said about the getting input from from just files about where you h where you have the data , have specified the features and so forth . professor c: i do n't i do n't see grad b: that 's , of course , easy also to do with , you know , xml . professor c: uh , you could have an x yeah , you could make and xml format for that . sure . grad b: so r professor c: that that um , you know , feature value xml format is probably as good a way as any . so it 's als yeah , i guess it 's also worth , um , while you 're poking around , poke around for xml packages that um , do things you 'd like . grad f: does n't does smartkom system have such packages ? grad b: yeah . professor c: sure . grad b: the the lib m - three - l library does that . it 's also professor c: and the question is , d you c you you 'll have to l we 'll have to l that should be ay we should be able to look at that grad b: no , u u y um the what i what sort of came to my mind i is was the notion of an idea that if if there are l nets that can actually lear try to set their own , um , probability factors based on on on on input professor c: yeah . grad b: which is in file format , if we , um , get really w wild on this , we may actually want to use some some corpora that other people made and , for example , if if they are in in mate , then we get x m l documents with discourse annotations , t you know , t from the discourse act down to the phonetic level . grad f: mm - hmm . grad b: um , michael has a project where you know , recognizing discourse acts and he does it all in mate , and so they 're actually annotating data and data and data . so if we w if we think it 's worth it one of these days , not not with this first prototype but maybe with a second , and we have the possibility of of taking input that 's generated elsewhere and learn from that , that 'd be nice . grad f: right . professor c: it 'd be nice , but but i i i do i do n't wan na count on it . i mean , you ca n't you ca n't run your project based on the speculation that that the data will come , grad b: no , no , uh , just for professor c: and you do n't have to actually design the nets . grad b: nuh . just a back door that i i think we should devote m professor c: could happen . yeah . so in terms of of the , um the what the smartkom gives us for m - three - l packages , it could be that they 're fine , or it could be eeh . you do n't you know , you do n't really like it . so we 're not we 're not abs we 're not required to use their packages . we are required at the end to give them stuff in their format , but hey . grad f: right . professor c: um , it 's , uh it does n't control what you do in you know , internally . grad b:  grad e: what 's the time frame for this ? grad b: two days ? two , three days ? professor c: huh ? yeah bu w i 'd like that this y yeah , this week , to ha to n to have y guys , uh , you know , pick the y you know , belief - net package grad b: no . professor c: and tell us what it is , and give us a pointer so we can play with it or something . grad f: sure . professor c: and , then as soon as we have it , i think we should start trying to populate it for this problem . make a first cut at , you know , what 's going on , and probably the ea easiest way to do that is some on - line way . i mean , you can f figure out whether you wan na make it a web site or you know , how grad b: uh i i i um , ok , i t yeah . i was actually more joking . with the two or three days . so this was was a usual jo professor c: ok , i was n't . grad b: um , it will take as long as y y yo you guys need for that . professor c: yeah . right . grad b: but um , maybe it might be interesting if if the two of you can agree on who 's gon na be the speaker next monday , to tell us something about the net you picked , and what it does , and how it does that . professor c: well , y well , or both of them speak . grad f: sure . grad b: yeah , or you can split it up . professor c: we do n't care . grad b: so , y grad f: hmm . grad b: so that will be sort of the assignment for next week , is to to for slides and whatever net you picked and what it can do and and how far you 've gotten . pppt ! professor c: well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . even if it 's really crude . ok ? so , you know , here a here are grad e: so we 're supposed to @ @ about features and whatnot , professor c: right . yeah . grad e: and grad f: mm - hmm . professor c: and , as i said , what i 'd like to do is , i mean , what would be really great is you bring it in if if if we could , uh , in the meeting , say , you know , `` here 's the package , here 's the current one we have , `` uh , you know , `` what other ideas do you have ? `` and then we can think about this idea of making up the data file . of , uh , you know , get a t a p tentative format for it , let 's say xml , that says , l you know , `` these are the various scenarios we 've experienced . `` we can just add to that and there 'll be this this file of them and when you think you 've got a better belief - net , you just run it against this , um this data file . grad f: so we 'll be like , hand , uh , doing all the probabilities . professor c: oh , yeah , unt until we know more . grad f: ok . grad e: and what 's the relation to this with changing the table so that the system works in english ? grad b: ok . so this is whi - while you were doing this , i received two lovely emails . the the full nt and the full linux version are there . i 've downloaded them both , and i started to unpack the linux one uh , the nt one worked fine . and i started unta pack the linux one , it told me that i ca n't really unpack it because it contains a future date . so this is the time difference between germany . i had to wait until one o ' clock this afternoon before i was able to unpack it . now , um then it will be my job to get this whole thing running both on swede and on this machine . and so that we have it . and then um hopefully that hoping that my urgent message will now come through to ralph and tilman that it will send some more documentation along , we i control p maybe that 's what i will do next monday is show the state and show the system and show that . professor c: yeah . yeah . so the answer , johno , is that these are , at the moment , separate . uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net . grad e: i guess my question was more about time frame . so we 're gon na do belief - nets this week , and then professor c: oh , yeah . i do n't know . n none of this is i n neither of these projects has got a real tight time - line , in the sense that over the next month there 's a there 's a deliverable . grad e: ok . professor c: ok . s so uh , it 's opportu in that sense it 's opportunistic . if if you know , if we do n't get any information for these guys f for several weeks then we are n't gon na sit around , you know , wasting time , trying to do the problem or guess what they you know , just pppt ! go on and do other things . grad e: ok . grad b: yeah , but uh but the uh this point is really i think very , very valid that ultimately we hope that that both will merge into a harmonious and , um , wonderful , um , state where we can not only do the bare necessities , ie , changing the table so it does exactly in english what it does in german , but also that we can sort of have the system where we can say , `` ok , this is what it usually does , and now we add this little thing to it `` , you know ? whatever , johno 's and bhaskara 's great belief - net , and we plug it in , and then for these certain tasks , and we know that navigational tasks are gon na be a core domain of the new system , it all all of a sudden it does much better . nuh ? because it can produce better answers , tell the person , as i s showed you on this map , n you know , produce either you know , a red line that goes to the vista point or a red line that goes to the tango point or red line that goes to the door , which would be great . so not only can you show that you know something sensible but ultimately , if you produce a system like this , it takes the person where it wants to go . rather than taking him always to the geometric center of a building , grad f: mmm . grad b: which is what they do now . and we even had to take out a bit . nancy , you missed that part . we had to take out a bit of the road work . so that it does n't take you to the wall every time . grad d: oh , really ? grad b: so . um so this was actually an actual problem that we encountered , which nobody have has because car navigation systems do n't really care . you know , they get you to the beginning of the street , some now do the house number . grad d: hmm . grad b: but even that is problematic . grad d: mm - hmm . grad b: if you go d if you wan na drive to the sap in waldorf , i 'm sure the same is true of microsoft , it takes you to the the address , whatever , street number blah - blah - blah , you are miles away from the entrance . professor c: yep . grad b: because the s postal address is maybe a mailbox somewhere . nuh ? grad d: mm - hmm . grad b: but the entrance where you actually wan na go is somewhere completely different . so unless you 're a mail person you really do n't wan na go there . grad d: right , yeah . professor c: probably not then , cuz y you probably ca n't drop the mail there anyway . grad b: probably neither e not even that . professor c: yeah . clear ? grad f: ok . sounds good . grad e: the powder - tower is made of red limestone . grad d: i was wondering . grad b: do you wan na see a picture ? grad d: ok . sure ! grad e: sure ! grad b: have to reboot for that though . grad d: um . so , you two , who 'll be working on this , li are are you gl will you be doing well , i mean are you supposed to just do it by thinking about the situation ? can you use the sample data ? professor c: of course they use the sample data . grad d: is it like yeah , i mean , ho is there more than is there a lot s of sample data that is beyond what you what you have there ? grad b: there there 's more than i showed , but um , um , i think this is sort of um , in part my job to look at that and and to see whether there are features in there that can be extracted , grad d: yeah . grad b: and to come up with some features that are not you know , empirically based on on a real experiment or on on on reality grad d: right . mm - hmm . grad b: but sort of on your intuition of you know , `` aha ! this is maybe a sign for that , grad d: mm - hmm . grad f: mm - hmm . grad b: and this is maybe a sign for this . `` grad d: mm - hmm . grad e: mm - hmm . grad f: so , yeah . later this week we should sort of get together , and sort of start thinking about that , hopefully . grad b: talk features . yep . professor c: ok . we can end the meeting and call adam , and then we wan na s look at some filthy pictures of heidelberg . we can do that as well . grad b: well they had they used the ammunition they stored the ammunition in that tower . professor c: uh , is that ok ? grad b: and that 's why , when it was hit by uh , a cannon ball , it exploded . professor c: alright . oh . ni grad e: it exploded . that 's why they call it the powder - tower . grad b: ahh . grad e: ok . i first thought it had something to do with the material that it w that 's why i asked . grad d: that 's right , ok . grad b: mmm .","output":"d wanted to know if the videos for the navigation system would be recorded from a first person perspective . d was also trying to understand how ambitious the system was . d learned that the goal was to understand how people reacted and talked in such a scenario . d provided some information about potential candidates for the human operator and wizard roles as well ."},{"instruction":"summarize the meeting","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"the meeting concerned mostly status updates and logistical affairs . the participants learned that the transcription status was good . the progress on the darpa demo was also good , except the interface did not look as pretty as they had wanted to . the storage disks , which they had been waiting for , had finally arrived , but the person responsible for installing them was going on break . the participants also decided to schedule less meetings , so they have updates to report when they do . the meeting ended with technical discussion about model performance ."},{"instruction":"summarize the discussion on storage disks and computer connections","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"the participants learned that the storage disks had eventually arrived . they were waiting on the disks to be installed . grad e volunteered storage space on their own computer for the meantime . the meetings were around 1.5 gigs uncompressed and .5 gigs compressed . so , the group needed substantial space . the professor encouraged the team members to talk to dave , the person responsible for managing the organization 's storage systems , and figure things out ."},{"instruction":"what did grad e contribute to the discussion on storage disks ?","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"grad e volunteered his 18 gigabyte drive to the group . the drive had 12 gigabytes of memory and he was not using it for anything ."},{"instruction":"what did the group think about dave leaving ?","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"the group needed dave johnson to install the some one hundred sun - blades that had arrived and would help with storage . but dave johnson , the professor informed them , was leaving for ten days . the professor informed the group that dave was always busy and the group realized that there was no dedicated person who could help them ."},{"instruction":"summarize the discussion about scheduling meetings going forward","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"the team thought that they should not have everyone attend meetings on specific topics . for general catchup meetings like this , they thought it would make sense to alternate every two weeks . the team joked around about having a guys meeting , as one of the groups would not have any female members . they were mainly concerned with collecting more data through their own meeting recordings . though , many of the meetings they were having for that purpose were shorter than they would have liked ."},{"instruction":"what did the professor think about scheduling meetings going forward ?","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"the professor polled the group on how many people would not be interested in meetings on recognition . he thought that they should at least try the smaller meetings and see what happens ."},{"instruction":"what was the team joking about when it came to scheduling meetings ?","input":"grad a: ok , we 're on . professor b: yeah . grad a: so , i think this is gon na be a pretty short meeting because i have four agenda items , three of them were requested by jane who is not gon na be at the meeting today . so . the uh first was transcription status . does anyone besides jane know what the transcription status is ? phd f: um , sort of , i do , peripherally . phd c: is that english ? phd f: um well first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them a week or week and a half ago phd d: that 's our system . grad a: ugh ! phd f: and that it 's gone out to the transcribers and hopefully next week we 'll have the transcription back from that . grad a: c can i have a pen ? phd f: um jane seems to be um moving right along on the transcriptions from the icsi side . she 's assigned , i think probably five or six m more meetings . phd c: yeah , i think we 're up to mr thirteen or something . phd d: mmm . phd f: yeah , so um , i guess she 's hired some new transcribers phd d: speaking grad e: which meetings is she transcribing ? phd f: and um well we 've we 've run out of e d us because a certain number of them are um , sort of awaiting to go to ibm . grad e: ok . phd c: for ibm , yeah . phd d: hmm . grad e: ok . phd f: and the rest are in process being transcribed uh here . phd d: so does she have transcribers right now who are basically sitting idle because there 's no data back from ibm grad e: so we 're doing some in parallel . grad a: yep . phd f: no . grad a: no , no . phd f: oh no no . grad a: we have n't done that process . phd d: no ? phd f: no . we 're not waiting on them . grad a: so . they ' r they 're doing the full transcription process . phd d: oh . oh , ok . grad e: so they 're just doing their own thing until phd f: yeah . phd d: because i i need to ask jane whether it 's it would be ok for her um , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . phd f: we 're doing it in parallel , yeah . grad e: ok . phd c: yep . phd d: um and we want it you know , we need the again , we we have a similar uh logistic set - up where we are supposed to send the data to munich grad a: right . phd d: and get it transcribed and get it back . but to get going we would like some of the data transcribed right away so we can get started . grad a: yep , sounds familiar . phd d: and so um i wanted to ask jane if if uh , you know , maybe one of their transcribers could could do i mean since these are very short , that should really be uh , professor b: mm - hmm . phd d: um it 's phd c: there 's only two channels . so it 's only yeah . phd d: yeah . phd c: as the synthesis does n't have to be transcribed i think . phd d: it 's only two right , s phd c: so . phd d: yeah . so so it 's basically one channel to transcribe . and it 's one session is only uh like seven professor b: so that should have ma many fewer and it 's also not uh a bunch of interruptions with people and all that , phd d: right . and some of it is read speech , so we could give them the the thing that they 're reading professor b: right ? so . yeah . phd d: and they just may grad a: make sure it 's right . phd c: yep . phd d: and so um , um , i guess since she 's i was gon na ask her but since she 's not around i maybe i 'll professor b: yeah , well it certainly seems phd d: uh if if that 's ok with you to to , you know , get that stuff uh to ask her for that , then i 'll do that . professor b: yeah . yeah , if we 're held up on this other stuff a little bit in order to encompass that , that 's ok because i i um , i mean i still have high hopes that the that the ibm pipeline 'll work out for us , so it 's phd d: yeah . ok , yeah . professor b: yeah . phd d: alrighty . phd f: oh , yeah , and also related to the transcription stuff , so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected and what stage each meeting is in , in terms of whether it 's grad a: can you mail that out to the list ? phd f: mm - hmm , yeah i will . i that 's the thing that i sent out just to foo people saying can you update these pages grad a: oh , ok , ok . phd f: and so that 's where i 'm putting it but i 'll i 'll send it out to the list telling people to look at it . grad a: yeah , i have n't done that . so . i have lots of stuff to add that 's just in my own directory . phd f: yeah . grad a: i 'll try to get to that . ok . so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm just gon na do it . and uh , if anyone objects too much then they can do it instead . professor b: you are going to grad a: i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them to suggest edits . and then bleep them out . professor b: ok . grad a: for the ones that we have . um phd c: so but it 's just transcripts , not the not the audio ? grad a: nope , they 'll have access to the audio also . phd c: ok , yeah , yep . ah . grad a: i mean that 's my intention . because the transcripts might not be right . phd c: yeah . phd f: so grad a: so you want people to be able to listen to them . phd c: yeah . phd f: so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and grad a: oh , that 's a good point . that 's a good point . yeah , it 's it 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . phd f: hmm . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on grad a: well , that was the other point . phd f: oh , was that another one ? grad a: yep , that 's another agenda item . phd f: ok . i 'll wait . grad a: so , uh but that is a good point so we 'll get to that , too . um , darpa demo status , not much to say . the back - end stuff is working out fine . it 's more or less ready to go . i 've added some stuff that uh indes indexes by the meeting type mr , edu , et cetera and also by the user id . so that the front - end can then do filtering based on that as well . uh the back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer . and uh dave gelbart says he 's a little too busy . so i think don and i are gon na work on that and and you and i can just talk about it off - line more . grad e: right . grad a: but uh the back - end was pretty smooth . professor b: oh grad a: so i think , we 'll have something . it may not be as as pretty as we might like , but we 'll have something . professor b: i wondered whe when we would reach dave 's saturation point . he 's sort of been been volunteering for everything grad a: yeah . professor b: and and uh phd d: mm - hmm . professor b: o k . finally said he was too busy . i guess we reached it . grad a: yeah , he he actually he volunteered but then he s then he retracted it . so . oh well . um grad e: and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom grad a: oh , cool . grad e: so , right now it 's just an x waves and then you have three windows but i do n't know , it looked pretty nice and i 'm sure it think it has potential for a little something , grad a: for a demo ? grad e: yeah , for a demo . grad a: yeah , sounds good . grad e: so professor b: ok , so again , the issue is for july , the issue 's gon na be what can we fit into a windows machine , uh , and so on , but grad e: oh . ok . grad a: so it might just be slides . grad e: yeah , ok . phd c: well yeah . grad e: well , we 'll see , um phd c: i 've been putting together uh transcriber things for windows so i and i installed it on dave gelbart 's pc and it worked just fine . so hopefully that will work . phd d: really ? so is that because there 's some people um it would be cool if we could uh get that to work uh at at sri phd c: yeah . yep . phd d: because the um grad a: well transcriber is tcl - tk , very generic with snack , phd d: we have m m we have more windows machines to run the phd c: yeah . grad a: so basically anything you can get snack to run on , it will work . phd d: right . phd c: yeah . yeah but but the problem is the version transcriber works with , the snack version , is one point six whatever and that 's not anymore supported . it 's not on on the web page anymore . but i just wrote an email to to the author of to the snack author and he sent me to one point six whatever library grad a: well i thought it was packaged with transcriber ? phd c: and so it works . yeah , but then you ca n't add our patches and then the the new version is is totally different grad a: oh . phd c: a and in yeah , in terms of of the source code . grad a: ah . phd c: you you ca n't find the tcl files anymore . it 's some whatever wrapped thing phd d: mmm . phd c: and you ca n't you ca n't access that so you have to install first install tcl then install snack and then install the transcriber thing and then do the patches . grad a: patch . ugh ! phd d: i i wonder if if we should contribute our changes back to the authors so that they maintain those changes along phd c: yeah . yeah . grad a: we have yeah b it 's just has n't made it into the release yet . phd d: we have ? oh . oh , ok . phd f: so did you um put the uh the nt version out on the uh meeting recorder page ? or phd c: no , i have n't done that yet . i 'm oh nope . but i definitely will do that . professor b: so , can some of the stuff that don 's talking about somehow fit into this uh , mean you just have a set of numbers that are associated with the grad e: yeah . phd c: so grad e: yeah , it 's basically ascii files or binary files , whatever representation . just three different it 's a waveform and just a stylized pitch vector basically so it 's phd d: so so well grad e: i mean we could do it in matl - { comment } i mean you could do it in a number of different places i 'm sure . phd d: but but it would be cool if the transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . phd c: yep . grad e: yeah . professor b: yes . grad e: yeah , that 'd be very cool . grad a: it 'd be easy enough to add that . again it 's it 's it 's more tcl - t grad e: yeah . grad a: so someone who 's familiar with tcl - tk has to do it , phd d: right . grad a: but uh , it would n't be hard to do . phd d: right . but it would almost be like having another waveform displayed . grad a: yep . phd c: yep . phd d: s grad e: mm - hmm . phd d: right . phd c: yeah . yeah , maybe we could l look into that . grad e: yeah . grad a: but it it seems to me that i c phd c: and grad a: it does n't seem like having that real time is that necessary . so yo it seems to me you could do images . grad e: um what do you mean by real time ? do you mean like phd f: like being able to scroll through it and stuff for the demo . grad e: ok . grad a: yeah , jus yeah . phd f: is that what you mean ? grad a: it just seems to me jus grad e: it would be cool to see it phd f: yeah . grad e: it would be cool like to see to hear it and see it , phd c: and to hear it . yeah . yeah . grad e: and see the pitch contours also . grad a: sure , but i do n't think i you can do all that just statically in phd c: yeah . grad e: i think it would lose yeah , i mean y grad a: just record the audio clip and show an image and i think that 's grad e: right , right . i just thought if you meant slides i thought you meant like just like um view graphs or something . professor b: you know , wh yeah . so . uh , no , we 're talking about on the computer and and um , i think when we were talking about this before we had littl this little demo meeting , grad e: right . professor b: we sort of set up a range of different degrees of liveness that you could have and , the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i think for a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it phd d: mm - hmm . professor b: so it 'd be a good thing to get in there . but , um anyway , jus just looking for ways that we could actually show what you 're doing , uh , in to people . grad e: mm - hmm . professor b: cuz a lot of this stuff , particularly for communicator , uh certainly a significant chunk of the things that we waved our arms about th originally had t had to do with prosodics it 'd be nice to show that we can actually get them and see them . phd d: mmm . grad e: mm - hmm . grad a: and the last i item on the agenda is disk issues yet again . so , we 're doing ok on backed up . we 're we 're only about thirty percent on the second disk . so , uh , we have a little bit of time before that becomes critical , but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . phd c: yeah . grad a: and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting data all at once , in a lot of different ways . phd c: yeah . phd f: oh there 's a lot of transcribers , too . grad a: yeah , there 're a lot of transcribers , phd c: yeah . grad a: so all of those need to be expanded , and then people are doing chunking and i want to do uh , uh , uh , the permission forms , phd f: mm - hmm . phd c: an phd f: right . grad a: so i want those to be live , so there 's a lot of data that has to be around . um and jane was gon na talk to , uh , dave johnson about it . one of the things i was thinking is we we just got these hundred alright , excuse me ten , uh sparc - blade sun - blades . professor b: did they come in ? phd f: sun - blades . phd d: yeah . phd f: yeah . they came in the other day . grad a: they came in but they 're not set up yet . professor b: oh . grad a: and so it seems to me we could hang scratch disk on those because they 'll be in the machine room , they 'll be on the fast connection to the rest of the machines . and if we just need un - backed - up space , we could just hang disks off them . phd f: well , is there why not just hang them off of abbott , is there a grad a: because there 's no more room in the disk racks on abbott . professor b: yeah . phd f: ah . professor b: were n't we gon na get phd f: ah , i see . professor b: well , maybe it should get another rack . phd d: but you still need to store the disks somehow . grad a: well , but the sun - blades have spare drive bays . phd d: so grad a: just put them in . phd f: you can put two phd d: oh you mean you put them inside the pizza boxes for the grad a: sure . phd c: internal . yeah . grad a: yeah . cuz the sun uh , these sun - blades take commodity hard drives . phd d: oh . grad a: so you can just go out and buy a pc hard drive and stick it in . phd d: mmm . professor b: but if abbott is going to be our disk server it it file server { comment } it seems like we would want to get it , uh , a second disk rack or something . phd d: plus we 're talking about buying a second dis uh , file server . grad a: well , i mean there are lots of long term solutions . what i 'm looking for is where do we s expand the next meeting ? phd c: yep . phd d: i see oh , i see . professor b: well , for the next meeting you might be out of luck with those ten , might n't you ? uh , you know dave johnson is gone for , like , ten days , grad a: oh , i did n't know he had left already . professor b: uh , well , tonight . grad a: oh , oh well . phd d: you mean he wo n't set up the mmm . professor b: i do n't know . grad e: how much space do you need for these ? professor b: i do n't know what his schedule is . grad a: you we need about a gig per meeting . professor b: i 'm just saying he 's gone . phd c: yep . phd f: i i thi grad e: i have um i have an eighteen gig drive hanging off of my computer . grad a: alright ! what 's your computer 's name ? grad e: so uh , samosa . professor b: you had an eighteen gigabyte drive . grad e: yeah , i had . well it 's about i think there 's about twelve gig left . grad a: so it and you have an x drives installed ? ok . grad e: yeah . so , i did n't realize it was so critical . grad a: and you 're o you 're offering ? grad e: i mean i 'm not doing anything on it right now until i get new meetings to transcri or that are new transcriptions coming in i really ca n't do anything . grad a: ok . grad e: um not that i ca n't do anything , i jus phd f: i i jus i just gave thilo some about ten gigs , the last ten gigs of space that there was on on uh abbott . uh and uh so but that but grad a: which one was that , x g ? x g ? phd c: xg . phd f: xg . grad a: ok . phd d: xg ? phd f: yeah . phd d: that 's also where we store the the uh hub - five training set waveforms , phd c: oops . grad a: but that wo n't be getting any bigger , phd d: right ? phd f: no . grad a: will it ? phd f: i do n't think that 's on xg . phd d: right . phd f: on xg is only carmen and du - and stephane 's disk . phd c: it 's yeah . phd d: but i 've also been storing i 've been storing the feature files there and i guess i can s start deleting some because we now know what the best features are grad e: well phd d: and we wo n't be using the old ones anymore . grad e: i have a lot of space , though . phd f: yeah , i do i do n't think it was on xg . phd d: uh oh thats xa oh that 's x phd c: is n't that xh ? phd f: i th grad a: not not for long . grad e: i have a lot of space and it 's not it 's n there 's very little uh yeah not for long . phd d: maybe i 'm confu grad e: but i mean it 's not going f phd d: oh no i 'm sorry . grad e: it 's not being used often at all . phd c: but i 'm using xh h , too . grad a: yeah , it 's probably probably only about four gig is on x on your x drive , phd c: so . phd d: oh ok . grad a: but we 'll definitely take it up if you grad e: i th phd d: i think you 're right . it 's xh and d grad e: i think it 's about four or five gig cuz i have four meetings on there , phd d: the b i 'm also using dg i got that confused . grad e: three or four meetings . phd d: ok . grad a: great . grad e: so . grad a: ok , so that will get us through the next couple days . professor b: we need we need another gigaquad . grad a: yep . at least . professor b: there should i d there should just be a b i should have a button . grad a: the `` more disk space `` button ? professor b: just press press each meeting saying `` we need more disk space `` `` this week `` . grad a: yep . professor b: skip the rest of the conversation . phd f: well we 've collected so far something like uh sixty - five meetings . professor b: and and how much does each meeting take ? phd f: and it 's about a gig uncompressed . phd c: it 's it 's a little bit more as i usually do n't do not uncompress the all of the pzm and the pda things . phd f: is a little more ? phd c: so . phd f: right , yeah so if you uncompressed everything it 's even more . phd c: it 's yeah . one point five or something . phd f: u uh compressed how much are they ? like grad a: half a gig . for all of them . phd f: about half ? phd c: yeah . yeah . yep . phd f: so we 're definitely are storing you know , all of those . so there 's what thirty some gig of just meetings so far ? professor b: so - so so maybe there 's a hundred gig or something . or i mean . cuz we we have the uncompressed around also . phd f: mm - hmm . right . professor b: so it 's like phd c: yeah . phd f: right . well we we have n't uncompressed all the meetings , but grad a: i would like to . professor b: yeah . well i mean it 's the they really are cheap . i mean it 's just a question of figuring out where they should be and hanging them , grad a: yep . phd f: right . professor b: but but uh , we could you know , if you want to get four disks , get four disks . i mean it 's it 's small i mean these things ar are just a few hundred dollars . phd f: yeah . well i sent that message out to , i guess , you and dave asking for if we could get some disk . professor b: yeah . phd f: i s i sent this out a a day ago grad a: and put it where ? professor b: right . phd f: but and dave did n't respond so i don i do n't know how the whole process works . i mean does he just go out and get them and if it 's ok , and grad a: yep . phd f: so i was assuming he was gon na take over that . but he 's probably too busy given that he 's leaving . professor b: yeah , i think you need a direct conversation with him . and just say an - e just ask him that , you know , wha what should you do . and in my answer back was `` are you sure you just want one ? `` so i mean i think that what you want to do is plan ahead a little bit and figure `` well , here 's what we pi figure on doing for the next few months `` . phd f: yeah . grad a: wa - a i know what they want . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . professor b: yeah . grad a: um and then they want everything else in the machine room . professor b: right . grad a: so the question is where are you gon na hang them ? phd f: mm - hmm . i do n't know what the space situation is in the machine room . grad a: right . phd f: so . professor b: right . so this is a question that 's pretty hard to solve without talking to dave , phd d: th - the phd f: i think part of the reason why dave ca n't get the the new machines up is because he does n't have room in the machine room right now . professor b: cuz it phd d: one mmm . grad a: yep . phd d: one one on - one thing to in to um t to do when you need to conserve space is phd f: so he has to re - arrange a bunch of stuff . phd d: i bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . grad a: yep . professor b: yeah . no . i think dave dave knows all these things , of course . an - and so , he always has a a lot of plans of things that he 's gon na do to make things better in many ways an and runs out of time . phd d: right . mm - hmm . grad a: but i i know that generally their first priority has been for backed up disk . and so i think what he 's been concentrating on is uh the back the back up system , rather than on new disk . phd d: mmm . mmm . grad a: so . which professor b: well . so . but this this is a very specific question for me . basically , we can easily get one to four disks , i mean you just go out and get four and we 've got the money for it , it 's no big deal . uh , but the question is where they go , and i do n't think we can solve that here , you just have to ask him . phd d: maybe we can put some disks in the in that back room there . grad a: yeah really . professor b: attach to grad a: popcorn . professor b: yeah ? phd d: to the machine that collects the data . so then you could , at least temporarily , store stuff there . grad a: yeah , it 's just it 's not on the net , so it 's a little awkward phd d: the only phd f: hmm . phd d: what do you mean it 's not on the net ? grad a: it 's not phd c: it 's not bad . grad a: it 's behind lots of fire walls that do n't allow any services through except s s phd d: oh because it 's because it 's an aciri machine ? grad a: yep . professor b: yeah . phd d: oh , oh oh . grad a: and also on the list is to get it into the normal icsi net , but who knows when that will happen ? phd d: but that ca n't be that hard . phd f: that might be a good short term solution , though . phd d: i mean grad a: no , the the problem with that apparently is that they do n't currently have a wire running to that back room that goes anywhere near one of the icsi routers . phd d: oh , grad a: so , they actually have to run a wire somewhere . professor b: yeah . yeah , e again , you know , any one of these things is certainly not a big deal . if there was a person dedicated to doing it they would happen pretty easily but it 's it 's jus every ever everybody everybody has a has grad a: but dave has to do all of them . professor b: well all of us have long lists of different things we 're doing . but at any rate i think that there 's a there 's a longer term thing and there 's immediate need and i think we need a a conversation with uh , maybe maybe after after tea or something you and i can go down and and talk to him about it just say `` wha you know , what should we do right now ? `` phd f: how long is david gon na be gone ? professor b: uh , eleven days or something ? grad a: oh my ! professor b: yeah basically tomorrow and all of the week after . grad a: and that 's all i have . professor b: um let 's see . the only oth thing other thing i was gon na add was that um uh , i talked briefly to mari and uh we had both been busy with other things so we have n't really connected that much since the last meeting we had here but we agreed that we would have a telephone meeting the friday after next . and i i i wanted to make it , um after the next one of these meetings , so something that we wan na do next meeting is is uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i can i can dream up text but this is basically gon na lead to the annual report . so um if w phd d: mm - hmm . grad a: this is the fifteenth ? so just a week from tomorrow ? professor b: um , that would grad a: ok . professor b: yeah . yeah . so , uh , we can this so that 's an phd d: is this got ta be in the morning ? professor b: um phd d: or because you know i fridays i have to leave uh like around uh two . so if it could be before that would be be professor b: no , no but i i i do n't need other folks for the meeting . i can do it . a a all i 'm saying is that on phd d: oh , ok , alright . oh i 'm sorry , i misunderstood . professor b: yeah so what i meant was on the me this meeting if i wa something i i i 'm making a major thing in the agenda is i wan na help in getting together a list of what it is that we 've done so i can tell her . phd d: i thought you are ok . alright . mm - hmm . professor b: i think i have a pretty good idea phd d: ok . professor b: but but um uh , and then the next day uh , late in the day i 'll be having that that discussion with her . phd d: mmm . professor b: um . so . phd d: um uh one thing i mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side professor b: mm - hmm . phd d: um but is n't necessarily related to meetings uh specifically . so . um . and i wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because i feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh professor b: think so ? phd d: well , it 's that it 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . grad a: i 'm interested . professor b: well , ok , so how many how many people here would not be interested in uh in a meeting about recognition ? phd c: me too . phd f: jane may not be . grad a: jane , i think . phd c: yep . phd d: well i know well , jane an well you mean in a separate meeting or ha ha talking about it in this grad a: no . if we talked about it in this meeting . phd f: he 's wondering how much overlap there will be . professor b: yeah , so you 're su phd d: ok . professor b: so . phd d: so , uh , uh , liz and jane probably . professor b: ok , so we 're gon na have a guy 's meeting . phd d: uh . uh , if you wan na put it that way . phd f: good thing liz is n't here . professor b: real grad e: watch a ball game ? professor b: yeah , real real real men `` real men do decoding `` or something like that . phd f: do n't listen to this , liz . phd d: right . professor b: uh . phd d: i mean it it 's sort of i mean when when the talk is about data collection stuff , sometimes i 've you know , i i 'm bored . professor b: yeah . grad a: the nod off ? phd d: so it 's i c i can sympathize with them not wanting to i to to be uh you know if i cou you know this could professor b: it 's cuz y you have a so you need a better developed feminine side . phd d: i 'm professor b: there 's probably gon na be a lot of `` bleeps `` in this meeting . phd d: not sure i wan na grad a: yeah , i would as { comment } i would guess . professor b: uh . um . phd d: yeah and professor b: i think it must be uh nearing the end of the week . um . yeah . i you know , i i 've heard some comments about like this . that m could be . phd d: mm - hmm . professor b: i mean the um . u phd d: and we do n't have to do it every week . phd f: could we phd d: we could do it every other week or so . you know , whatev or whenever we feel like we phd f: right , i was why do n't we alternate this meeting every other week ? grad a: or just alternate the focus . phd f: tha - that 's what i mean . grad a: yeah , so on even weeks have basic on data . professor b: yeah . phd d: we could do that , yeah . phd f: yeah . phd d: i i personally i 'd i 'm not in favor of more meetings . um . because , uh . professor b: right . grad a: i am . phd d: you know . grad a: oh sor phd f: but i do i do n't i mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . phd d: right . grad a: well , except that we keep going for our full time . phd f: so if we did that phd c: yep . phd f: well , cuz we get into these other topics . grad a: yeah . phd d: we feel we feel obligated to collect more data . grad e: yeah . grad a: ugh . phd f: yeah . grad a: i do n't . phd f: so if we could alternate the focus of the meeting grad a: let 's read digits and go . professor b: why do n't we just start with that . phd d: ummh . { comment } ummh . { comment } ok . professor b: and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . phd d: mm - hmm . professor b: but i i think that 's a great idea . uh . so uh . um . let 's chat about it with liz and jane when we get a chance , see what they think and phd d: mm - hmm . phd f: yeah that would be good . i mean andreas and i have various talks in the halls phd d: mm - hmm . phd f: and there 's lots of things , you know , details and stuff that would i think people 'd be interested in and i 'd you know , where do we go from here kind of things and so , it would be good . professor b: yeah , and you 're you 're attending the uh the front - end meeting as well as the others so you have you have probably one of the best you and i , i guess are the main ones who sort of see the bridge between the two . grad a: bridge . phd d: mm - hmm . professor b: we are doing recognition in both of them . so . phd f: mm - hmm . phd d: right . professor b: uh . grad a: ok ? phd d: so um . so so we could talk a little bit about that now if if there 's some time . grad a: no , no that would be for next week . phd d: um i jus so the latest result was that um um yot i tested the uh the sort of final version of the plp configuration um on development test data for for this year 's hub - five test set . professor b: mm - hmm . phd d: and the recognition performance was exactly , and i mean exactly up to the you know , the first decimal , same as with the uh mel cepstra front - end . grad a: mmm . phd f: for both females and males ? phd d: yes . uh , well i there was a little bit of a phd f: oh ! phd d: i overall . they they were the males i think were slightly better and the females were slightly worse but nothing really . phd f: mm - hmm . professor b: mm - hmm . phd d: i mean definitely not significant . phd f: mm - hmm . phd d: and then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . grad a: wow . just with rover ? phd d: so . t with n - best rover , which is like our new and improved version of rover . grad a: mm - hmm . phd d: which u actually uses the whole n - best list from both systems to mmm , uh c combine that . professor b: so except i mean the only key difference between the two really is the kind of smoothing at the end which is the auto - regressive versus the cepstral truncation . phd d: yeah . professor b: ok . phd d: and , the phd f: but a percent and a half ? grad a: yeah , it 's pretty impressive . phd f: that 's phd d: and and so uh after i told the my uh colleagues at sri about that , you know , now they definitely want to , you know , uh , have a next time we have an evaluation they want to do uh , you know , basically a at least the system combination . um , and , you know , why not ? professor b: sure , why not ? phd d: uh . so . grad a: we clearly got ta add a few more features , though . phd d: uh w what do you mean ? more features in the sense of front - end features or in the sense of just bells and whistles ? grad a: no , uh front - end features . you know we did plp and mel cepstra . let 's , you know , try rasta and msg , and phd d: oh i mean yeah . well right . so , we cou yeah . that 's the the the there 's one thing uh i mean you do n't want to overdo it because y every front - end you know , if you you know you basically multiply your effort by n , where n is a number of different systems phd f: oh . professor b: mm - hmm . phd d: and um . so . so one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . professor b: mmm . an phd d: so . phd f: do you think we 'd still get the one and a half uh phd d: i i think so . yeah . maybe a little less because at that point the error rates are lower and so if you know , maybe it 's only one percent or something but that would still be worthwhile doing . phd f: mm - hmm . phd d: so . um jus - you know , just wanted to let you know that that 's working out very nicely . grad a: cool . phd d: and then we had some results on digits , uh , with um we we so this was uh really { comment } really sort of just to get dave going with his um experiments . professor b: mm - hmm . phd d: and so , uh . but as a result , um , you know , we were sort of wondering why is the hub - five system doing so well on the digits . professor b: right . phd d: and the reason is basically there 's a whole bunch of read speech data in the hub - five training set . grad a: right . professor b: including digits i gather , yeah . phd d: and you c and not all of no it 's actually , digits is only a maybe a fifth of it . professor b: a fifth of it is how much ? phd d: the rest is is read is read timit data and uh atis data and wall street journal and stuff like that . professor b: right . but a fi a fifth is how much ? phd d: a fifth would be maybe uh two hours something . professor b: yeah , so i mean that 's actually not that different from the amount of training that there was . phd d: right . professor b: so . phd d: but it definitely helps to have the other read data in there professor b: oh yeah phd d: because we 're doing professor b: w phd d: you know the error rate is half of what you do if you train only on ti uh timit { comment } uh not timit uh ti - digits , professor b: mm - hmm . phd d: which is only what two hours something ? professor b: right . grad a: i do n't know . phd d: so . uh , more read speech data definitely helps . and you can leave out all the conversational data with no performance penalty . professor b: yeah that was the interesting thing . phd d: that 's e professor b: because because uh , it was apparent if you put in a bunch more data it would be better , phd d: that was e right , right . professor b: but but uh . phd d: right . phd f: well is there even more read speech data around ? phd d: oh , yeah . so we only for the hub - five training , we 're only using uh a fairly small subset of the macrophone database . phd f: mm - hmm . phd d: um , so , you could beef that up and probably do even better . grad a: i could also put in uh focus condition zero from hub - four from broadcast news , which is mostly prepared speech . phd f: mm - hmm . grad a: it 's not exactly read speech but it 's pretty darn close . phd d: yeah . yeah . right . well , i mean that 's plenty of read speech data . i mean , wall street journal , uh , take one example . grad a: yeah . that 's right . phd d: but um . so , you know that might be useful for the people who train the the digit recognizers to to use uh something other than ti - digits . grad a: yeah . professor b: well they been using timit . phd d: ok . professor b: that uh . they they uh they experimented for a while with a bunch of different databases with french and spanish and so forth cuz they 're multilingual tests phd d: mm - hmm . professor b: and and uh , um , and actually the best results they got wa were uh using timit . grad a: hmm . professor b: uh but uh which so that 's what they 're they 're using now . phd d: mmm . professor b: but but yeah certainly if we , um if we knew what the structure of what we 're doing there was . i mean there 's still a bunch of messing around with different kinds of uh noise robustness algorithms . phd d: mm - hmm . professor b: so we do n't know exactly which combination we 're gon na be going with . phd d: mm - hmm . professor b: once we know , then the trainable parts of it it 'd be great to run lots of lots of stuff through . phd d: mm - hmm . right . well , that was that . and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system and you wan na you wan na see where that stands ? phd f: well , i 'm phd d:  phd f: yeah , so andreas uh brought over the uh alignments that the sri system uses . and so i 'm in the process of um converting those alignments into uh label files that we can use to train uh a new net with . and uh so then i 'll train the net . and . phd d: an - and one side effect of that would be that it 's um that the phone set would change . so the mlp would be trained on i think only forty - six or forty - eight phd f: right . eight . phd d: forty - eight phones ? phd f: mm - hmm . phd d: uh which is smaller than the um than the phone set that that we 've been using so far . professor b: yeah . phd d: and that that that will probably help , actually , phd f: so it 's a little different ? phd d: because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um just you know we want to try things like deltas on the tandem features . and so you h have to multiply everything by two or three . and so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . professor b: sure . although we i mean , it 's not that many fewer and and and we take a klt anyway so we could phd d: right . exactly . professor b: yeah . phd d: so so that was the other thing . and then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . so that would mean just doing the top i do n't know ten or twelve or something of the klt dimensions . professor b: yeah , and i think and we sh again check we should check with stephane . my impression was that when we did that before that had very little uh he did n't lose very much . phd d: right . phd f: by just taking the top whatever ? grad a: yep . professor b: yeah yeah . phd d: but then and then something once we have the new m l p trained up , uh one thing i wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain mlp and also the you know , the dictionary that we use for the hub - five system . professor b: and the b and the base u starting off with the base of the alignments that you got from i from a pretty decent system . phd d: exactly . phd f: right . phd d: yeah . so that would basically give us a , um , more hopefully a a better system professor b: yeah . phd d: um because you know , compared to what eric did a while ago , where he trained up , i think , a system based on broadcast news and then uh tra retraining it on switchboard or s uh and professor b: yeah . phd d: but he i think he d he did n't he probably did n't use all the training data that was available . and his dictionary probably was n't as tuned to um conversational speech as as the as ours is . professor b: that 's that 's certainly one thing , yeah . phd d: so . professor b: uh . yeah . phd d: and the dictionary made a huge difference . uh . we we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on switchboard , which professor b: well the other thing is , dipping deep into history and into uh our resource management days , when we were collaborating with sri before , phd d: mm - hmm . mmm . professor b: uh it was i think , it is was a really key uh starting point for us that we actually got our alignment . phd d: mm - hmm . professor b: when we were working together we got our initial alignments from decipher , uh at the time . phd d: mm - hmm . yeah . professor b: uh . and . later we got away from it because because once we had decent systems going then it was it was typically better to use our own systems phd f: yeah . phd d: mm - hmm . professor b: cuz they were self consistent but but certainly to start off when we were trying to recover from our initial hundred and forty percent error uh rate . uh . but that was a that was a good good good way to start . phd d: yeah . professor b: and we 're not quite that bad with our our switchboard systems but it was they certainly are n't as good as sri 's , phd d: ok . yeah . professor b: so phd d: right . phd f: w what is the performance on s the best switchboard system that we 've done ? roughly ? professor b: well , the hybrid system we never got better than about fifty percent error . and uh it was i think there 's just a whole lot of things that uh no one ever had time for . we never did really fix up the dictionary . uh we always had a list of a half dozen things that we were gon na do and and a lot of them were pretty simple and we never did . phd d: yeah . mmm . professor b: uh , we never did an never did any adaptation phd d: but that w even that that number professor b: uh , we never did any phd d: right . and and that number i think was on switchboard - one data , right ? where the error rate now is in the twenties . professor b: yeah . yeah . phd d: so , um . professor b: so we were yeah . we were probably at least a factor or two off . phd d: that 's yet s right . professor b: yeah . phd d: so it would be so it would be good t to sort of r re uh professor b: yeah . phd d: just at least to give us an idea of how well the hybrid system would do . professor b: yeah . but i think again it 's yeah . it 's the conver it 's the s conversational speech bit . because our our broadcast news system is actually pretty good . phd d: mm - hmm . professor b: he knows . phd d: right . and the other thing that that would help us to evaluate is to see how well the m l p is trained up . right ? because it 's a pretty good um indicator of that . professor b: mm - hmm . phd d: so it 's sort of a sanity check of the m l p outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . phd f: mm - hmm . professor b: yeah . it 'll still probably be worse . i mean , it 's it 'd be context independent and so on . phd d: no . sure . not phd f: should we should we bother with um using the net before doing uh embedded training ? professor b: but . phd d: but phd f: i mean should should we even use that ? phd d: oh oh that 's a good question . phd f: or should i just go straight to phd d: yeah , we we were n't sure whether it 's worth to just use the alignments um from the s r i recognizer or whether to actually go through one or more iterations of embedded training where you realign . grad a: try it . you run it ? keep keep both versions ? see which one 's better ? professor b: uh , yeah . i mean . i think i agree with ad i mean basically you would then you proceed with the embedded training . phd d: mm - hmm . professor b: it 's gon na take you a while to train at this net anyway . phd d: mm - hmm . right . professor b: and while it 's training you may as well test the one you have and see how it did . phd d: ok . alright . phd f: mmm . grad a: i could make arguments either way . you know , it 's phd d: but but so i grad a: sort of given up guessing . phd d: well but i but in your experience i mean uh have you seen big improvements in s on some tasks with embedded training ? or was it sort of small - ish uh improvements that you got professor b: uh well . it depended on the task . i mean i think in this one i would sort of expect it to be important phd d: right . professor b: because we 're coming from uh , alignments that were achieved with an extremely different system . phd d: that are from another right . grad a: although , i mean we 've done it with when we were combining with the cambridge recurrent neural net , embedded training made it worse . phd d: right . professor b: uh . grad a: which i 've never figured out . professor b: right . but i mean i grad a: i think it 's a bug . phd d: so you you started training with outputs from a with alignments that were generated by the cambridge uh system ? grad a: yep . phd d: and then uh . grad a: yeah . professor b: yeah . phd d: hmm . well , that might probably just hmm . that was probably because your initial system i mean your system was ba worse than cambridge 's . and you um . professor b: was it ? i do n't think it was . grad a: no they were they were comparable . phd d: it was n't ? professor b: no . grad a: they were very close . phd d: really ? professor b: yeah . phd d: that 's weird . professor b: excuse me ? phd d: that 's that 's weird . grad a: that 's what i said . professor b: oh ! phd d: no i mean it 's weird that it did i 'm sorry . it 's w it 's weird that it got worse . phd f: that 's ambiguous . professor b: um . no . uh . tha - u we we 've see i mean and wi with the numbers ogi numbers task we 've seen a number of times people doing embedded trainings and things not getting better . phd d: oh actually it 's not that weird because we have seen we have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . professor b: yeah . it just phd d: yeah . professor b: but i but i would i would suspect that something that that had um a very different um feature set , for instance i mean they were using pretty diff similar feature sets to us . grad a: yep . professor b: i i would expect that something that had a different feature set would would uh benefit from phd d: mm - hmm . phd f: what about uh hidden unit size on this . professor b: oh , wait a minute , and the other thing uh , phd f: oh . professor b: sorry , it was the other thing is that what was in common { comment } to the cambridge system and our system is they both were training posteriors . grad a: right . ah yeah . professor b: so i mean , uh , that 's another pretty big difference grad a: that 's another big difference . professor b: and uh , one bac at least back at phd d: you mean with soft targets ? or ? sorry , i 'm sor i missed what what 's the key issue here ? professor b: oh , that uh both the cambridge system and our system were were training posteriors . and if we 're we 're coming from alignments coming from the sri system , it 's a likelihood - based system . so so that 's another difference . phd d: yeah . professor b: i mean . you know , there 's diffe different front - end different different uh , um , training criterion uh , i would think that in a that an embedded uh embedded uh training would have at least a good shot of improving it some more . phd d: mm - hmm . professor b: but we do n't know . phd d: ok . professor b: you gon na say something ? phd f: yeah . i was wondering uh you know what size net i should anybody have any intuitions or suggestions ? professor b: uh , how much training data ? phd f: well , i was gon na start off with the small train set . professor b: and how how many hours is that ? phd f: that 's why i was i i 'm not sure how much that is . phd d: uh , i think that has about well i you 'd would be gender - dependent training , right ? so so i think it 's uh that 's about mmm , something like thirty hours . phd f: gender - dependent , yeah . phd d: thirty hours per gender . phd f: thirty hours . grad a: i 'm not sure what this 'll mean . phd f: in the small training set ? grad a: hello ? phd d: i i think so . i 'll grad a: excuse me ? phd d: it 's definitely less than a hundred grad a: alright . phd d: you know , it 's more like like thirty forty hours something like that . grad a: wrong number . phd f: they called to tell us that ? professor b: yeah . phd d: yeah . professor b: um . so . uh . after run phd f: i mean , i did n't want to do too big , professor b: right . so phd f: just professor b: at least a couple thousand hidden units . i mean . it 's it 's th the thing i 'll i 'll think about it a little more phd d: mm - hmm . professor b: but it it 'd be toss up between two thousand and four thousand . phd f: mmm . professor b: you definitely would n't want the eight thousand . it 's m it 's more than phd f: and a thousand is too small ? professor b: oh let me think about it , but i think that that uh th at some point there 's diminishing returns . i mean it does n't actually get worse , typically , phd f: mm - hmm . grad a: mm - hmm . professor b: but it but but there is diminishing returns and you 're doubling the amount of time . phd d: remember you 'll have a smaller output layer so there 's gon na be fewer parameters there . grad a: but not by a lot . professor b: not by much . phd d: and then professor b: fifty s fifty four to forty eight ? grad a: vast majority is from the input unit . professor b: yeah . phd d: ok . yeah . professor b: yeah . it 'll have a very tiny effect . grad a: right , because you used the context windows and so the input to hidden is much , much larger . professor b: yeah . phd d: oh i see , i see , yeah , of course . professor b: yeah . phd d: yeah . it 's negligible , ok . professor b: yeah , so it 's it 'd be way , way less than ten percent of the difference . phd d: uh - huh . professor b: uh . there 's uh how bi how big let 's see . what am i trying to think of ? phd f: the the net that that we did use already uh was eight thousand hidden units and that 's the one that eric trained up . professor b: right . and that was trained up on uh like a hundred and forty hours of of speech . phd d: was that gender - dependent or independent ? phd f: gender - dependent . professor b: oh . so that would be like trained on s sixty or seventy hours . phd d: mm - hmm . professor b: so , uh , yeah definitely not the one thousand uh two thousand fr i mean the four thousand will be better and the two thousand will be almost will be faster and almost as good . grad a: it 'll be faster . professor b: so . phd f: yeah . phd d: mm - hmm . phd f: maybe i 'll start off with two thousand just to see . professor b: yeah . phd d: ok . phd f: ok . professor b: yeah , thirty hours is like a hundred and ten thousand uh seconds . uh , so that 's like eleven eleven million frames . and a two thousand hidden unit net is uh i guess about seven , eight hundred thousand parameters . so that 's probably that 's probably fine . i mean a four thousand is well within the range that you could benefit from but the two thousand 'd be faster so phd d: right . i actually have to go . professor b: alright . phd d: so . professor b: uncle bernie 's rule is ten to one . bernie woodrow 's rule of yeah uncle bernie yeah . grad a: we 're just waiting for you to leave . professor b: yes sir . grad a: anything else ? professor b: nah . grad a: ok . professor b: since we have nothing to talk about we only talked for an hour . grad a: if professor b: so . grad a: yeah that 's right . phd c: yeah . grad a: uh , well , we started late . phd f: transcript professor b: de - ba - de . de - ba - de that 's all folks !","output":"the team was joking about one meeting being a `` guys '' meeting because both the female members of the group would be in the other meeting . they also seemed to be using foul language and joked at all the bleeping it would entail in the transcription ."},{"instruction":"summarize the meeting","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"the meeting began with a discussion on the torrent project completion being pushed for two years . grad f then introduced intermediate categorization , which was his topic for his qualification exams . the team then discussed mean subtraction from sri . using it had led to an improvement in meeting recorder digits though near mic performance worsened . the professor points to pre-echoes as the culprit . the team continued to study differences between sri and aurora . the team thought it would be interesting to do the aurora tests with the sri system instead of the htk . the team was also exploring the wiener filter and vts . the professor did not seem too excited about the vts ."},{"instruction":"summarize the discussion on torrent schedule and intermediate categorization","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"the professor told the team that the torrent chip schedule kept getting pushed . then , grad f talked about his proposal , in which he was done with the section on intermediate categories . including features from intermediate categories was a potential way of reducing error ."},{"instruction":"what did grad f say about his proposal ?","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"grad f explained that he was focusing on writing his proposal for his qualification exams , which was on the 25th of july . he had to write a paper and pass it around before that date ."},{"instruction":"what did grad f think about intermediate categories ?","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"grad f informed the team that he was building a system that classified intermediate categories with multi-band techniques . then , to reduce error for phoneme recognition , the intermediate categories could be added to improve performance . the method could be replicated for large vocabulary tasks like switchboard ."},{"instruction":"summarize the discussion on mean subtraction in sri","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"the team got an improvement on the sri system for ti- digits and meeting recorder digits but near mic performance worsened . the team explored the reasons for this difference . the professor suggested getting rid of low energy sections . the team also discussed how more nuanced normalization approaches could improve task performance ."},{"instruction":"what did the professor think about echoes and reverberation ?","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"the professor thought it was possible to reduce the effects of reverberation by removing the low-energy segments . he thought a vad-like approach would work . this would make it so that the model was more likely to keep an echo than throw out speech ."},{"instruction":"what did phd c think about the signal to noise ratio ?","input":"professor b: i think for two years we were two months , uh , away from being done . phd a: and what was that , morgan ? what project ? professor b: uh , the , uh , torrent chip . phd a: oh . professor b: yeah . we were two we were phd c: yeah . professor b: uh , uh , we went through it jim and i went through old emails at one point and and for two years there was this thing saying , yeah , we 're we 're two months away from being done . it was very very believable schedules , too . i mean , we went through and with the schedules and we phd a: it was true for two years . professor b: yeah . oh , yeah . it was very true . phd a: so , should we just do the same kind of deal where we go around and do , uh , status report kind of things ? ok . and i guess when sunil gets here he can do his last or something . so . professor b: yeah . so we probably should wait for him to come before we do his . phd c: mm - hmm . phd a: ok . that 's a good idea . professor b: yeah . grad f: ok . professor b: yeah . phd a: any objection ? do y ok , m professor b: all in favor phd a: do you want to start , morgan ? do you have anything , or ? professor b: uh , i do n't do anything . i no , i mean , i i 'm involved in discussions with with people about what they 're doing , but i think they 're since they 're here , they can talk about it themselves . grad f: ok . so should i go so that , uh , phd a: yeah . why do n't you go ahead , barry ? grad f: you 're gon na talk about aurora stuff , per se ? phd a: ok . grad f: ok . um . well , this past week i 've just been , uh , getting down and dirty into writing my my proposal . so , um mmm . i just finished a section on , uh on talking about these intermediate categories that i want to classify , um , as a as a middle step . and , um , i hope to hope to get this , um a full rough draft done by , uh , monday so i can give it to morgan . phd a: when is your , uh , meeting ? grad f: um , my meeting phd a: yeah . grad f: with , uh ? oh , oh , you mean the the quals . phd a: the quals . yeah . grad f: uh , the quals are happening in july twenty - fifth . phd a: oh . soon . grad f: yeah . phd a: uh - huh . grad f: d - day . phd a: yeah . grad f: uh - huh . phd a: so , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and ? grad f: right , right . so , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . and , um , and then , um then everybody asks you questions . phd a: hmm . grad f: yeah . phd a: i remember now . grad f: yep . so , um . phd a: have you d ? i was just gon na ask , do you want to say any a little bit about it , grad f: y s phd a: or ? mmm . grad f: oh . uh , a little bit about ? phd a: wh - what you 're what you 're gon na you said you were talking about the , uh , particular features that you were looking at , grad f: oh , the the phd a: or grad f: right . well , i was , um , i think one of the perplexing problems is , um , for a while i was thinking that i had to come up with a complete set of intermediate features in intermediate categories to to classify right away . but what i 'm thinking now is , i would start with with a reasonable set . something something like , um , um like , uh , re regular phonetic features , just to just to start off that way . and do some phone recognition . um , build a system that , uh , classifies these , um these feat uh , these intermediate categories using , uh , multi - band techniques . combine them and do phon phoneme recognition . look at then i would look at the errors produced in the phoneme recognition and say , ok , well , i could probably reduce the errors if i included this extra feature or this extra intermediate category . that would that would reduce certain confusions over other confusions . and then and then reiterate . um , build the intermediate classifiers . uh , do phoneme recognition . look at the errors . and then postulate new or remove , um , intermediate categories . and then do it again . phd a: so you 're gon na use timit ? grad f: um , for that for that part of the the process , yeah , i would use timit . phd a: mm - hmm . grad f: and , um , then after after , uh , um , doing timit . right ? phd a: mm - hmm . grad f: um , that 's that 's , um that 's just the ph the phone recognition task . phd a: yeah . grad f: uh , i wanted to take a look at , um , things that i could model within word . so , i would mov i would then shift the focus to , um , something like schw - switchboard , uh , where i 'd i would be able to , um to model , um , intermediate categories that span across phonemes , phd a: mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on on a large vocabulary task like switchboard . uh , and for that for that part i would i 'd use the sri recognizer since it 's already set up for for switchboard . and i 'd run some some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: oh . so that 's why you were interested in getting your own features into the sri files . grad f: yeah . that 's why i i was asking about that . phd a: yeah . yeah . grad f: yeah . um , and i guess that 's that 's it . any any questions ? phd a: sounds good . so you just have a few more weeks , huh ? grad f: um , yeah . a few more . phd a: it 's about a month from now ? grad f: it 's a it 's a month and and a week . phd a: yeah . grad f: yeah . phd a: so , uh , you want to go next , dave ? and we 'll do grad e: oh . ok , sure . so , um , last week i finally got results from the sri system about this mean subtraction approach . and , um , we we got an improvement , uh , in word error rate , training on the ti - digits data set and testing on meeting recorder digits of , um , six percent to four point five percent , um , on the n on the far - mike data using pzm f , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . and , um , wh why would that be , um , considering that we actually got an improvement in near - mike performance using htk ? and so , uh , with some input from , uh , andreas , i have a theory in two parts . um , first of all htk sorry , sr - the sri system is doing channel adaptation , and so htk was n't . um , so this , um this mean subtraction approach will do a kind of channel normalization and so that might have given the htk use of it a boost that would n't have been applied in the sri case . and also , um , the andreas pointed out the sri system is using more parameters . it 's got finer - grained acoustic models . so those finer - grained acoustic models could be more sensitive to the artifacts in the re - synthesized audio . um . and me and barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . and so that seems like it could be difficult for training , cuz you could have different phones lined up with a different foreground phone , um , depending on the timing of the echo . so , um , i 'm gon na try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . so i 'm planning to use the macrophone set of , um , read speech , and , um hmm . professor b: i had another thought just now , which is , uh , remember we were talking before about we were talking in our meeting about , uh , this stuff that some of the other stuff that avendano did , where they were , um , getting rid of low - energy sections ? um , uh , if you if you did a high - pass filtering , as hirsch did in late eighties to reduce some of the effects of reverberation , uh , uh , avendano and hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a an all - positive power spectrum you get some negative values , and you got ta figure out what to do with them if you 're gon na continue treating this as a power spectrum . so , what what hirsch did was , uh , set them to zero set the negative values to zero . so if you imagine a a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . and it 's the low - energy parts of the speech where the reverberation is most audible . you know , you have the reverberation from higher - energy things showing up in so in this case you have some artificially imposed reverberation - like thing . i mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n and , um , what if you did ? i mean , there 's nothing to say that the the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . i mean , you also could , uh , just try to make it nicer . grad e: uh - huh . professor b: and one of the things you could do is , you could do some sort of vad - like thing grad e: mm - hmm . professor b: and you actually could take very low - energy sections and set them to some some , uh , very low or or near zero value . i mean , uh , i 'm just saying if in fact it turns out that that these echoes that you 're hearing are , uh grad e: uh - huh . professor b: or pre - echoes , whichever they are are are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: uh - huh . professor b: be pretty simple . i mean , you do it in a pretty conservative way grad e: ok . professor b: so that if you made a mistake you were more likely to keep in an echo than to throw out speech . grad e: hmm . phd g: um , what is the reverberation time like there ? grad e: in thi in this room ? uh phd g: on , uh , the the one what the s in the speech that you are you are using like ? grad e: y yeah . i i i i do n't know . professor b: so , it 's this room . phd g: it 's , uh professor b: it 's it 's this room . phd g: oh , this room ? professor b: so phd g: ok . professor b: so it 's these are just microphone this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: oh . professor b: uh , we should do a measurement in here . i g think we never have . i think it 's i would guess , uh , point seven , point eight seconds f uh , r t grad f: hmm ! professor b: something like that ? but it 's you know , it 's this room . phd g: mm - hmm . professor b: so . phd g: ok . mm - hmm . professor b: uh . but the other thing is , he 's putting in w i was using the word `` reverberation `` in two ways . he 's also putting in , uh , a he 's taking out some reverberation , but he 's putting in something , because he has averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . and since , you know , what you subtract , sometimes you 'll be you 'll be subtracting from some larger number and sometimes you wo n't . and phd g: mm - hmm . mm - hmm . professor b: so you can end up with some components in it that are affected by things that are seconds away . uh , and if it 's a low energy compo portion , you might actually hear some funny things . phd g: yeah . grad e: o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system is just as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . phd c: mm - hmm . i do n't see why why your signal is louder after processing , because yo grad e: yeah . i do n't know why - y , uh , either . phd c: yeah . professor b: i do n't think just multiplying the signal by two would have any effect . phd c: mm - hmm . grad e: oh , ok . professor b: yeah . i mean , i think if you really have louder signals , what you mean is that you have better signal - to - noise ratio . phd c: well , well professor b: so if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: mm - hmm . professor b: but just it being bigger if with the same signal - to - noise ratio grad e: it w i i it would n't affect things . professor b: no . phd c: yeah . grad e: ok . phd c: well , the system is use the absolute energy , so it 's a little bit dependent on on the signal level . but , not so much , i guess . professor b: well , yeah . but it 's trained and tested on the same thing . phd c: mmm . professor b: so if the if the if you change in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: mm - hmm . yeah . phd a: did you add this data to the training set , for the aurora ? or you just tested on this ? grad e: uh um . did i w what ? phd a: well , morgan was just saying that , uh , as long as you do it in both training and testing , it should n't have any effect . grad e: sorry ? yeah . phd a: but i i was sort of under the impression that you just tested with this data . grad e: i i b phd a: you did n't train it also . grad e: i right . i trained on clean ti - digits . i i did the mean subtraction on clean ti - digits . but i did n't i 'm not sure if it made the clean ti ti - digits any louder . professor b: oh , i see . grad e: i only remember noticing it made the , um , pzm signal louder . professor b: ok . well , i do n't understand then . yeah . grad e: huh . i do n't know . if it 's if it 's like , if it 's trying to find a a reverberation filter , it could be that this reverberation filter is making things quieter . and then if you take it out that taking it out makes things louder . i mean . professor b: uh , no . i mean , uh , there 's there 's nothing inherent about removing if you 're really removing , grad e: nuh - huh . professor b: uh , r uh , then i do n't see how that would make it louder . grad e: the mean . ok . yeah , i see . professor b: so it might be just some grad e: yeah . ok . so i should maybe listen to that stuff again . professor b: yeah . it might just be some artifact of the processing that that , uh , if you 're uh , yeah . i do n't know . grad e: oh . ok . phd a: i wonder if there could be something like , uh for s for the pzm data , phd c: eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . uh . i 'm just wondering if there 's something about the , um you know , doing the mean normalization where , uh , it it could cause you to have better signal - to - noise ratio . um . professor b: well , you know , there is this . wait a minute . it it i maybe i if , um subtracting the the mean log spectrum is is is like dividing by the spectrum . so , depending what you divide by , if your if s your estimate is off and sometimes you 're you 're you 're getting a small number , you could make it bigger . phd a: mm - hmm . grad e: mm - hmm . professor b: so , it 's it 's just a a question of there 's it it could be that there 's some normalization that 's missing , or something to make it grad e: mm - hmm . professor b: uh , y you 'd think it should n't be larger , but maybe in practice it is . that 's something to think about . grad e: hmm . professor b: i do n't know . phd c: i had a question about the system the sri system . so , you trained it on ti - digits ? but except this , it 's exactly the same system as the one that was tested before and that was trained on macrophone . right ? so on ti - digits it gives you one point two percent error rate and on macrophone it 's still o point eight . uh , but is it exactly the same system ? grad e: uh . i think so . phd c: hmm . grad e: if you 're talking about the macrophone results that andreas had about , um , a week and a half ago , i think it 's the same system . phd c: mm - hmm . so you use vtl - uh , vocal tract length normalization and , um , like mllr transformations also , grad e: mm - hmm . phd c: and professor b: i 'm sorry , was his point eight percent , er , a a result on testing on macrophone or or training ? phd c: all that stuff . grad e: that 's phd c: it was training on macrophone and testing yeah , on on meeting digits . professor b: oh . so that was done already . so we were uh , and it 's point eight ? ok . phd c: mm - hmm . professor b: ok . phd c: yeah . i i 've just been text { comment } testing the new aurora front - end with well , aurora system actually so front - end and htk , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . we have i have two point seven percent error rate . and before with the system that was proposed , it 's what ? it was three point nine . so . professor b: oh , that 's a lot better . phd c: we are getting better . professor b: so , what w ? phd c: and phd g: with the with the htk back - end ? what we have for aurora ? phd c: yeah . two point seven . phd g: i know in the meeting , like phd c: on the meeting we have two point seven . phd g: right . oh . grad f: that 's with the new iir filters ? phd c: uh . yeah , yeah . so , yeah , grad f: ok . phd c: we have the new lda filters , and i think , maybe i did n't look , but one thing that makes a difference is this dc offset compensation . uh , eh do y did you have a look at at the meet uh , meeting digits , if they have a dc component , or ? grad e: i i did n't . no . phd c: oh . professor b: hmm . phd g: no . the dc component could be negligible . i mean , if you are recording it through a mike . i mean , any all of the mikes have the dc removal some capacitor sitting right in that bias it . professor b: yeah . but this uh , uh , uh , no . because , uh , there 's a sample and hold in the a - tod . and these period these typically do have a dc offset . phd g: oh , ok . professor b: and and they can be surprisingly large . it depends on the electronics . phd g: oh , so it is the digital ok . it 's the a - tod that introduces the dc in . professor b: yeah . the microphone is n't gon na pass any dc . phd g: yeah . yeah . yeah . professor b: but but , phd g: ok . professor b: typi you know , unless actually , there are instrumentation mikes that that do pass go down to dc . but but , phd g: mm - hmm . professor b: uh , no , it 's the electronics . and they and phd g: mm - hmm . professor b: then there 's amplification afterwards . and you can get , i think it was i think it was in the wall street journal data that that i ca n't remember , one of the darpa things . there was this big dc - dc offset phd a: mm - hmm . professor b: we did n't we did n't know about for a while , while we were messing with it . and we were getting these terrible results . and then we were talking to somebody and they said , `` oh , yeah . did n't you know ? everybody knows that . there 's all this dc offset in th `` so , yes . you can have dc offset in the data . phd g: oh , ok . professor b: yeah . phd g: ok . phd a: so was that was that everything , dave ? grad e: oh . and i also , um , did some experiments about normalizing the phase . um . so i c i came up with a web page that people can take a look at . and , um , the interesting thing that i tried was , um , adam and morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , did n't work . um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . they they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum was n't really mathematically correct . so , what i did instead is i took the mean of the fft spectrum without taking the log or anything , and then i took the phase of that , and i subtracted that phase off to normalize . but that , um , did n't work either . professor b: see , we have a different interpretation of this . he says it does n't work . i said , i think it works magnificently , but just not for the task we intended . uh , it gets rid of the speech . phd a: what does it leave ? grad f: uh , gets rid of the speech . professor b: uh , it leaves you know , it leaves the junk . i mean , i i think it 's it 's tremendous . grad f: oh , wow . professor b: you see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: well , could you take what was left over and then subtract that ? professor b: ex - exactly . yeah , you got it . grad f: yeah . phd g: yeah . professor b: so , it 's it 's a general rule . phd g: oh , it 's professor b: just listen very carefully to what i say and do the opposite . including what i just said . grad e: and , yeah , that 's everything . phd a: all set ? do you want to go , stephane ? phd c: um . yeah . maybe , concerning these d still , these meeting digits . i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . and um . yeah . so , i think i will maybe train , like , gender - dependent models , because this is also one big difference between the two systems . um , the other differences were the fact that maybe the acoustic models of the sri are more sri system are more complex . but , uh , chuck , you did some experiments with this and phd a: it did n't seem to help in the htk system . phd c: it was hard t to to have some exper some improvement with this . um . professor b: well , it sounds like they also have he he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: mm - hmm . professor b: you know , they have channel adaptation . they have speaker adaptation . phd c: yeah . right . phd a: well , there 's also the normalization . professor b: yeah . yeah . phd c: yeah . grad f: yeah . phd a: like they do , um i 'm not sure how they would do it when they 're working with the digits , phd c: the vocal tr phd a: but , like , in the switchboard data , there 's , um conversation - side normalization for the non - c - zero components , phd c: yeah . yeah . this is another difference . their normalization works like on on the utterance levels . phd a: mm - hmm . phd c: but we have to do it we have a system that does it on - line . phd a: right . phd c: so , it might be it might be better with it might be worse if the channel is constant , phd a: yeah . phd c: or nnn . phd g: and the acoustic models are like - k triphone models or or is it the whole word ? phd c: sri it 's it 's tr grad f: sri . phd g: yeah . phd c: yeah . i guess it 's triphones . phd g: it 's triphone . professor b: i think it 's probably more than that . phd c: huh . professor b: i mean , so they they have i i thin think they use these , uh , uh , genone things . so there 's there 's these kind of , uh , uh , pooled models and and they can go out to all sorts of dependencies . phd g: oh . it 's like the tied state . professor b: so . phd a: mm - hmm . professor b: they have tied states and i think i i i do n't real i 'm talk i 'm just guessing here . but i think i think they they do n't just have triphones . phd g: ok . professor b: i think they have a range of of , uh , dependencies . phd c: mm - hmm . phd g: mm - hmm . phd c: mm - hmm . grad f: hmm . phd c: and yeah . well . um . well , the first thing i that i want to do is just maybe these gender things . uh . and maybe see with andreas if well , i i do n't know how much it helps , what 's the model . phd a: so so the n stuff on the numbers you got , the two point seven , is that using the same training data that the sri system used and got one point two ? phd c: that 's right . so it 's the clean ti - digits training set . phd a: so exact same training data ? phd c: right . phd a: ok . phd c: mm - hmm . i guess you used the clean training set . grad e: right . phd c: mm - hmm . grad e: for with the sri system phd c: well . grad e: you know , the the aurora baseline is set up with these , um this version of the clean training set that 's been filtered with this g - seven - one - two filter , and , um , to train the sri system on digits s - andreas used the original ti - digits , um , under u doctor - speech data ti - digits , which do n't have this filter . but i do n't think there 's any other difference . phd c: mm - hmm . mm - hmm . yeah . professor b: so is that ? uh , are are these results comparable ? so you you were getting with the , uh , aurora baseline something like two point four percent on clean ti - digits , when , uh , training the sri system with clean tr digits { comment } ti - digits . right ? and grad e: um . uh - huh . professor b: yeah . and , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: yeah . i think so . professor b: ok . phd c: yeah . professor b: so it 's about the same , phd c: mm - hmm . professor b: maybe a little worse . grad e: w w it was one one point two phd c: ye grad e: with the sri system , professor b: i 'm sorry . phd c: yeah . grad e: i phd c: the complete sri system is one point two . professor b: you you were htk . phd c: yeah . professor b: right ? ok . that 's right . so phd c: mm - hmm . professor b: ok , so the comparable number then , uh for what you were talking about then , since it was htk , would be the um , two point f phd c: it was four point something . right ? the htk system with , uh , b grad e: d d professor b: oh , right , right , right , right . phd c: mfcc features grad e: do you mean the b ? the baseline aurora - two system , trained on ti - digits , tested on meeting recorder near , i think we saw in it today , and it was about six point six percent . professor b: right . right , right , right . phd c: oh . professor b: ok . alright . so he 's doing some different things . phd c: so yeah . the only difference is the features , right now , between this and professor b: yes . ok , good . so they are helping . phd c: mm - hmm . professor b: that 's good to hear . yeah . phd c: they are helping . yeah . um . yeah . and another thing i i maybe would like to do is to just test the sri system that 's trained on macrophone test it on , uh , the noisy ti - digits , professor b: yeah . phd c: cuz i 'm still wondering where this improvement comes from . when you train on macrophone , it seems better on meeting digits . but i wonder if it 's just because maybe macrophone is acoustically closer to the meeting digits than than ti - digit is , which is ti - digits are very clean recorded digits professor b: mm - hmm . phd c: and phd a: you know , it would also be interesting to see , uh to do the regular aurora test , phd c: uh , f s phd a: um , but use the sri system instead of htk . phd c: that 's yeah . that 's what i wanted , just , uh yeah . so , just using the sri system , test it on and test it on aurora ti - digits . right . phd a: why not the full aurora , uh , test ? phd c: um . yeah . there is this problem of multilinguality yet . phd a: mm - hmm . phd c: so we do n't professor b: you 'd have to train the sri system with with all the different languages . phd c: i i phd a: right . phd c: we would have to train on phd a: yeah . that 's what i mean . phd c: yeah . phd a: so , like , comple professor b: it 'd be a lot of work . that 's the only thing . phd c: yeah . phd a: mmm . phd c: it 's phd a: well , i mean , phd c: mmm . phd a: uh , uh , i guess the work would be into getting the the files in the right formats , or something . right ? i mean phd c: mm - hmm . phd a: because when you train up the aurora system , you 're , uh you 're also training on all the data . phd c: that 's right . phd a: i mean , it 's phd c: yeah . yeah . i see . oh , so , ok . right . i see what you mean . professor b: that 's true , but i think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: mm - hmm . professor b: because on on whatever it is they 're trying , because it 's a lot of work , even just with the htk . phd a: mm - hmm . professor b: so , it 's it 's a good idea , but it seems like it makes sense to do some pruning phd a: mm - hmm . professor b: first with a a test or two that makes sense for you , phd a: yeah . professor b: and then take the likely candidates and go further . phd a: yeah . phd c: mm - hmm . yeah . but , just testing on ti - digits would already give us some information about what 's going on . and mm - hmm . uh , yeah . ok . uh , the next thing is this this vad problem that , um , um so , i 'm just talking about the the curves that i i sent i sent you so , whi that shows that when the snr decrease , uh , the current vad approach does n't drop much frames for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: i i just to clarify something for me . i they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: mm - hmm . professor b: so does any of this matter ? i mean , other than our interest in it . uh phd c: uh well . first of all , the boundaries might be , uh like we would have t two hundred milliseconds or before and after speech . uh . so removing more than that might still make a difference in the results . professor b: do we ? i mean , is there some reason that we think that 's the case ? phd c: and no . because we do n't did n't looked that much at that . professor b: yeah . phd c: but , still , i think it 's an interesting problem . professor b: oh , yeah . phd c: and um . yeah . professor b: but maybe we 'll get some insight on that when when , uh , the gang gets back from crete . because there 's lots of interesting problems , of course . phd c: mm - hmm . professor b: and then the thing is if if they really are going to have some means of giving us fairly tight , uh , boundaries , then that wo n't be so much the issue . phd c: yeah , yeah . mm - hmm . mm - hmm . professor b: um but i do n't know . phd g: because w we were wondering whether that vad is going to be , like , a realistic one or is it going to be some manual segmentation . and then , like , if if that vad is going to be a realistic one , then we can actually use their markers to shift the point around , i mean , the way we want professor b: mm - hmm . phd g: to find a i mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more suitable for us . professor b: right . phd g: but if that is going to be something like a manual , uh , segmenter , then we ca n't use that information anymore , phd c: mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: right . phd g: so . we do n't know what is the type of vad which they 're going to provide . professor b: yeah . phd c: yeah . and actually there 's yeah . there 's an uh , i think it 's still for even for the evaluation , uh , it might still be interesting to work on this because the boundaries apparently that they would provide is just , um , starting of speech and end of speech uh , at the utterance level . and um . phd g: with some some gap . phd c: so phd g: i mean , with some pauses in the center , provided they meet that whatever the hang - over time which they are talking . phd c: yeah . but when you have like , uh , five or six frames , both phd g: yeah . then the they will just fill fill it up . phd c: it it with phd g: i mean , th yeah . phd c: yeah . professor b: so if you could get at some of that , uh phd c: so professor b: although that 'd be hard . phd c: yeah . it might be useful for , like , noise estimation , and a lot of other things that we want to work on . professor b: but but yeah . phd g: yeah . professor b: right . ok . phd c: but mmm . yeah . so i did i just started to test putting together two vad which was was not much work actually . um , i im re - implemented a vad that 's very close to the , um , energy - based vad that , uh , the other aurora guys use . um . so , which is just putting a threshold on the noise energy , professor b: mm - hmm . phd c: and , detect detecting the first group of four frames that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . so it removes the first silent portion portion of each utterance . and it really removes it , um , still o on the noises where our mlp vad does n't work a lot . professor b: mmm . phd c: uh , professor b: cuz i would have thought that having some kind of spectral information , phd c: and professor b: uh uh , you know , in the old days people would use energy and zero crossings , for instance uh , would give you some better performance . right ? cuz you might have low - energy fricatives or or , uh stop consonants , or something like that . phd c: mm - hmm . professor b: uh . phd c: yeah . so , your point is will be to u use whatever professor b: oh , that if you d if you use purely energy and do n't look at anything spectral , then you do n't have a good way of distinguishing between low - energy speech components and nonspeech . and , um , phd c: mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . and and most , um , low - energy speech components that are unvoiced have a a high - pass kind of characteristic phd c: mm - hmm . professor b: an upward slope . so having some kind of a phd c: yeah . professor b: uh , you know , at the beginning of a of a of an s sound for instance , just starting in , it might be pretty low - energy , phd c: mm - hmm . professor b: but it will tend to have this high - frequency component . whereas , a a lot of rumble , and background noises , and so forth will be predominantly low - frequency . uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of phd c: yeah . professor b: it plus energy plus timing information is sort of phd c: mm - hmm . professor b: i mean , if you look up in rabiner and schafer from like twenty - five years ago or something , that 's sort of what they were using then . phd c: mm - hmm . professor b: so it 's it 's not a phd c: mm - hmm . grad f: hmm . phd c: so , yeah . it it might be that what i did is so , removes like low , um , uh low - energy , uh , speech frames . because the way i do it is i just i just combine the two decisions so , the one from the mlp and the one from the energy - based with the with the and operator . so , i only keep the frames where the two agree that it 's speech . so if the energy - based dropped dropped low - energy speech , mmm , they they are they are lost . mmm . professor b: mm - hmm . phd c: but s still , the way it 's done right now it it helps on on the noises where it seems to help on the noises where our vad was not very good . professor b: well , i guess i mean , one could imagine combining them in different ways . but but , i guess what you 're saying is that the the mlp - based one has the spectral information . so . phd c: yeah . but yeah . but the way it 's combined wi is maybe done well , yeah . professor b: well , you can imagine phd c: the way i use a an a `` and `` operator is so , it i , uh professor b: is ? phd c: the frames that are dropped by the energy - based system are are , uh , dropped , even if the , um , mlp decides to keep them . professor b: right . right . and that might not be optimal , phd c: but , yeah . professor b: but phd c: mm - hmm . phd a: no professor b: but i mean , i guess in principle what you 'd want to do is have a uh , a probability estimated by each one and and put them together . phd c: yeah . mmm . m yeah . phd a: something that that i 've used in the past is , um when just looking at the energy , is to look at the derivative . and you make your decision when the derivative is increasing for so many frames . then you say that 's beginning of speech . phd c: uh - huh . phd a: but , i 'm i 'm trying to remember if that requires that you keep some amount of speech in a buffer . i guess it depends on how you do it . but i mean , that 's that 's been a useful thing . professor b: yeah . phd c: mm - hmm . grad f: mm - hmm . phd g: yeah . well , every everywhere has a delay associated with it . i mean , you still have to k always keep a buffer , phd a: mm - hmm . phd g: then only make a decision because you still need to smooth the decision further . phd a: right . right . phd g: so that 's always there . phd a: yeah . ok . phd c: well , actually if i do n't maybe do n't want to work too much of on it right now . i just wanted to to see if it 's what i observed was the re was caused by this this vad problem . professor b: mm - hmm . phd c: and it seems to be the case . um . uh , the second thing is the this spectral subtraction . um . um , which i 've just started yesterday to launch a bunch of , uh , twenty - five experiments , uh , with different , uh , values for the parameters that are used . so , it 's the makhoul - type spectral subtraction which use an over - estimation factor . so , we substr i subtract more , um , noise than the noise spectra that is estimated on the noise portion of the s uh , the utterances . so i tried several , uh , over - estimation factors . and after subtraction , i also add a constant noise , and i also try different , uh , noise , uh , values and we 'll see what happen . professor b: hmm . ok . phd c: mm - hmm . mm - hmm . but st still when we look at the , um well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . um . on the other hand , when you subtract more and when you add more noise , you get rid of this musical noise but maybe you distort a lot of speech . so . well . mmm . well , it until now , it does n't seem to help . but we 'll see . so the next thing , maybe i what i will try to to do is just to try to smooth mmm , the , um to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or phd g: can smooth the snr estimate , also . phd c: yeah . right . mmm . phd g: your filter is a function of snr . hmm ? phd c: yeah . so , to get something that 's would be closer to what you tried to do with wiener filtering . phd g: yeah . phd c: and mm - hmm . yeah . phd g: actually , it 's , uh uh . i do n't know , it 's go ahead . phd c: it phd g: and it 's phd c: maybe you can phd g: go ahead . phd c: i think it 's that 's it for me . phd g: ok . so , uh u th i 've been playing with this wiener filter , like . and there are there were some bugs in the program , so i was p initially trying to clear them up . because one of the bug was i was assuming that always the vad uh , the initial frames were silence . it always started in the silence state , but it was n't for some utterances . so the it was n't estimating the noise initially , and then it never estimated , because i assumed that it was always silence . phd c: mm - hmm . so this is on speechdat - car italian ? phd g: yeah . phd c: so , in some cases s there are also phd g: speechdat - car italian . yeah . there 're a few cases , actually , which i found later , that there are . phd c: o uh - huh . phd g: so that was one of the bugs that was there in estimating the noise . and , uh , so once it was cleared , uh , i ran a few experiments with different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the snr also . and so the the trend seems to be like , uh , smoothing the current estimate of the clean speech for deriving the snr , which is like deriving the wiener filter , seems to be helping . then updating it quite fast using a very small time constant . so we 'll have , like , a few results where the estimating the the more smoothing is helping . but still it 's like it 's still comparable to the baseline . i have n't got anything beyond the baseline . but that 's , like , not using any wiener filter . and , uh , so i 'm i 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing snr . so there are three time constants that i have . so , i 'm just playing around . so , one is fixed in the line , like smoothing the clean speech is is helping , so i 'm not going to change it that much . but , the way i 'm estimating the noise and the way i 'm estimating the snr , i 'm just trying trying a little bit . so , that h and the other thing is , like , putting a floor on the , uh , snr , because that if some in some cases the clean speech is , like when it 's estimated , it goes to very low values , so the snr is , like , very low . and so that actually creates a lot of variance in the low - energy region of the speech . so , i 'm thinking of , like , putting a floor also for the snr so that it does n't vary a lot in the low - energy regions . and , uh . so . the results are , like so far i 've been testing only with the baseline , which is which does n't have any lda filtering and on - line normalization . i just want to separate the the contributions out . so it 's just vad , plus the wiener filter , plus the baseline system , which is , uh , just the spectral i mean , the mel sp mel , uh , frequency coefficients . um . and the other thing that i tried was but i just took of those , uh , carlos filters , which hynek had , to see whether it really h helps or not . i mean , it was just a a run to see whether it really degrades or it helps . and it 's it seems to be like it 's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band - pass m m filter on the cubic root of the power spectrum . so , that was the filter that hy - uh , carlos had . and so yeah . just just to see whether it really it 's it 's is it worth trying or not . so , it does n't seems to be degrading a lot on that . so there must be something that i can that can be done with that type of noise compensation also , which i guess i would ask carlos about that . i mean , how how he derived those filters and and where d if he has any filters which are derived on ogi stories , added with some type of noise which what we are using currently , or something like that . so maybe i 'll professor b: this is cubic root of power spectra ? phd g: yeah . cubic root of power spectrum . professor b: so , if you have this band - pass filter , you probably get n you get negative values . right ? phd g: yeah . and i 'm , like , floating it to z zeros right now . professor b: ok . phd g: so it has , like the spectrogram has , like uh , it actually , uh , enhances the onset and offset of i mean , the the begin and the end of the speech . so it 's there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: mm - hmm . phd g: because the filter has , like , a sort of mexican - hat type structure . professor b: mm - hmm . phd g: so , those are the regions where there are , like when i look at the spectrogram , there are those deep valleys on the begin and the end of the speech . but the rest of it seems to be , like , pretty nice . professor b: mm - hmm . phd g: so . that 's something i observe using that filter . and yeah . there are a few very not a lot of because the filter does n't have a really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . so , i 'll i 'll s may continue with that for some w i 'll i 'll maybe i 'll ask carlos a little more about how to play with those filters , and but while making this wiener filter better . so . yeah . that that 's it , morgan . professor b: uh , last week you were also talking about building up the subspace stuff ? phd g: yeah . i i i would actually m m did n't get enough time to work on the subspace last week . it was mostly about finding those bugs and professor b: ok . phd g: th you know , things , and i did n't work much on that . phd a: how about you , carmen ? phd d: well , i am still working with , eh , vts . and , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: hmm ? phd d: and , maybe , talking with stephane and with sunil , we decide that maybe it was interesting to to apply on - line normalization before applying vts . but then we decided that that 's it does n't work absolutely , because we modified also the noise . and well , thinking about that , we we then we decide that maybe is a good idea . we do n't know . i do n't hav i do n't this is i did n't do the experiment yet to apply vts in cepstral domain . professor b: the other thing is so so , in i i and not and c - zero would be a different so you could do a different normalization for c - zero than for other things anyway . i mean , the other thing i was gon na suggest is that you could have two kinds of normalization with with , uh , different time constants . so , uh , you could do some normalization s uh , before the vts , and then do some other normalization after . i do n't know . but but c - zero certainly acts differently than the others do , phd d: uh . professor b: so that 's phd c: mm - hmm . phd d: well , we s decide to m to to obtain the new expression if we work in the cepstral domain . and well . i am working in that now , professor b: uh - huh . phd d: but i 'm not sure if that will be usefu useful . i do n't know . it 's k it 's k it 's quite a lot it 's a lot of work . professor b: uh - huh . phd d: well , it 's not too much , but this it 's work . professor b: yeah . phd d: and i want to know if if we have some feeling that the result i i would like to know if i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m mel in filter bank domain . i r i 'm not sure . i do n't i do n't know absolutely nothing . phd c: mm - hmm . professor b: yeah . well , you 're i think you 're the first one here to work with vts , so , uh , maybe we could call someone else up who has , ask them their opinion . uh , phd c: mm - hmm . professor b: i do n't i do n't have a good feeling for it . um . phd g: pratibha . phd c: actually , the vts that you tested before was in the log domain and so the codebook is e e kind of dependent on the level of the speech signal . phd d: yeah ? phd c: and so i expect it if if you have something that 's independent of this , i expect it to it to , uh , be a better model of speech . phd d: to have better phd c: and . well . professor b: you you would n't even need to switch to cepstra . right ? i mean , you can just sort of normalize the phd c: no . we could normali norm i mean , remove the median . professor b: yeah . yeah . and then you have one number which is very dependent on the level cuz it is the level , phd d: mm - hmm . professor b: and the other which is n't . phd c: mm - hmm . yeah . but here also we would have to be careful about removing the mean of speech and not of noise . phd d: ye phd c: because it 's like first doing general normalization phd d: yea phd c: and then noise removal , which is phd d: yeah . we i was thinking to to to estimate the noise with the first frames and then apply the vad , professor b: mm - hmm . phd c: mm - hmm . phd d: before the on - line normalization . phd c: mm - hmm . phd d: we we see well , i am thinking about that and working about that , professor b: yeah . phd d: but i do n't have result this week . professor b: sure . i mean , one of the things we 've talked about maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? because we 've talked about potentially doing some combination of a couple of them . maybe maybe pretty soon we 'll have some sense of what their characteristics are , phd d: mm - hmm . professor b: so we can see what should be combined . phd c: mm - hmm . phd a: is that it ? ok ? professor b: ok . why do n't we read some digits ? phd a: yep . want to go ahead , morgan ? professor b: sure . phd a: transcript l dash two one five . professor b: o k .","output":"phd c was skeptical of why the signal was louder after processing . phd c suggested that the system is not too dependent on the signal level , agreeing with the professor that improvement in the model was more likely dependent on the ratio ."},{"instruction":"what was the general discussion ?","input":"grad f: test . postdoc g: ok . professor b: let 's see , i should be two . phd d: up high grad e: as close to your mouth as you can get it . professor b: la phd d: high as you can get . professor b: is this channel one ? postdoc g: yeah , on your upper lip . phd h: channel one one one . professor b: gee , ok . yes . ok . grad e: ok , so for for for people wearing the wireless mikes , like like this one , i find the easiest way to wear it is sorta this this sorta like that . phd h: this is chan channel channel one one two three grad f: channel five , channel five . professor b: yeah . mm - hmm . what do you do , grad e: it 's actually a lot more comfortable then if you try to put it over your temples , grad f: test , test test . professor b: you do it higher ? grad e: so professor b: mm - hmm . phd d: adam 's just trying to generate good uh data for the recognizer there . postdoc g: yeah , i think we 're supposed to that 's right . grad e: and then also , for for all of them , if your boom is adjustable , the boom should be towards the corner of your mouth , grad f: test test . phd a: by the way , there was a bug . yeah , i it was n't using the proper phd d: oh it was . grad e: and about a uh a thumb to a thumb and a half distance away from your mouth , phd a: basically it was n't adapting anything . phd d: oh . grad e: so about like i 'm wearing it now . phd d: oh that 's interesting . so why did n't you get the same results and the unadapted ? grad e: so so jane , you could actually do even a little closer to your mouth , phd h: it 's not always possible . phd a: hmm ? phd d: why did n't you get the same results and the unadapted ? postdoc g: i could can this be adjuste like this ? grad e: but phd a: oh , because when it estimates the transformer pro produces like a single matrix or something . grad e: yep . postdoc g: is that @ @ ? ok , thank you . grad f: adam , i 'm not phd d: o oh oh i see . grad f: uh , looks kinda low on channel five phd d: i see , i see . professor b: ok . grad f: no ? grad e: channel five , s speak again . grad f: maybe not . postdoc g: hello . phd a: basically there were no counts grad e: yeah , that 's alright . grad f: hello ? grad e: i mean , we could we could up the gain slightly if you wanted to . grad f: it 's ok ? phd h: yeah . grad f: is this ok ? phd h: ok . phd d: i see what you mean . phd c: who 's channel b ? grad e: but uh , channel b is probably liz . phd c: uh oh . phd h: uh channel b i am channel b . professor b: you wan na close this , postdoc g: channel eight , eight . professor b: or phd c: no i grad e: thank you . phd h: no , channel b . phd a: hello , hello . phd c: yeah , yeah , you 're channel b . phd h: yeah , yeah . phd c: so can you talk a bit ? i thought it might be too phd h: ok , yeah , channel b , one two three four five . phd c: ok . grad e: yeah , it 's alright . so , the gain is n't real good . professor b: we 're recording , phd c: ok . professor b: right ? grad e: ok , so we are recording . phd h: ah . professor b: yeah . phd a: ok . grad e: um everyone should have at least two forms possibly three in front of you depending on who you are . grad f: oh . grad e: um we we 're doing a new speaker form and you only have to spea fill out the speaker form once but everyone does need to do it . and so that 's the name , sex , email , et cetera . phd h: mm - hmm . grad e: we we had a lot of discussion about the variety of english and so on so if you do n't know what to put just leave it blank . um i i designed the form and i do n't know what to put for my own region , phd a: mmm . grad e: so phd d: california . phd a: i think grad e: california . phd h: california . phd a: um may i make one suggestion ? instead of age put date of uh year of birth grad e: sure . phd a: because age will change , but the year of birth changes , you know , stays the same , usually . grad e: oh . phd c: a actually , wait a minute , grad e: birth year ? postdoc g: although on phd a: yeah . phd c: should n't it be the other way around ? phd d: not for me . postdoc g: course on the other on the other hand you could you view it as the age at the time of the phd c: on the other side , phd a: well the thing is , if ten years from now you look at this form knowing that phd c: yeah . postdoc g: yes , but what we care about is the age at at the recording date rather than the phd c: o yeah . phd d: but there 's no other date on the form . phd c: w we do n't care how they old they really are . phd a: well well i do n't know . postdoc g: yes . unless we wan na send them a card . grad e: well i guess it depends on how long the corpus is gon na be collected for . phd a: anyway . postdoc g: yeah , that 's true . phd c: i still do n't see the problem . grad e: either way yeah i think i think age is alright phd a: ok . grad e: and then um there will be attached to this a point or two these forms uh so that you 'll be able to extract the date off that phd a: mm - hmm . grad e: so , anyway . and so then you also have a digits form which needs to be filled out every time , the speaker form only once , the digit form every time even if you do n't read the digits you have to fill out the digits form so that we know that you were at the meeting . ok ? and then also if you have n't filled one out already you do have to fill out a consent form . and that should just be one person whose name i do n't know . ok ? grad f: do you want this adam ? grad e: uh sure . thank you . professor b: so uh grad e: ok so should we do agenda items ? professor b: uh oh that 's a good idea . i should n't run the meeting . grad e: uh well i have i wan na talk about new microphones and wireless stuff . postdoc g: mmm . grad e: and i 'm sure liz and andreas wan na talk about recognition results . anything else ? phd c: i guess what time do we have to leave ? three thirty ? phd a: yeah . phd c: yeah , grad e: why do n't you go first then . phd c: so . professor b: yeah , good idea . phd a: ok . phd c: um well , i i sent out an email s couple hours ago so um with andreas ' help um andreas put together a sort of no frills recognizer which is uh gender - dependent but like no adaptation , no cross - word models , no trigrams a bigram recognizer and that 's trained on switchboard which is telephone conversations . um and thanks to don 's help wh who don took the first meeting that jane had transcribed and um you know separated used the individual channels we segmented it in into the segments that jane had used and uh don sampled that so so eight k um and then we ran up to i guess the first twenty minutes , up to synch time of one two zero zero so is that that 's twenty minutes or so ? um yeah because i guess there 's some , grad e: or so . phd c: and don can talk to jane about this , there 's some bug in the actual synch time file that ah uh i 'm we 're not sure where it came from but stuff after that was a little messier . anyway so it 's twenty minutes and i actually grad e: hmm . phd c: um grad e: i was that did that did that recording have the glitch in the middle ? postdoc g: i 'm puzzled by that . i oh oh , i see . phd c: there 's there 's a postdoc g: oh there was a glitch somewhere . phd c: yeah , so that actually um grad f: was it twenty minutes in , phd c: if it was twenty minutes in then i do n't know postdoc g: i forgot about that . grad f: i thought phd a: well it was interesting , postdoc g: well , i mean , they phd a: suddenly the the overall error rate when we first ran it was like eighty percent grad e: i do n't remember when it is . postdoc g: but i was able to can transcribe phd a: but i looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the it was actually recognized phd c: wel grad e: oh no . grad f: yeah , that might be that might be that might be my fault . postdoc g: wow . phd a: so grad e: oh so that was just a parsing mismatch . grad f: i 'm not phd a: ok . phd c: no actually it was yeah i it was a complicated bug because they were sometimes one off and then sometimes totally random so um grad f: yeah , i was pretty certain that it worked up until that time , postdoc g: oh . that 's not good . phd c: yeah phd a: ok . phd c: so that 's what we have grad e: alright . grad f: so phd c: but that that will be completely gone if this synch time problem postdoc g: yeah . grad e: the the glitch phd a: so so we have everything recognized but we scored only the first uh whatever , up to that time to postdoc g: and the only glitch grad e: yeah . postdoc g: yeah . phd c: so you guys know . professor b: s sorry i have n't seen the email , phd c: yeah . grad e: th - the postdoc g: the the well wait professor b: what was the score ? phd c: so here 's the actual copy of the email postdoc g: we should say something about the glitch . he he can say something about the glitch . phd c: um oh ok grad e: yeah . postdoc g: cuz it 's it 's it 's h it 's it 's very small phd c: so does this glitch occur at other grad e: there there there 's an acoustic glitch that occurs where um the channels get slightly asynchronized postdoc g: very small . yep . phd c: oh . phd a: mmm . phd c: right . grad e: so the that that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for a fraction of a second professor b: hmm . grad f: hmm . grad e: and so the channels get a little asynchronous and so if you listen to it in the middle there 's a little part where it starts doing doing click sounds . professor b: so phd c: and is it only once that that happens ? grad e: but yeah phd c: ok . grad e: it right once in the middle . phd c: there 's the previous page has some more information about sort of what was wrong professor b: so so un unsurprisingly adam is the golden voice , phd c: but grad e: um but that should n't affect anything phd c: ok so that 's actually postdoc g: s and it professor b: you see this here ? phd c: it y it 's grad e: yeah yeah `` bah `` phd c: ok no phd a: oh , and phd c: what happens is it actually affects the script that don phd d: huh . phd c: i mean if we know about it then i guess it could always be checked for it grad e: well the acoustic one should n't do anything . phd c: but they grad f: yeah , i do n't know exactly what affected it postdoc g: i agree . i agree . phd a: i i have grad f: but i 'll i 'll talk to you about it , phd a: yeah . grad e: but i i do remember phd c: yeah . grad f: i 'll show you the point . postdoc g: yeah . it it had no effect on my transcription , phd a: mmm . postdoc g: you know , i mean i i had no trouble hearing it and and having time bins grad e: i do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect . postdoc g: but there was a oh . phd c: well , the the synch time the synch numbers have more significant digits than they should , grad f: that 's what happened . postdoc g: oh . phd h: yeah . grad e: where where they were n't monotonic . grad f: there was yeah , i mean phd c: right ? there 's things that are l in smaller increments than a frame . phd h: yeah . postdoc g: oh , interesting . phd c: and so then , i mean you look at that and it 's got you know more than three significant digits in a synch time then that ca n't be right grad e: oh ok so that 's grad f: hmm . postdoc g: oh . phd a: mmm . phd c: so anyway it 's it 's just grad e: yeah sounds like a bug . postdoc g: yeah . phd c: that 's why we only have twenty minutes but there 's a significant amount of grad f: non - zero ? um there are like more cuz there 's a lot of zeros i tacked on just because of the way the script ran , grad e: the other one i saw was that it yeah . grad f: i mean but there were there was a point . phd c: yeah that was fine . that that was ok . grad e: the other one i saw was non non - monotonic synch times grad f: ok . grad e: and that definitely indicra indicates a bug . grad f: uh . phd c: well that would really be a problem , yeah . so anyway these are just the ones that are the prebug for one meeting . grad f: yeah . phd c: um and what 's which grad e: so that 's very encouraging . phd c: this is really encouraging cuz this is free recognition , professor b: hmm . phd h: yeah . professor b: cool . phd a: mmm . phd c: there 's no i mean the language model for switchboard is totally different so you can see some like this trent lott which phd d: trent lott . phd c: um i mean these are sort of funny ones , phd d: it 'll get those though . phd c: there 's a lot of perfect ones and good ones and all the references , i mean you can read them and when we get more results you can look through and see grad e: i and as i said i would like to look at the lattices phd a: mm - hmm . phd c: but um it 's pretty good . grad e: because it sounded like even the ones it got wrong it sort of got it right ? phd c: well so i guess we can generate grad e: sounds likes ? phd a: there are a fair number of errors that are , you know where got the plural s wrong or the inflection on the verb wrong . postdoc g: mm - hmm . phd c: um grad e: yeah , and who cares ? and and there were lots of of course the `` uh uh `` - s , `` in on `` - s `` of uh `` - s . phd a: mmm , so if phd c: there 's no those are actually phd a: yeah . phd c: a lot of the errors i think are out of vocabulary , phd a: mm - hmm . phd c: so is it like pzm is three words , it 's pzm , phd a: mm - hmm . phd c: i mean there 's nothing there 's no language model for pzm or grad e: right . ri - ri right . phd c: um grad e: did you say there 's no language for pzm ? phd c: no language model , i mean those grad e: do you mean so every time someone says pzm it 's an error ? maybe we should n't say pzm in these meetings . phd c: well well there 's all kinds of other stuff like jimlet and i mean um anyway there grad e: yeah , that 's right , jimlet . professor b: well , we do n't even know what that means , phd c: so but this is really encouraging because professor b: so i grad e: yeah , that 's right . phd c: so , i mean the bottom line is even though it 's not a huge amount of data um it should be uh reasonable to actually run recognition and be like within the scope of of r reasonable s you know switchboard this is like h about how well we do on switchboard - two data with the switchboard - one trained mostly trained recognizer grad e: right . phd c: and switchboard - two is got sort of a different population of speakers and a different topic grad e: excellent . phd c: and they 're talking about things in the news that happened after switchboard - one so there was @ @ so that 's great . professor b: yeah . yeah so we 're in better shape than we were say when we did had the ninety - three workshop phd c: um professor b: and we were all getting like seventy percent error on switchboard . phd a: mm - hmm . phd c: oh yeah professor b: you know phd c: i mean this is really , phd a: mmm . phd c: and thanks to andreas who , i mean this is a phd a: mmm . grad e: well especially for the very first run , i mean you phd a: oh it 's the professor b: yeah . phd c: eh um professor b: yeah . phd c: yeah grad e: the first run i ran of switchboard i got a hundred twenty percent word error but phd c: so and what al also this means is that postdoc g: right . phd c: um grad e: not switchboard , phd a: well it 's phd c: i mean there 's a bunch of things in this note to various people grad e: uh broadcast news . phd c: especially i guess um with jane that that would help for since we have this new data now uh in order to go from the transcripts more easily to um just the words that the recognizer would use for scoring . i had to deal with some of it by hand but i think a lot of it can be automated s by professor b: oh one thing i guess i did n't get so you know the language model was straight from from bigram from switchboard the acoustic models were also from switchboard or or phd a: yeah . phd c: yeah . professor b: so they did n't have anything from this acoustic data in yet ? postdoc g: that 's amazing . grad e: yeah , so that 's great . phd c: no . professor b: ok . phd c: and actually we actually um used switchboard telephone bandwidth models postdoc g: that 's amazing . phd a: well that 's those are the only we ones there are , professor b: yeah . phd c: which i guess phd d: i was just gon na say , phd c: so that 's the on that 's the only acoustic training data that we have a lot of phd d: yeah . phd a: i mean grad e: yeah . phd a: right . phd c: and i guess ramana , so a guy at sri said that um there 's not a huge amount of difference going from professor b: right . phd c: it 's it 's not like we probably lose a huge amount but we wo n't know because we do n't have any full band models for s conversational speech . phd d: it 's probably not as bad as going f using full band models on telephone band speech phd c: so . phd a: oh yeah . phd c: right . phd d: right ? phd a: yeah . professor b: yeah , phd c: right , so it 's so professor b: but for broadcast news when we we played around between the two there was n't a huge loss . grad e: right , it was not a big deal . phd c: yeah phd a: i should i should say that the language model is not just switchboard phd c: so i wou so that 's good . grad e: although combining em worked well . phd a: it 's also i mean there 's uh actually more data is from broadcast news but with a little less weight phd c: yeah . phd a: uh because professor b: uh - huh . phd c: like trent lott must have been from phd a: mm - hmm , right . phd c: i guess switchboard was before phd a: um by the way just for fun we also ran , phd c: uh . professor b: good point . phd a: i mean our complete system starts by doing ge a gender detection professor b: mm - hmm . phd a: so just for the heck of it i ran that grad e: and it said a hundred percent male ? phd a: um and it might be reassuring for everybody to know that it got all the genders right . phd c: the j phd a: yeah so grad e: oh it did ? postdoc g: oh that 's i 'm glad . grad e: it got all two genders ? phd c: yeah but you know jane and adam have you kn about equal performance phd a: yeah . yes . phd c: and uh and that 's interesting cuz i think the their language models are quite different so and i i 'm pretty sure from listening to eric that , you know given the words he was saying and given his pronunciation that the reason that he 's so much worse is the lapel . professor b: yeah . grad e: right . postdoc g: that makes a lot of sense , phd c: so it 's nice now if we can just sort of eliminate the lapel one when when we get new microphones postdoc g: yeah . very possible . professor b: yeah i i i would bet on that too phd c: that would be worth it professor b: cuz he certainly in that when as a as a burp user he was he was a pretty uh strong one . phd c: um yeah grad e: sheep . phd c: he he he sounded to me just from he sounded like a , professor b: yeah . phd c: what 's it a sheep or a goat ? professor b: sheep . grad e: a sheep . phd c: sheep , grad e: baah . professor b: yeah . sheep is good . phd c: right . sounded good . professor b: yeah . phd c: right so um so i guess the good news is that postdoc g: mm - hmm . phd c: and and again this is without a lot of the sort of bells and whistles that we c can do with the sri system and we 'll have more data and we can also start to maybe adapt the language models once we have enough meetings . so this is only twenty minutes of one meeting with no no tailoring at all . phd a: i mean clearly there are um with just a small amount of uh actual meeting transcriptions uh thrown into the language model you can probably do quite a bit better because the phd c: yeah . the voca the vocabulary especially grad e: or just dictionary . phd c: yeah . phd a: not that much the vocabulary actually phd c: yeah , so . phd a: i think um well we have to see but it 's uh phd c: yeah . it 's pretty good um so then professor b: have to add pzm and so on grad e: and i have to try it on the far field mike professor b: but phd c: pzm grad e: yeah . phd c: and then there 's things like for the transcription i got when someone has a digit in the transcript i do n't know if they said , you know one one or eleven and i do n't know if they said tcl or tcl . there 's things like that where , you know the um we 'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and i 'm hoping and this is this is good news because that means the force alignments should be good and if the force alignments , i mean it 's good news anyway but if the force alignments are good we can get all kinds of information . for example about , you know prosodic information and speaker overlaps and so forth directly from the aligned times . um so that 'll be something that actually in order to assess the forced alignment um we need s some linguists or some people to look at it and say are these boundaries in about the right place . because it 's just gon na give us time marks phd d: but you know grad e: well we 've done that for one meeting . phd c: so . for forced alignment . grad e: uh oh oh f not for words phd c: ye - right . grad e: i 'm sorry just for overlaps is we did it for not not for words . phd c: right . so this would be like if you take the words um you know and force align them on all the individual close talk uh close talking mikes then how good are these sort of in reality grad e: right . phd c: and then i was thinking it grad e: so we might want to take twenty minutes and do a closer word level transcription . maybe actually mark the word boundaries . phd c: oh or i have someone look at the alignments uh maybe a linguist who can say um you know roughly if these are ok and how far away they are . professor b: yeah . phd c: um but i think it 's got ta be pretty good because otherwise the word recognition would be really b crummy . grad e: right , right . phd c: it would n't necessarily be the other way around , if the wor word recognition was crummy the alignment might be ok but if the word recognition is this good the alignment should be pretty good . so that 's about it . professor b: i r phd d: i wonder if this is a good thing or a bad thing though , i mean if we 're pr grad e: that we 're starting so well ? phd d: yeah if we 're producing a database that everybody 's gon na do well on professor b: oh grad e: do n't worry about it w d that 's that 's the close talking mikes . try it on the p z ms and and professor b: yeah , which i would which well n n n n phd d: so the real value of the database is these ? phd h: yeah , yeah , yeah , yeah . grad e: yeah , abso well no but professor b: i mean there 's still just the w the percentages and , i mean they 're not a as we 've talked about before there 's probably overlaps phd c: this i yeah . this is not that good . professor b: there 's probably overlaps in in uh in fair number in switchboard as well so but but there 's other phenomena , it 's a meeting , it 's a different thing and there 's lots of stuff to learn with the close talking mikes but uh yeah certainly i 'd like to see as soon as we could , i mean maybe get some of the glitches out of the way but soon as we could how well it does with say with the p z ms or maybe even one of the phd c: right . professor b: and uh see if it 's , you know is it a hundred twenty percent or maybe it 's not maybe if with some adaptation you get this down to fifty percent or forty - five percent or something and and then if for the pzm it 's seventy or something like that that 's actually something we could sort of work with a little bit phd c: yeah . professor b: so phd c: no i think it 's really , i mean this way we least have a baseline we know that for instance the transcripts are very good so once you can get to the words that the recognizer which is a total subset of the things you need to understand the the text um yeah they 're pretty good so and and it 's converting automatically from the xml to the chopping up the wave forms and so forth it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard so that 's good . and um let 's see there was one more thing i wanted to to mention i ca n't remember um sorry ca n't remember . anyway it 's postdoc g: congratulations is really great . professor b: yeah . phd c: well it was , i mean i really did n't do this myself grad e: yeah , it 's really good . phd c: so andreas set up this recognizer and by the way the recognizer all the files i 'm moving to sri and running everything there so i brought back just these result files and people can look at them um so phd a: we we talked about setting up the sri recognizer here . that 's you know if if there are more machines um uh here plus people can could run their own uh you know variants of of of the recognition runs um certainly doable . um . professor b: yeah and well certainly if the recognition as opposed to training , yeah . phd a: yeah . professor b: seems reasonable . postdoc g: i need t hmm . i need to ask one question . phd a: yeah . postdoc g: which is um so this issue of the uh legalistic aspects of the pre - sent you know pre - adapted yeah , well , so what i mean is um the uh the data that you take into sri , first first question , you 're maintaining it in in a place that would n't be publicly readable that that kind of stuff , right ? phd a: u um phd c: from the outside world or postdoc g: by uh people uh who are not associated with this project . phd a: oh . grad e: it 's human subjects issues , i told you about that . phd c: um oh . postdoc g: exactly . phd c: well ok we have n no names . although i sh um grad e: that that 's not the issue , phd c: de audio data itself ? grad e: it 's just the audio data itself , until people have a chance to edit it . postdoc g: mm - hmm , exactly . phd c: uh so well i can i can protect my directories through there . postdoc g: yeah . phd c: right now they 're not they 're in the speech group directories which so i will postdoc g: great . phd c: i did n't know that actually . professor b: yeah so we just have to go through this process of having people approve the transcriptions , phd c: yeah ok . professor b: say it 's ok . phd c: right ok . postdoc g: yeah , we had to get them to approve em and then i cuz cuz the other question i was gon na ask is if we 're having um you know it 's but this this meeting that you have , no problem cuz i i well i mean i i speak for myself grad e: it 's us . postdoc g: but but i think that we did n't do anything that but well anyway so uh i would n't be too concerned about it with respect to that although we should clear it with eric and dan of course but these results are based on data which have n't had the uh have n't had the chance to be reviewed by the subjects phd c: that 's true . postdoc g: and i do n't know how that stands , i mean if you if you get fantastic results and it 's involving { comment } data which which later end up being lessened by , you know certain elisions , then i do n't know but i wanted to raise that issue , professor b: well we , postdoc g: that 's all . professor b: i mean once we get all this streamlined it may be sh it hopefully it will be fairly quick but we get the transcriptions , people approve them and so on it 's just that we 're grad e: alright we need to work at a system for doing that approval so that we can send people the transcripts postdoc g: great . phd a: mmm . postdoc g: yeah . grad e: and get back any bleeps that they want phd c: yeah actually the bleeps are also an issue i thought . professor b: it 's gon na be a rare thing that there 's a bleep for the most part . phd a: u uh actually i had a question about the downsampling , um i do n't know who , i mean how this was done but is is there are there any um issues with downsampling phd c: don did this . phd a: because i know that the recognizer um that we use h can do it sort of on the fly um so we would n't have to have it eh you know do it uh explicitly beforehand . and is there any um i are there other d sev uh is there more than one way to do the downsampling where one might be better than another ? grad f: there are lots of w there are lots of ways to do the downsampling um different filters to put on , phd a: ok . right . ok . grad f: like anti - aliasing stuff . phd a: so so the th grad e: i do n't think we even know which one i assume you 're using syncat to do it ? grad f: no , i 'm using uh sn snd uh are resample . grad e: or sound resample ? phd c: re - re ref grad e: resample . phd c: yeah . grad e: yeah and dan 's archaic acronyms . grad f: rsmp . yeah , i do n't really . phd c: missing all the vowels . grad f: i just yeah i found it . phd c: some of the vowels , grad e: not all of them . phd c: almost all the vowels , that 's the hard part . phd a: so so the other thing we should try is to just take the original wave forms , grad e: and a few of the consonants . phd a: i mean segment them but not downsample them . phd c: yeah we could we could try that and and compare phd a: and and feed them to feed them to the sri recognizer and see if if the sri front - end does something . grad f: yeah , that 's phd c: yeah . grad e: i suspect that 's sort of premature optimization , but sure . phd c: we can try it . i i only downsampled them first cuz i was phd a: well grad f: i mean that 's just one line that 's one line of code to comment at phd c: yeah phd a: right and and it does n't is no more work for um you know for us . grad f: so grad e: mm - hmm . grad f: yeah . phd c: well they 're just bigger to transfer , that 's why i s downsampled them before but phd a: well but they 're only twice as big so phd c: well i mean that was if it 's the same then we can downsample here phd a: i mean it 's it 's just a phd c: but if it 's grad f: although those eighty meg files take a while to copy into my directories phd c: yeah . grad f: so , but no , i mean it 's not i it would n't be a problem if you 're interested in it phd c: we could try that . phd a: yeah i mean it would be uh you know it would probably take uh about um you know grad f: it would phd a: minus the transfer time it would it would take uh you know ten minutes to try and and and grad f: yeah . grad e: it 's about a fifty minute drive , right ? phd a: and and if for some reason we see that it works better then we might investigate why phd c: well it takes more disk space too so i was just phd a: and , you know , what yeah . grad f: mmm . in the front - end we could do that . phd a: yeah . professor b: so you just train just different filters grad f: yeah , i professor b: and so you 're just wondering whether the filter is grad f: yeah , i can imagine it would be phd a: right . right . phd c: so we could try that with this particular twenty minutes of speech and sort of see if there 's any differences . grad f: i mean i guess there 's some phd a: you know a at some point someone might have optimized whatever filtering is done for the actual recognition um performance . grad f: hmm . phd a: so in other words right , professor b: right . phd a: so grad e: it just seems to me that , you know small changes to the language model and the vocabulary will so swamp that that it may be premature to worry about that . i mean so one is a half a percent better than the other i do n't think that gives you any information . phd c: well it 's just as easy to to give you the sixteen k individual , grad e: yep . phd c: it was just more disk space you know for storing them professor b: are you are you using uh uh mel cepstrum or plp over there ? phd c: so phd a: mel cepstrum . professor b: so probably does n't matter . phd c: well we could try . grad f: there 's there 's your answer . professor b: but but it would n't hurt to try , phd c: could easily try phd a: that 's what i would assume but you never know , professor b: yeah . phd c: so phd a: you know . professor b: sure . no the reason i say this postdoc g: just mm - hmm . professor b: plp uses uh auto - regressive filtering and uh modeling and so it can be sensitive to the kind of filtering that you 're doing phd a: mm - hmm . professor b: but uh uh mel cepstrum uh might not b you would n't expect to be so much but phd c: well we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti stick them somewhere grad f: yeah , it 's it 's really not a problem . phd a: actually , no . phd c: and i 'll rerun it with phd a: do n't stop . do n't stop at that part because we 're actually using the entire conversation to estimate the speaker parameters , grad f: keep going . yeah . phd a: so should n't use you should s you know , get grad f: yeah , i mean i 'll i have to do is eh e the reference file would stay the same , phd c: ok . phd a: right . grad f: it 's just the individual segments would be approximately twice as long phd a: mmm . phd c: right . right . grad f: and i could just replace them with the bigger ones in the directory , phd a: right . phd c: i mean i corrected all grad e: yeah . grad f: that 's not a problem . phd c: i mean i hand - edited the whole the whole meeting so that can be run it 's just once we get the the bug out . phd a: mmm . postdoc g: one one question which is i i had the impression { comment } from this from this meeting that w that i transcribed that um that there was already automatic downsampling occurring , phd a: yeah . mm - hmm . postdoc g: is that i thought that in order to grad e: yep . postdoc g: so it was so it 's like there 's already down grad e: there 's one level that 's already happening right here . professor b: this is being recorded at forty - eight kilohertz . which is more that anybody needs postdoc g: ok . grad e: right . grad f: oh . grad e: and it gets downsampled to sixteen . postdoc g: ok . professor b: so phd c: and that 's actually said in your meeting , grad f: hmm . postdoc g: oh ok . phd c: that 's how i know that . postdoc g: that 's exactly , and that 's how i know it . professor b: yeah . phd c: i i it 's like are we downsampling to sixteen ? professor b: it 's a digital audio orientation for the board phd c: right . phd a: mmm . professor b: it 's in the monitor so it 's phd c: thank god it 's not more than that . grad e: so professor b: yeah . grad e: and i have no idea what filter it 's using , grad f: is eight kilohertz is is eighty kilohertz generally accepted as like standard for voice ? grad e: so professor b: for telephone stuff . grad e: telephone . phd d: telephone . grad f: yeah that 's what i was gon na say , i mean like professor b: so it 's it 's it 's just that they were operating from switchboard which was a completely telephone database grad f: so oh , i see , so . professor b: and so that was a standard for that sixteen s grad f: ok . grad e: so sixteen seems to be pretty typical for with this sort of thing . professor b: sixteen is more common for for uh broadband stuff that is n't grad f: right . grad e: that is n't music . professor b: that is n't music and is n't telephone , phd c: and i guess if you 're comparing like uh if you wan na run recognition on the pzm stuff you would want you do n't want to downsample the wh that professor b: yeah . grad e: why is that ? professor b: i do n't know . phd c: right ? well i don i mean if it 's any better professor b: no actually i would think that you would you would get better you 'd get better high frequencies in the local mike . grad e: all the way around i 'd think . professor b: uh but who knows ? i mean we do we we we we we wan na find all this stuff out , phd c: yeah well we could try it . grad e: yeah . professor b: we do n't know . grad e: we 're gon na have plenty of low frequency on the p z ms with the fans . phd c: ok . yeah . professor b: uh yeah . yeah . phd c: oh yeah there was just one more thing i wanted to say which is totally unrelated to the recognition except that um well well it 's sort of related but um good news also uh i got well chuck fillmore agreed to record meetings but he had too many people in his meetings and that 's too bad cuz they 're very animated and but uh jerry also agreed so uh we 're starting on on phd a: they 're less animated . phd c: well but he has fewer he he wo n't have more than eight and it 's a meeting on even deeper understanding , edu , so that sounds interesting . as a compliment to our front - end meeting grad e: dot edu ? phd c: and um so that 's gon na start monday and one of the things that i was realizing is um it would be really great if anyone has any ideas on some kind of time synchronous way that people in the meeting can make a comment to the person whose gon na transcribe it or or put a push a button or something when they wan na make a note about `` oh boy you should probably erase those last few `` or uh `` wait i want this not to be recorded now `` or uh something like that s professor b: were n't we gon na do something with a pad at one point ? postdoc g: the cross pads ? grad e: yeah , we could do it with the cross pads . phd c: cuz i was thinking you know if if the person who sets up the meeting is n't there and it 's a group that we do n't know um and this came up talking to to jerry also that you know is there any way for them to indicate to make sure that the qu request that they have that they make explicitly get addressed somehow professor b: yeah . phd c: so i do n't know if anyone has ideas or you could even write down `` oh it 's about three twenty five and `` professor b: well what i was just suggesting is is we have these this cross pad just for this purpose grad e: yeah , and use that . professor b: and just use that grad e: not a bad idea . professor b: and if we sink it in phd c: that would be great . professor b: the other thing is eh phd c: that be great . professor b: i do n't know if you know this or if it 's a question for the mail to dan but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? grad e: i do n't know . i do n't know . i 'll send mail to dan and ask . i i think that it 's the maximum we can do without a lot of effort because it 's one board with two digital channels . professor b: oh it is one board . grad e: e eight each . so it it takes two fibers in to the one board . and so w i think if we wan na do that more than that we 'd have to have two boards , and then you have the synchronization issue . professor b: but that 's a question because that would if it was possible cuz it is i you know already we have a a a group of people in this room that can not all be miked grad e: right . professor b: and it 's not just cuz we have n't been to the store , right it 's phd d: what is the limit on each of those f fiber channels , is it the grad e: eight . phd d: it just it 's eight channels come in , does it have do with the sampling rate ? grad e: it 's eight . i have no idea . but each each fiber channel has eight eight channels and there are two ch two fibers that go in to the card . professor b: it might be a hard limitation , grad e: so professor b: i mean one thing is it the whole thing as i said is is all structured in terms of forty - eight kilohertz sampling so that pushes requirements up a bit grad e: yeah . professor b: but phd d: i was just wondering if if that could change . grad e: i mean then we 'd also have to get another add and another mixer and all that sort of stuff . phd d: if we could drop that . professor b: yeah . grad e: so i i 'll send a mail to dan and ask him . professor b: yeah . grad e: ok on the uh are we done with that ? so the oth topic is uh getting more mikes and different mikes , so i got a quote um we can fit we have room for one more wireless and the wireless , this unit here is three fifty three hundred fifty dollars , it i did n't realize but we also have to get a tuner the receiver the other end , that 's uh four thirty um and then also phd c: for for each ? phd d: wow . phd c: i mean the tuner is four thirty for each . grad e: yep . phd c: wow . grad e: and we just need one more so so professor b: yeah at least w we got the good ones . grad e: yeah . so that 's you know something like seven hundred eighty bucks for one more of these . professor b: yeah . ok . grad e: um and then also um it turns out that the connector that this thing uses is proprietary of sony phd d: oh . grad e: believe it or not and sony only sells this headset . postdoc g: mmm . grad e: so if we wan na use a different set headset the solution that the guy suggested and they apparently lots of people have done is sony will sell you the jack with just wires coming out the end and then you can buy a headset that has pigtail and solder it yourself . and that 's the other solution and so the jacks are forty bucks apiece and the he recommended um a crown cm three eleven ae headset for two hundred bucks apiece . professor b: there is n't this some sort of thing that plugs in , you actually have to go and do the soldering yourself ? grad e: becau - the reason is the only only thing you can get that will plug into this is this mike or just the connector . professor b: no i understand . the reason i ask is these sort of handmade uh wiring jobs fall apart in use so the other thing is to see if we can uh get them to do a custom job and put it together for this . grad e: oh i 'm sure they would , they would just charge us , phd d: well , and they 'd probably want quantity too , grad e: so . professor b: well phd d: they 'd professor b: no they 'll just charge us more , so it 's this phd d: mmm . grad e: so so my question is should we go ahead and get na nine identical head - mounted crown mikes ? professor b: not before having one come here and have some people try it out . grad e: ok . professor b: because there 's no point in doing that if it 's not gon na be any better . grad e: so why do n't we get one of these with the crown with a different headset ? professor b: yeah . grad e: and and see if that works . professor b: and see if it 's preferable and if it is then we 'll get more . phd c: comfort . grad e: yeah . professor b: yeah . phd c: cuz i mean i think the microphones are ok it 's just the the grad e: right , it 's just they 're not comfortable to wear . professor b: right . phd c: could make our own handbands and grad e: um , and he said they do n't have any of these in stock but they have them in la and so it will take about a week to get here . professor b: yeah well it 's grad e: um so ok to just go order ? professor b: we 're in this for the long term , yeah . just order it . grad e: ok phd c: it 's a lot of money for a handband . grad e: and who is the contact if i wan na do an invoice grad f: yeah . grad e: cuz i think that 's how we did it before . professor b: uh we 'll do this off - line , yeah . grad f: it 's a long time to get from la . grad e: ok . and then nine channels is the maximum we can do , so . professor b: uh y right cuz so one is for the daisy chain so that 's fifteen instead of sixteen grad e: without getting more stuff . professor b: and there 's six on the table so that 's nine . grad e: right . phd c: can i ask a really dumb question ? professor b: yeah . phd c: is is there any way we can have you know like a a wireless microphone that you pass around to the people who you know the extra people for the times they wan na talk that grad e: probably . professor b: that 's a good idea . phd c: i mean professor b: that 's not a dumb question , it 's a good idea , phd c: well i mean phd a: like uh like you know jerry springer thing , professor b: yeah . grad e: i 'm just not sure how we would handle that in the grad f: that 's like the conch . phd c: well but phd d: like at conferences phd a: you know r phd c: well but there might be a way to say that there are gon na be these different people grad f: see , look . phd c: um and i do n't know identifying somehow ? phd d: so nail the chairs down . phd a: yeah . grad e: yeah , somehow . phd c: you know i was just thinking of jerry springer . grad e: it 's not a bad idea . professor b: no that no no phd a:  professor b: that 's a very if we ca n't get another board and even if we can i have a feeling they 'll be some work . phd d: the springer mike . phd c: i mean for the few times that you might wan na have that . professor b: let 's figure that we have eight which are set up and then there 's a ninth which is passed around to grad e: a hand - held , yeah . professor b: that 's a good idea phd d: infinite expansion . professor b: right . kind of rules out overlap but but uh phd c: well or also for you know if people are not professor b: yeah . grad e: well we could just hand around the lapel . professor b: uh no no that 's grad e: rather than get a phd c: no not the lapel . grad e: do you want a handset ? professor b: no . grad e: well i mean is the is the hand - held really any better ? phd d: liz hates the lapel . professor b: yes . phd c: i do n't know grad e: ok . phd c: but i d i know the lapel is really suboptimal . professor b: no it no it depends on the hand - held grad e: is awful ? professor b: but hand many hand - helds are built wi with sort of uh anti - shock sort of things so that it it is less uh susceptible to hand noises . if you hold the lapel mike i you just get all k sorts of junk . phd d: mm - hmm . phd c: right . i mean the ones they really pass around must be sort of ok . grad e: ok . professor b: so grad e: so i wonder if they have one that will hook up . professor b: yeah . they have what ? grad e: i wonder if they have one that will hook up to this or whether again we 'll have to wire it ourselves . phd d: well , you would n't want it to hook there you 'd just want it to hook into the receiver in the other room , right ? professor b: no that 's uh you need a transmitter . grad e: what ? phd d: is th is n't that built into the mike ? professor b: oh i see . get a get a different radio , yeah . phd c: yeah just these ones that they pass around with no you know wireless professor b: yeah . but you need a ra but it has to correspond to the receiver . phd d: have a little antenna coming out the bottom . grad e: it 's gon na be much easier to get one of these and just plug in a mike , is n't it ? phd d: but then the mike has to h phd a: do you have to hand it around and if you have two pieces of professor b: no no phd c: right . grad f: yeah . phd a:  professor b: so right , so this is a good point , so yeah you have these these mikes with a little antenna on the end right ? grad e: ok . and do you think you would be able to use the same receiver ? professor b: i do n't know . you 'll have to check with them , grad e: ok i 'll i 'll ask . professor b: yeah . but that 's that 's a great idea phd d: it 's just a frequency . grad e: yeah . professor b: and then just sort of have that as the and then you can have groups of twenty people or whatever and and uh phd c: yeah because there 's only i mean as andreas pointed out actually i think in the large the larger the group the less interaction the less people are talking um over each other phd a: pretty soon . phd d: mmm , yeah . phd c: it just there might be a lot of people that speak once or twice and professor b: right . phd a: um got ta go . professor b: off you go , yeah . grad e: ok so i guess people who have to leave can leave and do we have anything else to discuss or should we just do digits ? postdoc g: i i thought of some extra a couple of extra things i 'd like to mention . grad e: ok . postdoc g: one of them is to give you a status in terms of the transcriptions so far . so um as of last night um i 'd assigned twelve hours and they 'd finished nine grad e: uh yep , postdoc g: and my goal was to have eleven done by the end of the month , i think that by tomorrow we 'll have ten . phd c: uh it 's great professor b: pretty close , postdoc g: so they 're still working . professor b: that 's good . phd c: i j and this i got this email from jane at like two in the morning or something phd d: wow . grad e: that 's good . phd c: so it 's really great postdoc g: it 's working out , thanks . phd c: it 's really great . postdoc g: thanks . and then um also an idea for another meeting , which would be to have the transcribers talk about the data it 's sort of a a little bit a little bit phd c: that 's a great idea . professor b: super idea . grad e: yep , that 'd be very interesting . phd c: that 's a great idea cuz i 'd like to g have it recorded so that we can remember all the little things , grad f: yeah . grad e: i 'd love to hear what they have to say . postdoc g: yeah . phd c: that 's a great idea . phd d: so if we got them to talk about this meeting , it would be a meta meta meeting . postdoc g: yeah . yeah , exa exactly i guess nested several layers , professor b: now you have eight transcribers and there 's ten of us postdoc g: but professor b: so how do we do this , is the only thing . phd c: or just have them talk amongst themselves . phd d: have them have their own meeting . phd c: and have postdoc g: well that 's what i 'm thinking , professor b: oh . postdoc g: yeah . have them talk about the data and they and they 've made observations to me phd c: that would be great . postdoc g: like they say uh you know this meeting that we think has so much overlap , in fact it does but there are other groups of similar size that have very little , you know it 's part of it 's it 's the norm of the group and all that and they have various observations that would be fun , i think . phd c: that 's a great idea . grad e: yeah , i 'd like to hear what they s say . postdoc g: yeah . phd c: be great . professor b: so maybe we could they could have a meeting more or less without us that to do this and we should record it postdoc g: ok . professor b: and then maybe one or two of them could come to one of these meetings and and could you know could tell us about it . postdoc g: yeah . grad e: give us a status . phd c: yeah . postdoc g: oh good . ok . professor b: yeah . phd c: it 's they will get to transcribe their own meeting but they also get paid for having a break grad e: that would be weird . postdoc g: what what yeah that 's right . phd c: and i think that 's a good idea , postdoc g: yeah exactly , yeah . professor b: yeah . phd c: get them involved . postdoc g: great . phd c: um that 's a great idea . postdoc g: great . professor b: super . phd c: i 'm really sorry i have to g no i have to go as well . professor b: ok . postdoc g: and then i wanted to also um say something about the fiscus uh uh john john fiscus visit tomorrow . and which is to say that w it 'll be from nine to one that i 'm going to uh uh offer the organization allow him to uh adjust it if he wishes but to be basically in three parts , the acoustic part coming first which would be basically the room engineering aspects um other things and he 'll be also presenting what nist is doing and and uh then uh number two would be sort of a the the transcription process so this would be a focus on like presegmentation and the modifications to the the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which uh dave gelbart 's been doing and then um uh and of course the presegmentation thilo 's been doing and then um the third part would and again he has some stuff that 's i relevant with respect to nist and then the third one would be focus on transcription standards so at nist he 's interested in this establishment of a global encoding standard i guess i would say and i want it , you know k yeah see what they 're doing and also present what what we 've chosen as ours and and discuss that kind of thing . and so but he 's only here until until one and actually we 're thinking of noon being uh lunch time so basically hoping that we can get as much of this done as possible before noon . s professor b: ok . postdoc g: and everybody who wants to attend is welcome . so grad e: oh , where you 're gon na meet ? postdoc g: yeah . here mostly but i 've also reserved the barco room um eh to figure out how that works in terms of like maybe having a live demonstration . professor b: ok but the nine o ' cl nine o ' clock will be i be in here . yeah , ok . postdoc g: yeah . mm - hmm . grad e: i assume we 're not gon na try to record it ? postdoc g: oh i think that would be hard , yeah . professor b: yeah , i think just adds grad e: alright . postdoc g: yeah . professor b: um good . postdoc g: thank you though , uh - huh . professor b: so maybe do digits and recess ? grad e: unless there 's anything else ? postdoc g: yeah . yeah . phd d: do digital ones ? professor b: uh ok . postdoc g: yeah . grad e: uh should y we make him wear andreas ' mike or would that just be too confusing ? professor b: yeah . no i do n't think it 's confusing . well , it does n't confuse me . postdoc g: when we do this in the key in the key in the key it has to indicate that channel change , phd d: does it mess up the forms ? postdoc g: right ? grad e: uh yeah i just do n't know how we would do that , so . i mean other than free free form . postdoc g: well i have a time mark . phd d: the on switch is here on the on the top there . postdoc g: yeah . professor b: ok . grad e: and just clip it to your collar . professor b: that 's fine . grad j: ok , my name is uh espen eriksen . i 'm a norwegian . um uh this is my second semester at berkeley . currently i 'm taking uh my first graduate level courses in dsp and um when i come back to norway i 'm gon na continue with the more of a research project work kind of work . so this semester i 'm starting up with a with a small project through uh dave gelbart which i 'm taking a course with i got in touch with him and he told me about this project . so with the help of uh dan ellis i 'm gon na do small project associated to this . what i 'm gon na try to do is uh use use ech echo cancellation to uh to handle the periods where you have overlapping talk . to try to do something about that . so currently i 'm um i 'm just reading up on echo cancellation , s looking into the theory behind that and then uh hopefully i get some results . so it it 's a it 's a project goes over the course of one semester . grad e: great . grad j: so i 'm just here today to introduce myself . tell about i 'll be i 'll be working on this . grad e: and are you staying at berkeley or is are you just here a semester ? grad j: this is my second semester and last . grad e: ah second and last , professor b: yeah . grad e: ok . grad j: so i leave professor b: he 's in the he 's in the cour two two five d course . grad j: yeah , i 'm in morgan 's course , professor b: so , yeah . grad j: yeah . grad e: good . phd d: welcome . postdoc g: then you then you go back to norway , that 's ok . grad j: yeah . grad f: we were just talking about something like this yesterday or yeah yesterday with liz . about doing some of the echo cancellation stuff or possibly the spectroanalysis over the overlaps , so . cool . grad j: yeah . professor b: ok , grad e: digits ? professor b: let 's do digits . ok . grad e: and stop .","output":"the group discussed recognition results generated for 20 minutes of close-talking microphone data . recognition performance was very good , indicating promising results for forced alignment procedures and the ability to analyze other important signal information , e.g . prosody and overlapping speech . it was decided that close-talking data should be downsampled and fed to the sri recognizer to compare recognition performance , and that data from the far-field microphones should be tested on the recognizer as soon as possible . the group also discussed recording setup and equipment issues ."},{"instruction":"summarize what was said about the microphone data","input":"grad f: test . postdoc g: ok . professor b: let 's see , i should be two . phd d: up high grad e: as close to your mouth as you can get it . professor b: la phd d: high as you can get . professor b: is this channel one ? postdoc g: yeah , on your upper lip . phd h: channel one one one . professor b: gee , ok . yes . ok . grad e: ok , so for for for people wearing the wireless mikes , like like this one , i find the easiest way to wear it is sorta this this sorta like that . phd h: this is chan channel channel one one two three grad f: channel five , channel five . professor b: yeah . mm - hmm . what do you do , grad e: it 's actually a lot more comfortable then if you try to put it over your temples , grad f: test , test test . professor b: you do it higher ? grad e: so professor b: mm - hmm . phd d: adam 's just trying to generate good uh data for the recognizer there . postdoc g: yeah , i think we 're supposed to that 's right . grad e: and then also , for for all of them , if your boom is adjustable , the boom should be towards the corner of your mouth , grad f: test test . phd a: by the way , there was a bug . yeah , i it was n't using the proper phd d: oh it was . grad e: and about a uh a thumb to a thumb and a half distance away from your mouth , phd a: basically it was n't adapting anything . phd d: oh . grad e: so about like i 'm wearing it now . phd d: oh that 's interesting . so why did n't you get the same results and the unadapted ? grad e: so so jane , you could actually do even a little closer to your mouth , phd h: it 's not always possible . phd a: hmm ? phd d: why did n't you get the same results and the unadapted ? postdoc g: i could can this be adjuste like this ? grad e: but phd a: oh , because when it estimates the transformer pro produces like a single matrix or something . grad e: yep . postdoc g: is that @ @ ? ok , thank you . grad f: adam , i 'm not phd d: o oh oh i see . grad f: uh , looks kinda low on channel five phd d: i see , i see . professor b: ok . grad f: no ? grad e: channel five , s speak again . grad f: maybe not . postdoc g: hello . phd a: basically there were no counts grad e: yeah , that 's alright . grad f: hello ? grad e: i mean , we could we could up the gain slightly if you wanted to . grad f: it 's ok ? phd h: yeah . grad f: is this ok ? phd h: ok . phd d: i see what you mean . phd c: who 's channel b ? grad e: but uh , channel b is probably liz . phd c: uh oh . phd h: uh channel b i am channel b . professor b: you wan na close this , postdoc g: channel eight , eight . professor b: or phd c: no i grad e: thank you . phd h: no , channel b . phd a: hello , hello . phd c: yeah , yeah , you 're channel b . phd h: yeah , yeah . phd c: so can you talk a bit ? i thought it might be too phd h: ok , yeah , channel b , one two three four five . phd c: ok . grad e: yeah , it 's alright . so , the gain is n't real good . professor b: we 're recording , phd c: ok . professor b: right ? grad e: ok , so we are recording . phd h: ah . professor b: yeah . phd a: ok . grad e: um everyone should have at least two forms possibly three in front of you depending on who you are . grad f: oh . grad e: um we we 're doing a new speaker form and you only have to spea fill out the speaker form once but everyone does need to do it . and so that 's the name , sex , email , et cetera . phd h: mm - hmm . grad e: we we had a lot of discussion about the variety of english and so on so if you do n't know what to put just leave it blank . um i i designed the form and i do n't know what to put for my own region , phd a: mmm . grad e: so phd d: california . phd a: i think grad e: california . phd h: california . phd a: um may i make one suggestion ? instead of age put date of uh year of birth grad e: sure . phd a: because age will change , but the year of birth changes , you know , stays the same , usually . grad e: oh . phd c: a actually , wait a minute , grad e: birth year ? postdoc g: although on phd a: yeah . phd c: should n't it be the other way around ? phd d: not for me . postdoc g: course on the other on the other hand you could you view it as the age at the time of the phd c: on the other side , phd a: well the thing is , if ten years from now you look at this form knowing that phd c: yeah . postdoc g: yes , but what we care about is the age at at the recording date rather than the phd c: o yeah . phd d: but there 's no other date on the form . phd c: w we do n't care how they old they really are . phd a: well well i do n't know . postdoc g: yes . unless we wan na send them a card . grad e: well i guess it depends on how long the corpus is gon na be collected for . phd a: anyway . postdoc g: yeah , that 's true . phd c: i still do n't see the problem . grad e: either way yeah i think i think age is alright phd a: ok . grad e: and then um there will be attached to this a point or two these forms uh so that you 'll be able to extract the date off that phd a: mm - hmm . grad e: so , anyway . and so then you also have a digits form which needs to be filled out every time , the speaker form only once , the digit form every time even if you do n't read the digits you have to fill out the digits form so that we know that you were at the meeting . ok ? and then also if you have n't filled one out already you do have to fill out a consent form . and that should just be one person whose name i do n't know . ok ? grad f: do you want this adam ? grad e: uh sure . thank you . professor b: so uh grad e: ok so should we do agenda items ? professor b: uh oh that 's a good idea . i should n't run the meeting . grad e: uh well i have i wan na talk about new microphones and wireless stuff . postdoc g: mmm . grad e: and i 'm sure liz and andreas wan na talk about recognition results . anything else ? phd c: i guess what time do we have to leave ? three thirty ? phd a: yeah . phd c: yeah , grad e: why do n't you go first then . phd c: so . professor b: yeah , good idea . phd a: ok . phd c: um well , i i sent out an email s couple hours ago so um with andreas ' help um andreas put together a sort of no frills recognizer which is uh gender - dependent but like no adaptation , no cross - word models , no trigrams a bigram recognizer and that 's trained on switchboard which is telephone conversations . um and thanks to don 's help wh who don took the first meeting that jane had transcribed and um you know separated used the individual channels we segmented it in into the segments that jane had used and uh don sampled that so so eight k um and then we ran up to i guess the first twenty minutes , up to synch time of one two zero zero so is that that 's twenty minutes or so ? um yeah because i guess there 's some , grad e: or so . phd c: and don can talk to jane about this , there 's some bug in the actual synch time file that ah uh i 'm we 're not sure where it came from but stuff after that was a little messier . anyway so it 's twenty minutes and i actually grad e: hmm . phd c: um grad e: i was that did that did that recording have the glitch in the middle ? postdoc g: i 'm puzzled by that . i oh oh , i see . phd c: there 's there 's a postdoc g: oh there was a glitch somewhere . phd c: yeah , so that actually um grad f: was it twenty minutes in , phd c: if it was twenty minutes in then i do n't know postdoc g: i forgot about that . grad f: i thought phd a: well it was interesting , postdoc g: well , i mean , they phd a: suddenly the the overall error rate when we first ran it was like eighty percent grad e: i do n't remember when it is . postdoc g: but i was able to can transcribe phd a: but i looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the it was actually recognized phd c: wel grad e: oh no . grad f: yeah , that might be that might be that might be my fault . postdoc g: wow . phd a: so grad e: oh so that was just a parsing mismatch . grad f: i 'm not phd a: ok . phd c: no actually it was yeah i it was a complicated bug because they were sometimes one off and then sometimes totally random so um grad f: yeah , i was pretty certain that it worked up until that time , postdoc g: oh . that 's not good . phd c: yeah phd a: ok . phd c: so that 's what we have grad e: alright . grad f: so phd c: but that that will be completely gone if this synch time problem postdoc g: yeah . grad e: the the glitch phd a: so so we have everything recognized but we scored only the first uh whatever , up to that time to postdoc g: and the only glitch grad e: yeah . postdoc g: yeah . phd c: so you guys know . professor b: s sorry i have n't seen the email , phd c: yeah . grad e: th - the postdoc g: the the well wait professor b: what was the score ? phd c: so here 's the actual copy of the email postdoc g: we should say something about the glitch . he he can say something about the glitch . phd c: um oh ok grad e: yeah . postdoc g: cuz it 's it 's it 's h it 's it 's very small phd c: so does this glitch occur at other grad e: there there there 's an acoustic glitch that occurs where um the channels get slightly asynchronized postdoc g: very small . yep . phd c: oh . phd a: mmm . phd c: right . grad e: so the that that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for a fraction of a second professor b: hmm . grad f: hmm . grad e: and so the channels get a little asynchronous and so if you listen to it in the middle there 's a little part where it starts doing doing click sounds . professor b: so phd c: and is it only once that that happens ? grad e: but yeah phd c: ok . grad e: it right once in the middle . phd c: there 's the previous page has some more information about sort of what was wrong professor b: so so un unsurprisingly adam is the golden voice , phd c: but grad e: um but that should n't affect anything phd c: ok so that 's actually postdoc g: s and it professor b: you see this here ? phd c: it y it 's grad e: yeah yeah `` bah `` phd c: ok no phd a: oh , and phd c: what happens is it actually affects the script that don phd d: huh . phd c: i mean if we know about it then i guess it could always be checked for it grad e: well the acoustic one should n't do anything . phd c: but they grad f: yeah , i do n't know exactly what affected it postdoc g: i agree . i agree . phd a: i i have grad f: but i 'll i 'll talk to you about it , phd a: yeah . grad e: but i i do remember phd c: yeah . grad f: i 'll show you the point . postdoc g: yeah . it it had no effect on my transcription , phd a: mmm . postdoc g: you know , i mean i i had no trouble hearing it and and having time bins grad e: i do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect . postdoc g: but there was a oh . phd c: well , the the synch time the synch numbers have more significant digits than they should , grad f: that 's what happened . postdoc g: oh . phd h: yeah . grad e: where where they were n't monotonic . grad f: there was yeah , i mean phd c: right ? there 's things that are l in smaller increments than a frame . phd h: yeah . postdoc g: oh , interesting . phd c: and so then , i mean you look at that and it 's got you know more than three significant digits in a synch time then that ca n't be right grad e: oh ok so that 's grad f: hmm . postdoc g: oh . phd a: mmm . phd c: so anyway it 's it 's just grad e: yeah sounds like a bug . postdoc g: yeah . phd c: that 's why we only have twenty minutes but there 's a significant amount of grad f: non - zero ? um there are like more cuz there 's a lot of zeros i tacked on just because of the way the script ran , grad e: the other one i saw was that it yeah . grad f: i mean but there were there was a point . phd c: yeah that was fine . that that was ok . grad e: the other one i saw was non non - monotonic synch times grad f: ok . grad e: and that definitely indicra indicates a bug . grad f: uh . phd c: well that would really be a problem , yeah . so anyway these are just the ones that are the prebug for one meeting . grad f: yeah . phd c: um and what 's which grad e: so that 's very encouraging . phd c: this is really encouraging cuz this is free recognition , professor b: hmm . phd h: yeah . professor b: cool . phd a: mmm . phd c: there 's no i mean the language model for switchboard is totally different so you can see some like this trent lott which phd d: trent lott . phd c: um i mean these are sort of funny ones , phd d: it 'll get those though . phd c: there 's a lot of perfect ones and good ones and all the references , i mean you can read them and when we get more results you can look through and see grad e: i and as i said i would like to look at the lattices phd a: mm - hmm . phd c: but um it 's pretty good . grad e: because it sounded like even the ones it got wrong it sort of got it right ? phd c: well so i guess we can generate grad e: sounds likes ? phd a: there are a fair number of errors that are , you know where got the plural s wrong or the inflection on the verb wrong . postdoc g: mm - hmm . phd c: um grad e: yeah , and who cares ? and and there were lots of of course the `` uh uh `` - s , `` in on `` - s `` of uh `` - s . phd a: mmm , so if phd c: there 's no those are actually phd a: yeah . phd c: a lot of the errors i think are out of vocabulary , phd a: mm - hmm . phd c: so is it like pzm is three words , it 's pzm , phd a: mm - hmm . phd c: i mean there 's nothing there 's no language model for pzm or grad e: right . ri - ri right . phd c: um grad e: did you say there 's no language for pzm ? phd c: no language model , i mean those grad e: do you mean so every time someone says pzm it 's an error ? maybe we should n't say pzm in these meetings . phd c: well well there 's all kinds of other stuff like jimlet and i mean um anyway there grad e: yeah , that 's right , jimlet . professor b: well , we do n't even know what that means , phd c: so but this is really encouraging because professor b: so i grad e: yeah , that 's right . phd c: so , i mean the bottom line is even though it 's not a huge amount of data um it should be uh reasonable to actually run recognition and be like within the scope of of r reasonable s you know switchboard this is like h about how well we do on switchboard - two data with the switchboard - one trained mostly trained recognizer grad e: right . phd c: and switchboard - two is got sort of a different population of speakers and a different topic grad e: excellent . phd c: and they 're talking about things in the news that happened after switchboard - one so there was @ @ so that 's great . professor b: yeah . yeah so we 're in better shape than we were say when we did had the ninety - three workshop phd c: um professor b: and we were all getting like seventy percent error on switchboard . phd a: mm - hmm . phd c: oh yeah professor b: you know phd c: i mean this is really , phd a: mmm . phd c: and thanks to andreas who , i mean this is a phd a: mmm . grad e: well especially for the very first run , i mean you phd a: oh it 's the professor b: yeah . phd c: eh um professor b: yeah . phd c: yeah grad e: the first run i ran of switchboard i got a hundred twenty percent word error but phd c: so and what al also this means is that postdoc g: right . phd c: um grad e: not switchboard , phd a: well it 's phd c: i mean there 's a bunch of things in this note to various people grad e: uh broadcast news . phd c: especially i guess um with jane that that would help for since we have this new data now uh in order to go from the transcripts more easily to um just the words that the recognizer would use for scoring . i had to deal with some of it by hand but i think a lot of it can be automated s by professor b: oh one thing i guess i did n't get so you know the language model was straight from from bigram from switchboard the acoustic models were also from switchboard or or phd a: yeah . phd c: yeah . professor b: so they did n't have anything from this acoustic data in yet ? postdoc g: that 's amazing . grad e: yeah , so that 's great . phd c: no . professor b: ok . phd c: and actually we actually um used switchboard telephone bandwidth models postdoc g: that 's amazing . phd a: well that 's those are the only we ones there are , professor b: yeah . phd c: which i guess phd d: i was just gon na say , phd c: so that 's the on that 's the only acoustic training data that we have a lot of phd d: yeah . phd a: i mean grad e: yeah . phd a: right . phd c: and i guess ramana , so a guy at sri said that um there 's not a huge amount of difference going from professor b: right . phd c: it 's it 's not like we probably lose a huge amount but we wo n't know because we do n't have any full band models for s conversational speech . phd d: it 's probably not as bad as going f using full band models on telephone band speech phd c: so . phd a: oh yeah . phd c: right . phd d: right ? phd a: yeah . professor b: yeah , phd c: right , so it 's so professor b: but for broadcast news when we we played around between the two there was n't a huge loss . grad e: right , it was not a big deal . phd c: yeah phd a: i should i should say that the language model is not just switchboard phd c: so i wou so that 's good . grad e: although combining em worked well . phd a: it 's also i mean there 's uh actually more data is from broadcast news but with a little less weight phd c: yeah . phd a: uh because professor b: uh - huh . phd c: like trent lott must have been from phd a: mm - hmm , right . phd c: i guess switchboard was before phd a: um by the way just for fun we also ran , phd c: uh . professor b: good point . phd a: i mean our complete system starts by doing ge a gender detection professor b: mm - hmm . phd a: so just for the heck of it i ran that grad e: and it said a hundred percent male ? phd a: um and it might be reassuring for everybody to know that it got all the genders right . phd c: the j phd a: yeah so grad e: oh it did ? postdoc g: oh that 's i 'm glad . grad e: it got all two genders ? phd c: yeah but you know jane and adam have you kn about equal performance phd a: yeah . yes . phd c: and uh and that 's interesting cuz i think the their language models are quite different so and i i 'm pretty sure from listening to eric that , you know given the words he was saying and given his pronunciation that the reason that he 's so much worse is the lapel . professor b: yeah . grad e: right . postdoc g: that makes a lot of sense , phd c: so it 's nice now if we can just sort of eliminate the lapel one when when we get new microphones postdoc g: yeah . very possible . professor b: yeah i i i would bet on that too phd c: that would be worth it professor b: cuz he certainly in that when as a as a burp user he was he was a pretty uh strong one . phd c: um yeah grad e: sheep . phd c: he he he sounded to me just from he sounded like a , professor b: yeah . phd c: what 's it a sheep or a goat ? professor b: sheep . grad e: a sheep . phd c: sheep , grad e: baah . professor b: yeah . sheep is good . phd c: right . sounded good . professor b: yeah . phd c: right so um so i guess the good news is that postdoc g: mm - hmm . phd c: and and again this is without a lot of the sort of bells and whistles that we c can do with the sri system and we 'll have more data and we can also start to maybe adapt the language models once we have enough meetings . so this is only twenty minutes of one meeting with no no tailoring at all . phd a: i mean clearly there are um with just a small amount of uh actual meeting transcriptions uh thrown into the language model you can probably do quite a bit better because the phd c: yeah . the voca the vocabulary especially grad e: or just dictionary . phd c: yeah . phd a: not that much the vocabulary actually phd c: yeah , so . phd a: i think um well we have to see but it 's uh phd c: yeah . it 's pretty good um so then professor b: have to add pzm and so on grad e: and i have to try it on the far field mike professor b: but phd c: pzm grad e: yeah . phd c: and then there 's things like for the transcription i got when someone has a digit in the transcript i do n't know if they said , you know one one or eleven and i do n't know if they said tcl or tcl . there 's things like that where , you know the um we 'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and i 'm hoping and this is this is good news because that means the force alignments should be good and if the force alignments , i mean it 's good news anyway but if the force alignments are good we can get all kinds of information . for example about , you know prosodic information and speaker overlaps and so forth directly from the aligned times . um so that 'll be something that actually in order to assess the forced alignment um we need s some linguists or some people to look at it and say are these boundaries in about the right place . because it 's just gon na give us time marks phd d: but you know grad e: well we 've done that for one meeting . phd c: so . for forced alignment . grad e: uh oh oh f not for words phd c: ye - right . grad e: i 'm sorry just for overlaps is we did it for not not for words . phd c: right . so this would be like if you take the words um you know and force align them on all the individual close talk uh close talking mikes then how good are these sort of in reality grad e: right . phd c: and then i was thinking it grad e: so we might want to take twenty minutes and do a closer word level transcription . maybe actually mark the word boundaries . phd c: oh or i have someone look at the alignments uh maybe a linguist who can say um you know roughly if these are ok and how far away they are . professor b: yeah . phd c: um but i think it 's got ta be pretty good because otherwise the word recognition would be really b crummy . grad e: right , right . phd c: it would n't necessarily be the other way around , if the wor word recognition was crummy the alignment might be ok but if the word recognition is this good the alignment should be pretty good . so that 's about it . professor b: i r phd d: i wonder if this is a good thing or a bad thing though , i mean if we 're pr grad e: that we 're starting so well ? phd d: yeah if we 're producing a database that everybody 's gon na do well on professor b: oh grad e: do n't worry about it w d that 's that 's the close talking mikes . try it on the p z ms and and professor b: yeah , which i would which well n n n n phd d: so the real value of the database is these ? phd h: yeah , yeah , yeah , yeah . grad e: yeah , abso well no but professor b: i mean there 's still just the w the percentages and , i mean they 're not a as we 've talked about before there 's probably overlaps phd c: this i yeah . this is not that good . professor b: there 's probably overlaps in in uh in fair number in switchboard as well so but but there 's other phenomena , it 's a meeting , it 's a different thing and there 's lots of stuff to learn with the close talking mikes but uh yeah certainly i 'd like to see as soon as we could , i mean maybe get some of the glitches out of the way but soon as we could how well it does with say with the p z ms or maybe even one of the phd c: right . professor b: and uh see if it 's , you know is it a hundred twenty percent or maybe it 's not maybe if with some adaptation you get this down to fifty percent or forty - five percent or something and and then if for the pzm it 's seventy or something like that that 's actually something we could sort of work with a little bit phd c: yeah . professor b: so phd c: no i think it 's really , i mean this way we least have a baseline we know that for instance the transcripts are very good so once you can get to the words that the recognizer which is a total subset of the things you need to understand the the text um yeah they 're pretty good so and and it 's converting automatically from the xml to the chopping up the wave forms and so forth it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard so that 's good . and um let 's see there was one more thing i wanted to to mention i ca n't remember um sorry ca n't remember . anyway it 's postdoc g: congratulations is really great . professor b: yeah . phd c: well it was , i mean i really did n't do this myself grad e: yeah , it 's really good . phd c: so andreas set up this recognizer and by the way the recognizer all the files i 'm moving to sri and running everything there so i brought back just these result files and people can look at them um so phd a: we we talked about setting up the sri recognizer here . that 's you know if if there are more machines um uh here plus people can could run their own uh you know variants of of of the recognition runs um certainly doable . um . professor b: yeah and well certainly if the recognition as opposed to training , yeah . phd a: yeah . professor b: seems reasonable . postdoc g: i need t hmm . i need to ask one question . phd a: yeah . postdoc g: which is um so this issue of the uh legalistic aspects of the pre - sent you know pre - adapted yeah , well , so what i mean is um the uh the data that you take into sri , first first question , you 're maintaining it in in a place that would n't be publicly readable that that kind of stuff , right ? phd a: u um phd c: from the outside world or postdoc g: by uh people uh who are not associated with this project . phd a: oh . grad e: it 's human subjects issues , i told you about that . phd c: um oh . postdoc g: exactly . phd c: well ok we have n no names . although i sh um grad e: that that 's not the issue , phd c: de audio data itself ? grad e: it 's just the audio data itself , until people have a chance to edit it . postdoc g: mm - hmm , exactly . phd c: uh so well i can i can protect my directories through there . postdoc g: yeah . phd c: right now they 're not they 're in the speech group directories which so i will postdoc g: great . phd c: i did n't know that actually . professor b: yeah so we just have to go through this process of having people approve the transcriptions , phd c: yeah ok . professor b: say it 's ok . phd c: right ok . postdoc g: yeah , we had to get them to approve em and then i cuz cuz the other question i was gon na ask is if we 're having um you know it 's but this this meeting that you have , no problem cuz i i well i mean i i speak for myself grad e: it 's us . postdoc g: but but i think that we did n't do anything that but well anyway so uh i would n't be too concerned about it with respect to that although we should clear it with eric and dan of course but these results are based on data which have n't had the uh have n't had the chance to be reviewed by the subjects phd c: that 's true . postdoc g: and i do n't know how that stands , i mean if you if you get fantastic results and it 's involving { comment } data which which later end up being lessened by , you know certain elisions , then i do n't know but i wanted to raise that issue , professor b: well we , postdoc g: that 's all . professor b: i mean once we get all this streamlined it may be sh it hopefully it will be fairly quick but we get the transcriptions , people approve them and so on it 's just that we 're grad e: alright we need to work at a system for doing that approval so that we can send people the transcripts postdoc g: great . phd a: mmm . postdoc g: yeah . grad e: and get back any bleeps that they want phd c: yeah actually the bleeps are also an issue i thought . professor b: it 's gon na be a rare thing that there 's a bleep for the most part . phd a: u uh actually i had a question about the downsampling , um i do n't know who , i mean how this was done but is is there are there any um issues with downsampling phd c: don did this . phd a: because i know that the recognizer um that we use h can do it sort of on the fly um so we would n't have to have it eh you know do it uh explicitly beforehand . and is there any um i are there other d sev uh is there more than one way to do the downsampling where one might be better than another ? grad f: there are lots of w there are lots of ways to do the downsampling um different filters to put on , phd a: ok . right . ok . grad f: like anti - aliasing stuff . phd a: so so the th grad e: i do n't think we even know which one i assume you 're using syncat to do it ? grad f: no , i 'm using uh sn snd uh are resample . grad e: or sound resample ? phd c: re - re ref grad e: resample . phd c: yeah . grad e: yeah and dan 's archaic acronyms . grad f: rsmp . yeah , i do n't really . phd c: missing all the vowels . grad f: i just yeah i found it . phd c: some of the vowels , grad e: not all of them . phd c: almost all the vowels , that 's the hard part . phd a: so so the other thing we should try is to just take the original wave forms , grad e: and a few of the consonants . phd a: i mean segment them but not downsample them . phd c: yeah we could we could try that and and compare phd a: and and feed them to feed them to the sri recognizer and see if if the sri front - end does something . grad f: yeah , that 's phd c: yeah . grad e: i suspect that 's sort of premature optimization , but sure . phd c: we can try it . i i only downsampled them first cuz i was phd a: well grad f: i mean that 's just one line that 's one line of code to comment at phd c: yeah phd a: right and and it does n't is no more work for um you know for us . grad f: so grad e: mm - hmm . grad f: yeah . phd c: well they 're just bigger to transfer , that 's why i s downsampled them before but phd a: well but they 're only twice as big so phd c: well i mean that was if it 's the same then we can downsample here phd a: i mean it 's it 's just a phd c: but if it 's grad f: although those eighty meg files take a while to copy into my directories phd c: yeah . grad f: so , but no , i mean it 's not i it would n't be a problem if you 're interested in it phd c: we could try that . phd a: yeah i mean it would be uh you know it would probably take uh about um you know grad f: it would phd a: minus the transfer time it would it would take uh you know ten minutes to try and and and grad f: yeah . grad e: it 's about a fifty minute drive , right ? phd a: and and if for some reason we see that it works better then we might investigate why phd c: well it takes more disk space too so i was just phd a: and , you know , what yeah . grad f: mmm . in the front - end we could do that . phd a: yeah . professor b: so you just train just different filters grad f: yeah , i professor b: and so you 're just wondering whether the filter is grad f: yeah , i can imagine it would be phd a: right . right . phd c: so we could try that with this particular twenty minutes of speech and sort of see if there 's any differences . grad f: i mean i guess there 's some phd a: you know a at some point someone might have optimized whatever filtering is done for the actual recognition um performance . grad f: hmm . phd a: so in other words right , professor b: right . phd a: so grad e: it just seems to me that , you know small changes to the language model and the vocabulary will so swamp that that it may be premature to worry about that . i mean so one is a half a percent better than the other i do n't think that gives you any information . phd c: well it 's just as easy to to give you the sixteen k individual , grad e: yep . phd c: it was just more disk space you know for storing them professor b: are you are you using uh uh mel cepstrum or plp over there ? phd c: so phd a: mel cepstrum . professor b: so probably does n't matter . phd c: well we could try . grad f: there 's there 's your answer . professor b: but but it would n't hurt to try , phd c: could easily try phd a: that 's what i would assume but you never know , professor b: yeah . phd c: so phd a: you know . professor b: sure . no the reason i say this postdoc g: just mm - hmm . professor b: plp uses uh auto - regressive filtering and uh modeling and so it can be sensitive to the kind of filtering that you 're doing phd a: mm - hmm . professor b: but uh uh mel cepstrum uh might not b you would n't expect to be so much but phd c: well we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti stick them somewhere grad f: yeah , it 's it 's really not a problem . phd a: actually , no . phd c: and i 'll rerun it with phd a: do n't stop . do n't stop at that part because we 're actually using the entire conversation to estimate the speaker parameters , grad f: keep going . yeah . phd a: so should n't use you should s you know , get grad f: yeah , i mean i 'll i have to do is eh e the reference file would stay the same , phd c: ok . phd a: right . grad f: it 's just the individual segments would be approximately twice as long phd a: mmm . phd c: right . right . grad f: and i could just replace them with the bigger ones in the directory , phd a: right . phd c: i mean i corrected all grad e: yeah . grad f: that 's not a problem . phd c: i mean i hand - edited the whole the whole meeting so that can be run it 's just once we get the the bug out . phd a: mmm . postdoc g: one one question which is i i had the impression { comment } from this from this meeting that w that i transcribed that um that there was already automatic downsampling occurring , phd a: yeah . mm - hmm . postdoc g: is that i thought that in order to grad e: yep . postdoc g: so it was so it 's like there 's already down grad e: there 's one level that 's already happening right here . professor b: this is being recorded at forty - eight kilohertz . which is more that anybody needs postdoc g: ok . grad e: right . grad f: oh . grad e: and it gets downsampled to sixteen . postdoc g: ok . professor b: so phd c: and that 's actually said in your meeting , grad f: hmm . postdoc g: oh ok . phd c: that 's how i know that . postdoc g: that 's exactly , and that 's how i know it . professor b: yeah . phd c: i i it 's like are we downsampling to sixteen ? professor b: it 's a digital audio orientation for the board phd c: right . phd a: mmm . professor b: it 's in the monitor so it 's phd c: thank god it 's not more than that . grad e: so professor b: yeah . grad e: and i have no idea what filter it 's using , grad f: is eight kilohertz is is eighty kilohertz generally accepted as like standard for voice ? grad e: so professor b: for telephone stuff . grad e: telephone . phd d: telephone . grad f: yeah that 's what i was gon na say , i mean like professor b: so it 's it 's it 's just that they were operating from switchboard which was a completely telephone database grad f: so oh , i see , so . professor b: and so that was a standard for that sixteen s grad f: ok . grad e: so sixteen seems to be pretty typical for with this sort of thing . professor b: sixteen is more common for for uh broadband stuff that is n't grad f: right . grad e: that is n't music . professor b: that is n't music and is n't telephone , phd c: and i guess if you 're comparing like uh if you wan na run recognition on the pzm stuff you would want you do n't want to downsample the wh that professor b: yeah . grad e: why is that ? professor b: i do n't know . phd c: right ? well i don i mean if it 's any better professor b: no actually i would think that you would you would get better you 'd get better high frequencies in the local mike . grad e: all the way around i 'd think . professor b: uh but who knows ? i mean we do we we we we we wan na find all this stuff out , phd c: yeah well we could try it . grad e: yeah . professor b: we do n't know . grad e: we 're gon na have plenty of low frequency on the p z ms with the fans . phd c: ok . yeah . professor b: uh yeah . yeah . phd c: oh yeah there was just one more thing i wanted to say which is totally unrelated to the recognition except that um well well it 's sort of related but um good news also uh i got well chuck fillmore agreed to record meetings but he had too many people in his meetings and that 's too bad cuz they 're very animated and but uh jerry also agreed so uh we 're starting on on phd a: they 're less animated . phd c: well but he has fewer he he wo n't have more than eight and it 's a meeting on even deeper understanding , edu , so that sounds interesting . as a compliment to our front - end meeting grad e: dot edu ? phd c: and um so that 's gon na start monday and one of the things that i was realizing is um it would be really great if anyone has any ideas on some kind of time synchronous way that people in the meeting can make a comment to the person whose gon na transcribe it or or put a push a button or something when they wan na make a note about `` oh boy you should probably erase those last few `` or uh `` wait i want this not to be recorded now `` or uh something like that s professor b: were n't we gon na do something with a pad at one point ? postdoc g: the cross pads ? grad e: yeah , we could do it with the cross pads . phd c: cuz i was thinking you know if if the person who sets up the meeting is n't there and it 's a group that we do n't know um and this came up talking to to jerry also that you know is there any way for them to indicate to make sure that the qu request that they have that they make explicitly get addressed somehow professor b: yeah . phd c: so i do n't know if anyone has ideas or you could even write down `` oh it 's about three twenty five and `` professor b: well what i was just suggesting is is we have these this cross pad just for this purpose grad e: yeah , and use that . professor b: and just use that grad e: not a bad idea . professor b: and if we sink it in phd c: that would be great . professor b: the other thing is eh phd c: that be great . professor b: i do n't know if you know this or if it 's a question for the mail to dan but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? grad e: i do n't know . i do n't know . i 'll send mail to dan and ask . i i think that it 's the maximum we can do without a lot of effort because it 's one board with two digital channels . professor b: oh it is one board . grad e: e eight each . so it it takes two fibers in to the one board . and so w i think if we wan na do that more than that we 'd have to have two boards , and then you have the synchronization issue . professor b: but that 's a question because that would if it was possible cuz it is i you know already we have a a a group of people in this room that can not all be miked grad e: right . professor b: and it 's not just cuz we have n't been to the store , right it 's phd d: what is the limit on each of those f fiber channels , is it the grad e: eight . phd d: it just it 's eight channels come in , does it have do with the sampling rate ? grad e: it 's eight . i have no idea . but each each fiber channel has eight eight channels and there are two ch two fibers that go in to the card . professor b: it might be a hard limitation , grad e: so professor b: i mean one thing is it the whole thing as i said is is all structured in terms of forty - eight kilohertz sampling so that pushes requirements up a bit grad e: yeah . professor b: but phd d: i was just wondering if if that could change . grad e: i mean then we 'd also have to get another add and another mixer and all that sort of stuff . phd d: if we could drop that . professor b: yeah . grad e: so i i 'll send a mail to dan and ask him . professor b: yeah . grad e: ok on the uh are we done with that ? so the oth topic is uh getting more mikes and different mikes , so i got a quote um we can fit we have room for one more wireless and the wireless , this unit here is three fifty three hundred fifty dollars , it i did n't realize but we also have to get a tuner the receiver the other end , that 's uh four thirty um and then also phd c: for for each ? phd d: wow . phd c: i mean the tuner is four thirty for each . grad e: yep . phd c: wow . grad e: and we just need one more so so professor b: yeah at least w we got the good ones . grad e: yeah . so that 's you know something like seven hundred eighty bucks for one more of these . professor b: yeah . ok . grad e: um and then also um it turns out that the connector that this thing uses is proprietary of sony phd d: oh . grad e: believe it or not and sony only sells this headset . postdoc g: mmm . grad e: so if we wan na use a different set headset the solution that the guy suggested and they apparently lots of people have done is sony will sell you the jack with just wires coming out the end and then you can buy a headset that has pigtail and solder it yourself . and that 's the other solution and so the jacks are forty bucks apiece and the he recommended um a crown cm three eleven ae headset for two hundred bucks apiece . professor b: there is n't this some sort of thing that plugs in , you actually have to go and do the soldering yourself ? grad e: becau - the reason is the only only thing you can get that will plug into this is this mike or just the connector . professor b: no i understand . the reason i ask is these sort of handmade uh wiring jobs fall apart in use so the other thing is to see if we can uh get them to do a custom job and put it together for this . grad e: oh i 'm sure they would , they would just charge us , phd d: well , and they 'd probably want quantity too , grad e: so . professor b: well phd d: they 'd professor b: no they 'll just charge us more , so it 's this phd d: mmm . grad e: so so my question is should we go ahead and get na nine identical head - mounted crown mikes ? professor b: not before having one come here and have some people try it out . grad e: ok . professor b: because there 's no point in doing that if it 's not gon na be any better . grad e: so why do n't we get one of these with the crown with a different headset ? professor b: yeah . grad e: and and see if that works . professor b: and see if it 's preferable and if it is then we 'll get more . phd c: comfort . grad e: yeah . professor b: yeah . phd c: cuz i mean i think the microphones are ok it 's just the the grad e: right , it 's just they 're not comfortable to wear . professor b: right . phd c: could make our own handbands and grad e: um , and he said they do n't have any of these in stock but they have them in la and so it will take about a week to get here . professor b: yeah well it 's grad e: um so ok to just go order ? professor b: we 're in this for the long term , yeah . just order it . grad e: ok phd c: it 's a lot of money for a handband . grad e: and who is the contact if i wan na do an invoice grad f: yeah . grad e: cuz i think that 's how we did it before . professor b: uh we 'll do this off - line , yeah . grad f: it 's a long time to get from la . grad e: ok . and then nine channels is the maximum we can do , so . professor b: uh y right cuz so one is for the daisy chain so that 's fifteen instead of sixteen grad e: without getting more stuff . professor b: and there 's six on the table so that 's nine . grad e: right . phd c: can i ask a really dumb question ? professor b: yeah . phd c: is is there any way we can have you know like a a wireless microphone that you pass around to the people who you know the extra people for the times they wan na talk that grad e: probably . professor b: that 's a good idea . phd c: i mean professor b: that 's not a dumb question , it 's a good idea , phd c: well i mean phd a: like uh like you know jerry springer thing , professor b: yeah . grad e: i 'm just not sure how we would handle that in the grad f: that 's like the conch . phd c: well but phd d: like at conferences phd a: you know r phd c: well but there might be a way to say that there are gon na be these different people grad f: see , look . phd c: um and i do n't know identifying somehow ? phd d: so nail the chairs down . phd a: yeah . grad e: yeah , somehow . phd c: you know i was just thinking of jerry springer . grad e: it 's not a bad idea . professor b: no that no no phd a:  professor b: that 's a very if we ca n't get another board and even if we can i have a feeling they 'll be some work . phd d: the springer mike . phd c: i mean for the few times that you might wan na have that . professor b: let 's figure that we have eight which are set up and then there 's a ninth which is passed around to grad e: a hand - held , yeah . professor b: that 's a good idea phd d: infinite expansion . professor b: right . kind of rules out overlap but but uh phd c: well or also for you know if people are not professor b: yeah . grad e: well we could just hand around the lapel . professor b: uh no no that 's grad e: rather than get a phd c: no not the lapel . grad e: do you want a handset ? professor b: no . grad e: well i mean is the is the hand - held really any better ? phd d: liz hates the lapel . professor b: yes . phd c: i do n't know grad e: ok . phd c: but i d i know the lapel is really suboptimal . professor b: no it no it depends on the hand - held grad e: is awful ? professor b: but hand many hand - helds are built wi with sort of uh anti - shock sort of things so that it it is less uh susceptible to hand noises . if you hold the lapel mike i you just get all k sorts of junk . phd d: mm - hmm . phd c: right . i mean the ones they really pass around must be sort of ok . grad e: ok . professor b: so grad e: so i wonder if they have one that will hook up . professor b: yeah . they have what ? grad e: i wonder if they have one that will hook up to this or whether again we 'll have to wire it ourselves . phd d: well , you would n't want it to hook there you 'd just want it to hook into the receiver in the other room , right ? professor b: no that 's uh you need a transmitter . grad e: what ? phd d: is th is n't that built into the mike ? professor b: oh i see . get a get a different radio , yeah . phd c: yeah just these ones that they pass around with no you know wireless professor b: yeah . but you need a ra but it has to correspond to the receiver . phd d: have a little antenna coming out the bottom . grad e: it 's gon na be much easier to get one of these and just plug in a mike , is n't it ? phd d: but then the mike has to h phd a: do you have to hand it around and if you have two pieces of professor b: no no phd c: right . grad f: yeah . phd a:  professor b: so right , so this is a good point , so yeah you have these these mikes with a little antenna on the end right ? grad e: ok . and do you think you would be able to use the same receiver ? professor b: i do n't know . you 'll have to check with them , grad e: ok i 'll i 'll ask . professor b: yeah . but that 's that 's a great idea phd d: it 's just a frequency . grad e: yeah . professor b: and then just sort of have that as the and then you can have groups of twenty people or whatever and and uh phd c: yeah because there 's only i mean as andreas pointed out actually i think in the large the larger the group the less interaction the less people are talking um over each other phd a: pretty soon . phd d: mmm , yeah . phd c: it just there might be a lot of people that speak once or twice and professor b: right . phd a: um got ta go . professor b: off you go , yeah . grad e: ok so i guess people who have to leave can leave and do we have anything else to discuss or should we just do digits ? postdoc g: i i thought of some extra a couple of extra things i 'd like to mention . grad e: ok . postdoc g: one of them is to give you a status in terms of the transcriptions so far . so um as of last night um i 'd assigned twelve hours and they 'd finished nine grad e: uh yep , postdoc g: and my goal was to have eleven done by the end of the month , i think that by tomorrow we 'll have ten . phd c: uh it 's great professor b: pretty close , postdoc g: so they 're still working . professor b: that 's good . phd c: i j and this i got this email from jane at like two in the morning or something phd d: wow . grad e: that 's good . phd c: so it 's really great postdoc g: it 's working out , thanks . phd c: it 's really great . postdoc g: thanks . and then um also an idea for another meeting , which would be to have the transcribers talk about the data it 's sort of a a little bit a little bit phd c: that 's a great idea . professor b: super idea . grad e: yep , that 'd be very interesting . phd c: that 's a great idea cuz i 'd like to g have it recorded so that we can remember all the little things , grad f: yeah . grad e: i 'd love to hear what they have to say . postdoc g: yeah . phd c: that 's a great idea . phd d: so if we got them to talk about this meeting , it would be a meta meta meeting . postdoc g: yeah . yeah , exa exactly i guess nested several layers , professor b: now you have eight transcribers and there 's ten of us postdoc g: but professor b: so how do we do this , is the only thing . phd c: or just have them talk amongst themselves . phd d: have them have their own meeting . phd c: and have postdoc g: well that 's what i 'm thinking , professor b: oh . postdoc g: yeah . have them talk about the data and they and they 've made observations to me phd c: that would be great . postdoc g: like they say uh you know this meeting that we think has so much overlap , in fact it does but there are other groups of similar size that have very little , you know it 's part of it 's it 's the norm of the group and all that and they have various observations that would be fun , i think . phd c: that 's a great idea . grad e: yeah , i 'd like to hear what they s say . postdoc g: yeah . phd c: be great . professor b: so maybe we could they could have a meeting more or less without us that to do this and we should record it postdoc g: ok . professor b: and then maybe one or two of them could come to one of these meetings and and could you know could tell us about it . postdoc g: yeah . grad e: give us a status . phd c: yeah . postdoc g: oh good . ok . professor b: yeah . phd c: it 's they will get to transcribe their own meeting but they also get paid for having a break grad e: that would be weird . postdoc g: what what yeah that 's right . phd c: and i think that 's a good idea , postdoc g: yeah exactly , yeah . professor b: yeah . phd c: get them involved . postdoc g: great . phd c: um that 's a great idea . postdoc g: great . professor b: super . phd c: i 'm really sorry i have to g no i have to go as well . professor b: ok . postdoc g: and then i wanted to also um say something about the fiscus uh uh john john fiscus visit tomorrow . and which is to say that w it 'll be from nine to one that i 'm going to uh uh offer the organization allow him to uh adjust it if he wishes but to be basically in three parts , the acoustic part coming first which would be basically the room engineering aspects um other things and he 'll be also presenting what nist is doing and and uh then uh number two would be sort of a the the transcription process so this would be a focus on like presegmentation and the modifications to the the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which uh dave gelbart 's been doing and then um uh and of course the presegmentation thilo 's been doing and then um the third part would and again he has some stuff that 's i relevant with respect to nist and then the third one would be focus on transcription standards so at nist he 's interested in this establishment of a global encoding standard i guess i would say and i want it , you know k yeah see what they 're doing and also present what what we 've chosen as ours and and discuss that kind of thing . and so but he 's only here until until one and actually we 're thinking of noon being uh lunch time so basically hoping that we can get as much of this done as possible before noon . s professor b: ok . postdoc g: and everybody who wants to attend is welcome . so grad e: oh , where you 're gon na meet ? postdoc g: yeah . here mostly but i 've also reserved the barco room um eh to figure out how that works in terms of like maybe having a live demonstration . professor b: ok but the nine o ' cl nine o ' clock will be i be in here . yeah , ok . postdoc g: yeah . mm - hmm . grad e: i assume we 're not gon na try to record it ? postdoc g: oh i think that would be hard , yeah . professor b: yeah , i think just adds grad e: alright . postdoc g: yeah . professor b: um good . postdoc g: thank you though , uh - huh . professor b: so maybe do digits and recess ? grad e: unless there 's anything else ? postdoc g: yeah . yeah . phd d: do digital ones ? professor b: uh ok . postdoc g: yeah . grad e: uh should y we make him wear andreas ' mike or would that just be too confusing ? professor b: yeah . no i do n't think it 's confusing . well , it does n't confuse me . postdoc g: when we do this in the key in the key in the key it has to indicate that channel change , phd d: does it mess up the forms ? postdoc g: right ? grad e: uh yeah i just do n't know how we would do that , so . i mean other than free free form . postdoc g: well i have a time mark . phd d: the on switch is here on the on the top there . postdoc g: yeah . professor b: ok . grad e: and just clip it to your collar . professor b: that 's fine . grad j: ok , my name is uh espen eriksen . i 'm a norwegian . um uh this is my second semester at berkeley . currently i 'm taking uh my first graduate level courses in dsp and um when i come back to norway i 'm gon na continue with the more of a research project work kind of work . so this semester i 'm starting up with a with a small project through uh dave gelbart which i 'm taking a course with i got in touch with him and he told me about this project . so with the help of uh dan ellis i 'm gon na do small project associated to this . what i 'm gon na try to do is uh use use ech echo cancellation to uh to handle the periods where you have overlapping talk . to try to do something about that . so currently i 'm um i 'm just reading up on echo cancellation , s looking into the theory behind that and then uh hopefully i get some results . so it it 's a it 's a project goes over the course of one semester . grad e: great . grad j: so i 'm just here today to introduce myself . tell about i 'll be i 'll be working on this . grad e: and are you staying at berkeley or is are you just here a semester ? grad j: this is my second semester and last . grad e: ah second and last , professor b: yeah . grad e: ok . grad j: so i leave professor b: he 's in the he 's in the cour two two five d course . grad j: yeah , i 'm in morgan 's course , professor b: so , yeah . grad j: yeah . grad e: good . phd d: welcome . postdoc g: then you then you go back to norway , that 's ok . grad j: yeah . grad f: we were just talking about something like this yesterday or yeah yesterday with liz . about doing some of the echo cancellation stuff or possibly the spectroanalysis over the overlaps , so . cool . grad j: yeah . professor b: ok , grad e: digits ? professor b: let 's do digits . ok . grad e: and stop .","output":"the group discussed recognition results generated for 20 minutes of close-talking microphone data . recognition performance was very good , indicating promising results for forced alignment procedures and the ability to analyze other important signal information , e.g . prosody and overlapping speech . it was decided that close-talking data should be downsampled and fed to the sri recognizer to compare recognition performance , and that data from the far-field microphones should be tested on the recognizer as soon as possible ."},{"instruction":"what was decided on the microphone procedures ?","input":"grad f: test . postdoc g: ok . professor b: let 's see , i should be two . phd d: up high grad e: as close to your mouth as you can get it . professor b: la phd d: high as you can get . professor b: is this channel one ? postdoc g: yeah , on your upper lip . phd h: channel one one one . professor b: gee , ok . yes . ok . grad e: ok , so for for for people wearing the wireless mikes , like like this one , i find the easiest way to wear it is sorta this this sorta like that . phd h: this is chan channel channel one one two three grad f: channel five , channel five . professor b: yeah . mm - hmm . what do you do , grad e: it 's actually a lot more comfortable then if you try to put it over your temples , grad f: test , test test . professor b: you do it higher ? grad e: so professor b: mm - hmm . phd d: adam 's just trying to generate good uh data for the recognizer there . postdoc g: yeah , i think we 're supposed to that 's right . grad e: and then also , for for all of them , if your boom is adjustable , the boom should be towards the corner of your mouth , grad f: test test . phd a: by the way , there was a bug . yeah , i it was n't using the proper phd d: oh it was . grad e: and about a uh a thumb to a thumb and a half distance away from your mouth , phd a: basically it was n't adapting anything . phd d: oh . grad e: so about like i 'm wearing it now . phd d: oh that 's interesting . so why did n't you get the same results and the unadapted ? grad e: so so jane , you could actually do even a little closer to your mouth , phd h: it 's not always possible . phd a: hmm ? phd d: why did n't you get the same results and the unadapted ? postdoc g: i could can this be adjuste like this ? grad e: but phd a: oh , because when it estimates the transformer pro produces like a single matrix or something . grad e: yep . postdoc g: is that @ @ ? ok , thank you . grad f: adam , i 'm not phd d: o oh oh i see . grad f: uh , looks kinda low on channel five phd d: i see , i see . professor b: ok . grad f: no ? grad e: channel five , s speak again . grad f: maybe not . postdoc g: hello . phd a: basically there were no counts grad e: yeah , that 's alright . grad f: hello ? grad e: i mean , we could we could up the gain slightly if you wanted to . grad f: it 's ok ? phd h: yeah . grad f: is this ok ? phd h: ok . phd d: i see what you mean . phd c: who 's channel b ? grad e: but uh , channel b is probably liz . phd c: uh oh . phd h: uh channel b i am channel b . professor b: you wan na close this , postdoc g: channel eight , eight . professor b: or phd c: no i grad e: thank you . phd h: no , channel b . phd a: hello , hello . phd c: yeah , yeah , you 're channel b . phd h: yeah , yeah . phd c: so can you talk a bit ? i thought it might be too phd h: ok , yeah , channel b , one two three four five . phd c: ok . grad e: yeah , it 's alright . so , the gain is n't real good . professor b: we 're recording , phd c: ok . professor b: right ? grad e: ok , so we are recording . phd h: ah . professor b: yeah . phd a: ok . grad e: um everyone should have at least two forms possibly three in front of you depending on who you are . grad f: oh . grad e: um we we 're doing a new speaker form and you only have to spea fill out the speaker form once but everyone does need to do it . and so that 's the name , sex , email , et cetera . phd h: mm - hmm . grad e: we we had a lot of discussion about the variety of english and so on so if you do n't know what to put just leave it blank . um i i designed the form and i do n't know what to put for my own region , phd a: mmm . grad e: so phd d: california . phd a: i think grad e: california . phd h: california . phd a: um may i make one suggestion ? instead of age put date of uh year of birth grad e: sure . phd a: because age will change , but the year of birth changes , you know , stays the same , usually . grad e: oh . phd c: a actually , wait a minute , grad e: birth year ? postdoc g: although on phd a: yeah . phd c: should n't it be the other way around ? phd d: not for me . postdoc g: course on the other on the other hand you could you view it as the age at the time of the phd c: on the other side , phd a: well the thing is , if ten years from now you look at this form knowing that phd c: yeah . postdoc g: yes , but what we care about is the age at at the recording date rather than the phd c: o yeah . phd d: but there 's no other date on the form . phd c: w we do n't care how they old they really are . phd a: well well i do n't know . postdoc g: yes . unless we wan na send them a card . grad e: well i guess it depends on how long the corpus is gon na be collected for . phd a: anyway . postdoc g: yeah , that 's true . phd c: i still do n't see the problem . grad e: either way yeah i think i think age is alright phd a: ok . grad e: and then um there will be attached to this a point or two these forms uh so that you 'll be able to extract the date off that phd a: mm - hmm . grad e: so , anyway . and so then you also have a digits form which needs to be filled out every time , the speaker form only once , the digit form every time even if you do n't read the digits you have to fill out the digits form so that we know that you were at the meeting . ok ? and then also if you have n't filled one out already you do have to fill out a consent form . and that should just be one person whose name i do n't know . ok ? grad f: do you want this adam ? grad e: uh sure . thank you . professor b: so uh grad e: ok so should we do agenda items ? professor b: uh oh that 's a good idea . i should n't run the meeting . grad e: uh well i have i wan na talk about new microphones and wireless stuff . postdoc g: mmm . grad e: and i 'm sure liz and andreas wan na talk about recognition results . anything else ? phd c: i guess what time do we have to leave ? three thirty ? phd a: yeah . phd c: yeah , grad e: why do n't you go first then . phd c: so . professor b: yeah , good idea . phd a: ok . phd c: um well , i i sent out an email s couple hours ago so um with andreas ' help um andreas put together a sort of no frills recognizer which is uh gender - dependent but like no adaptation , no cross - word models , no trigrams a bigram recognizer and that 's trained on switchboard which is telephone conversations . um and thanks to don 's help wh who don took the first meeting that jane had transcribed and um you know separated used the individual channels we segmented it in into the segments that jane had used and uh don sampled that so so eight k um and then we ran up to i guess the first twenty minutes , up to synch time of one two zero zero so is that that 's twenty minutes or so ? um yeah because i guess there 's some , grad e: or so . phd c: and don can talk to jane about this , there 's some bug in the actual synch time file that ah uh i 'm we 're not sure where it came from but stuff after that was a little messier . anyway so it 's twenty minutes and i actually grad e: hmm . phd c: um grad e: i was that did that did that recording have the glitch in the middle ? postdoc g: i 'm puzzled by that . i oh oh , i see . phd c: there 's there 's a postdoc g: oh there was a glitch somewhere . phd c: yeah , so that actually um grad f: was it twenty minutes in , phd c: if it was twenty minutes in then i do n't know postdoc g: i forgot about that . grad f: i thought phd a: well it was interesting , postdoc g: well , i mean , they phd a: suddenly the the overall error rate when we first ran it was like eighty percent grad e: i do n't remember when it is . postdoc g: but i was able to can transcribe phd a: but i looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the it was actually recognized phd c: wel grad e: oh no . grad f: yeah , that might be that might be that might be my fault . postdoc g: wow . phd a: so grad e: oh so that was just a parsing mismatch . grad f: i 'm not phd a: ok . phd c: no actually it was yeah i it was a complicated bug because they were sometimes one off and then sometimes totally random so um grad f: yeah , i was pretty certain that it worked up until that time , postdoc g: oh . that 's not good . phd c: yeah phd a: ok . phd c: so that 's what we have grad e: alright . grad f: so phd c: but that that will be completely gone if this synch time problem postdoc g: yeah . grad e: the the glitch phd a: so so we have everything recognized but we scored only the first uh whatever , up to that time to postdoc g: and the only glitch grad e: yeah . postdoc g: yeah . phd c: so you guys know . professor b: s sorry i have n't seen the email , phd c: yeah . grad e: th - the postdoc g: the the well wait professor b: what was the score ? phd c: so here 's the actual copy of the email postdoc g: we should say something about the glitch . he he can say something about the glitch . phd c: um oh ok grad e: yeah . postdoc g: cuz it 's it 's it 's h it 's it 's very small phd c: so does this glitch occur at other grad e: there there there 's an acoustic glitch that occurs where um the channels get slightly asynchronized postdoc g: very small . yep . phd c: oh . phd a: mmm . phd c: right . grad e: so the that that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for a fraction of a second professor b: hmm . grad f: hmm . grad e: and so the channels get a little asynchronous and so if you listen to it in the middle there 's a little part where it starts doing doing click sounds . professor b: so phd c: and is it only once that that happens ? grad e: but yeah phd c: ok . grad e: it right once in the middle . phd c: there 's the previous page has some more information about sort of what was wrong professor b: so so un unsurprisingly adam is the golden voice , phd c: but grad e: um but that should n't affect anything phd c: ok so that 's actually postdoc g: s and it professor b: you see this here ? phd c: it y it 's grad e: yeah yeah `` bah `` phd c: ok no phd a: oh , and phd c: what happens is it actually affects the script that don phd d: huh . phd c: i mean if we know about it then i guess it could always be checked for it grad e: well the acoustic one should n't do anything . phd c: but they grad f: yeah , i do n't know exactly what affected it postdoc g: i agree . i agree . phd a: i i have grad f: but i 'll i 'll talk to you about it , phd a: yeah . grad e: but i i do remember phd c: yeah . grad f: i 'll show you the point . postdoc g: yeah . it it had no effect on my transcription , phd a: mmm . postdoc g: you know , i mean i i had no trouble hearing it and and having time bins grad e: i do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect . postdoc g: but there was a oh . phd c: well , the the synch time the synch numbers have more significant digits than they should , grad f: that 's what happened . postdoc g: oh . phd h: yeah . grad e: where where they were n't monotonic . grad f: there was yeah , i mean phd c: right ? there 's things that are l in smaller increments than a frame . phd h: yeah . postdoc g: oh , interesting . phd c: and so then , i mean you look at that and it 's got you know more than three significant digits in a synch time then that ca n't be right grad e: oh ok so that 's grad f: hmm . postdoc g: oh . phd a: mmm . phd c: so anyway it 's it 's just grad e: yeah sounds like a bug . postdoc g: yeah . phd c: that 's why we only have twenty minutes but there 's a significant amount of grad f: non - zero ? um there are like more cuz there 's a lot of zeros i tacked on just because of the way the script ran , grad e: the other one i saw was that it yeah . grad f: i mean but there were there was a point . phd c: yeah that was fine . that that was ok . grad e: the other one i saw was non non - monotonic synch times grad f: ok . grad e: and that definitely indicra indicates a bug . grad f: uh . phd c: well that would really be a problem , yeah . so anyway these are just the ones that are the prebug for one meeting . grad f: yeah . phd c: um and what 's which grad e: so that 's very encouraging . phd c: this is really encouraging cuz this is free recognition , professor b: hmm . phd h: yeah . professor b: cool . phd a: mmm . phd c: there 's no i mean the language model for switchboard is totally different so you can see some like this trent lott which phd d: trent lott . phd c: um i mean these are sort of funny ones , phd d: it 'll get those though . phd c: there 's a lot of perfect ones and good ones and all the references , i mean you can read them and when we get more results you can look through and see grad e: i and as i said i would like to look at the lattices phd a: mm - hmm . phd c: but um it 's pretty good . grad e: because it sounded like even the ones it got wrong it sort of got it right ? phd c: well so i guess we can generate grad e: sounds likes ? phd a: there are a fair number of errors that are , you know where got the plural s wrong or the inflection on the verb wrong . postdoc g: mm - hmm . phd c: um grad e: yeah , and who cares ? and and there were lots of of course the `` uh uh `` - s , `` in on `` - s `` of uh `` - s . phd a: mmm , so if phd c: there 's no those are actually phd a: yeah . phd c: a lot of the errors i think are out of vocabulary , phd a: mm - hmm . phd c: so is it like pzm is three words , it 's pzm , phd a: mm - hmm . phd c: i mean there 's nothing there 's no language model for pzm or grad e: right . ri - ri right . phd c: um grad e: did you say there 's no language for pzm ? phd c: no language model , i mean those grad e: do you mean so every time someone says pzm it 's an error ? maybe we should n't say pzm in these meetings . phd c: well well there 's all kinds of other stuff like jimlet and i mean um anyway there grad e: yeah , that 's right , jimlet . professor b: well , we do n't even know what that means , phd c: so but this is really encouraging because professor b: so i grad e: yeah , that 's right . phd c: so , i mean the bottom line is even though it 's not a huge amount of data um it should be uh reasonable to actually run recognition and be like within the scope of of r reasonable s you know switchboard this is like h about how well we do on switchboard - two data with the switchboard - one trained mostly trained recognizer grad e: right . phd c: and switchboard - two is got sort of a different population of speakers and a different topic grad e: excellent . phd c: and they 're talking about things in the news that happened after switchboard - one so there was @ @ so that 's great . professor b: yeah . yeah so we 're in better shape than we were say when we did had the ninety - three workshop phd c: um professor b: and we were all getting like seventy percent error on switchboard . phd a: mm - hmm . phd c: oh yeah professor b: you know phd c: i mean this is really , phd a: mmm . phd c: and thanks to andreas who , i mean this is a phd a: mmm . grad e: well especially for the very first run , i mean you phd a: oh it 's the professor b: yeah . phd c: eh um professor b: yeah . phd c: yeah grad e: the first run i ran of switchboard i got a hundred twenty percent word error but phd c: so and what al also this means is that postdoc g: right . phd c: um grad e: not switchboard , phd a: well it 's phd c: i mean there 's a bunch of things in this note to various people grad e: uh broadcast news . phd c: especially i guess um with jane that that would help for since we have this new data now uh in order to go from the transcripts more easily to um just the words that the recognizer would use for scoring . i had to deal with some of it by hand but i think a lot of it can be automated s by professor b: oh one thing i guess i did n't get so you know the language model was straight from from bigram from switchboard the acoustic models were also from switchboard or or phd a: yeah . phd c: yeah . professor b: so they did n't have anything from this acoustic data in yet ? postdoc g: that 's amazing . grad e: yeah , so that 's great . phd c: no . professor b: ok . phd c: and actually we actually um used switchboard telephone bandwidth models postdoc g: that 's amazing . phd a: well that 's those are the only we ones there are , professor b: yeah . phd c: which i guess phd d: i was just gon na say , phd c: so that 's the on that 's the only acoustic training data that we have a lot of phd d: yeah . phd a: i mean grad e: yeah . phd a: right . phd c: and i guess ramana , so a guy at sri said that um there 's not a huge amount of difference going from professor b: right . phd c: it 's it 's not like we probably lose a huge amount but we wo n't know because we do n't have any full band models for s conversational speech . phd d: it 's probably not as bad as going f using full band models on telephone band speech phd c: so . phd a: oh yeah . phd c: right . phd d: right ? phd a: yeah . professor b: yeah , phd c: right , so it 's so professor b: but for broadcast news when we we played around between the two there was n't a huge loss . grad e: right , it was not a big deal . phd c: yeah phd a: i should i should say that the language model is not just switchboard phd c: so i wou so that 's good . grad e: although combining em worked well . phd a: it 's also i mean there 's uh actually more data is from broadcast news but with a little less weight phd c: yeah . phd a: uh because professor b: uh - huh . phd c: like trent lott must have been from phd a: mm - hmm , right . phd c: i guess switchboard was before phd a: um by the way just for fun we also ran , phd c: uh . professor b: good point . phd a: i mean our complete system starts by doing ge a gender detection professor b: mm - hmm . phd a: so just for the heck of it i ran that grad e: and it said a hundred percent male ? phd a: um and it might be reassuring for everybody to know that it got all the genders right . phd c: the j phd a: yeah so grad e: oh it did ? postdoc g: oh that 's i 'm glad . grad e: it got all two genders ? phd c: yeah but you know jane and adam have you kn about equal performance phd a: yeah . yes . phd c: and uh and that 's interesting cuz i think the their language models are quite different so and i i 'm pretty sure from listening to eric that , you know given the words he was saying and given his pronunciation that the reason that he 's so much worse is the lapel . professor b: yeah . grad e: right . postdoc g: that makes a lot of sense , phd c: so it 's nice now if we can just sort of eliminate the lapel one when when we get new microphones postdoc g: yeah . very possible . professor b: yeah i i i would bet on that too phd c: that would be worth it professor b: cuz he certainly in that when as a as a burp user he was he was a pretty uh strong one . phd c: um yeah grad e: sheep . phd c: he he he sounded to me just from he sounded like a , professor b: yeah . phd c: what 's it a sheep or a goat ? professor b: sheep . grad e: a sheep . phd c: sheep , grad e: baah . professor b: yeah . sheep is good . phd c: right . sounded good . professor b: yeah . phd c: right so um so i guess the good news is that postdoc g: mm - hmm . phd c: and and again this is without a lot of the sort of bells and whistles that we c can do with the sri system and we 'll have more data and we can also start to maybe adapt the language models once we have enough meetings . so this is only twenty minutes of one meeting with no no tailoring at all . phd a: i mean clearly there are um with just a small amount of uh actual meeting transcriptions uh thrown into the language model you can probably do quite a bit better because the phd c: yeah . the voca the vocabulary especially grad e: or just dictionary . phd c: yeah . phd a: not that much the vocabulary actually phd c: yeah , so . phd a: i think um well we have to see but it 's uh phd c: yeah . it 's pretty good um so then professor b: have to add pzm and so on grad e: and i have to try it on the far field mike professor b: but phd c: pzm grad e: yeah . phd c: and then there 's things like for the transcription i got when someone has a digit in the transcript i do n't know if they said , you know one one or eleven and i do n't know if they said tcl or tcl . there 's things like that where , you know the um we 'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and i 'm hoping and this is this is good news because that means the force alignments should be good and if the force alignments , i mean it 's good news anyway but if the force alignments are good we can get all kinds of information . for example about , you know prosodic information and speaker overlaps and so forth directly from the aligned times . um so that 'll be something that actually in order to assess the forced alignment um we need s some linguists or some people to look at it and say are these boundaries in about the right place . because it 's just gon na give us time marks phd d: but you know grad e: well we 've done that for one meeting . phd c: so . for forced alignment . grad e: uh oh oh f not for words phd c: ye - right . grad e: i 'm sorry just for overlaps is we did it for not not for words . phd c: right . so this would be like if you take the words um you know and force align them on all the individual close talk uh close talking mikes then how good are these sort of in reality grad e: right . phd c: and then i was thinking it grad e: so we might want to take twenty minutes and do a closer word level transcription . maybe actually mark the word boundaries . phd c: oh or i have someone look at the alignments uh maybe a linguist who can say um you know roughly if these are ok and how far away they are . professor b: yeah . phd c: um but i think it 's got ta be pretty good because otherwise the word recognition would be really b crummy . grad e: right , right . phd c: it would n't necessarily be the other way around , if the wor word recognition was crummy the alignment might be ok but if the word recognition is this good the alignment should be pretty good . so that 's about it . professor b: i r phd d: i wonder if this is a good thing or a bad thing though , i mean if we 're pr grad e: that we 're starting so well ? phd d: yeah if we 're producing a database that everybody 's gon na do well on professor b: oh grad e: do n't worry about it w d that 's that 's the close talking mikes . try it on the p z ms and and professor b: yeah , which i would which well n n n n phd d: so the real value of the database is these ? phd h: yeah , yeah , yeah , yeah . grad e: yeah , abso well no but professor b: i mean there 's still just the w the percentages and , i mean they 're not a as we 've talked about before there 's probably overlaps phd c: this i yeah . this is not that good . professor b: there 's probably overlaps in in uh in fair number in switchboard as well so but but there 's other phenomena , it 's a meeting , it 's a different thing and there 's lots of stuff to learn with the close talking mikes but uh yeah certainly i 'd like to see as soon as we could , i mean maybe get some of the glitches out of the way but soon as we could how well it does with say with the p z ms or maybe even one of the phd c: right . professor b: and uh see if it 's , you know is it a hundred twenty percent or maybe it 's not maybe if with some adaptation you get this down to fifty percent or forty - five percent or something and and then if for the pzm it 's seventy or something like that that 's actually something we could sort of work with a little bit phd c: yeah . professor b: so phd c: no i think it 's really , i mean this way we least have a baseline we know that for instance the transcripts are very good so once you can get to the words that the recognizer which is a total subset of the things you need to understand the the text um yeah they 're pretty good so and and it 's converting automatically from the xml to the chopping up the wave forms and so forth it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard so that 's good . and um let 's see there was one more thing i wanted to to mention i ca n't remember um sorry ca n't remember . anyway it 's postdoc g: congratulations is really great . professor b: yeah . phd c: well it was , i mean i really did n't do this myself grad e: yeah , it 's really good . phd c: so andreas set up this recognizer and by the way the recognizer all the files i 'm moving to sri and running everything there so i brought back just these result files and people can look at them um so phd a: we we talked about setting up the sri recognizer here . that 's you know if if there are more machines um uh here plus people can could run their own uh you know variants of of of the recognition runs um certainly doable . um . professor b: yeah and well certainly if the recognition as opposed to training , yeah . phd a: yeah . professor b: seems reasonable . postdoc g: i need t hmm . i need to ask one question . phd a: yeah . postdoc g: which is um so this issue of the uh legalistic aspects of the pre - sent you know pre - adapted yeah , well , so what i mean is um the uh the data that you take into sri , first first question , you 're maintaining it in in a place that would n't be publicly readable that that kind of stuff , right ? phd a: u um phd c: from the outside world or postdoc g: by uh people uh who are not associated with this project . phd a: oh . grad e: it 's human subjects issues , i told you about that . phd c: um oh . postdoc g: exactly . phd c: well ok we have n no names . although i sh um grad e: that that 's not the issue , phd c: de audio data itself ? grad e: it 's just the audio data itself , until people have a chance to edit it . postdoc g: mm - hmm , exactly . phd c: uh so well i can i can protect my directories through there . postdoc g: yeah . phd c: right now they 're not they 're in the speech group directories which so i will postdoc g: great . phd c: i did n't know that actually . professor b: yeah so we just have to go through this process of having people approve the transcriptions , phd c: yeah ok . professor b: say it 's ok . phd c: right ok . postdoc g: yeah , we had to get them to approve em and then i cuz cuz the other question i was gon na ask is if we 're having um you know it 's but this this meeting that you have , no problem cuz i i well i mean i i speak for myself grad e: it 's us . postdoc g: but but i think that we did n't do anything that but well anyway so uh i would n't be too concerned about it with respect to that although we should clear it with eric and dan of course but these results are based on data which have n't had the uh have n't had the chance to be reviewed by the subjects phd c: that 's true . postdoc g: and i do n't know how that stands , i mean if you if you get fantastic results and it 's involving { comment } data which which later end up being lessened by , you know certain elisions , then i do n't know but i wanted to raise that issue , professor b: well we , postdoc g: that 's all . professor b: i mean once we get all this streamlined it may be sh it hopefully it will be fairly quick but we get the transcriptions , people approve them and so on it 's just that we 're grad e: alright we need to work at a system for doing that approval so that we can send people the transcripts postdoc g: great . phd a: mmm . postdoc g: yeah . grad e: and get back any bleeps that they want phd c: yeah actually the bleeps are also an issue i thought . professor b: it 's gon na be a rare thing that there 's a bleep for the most part . phd a: u uh actually i had a question about the downsampling , um i do n't know who , i mean how this was done but is is there are there any um issues with downsampling phd c: don did this . phd a: because i know that the recognizer um that we use h can do it sort of on the fly um so we would n't have to have it eh you know do it uh explicitly beforehand . and is there any um i are there other d sev uh is there more than one way to do the downsampling where one might be better than another ? grad f: there are lots of w there are lots of ways to do the downsampling um different filters to put on , phd a: ok . right . ok . grad f: like anti - aliasing stuff . phd a: so so the th grad e: i do n't think we even know which one i assume you 're using syncat to do it ? grad f: no , i 'm using uh sn snd uh are resample . grad e: or sound resample ? phd c: re - re ref grad e: resample . phd c: yeah . grad e: yeah and dan 's archaic acronyms . grad f: rsmp . yeah , i do n't really . phd c: missing all the vowels . grad f: i just yeah i found it . phd c: some of the vowels , grad e: not all of them . phd c: almost all the vowels , that 's the hard part . phd a: so so the other thing we should try is to just take the original wave forms , grad e: and a few of the consonants . phd a: i mean segment them but not downsample them . phd c: yeah we could we could try that and and compare phd a: and and feed them to feed them to the sri recognizer and see if if the sri front - end does something . grad f: yeah , that 's phd c: yeah . grad e: i suspect that 's sort of premature optimization , but sure . phd c: we can try it . i i only downsampled them first cuz i was phd a: well grad f: i mean that 's just one line that 's one line of code to comment at phd c: yeah phd a: right and and it does n't is no more work for um you know for us . grad f: so grad e: mm - hmm . grad f: yeah . phd c: well they 're just bigger to transfer , that 's why i s downsampled them before but phd a: well but they 're only twice as big so phd c: well i mean that was if it 's the same then we can downsample here phd a: i mean it 's it 's just a phd c: but if it 's grad f: although those eighty meg files take a while to copy into my directories phd c: yeah . grad f: so , but no , i mean it 's not i it would n't be a problem if you 're interested in it phd c: we could try that . phd a: yeah i mean it would be uh you know it would probably take uh about um you know grad f: it would phd a: minus the transfer time it would it would take uh you know ten minutes to try and and and grad f: yeah . grad e: it 's about a fifty minute drive , right ? phd a: and and if for some reason we see that it works better then we might investigate why phd c: well it takes more disk space too so i was just phd a: and , you know , what yeah . grad f: mmm . in the front - end we could do that . phd a: yeah . professor b: so you just train just different filters grad f: yeah , i professor b: and so you 're just wondering whether the filter is grad f: yeah , i can imagine it would be phd a: right . right . phd c: so we could try that with this particular twenty minutes of speech and sort of see if there 's any differences . grad f: i mean i guess there 's some phd a: you know a at some point someone might have optimized whatever filtering is done for the actual recognition um performance . grad f: hmm . phd a: so in other words right , professor b: right . phd a: so grad e: it just seems to me that , you know small changes to the language model and the vocabulary will so swamp that that it may be premature to worry about that . i mean so one is a half a percent better than the other i do n't think that gives you any information . phd c: well it 's just as easy to to give you the sixteen k individual , grad e: yep . phd c: it was just more disk space you know for storing them professor b: are you are you using uh uh mel cepstrum or plp over there ? phd c: so phd a: mel cepstrum . professor b: so probably does n't matter . phd c: well we could try . grad f: there 's there 's your answer . professor b: but but it would n't hurt to try , phd c: could easily try phd a: that 's what i would assume but you never know , professor b: yeah . phd c: so phd a: you know . professor b: sure . no the reason i say this postdoc g: just mm - hmm . professor b: plp uses uh auto - regressive filtering and uh modeling and so it can be sensitive to the kind of filtering that you 're doing phd a: mm - hmm . professor b: but uh uh mel cepstrum uh might not b you would n't expect to be so much but phd c: well we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti stick them somewhere grad f: yeah , it 's it 's really not a problem . phd a: actually , no . phd c: and i 'll rerun it with phd a: do n't stop . do n't stop at that part because we 're actually using the entire conversation to estimate the speaker parameters , grad f: keep going . yeah . phd a: so should n't use you should s you know , get grad f: yeah , i mean i 'll i have to do is eh e the reference file would stay the same , phd c: ok . phd a: right . grad f: it 's just the individual segments would be approximately twice as long phd a: mmm . phd c: right . right . grad f: and i could just replace them with the bigger ones in the directory , phd a: right . phd c: i mean i corrected all grad e: yeah . grad f: that 's not a problem . phd c: i mean i hand - edited the whole the whole meeting so that can be run it 's just once we get the the bug out . phd a: mmm . postdoc g: one one question which is i i had the impression { comment } from this from this meeting that w that i transcribed that um that there was already automatic downsampling occurring , phd a: yeah . mm - hmm . postdoc g: is that i thought that in order to grad e: yep . postdoc g: so it was so it 's like there 's already down grad e: there 's one level that 's already happening right here . professor b: this is being recorded at forty - eight kilohertz . which is more that anybody needs postdoc g: ok . grad e: right . grad f: oh . grad e: and it gets downsampled to sixteen . postdoc g: ok . professor b: so phd c: and that 's actually said in your meeting , grad f: hmm . postdoc g: oh ok . phd c: that 's how i know that . postdoc g: that 's exactly , and that 's how i know it . professor b: yeah . phd c: i i it 's like are we downsampling to sixteen ? professor b: it 's a digital audio orientation for the board phd c: right . phd a: mmm . professor b: it 's in the monitor so it 's phd c: thank god it 's not more than that . grad e: so professor b: yeah . grad e: and i have no idea what filter it 's using , grad f: is eight kilohertz is is eighty kilohertz generally accepted as like standard for voice ? grad e: so professor b: for telephone stuff . grad e: telephone . phd d: telephone . grad f: yeah that 's what i was gon na say , i mean like professor b: so it 's it 's it 's just that they were operating from switchboard which was a completely telephone database grad f: so oh , i see , so . professor b: and so that was a standard for that sixteen s grad f: ok . grad e: so sixteen seems to be pretty typical for with this sort of thing . professor b: sixteen is more common for for uh broadband stuff that is n't grad f: right . grad e: that is n't music . professor b: that is n't music and is n't telephone , phd c: and i guess if you 're comparing like uh if you wan na run recognition on the pzm stuff you would want you do n't want to downsample the wh that professor b: yeah . grad e: why is that ? professor b: i do n't know . phd c: right ? well i don i mean if it 's any better professor b: no actually i would think that you would you would get better you 'd get better high frequencies in the local mike . grad e: all the way around i 'd think . professor b: uh but who knows ? i mean we do we we we we we wan na find all this stuff out , phd c: yeah well we could try it . grad e: yeah . professor b: we do n't know . grad e: we 're gon na have plenty of low frequency on the p z ms with the fans . phd c: ok . yeah . professor b: uh yeah . yeah . phd c: oh yeah there was just one more thing i wanted to say which is totally unrelated to the recognition except that um well well it 's sort of related but um good news also uh i got well chuck fillmore agreed to record meetings but he had too many people in his meetings and that 's too bad cuz they 're very animated and but uh jerry also agreed so uh we 're starting on on phd a: they 're less animated . phd c: well but he has fewer he he wo n't have more than eight and it 's a meeting on even deeper understanding , edu , so that sounds interesting . as a compliment to our front - end meeting grad e: dot edu ? phd c: and um so that 's gon na start monday and one of the things that i was realizing is um it would be really great if anyone has any ideas on some kind of time synchronous way that people in the meeting can make a comment to the person whose gon na transcribe it or or put a push a button or something when they wan na make a note about `` oh boy you should probably erase those last few `` or uh `` wait i want this not to be recorded now `` or uh something like that s professor b: were n't we gon na do something with a pad at one point ? postdoc g: the cross pads ? grad e: yeah , we could do it with the cross pads . phd c: cuz i was thinking you know if if the person who sets up the meeting is n't there and it 's a group that we do n't know um and this came up talking to to jerry also that you know is there any way for them to indicate to make sure that the qu request that they have that they make explicitly get addressed somehow professor b: yeah . phd c: so i do n't know if anyone has ideas or you could even write down `` oh it 's about three twenty five and `` professor b: well what i was just suggesting is is we have these this cross pad just for this purpose grad e: yeah , and use that . professor b: and just use that grad e: not a bad idea . professor b: and if we sink it in phd c: that would be great . professor b: the other thing is eh phd c: that be great . professor b: i do n't know if you know this or if it 's a question for the mail to dan but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? grad e: i do n't know . i do n't know . i 'll send mail to dan and ask . i i think that it 's the maximum we can do without a lot of effort because it 's one board with two digital channels . professor b: oh it is one board . grad e: e eight each . so it it takes two fibers in to the one board . and so w i think if we wan na do that more than that we 'd have to have two boards , and then you have the synchronization issue . professor b: but that 's a question because that would if it was possible cuz it is i you know already we have a a a group of people in this room that can not all be miked grad e: right . professor b: and it 's not just cuz we have n't been to the store , right it 's phd d: what is the limit on each of those f fiber channels , is it the grad e: eight . phd d: it just it 's eight channels come in , does it have do with the sampling rate ? grad e: it 's eight . i have no idea . but each each fiber channel has eight eight channels and there are two ch two fibers that go in to the card . professor b: it might be a hard limitation , grad e: so professor b: i mean one thing is it the whole thing as i said is is all structured in terms of forty - eight kilohertz sampling so that pushes requirements up a bit grad e: yeah . professor b: but phd d: i was just wondering if if that could change . grad e: i mean then we 'd also have to get another add and another mixer and all that sort of stuff . phd d: if we could drop that . professor b: yeah . grad e: so i i 'll send a mail to dan and ask him . professor b: yeah . grad e: ok on the uh are we done with that ? so the oth topic is uh getting more mikes and different mikes , so i got a quote um we can fit we have room for one more wireless and the wireless , this unit here is three fifty three hundred fifty dollars , it i did n't realize but we also have to get a tuner the receiver the other end , that 's uh four thirty um and then also phd c: for for each ? phd d: wow . phd c: i mean the tuner is four thirty for each . grad e: yep . phd c: wow . grad e: and we just need one more so so professor b: yeah at least w we got the good ones . grad e: yeah . so that 's you know something like seven hundred eighty bucks for one more of these . professor b: yeah . ok . grad e: um and then also um it turns out that the connector that this thing uses is proprietary of sony phd d: oh . grad e: believe it or not and sony only sells this headset . postdoc g: mmm . grad e: so if we wan na use a different set headset the solution that the guy suggested and they apparently lots of people have done is sony will sell you the jack with just wires coming out the end and then you can buy a headset that has pigtail and solder it yourself . and that 's the other solution and so the jacks are forty bucks apiece and the he recommended um a crown cm three eleven ae headset for two hundred bucks apiece . professor b: there is n't this some sort of thing that plugs in , you actually have to go and do the soldering yourself ? grad e: becau - the reason is the only only thing you can get that will plug into this is this mike or just the connector . professor b: no i understand . the reason i ask is these sort of handmade uh wiring jobs fall apart in use so the other thing is to see if we can uh get them to do a custom job and put it together for this . grad e: oh i 'm sure they would , they would just charge us , phd d: well , and they 'd probably want quantity too , grad e: so . professor b: well phd d: they 'd professor b: no they 'll just charge us more , so it 's this phd d: mmm . grad e: so so my question is should we go ahead and get na nine identical head - mounted crown mikes ? professor b: not before having one come here and have some people try it out . grad e: ok . professor b: because there 's no point in doing that if it 's not gon na be any better . grad e: so why do n't we get one of these with the crown with a different headset ? professor b: yeah . grad e: and and see if that works . professor b: and see if it 's preferable and if it is then we 'll get more . phd c: comfort . grad e: yeah . professor b: yeah . phd c: cuz i mean i think the microphones are ok it 's just the the grad e: right , it 's just they 're not comfortable to wear . professor b: right . phd c: could make our own handbands and grad e: um , and he said they do n't have any of these in stock but they have them in la and so it will take about a week to get here . professor b: yeah well it 's grad e: um so ok to just go order ? professor b: we 're in this for the long term , yeah . just order it . grad e: ok phd c: it 's a lot of money for a handband . grad e: and who is the contact if i wan na do an invoice grad f: yeah . grad e: cuz i think that 's how we did it before . professor b: uh we 'll do this off - line , yeah . grad f: it 's a long time to get from la . grad e: ok . and then nine channels is the maximum we can do , so . professor b: uh y right cuz so one is for the daisy chain so that 's fifteen instead of sixteen grad e: without getting more stuff . professor b: and there 's six on the table so that 's nine . grad e: right . phd c: can i ask a really dumb question ? professor b: yeah . phd c: is is there any way we can have you know like a a wireless microphone that you pass around to the people who you know the extra people for the times they wan na talk that grad e: probably . professor b: that 's a good idea . phd c: i mean professor b: that 's not a dumb question , it 's a good idea , phd c: well i mean phd a: like uh like you know jerry springer thing , professor b: yeah . grad e: i 'm just not sure how we would handle that in the grad f: that 's like the conch . phd c: well but phd d: like at conferences phd a: you know r phd c: well but there might be a way to say that there are gon na be these different people grad f: see , look . phd c: um and i do n't know identifying somehow ? phd d: so nail the chairs down . phd a: yeah . grad e: yeah , somehow . phd c: you know i was just thinking of jerry springer . grad e: it 's not a bad idea . professor b: no that no no phd a:  professor b: that 's a very if we ca n't get another board and even if we can i have a feeling they 'll be some work . phd d: the springer mike . phd c: i mean for the few times that you might wan na have that . professor b: let 's figure that we have eight which are set up and then there 's a ninth which is passed around to grad e: a hand - held , yeah . professor b: that 's a good idea phd d: infinite expansion . professor b: right . kind of rules out overlap but but uh phd c: well or also for you know if people are not professor b: yeah . grad e: well we could just hand around the lapel . professor b: uh no no that 's grad e: rather than get a phd c: no not the lapel . grad e: do you want a handset ? professor b: no . grad e: well i mean is the is the hand - held really any better ? phd d: liz hates the lapel . professor b: yes . phd c: i do n't know grad e: ok . phd c: but i d i know the lapel is really suboptimal . professor b: no it no it depends on the hand - held grad e: is awful ? professor b: but hand many hand - helds are built wi with sort of uh anti - shock sort of things so that it it is less uh susceptible to hand noises . if you hold the lapel mike i you just get all k sorts of junk . phd d: mm - hmm . phd c: right . i mean the ones they really pass around must be sort of ok . grad e: ok . professor b: so grad e: so i wonder if they have one that will hook up . professor b: yeah . they have what ? grad e: i wonder if they have one that will hook up to this or whether again we 'll have to wire it ourselves . phd d: well , you would n't want it to hook there you 'd just want it to hook into the receiver in the other room , right ? professor b: no that 's uh you need a transmitter . grad e: what ? phd d: is th is n't that built into the mike ? professor b: oh i see . get a get a different radio , yeah . phd c: yeah just these ones that they pass around with no you know wireless professor b: yeah . but you need a ra but it has to correspond to the receiver . phd d: have a little antenna coming out the bottom . grad e: it 's gon na be much easier to get one of these and just plug in a mike , is n't it ? phd d: but then the mike has to h phd a: do you have to hand it around and if you have two pieces of professor b: no no phd c: right . grad f: yeah . phd a:  professor b: so right , so this is a good point , so yeah you have these these mikes with a little antenna on the end right ? grad e: ok . and do you think you would be able to use the same receiver ? professor b: i do n't know . you 'll have to check with them , grad e: ok i 'll i 'll ask . professor b: yeah . but that 's that 's a great idea phd d: it 's just a frequency . grad e: yeah . professor b: and then just sort of have that as the and then you can have groups of twenty people or whatever and and uh phd c: yeah because there 's only i mean as andreas pointed out actually i think in the large the larger the group the less interaction the less people are talking um over each other phd a: pretty soon . phd d: mmm , yeah . phd c: it just there might be a lot of people that speak once or twice and professor b: right . phd a: um got ta go . professor b: off you go , yeah . grad e: ok so i guess people who have to leave can leave and do we have anything else to discuss or should we just do digits ? postdoc g: i i thought of some extra a couple of extra things i 'd like to mention . grad e: ok . postdoc g: one of them is to give you a status in terms of the transcriptions so far . so um as of last night um i 'd assigned twelve hours and they 'd finished nine grad e: uh yep , postdoc g: and my goal was to have eleven done by the end of the month , i think that by tomorrow we 'll have ten . phd c: uh it 's great professor b: pretty close , postdoc g: so they 're still working . professor b: that 's good . phd c: i j and this i got this email from jane at like two in the morning or something phd d: wow . grad e: that 's good . phd c: so it 's really great postdoc g: it 's working out , thanks . phd c: it 's really great . postdoc g: thanks . and then um also an idea for another meeting , which would be to have the transcribers talk about the data it 's sort of a a little bit a little bit phd c: that 's a great idea . professor b: super idea . grad e: yep , that 'd be very interesting . phd c: that 's a great idea cuz i 'd like to g have it recorded so that we can remember all the little things , grad f: yeah . grad e: i 'd love to hear what they have to say . postdoc g: yeah . phd c: that 's a great idea . phd d: so if we got them to talk about this meeting , it would be a meta meta meeting . postdoc g: yeah . yeah , exa exactly i guess nested several layers , professor b: now you have eight transcribers and there 's ten of us postdoc g: but professor b: so how do we do this , is the only thing . phd c: or just have them talk amongst themselves . phd d: have them have their own meeting . phd c: and have postdoc g: well that 's what i 'm thinking , professor b: oh . postdoc g: yeah . have them talk about the data and they and they 've made observations to me phd c: that would be great . postdoc g: like they say uh you know this meeting that we think has so much overlap , in fact it does but there are other groups of similar size that have very little , you know it 's part of it 's it 's the norm of the group and all that and they have various observations that would be fun , i think . phd c: that 's a great idea . grad e: yeah , i 'd like to hear what they s say . postdoc g: yeah . phd c: be great . professor b: so maybe we could they could have a meeting more or less without us that to do this and we should record it postdoc g: ok . professor b: and then maybe one or two of them could come to one of these meetings and and could you know could tell us about it . postdoc g: yeah . grad e: give us a status . phd c: yeah . postdoc g: oh good . ok . professor b: yeah . phd c: it 's they will get to transcribe their own meeting but they also get paid for having a break grad e: that would be weird . postdoc g: what what yeah that 's right . phd c: and i think that 's a good idea , postdoc g: yeah exactly , yeah . professor b: yeah . phd c: get them involved . postdoc g: great . phd c: um that 's a great idea . postdoc g: great . professor b: super . phd c: i 'm really sorry i have to g no i have to go as well . professor b: ok . postdoc g: and then i wanted to also um say something about the fiscus uh uh john john fiscus visit tomorrow . and which is to say that w it 'll be from nine to one that i 'm going to uh uh offer the organization allow him to uh adjust it if he wishes but to be basically in three parts , the acoustic part coming first which would be basically the room engineering aspects um other things and he 'll be also presenting what nist is doing and and uh then uh number two would be sort of a the the transcription process so this would be a focus on like presegmentation and the modifications to the the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which uh dave gelbart 's been doing and then um uh and of course the presegmentation thilo 's been doing and then um the third part would and again he has some stuff that 's i relevant with respect to nist and then the third one would be focus on transcription standards so at nist he 's interested in this establishment of a global encoding standard i guess i would say and i want it , you know k yeah see what they 're doing and also present what what we 've chosen as ours and and discuss that kind of thing . and so but he 's only here until until one and actually we 're thinking of noon being uh lunch time so basically hoping that we can get as much of this done as possible before noon . s professor b: ok . postdoc g: and everybody who wants to attend is welcome . so grad e: oh , where you 're gon na meet ? postdoc g: yeah . here mostly but i 've also reserved the barco room um eh to figure out how that works in terms of like maybe having a live demonstration . professor b: ok but the nine o ' cl nine o ' clock will be i be in here . yeah , ok . postdoc g: yeah . mm - hmm . grad e: i assume we 're not gon na try to record it ? postdoc g: oh i think that would be hard , yeah . professor b: yeah , i think just adds grad e: alright . postdoc g: yeah . professor b: um good . postdoc g: thank you though , uh - huh . professor b: so maybe do digits and recess ? grad e: unless there 's anything else ? postdoc g: yeah . yeah . phd d: do digital ones ? professor b: uh ok . postdoc g: yeah . grad e: uh should y we make him wear andreas ' mike or would that just be too confusing ? professor b: yeah . no i do n't think it 's confusing . well , it does n't confuse me . postdoc g: when we do this in the key in the key in the key it has to indicate that channel change , phd d: does it mess up the forms ? postdoc g: right ? grad e: uh yeah i just do n't know how we would do that , so . i mean other than free free form . postdoc g: well i have a time mark . phd d: the on switch is here on the on the top there . postdoc g: yeah . professor b: ok . grad e: and just clip it to your collar . professor b: that 's fine . grad j: ok , my name is uh espen eriksen . i 'm a norwegian . um uh this is my second semester at berkeley . currently i 'm taking uh my first graduate level courses in dsp and um when i come back to norway i 'm gon na continue with the more of a research project work kind of work . so this semester i 'm starting up with a with a small project through uh dave gelbart which i 'm taking a course with i got in touch with him and he told me about this project . so with the help of uh dan ellis i 'm gon na do small project associated to this . what i 'm gon na try to do is uh use use ech echo cancellation to uh to handle the periods where you have overlapping talk . to try to do something about that . so currently i 'm um i 'm just reading up on echo cancellation , s looking into the theory behind that and then uh hopefully i get some results . so it it 's a it 's a project goes over the course of one semester . grad e: great . grad j: so i 'm just here today to introduce myself . tell about i 'll be i 'll be working on this . grad e: and are you staying at berkeley or is are you just here a semester ? grad j: this is my second semester and last . grad e: ah second and last , professor b: yeah . grad e: ok . grad j: so i leave professor b: he 's in the he 's in the cour two two five d course . grad j: yeah , i 'm in morgan 's course , professor b: so , yeah . grad j: yeah . grad e: good . phd d: welcome . postdoc g: then you then you go back to norway , that 's ok . grad j: yeah . grad f: we were just talking about something like this yesterday or yeah yesterday with liz . about doing some of the echo cancellation stuff or possibly the spectroanalysis over the overlaps , so . cool . grad j: yeah . professor b: ok , grad e: digits ? professor b: let 's do digits . ok . grad e: and stop .","output":"following close-talking microphone recognition procedures , it was decided that data from the far-field microphones ( or pzms ) should be tested on the recognizer as soon as possible . speaker mn017 will compare close-talking microphone recognition results with those obtained for downsampled data . the sri recognizer will be set up at icsi to enable researchers to run their own variants ."},{"instruction":"what were the changes decided on the equipment ?","input":"grad f: test . postdoc g: ok . professor b: let 's see , i should be two . phd d: up high grad e: as close to your mouth as you can get it . professor b: la phd d: high as you can get . professor b: is this channel one ? postdoc g: yeah , on your upper lip . phd h: channel one one one . professor b: gee , ok . yes . ok . grad e: ok , so for for for people wearing the wireless mikes , like like this one , i find the easiest way to wear it is sorta this this sorta like that . phd h: this is chan channel channel one one two three grad f: channel five , channel five . professor b: yeah . mm - hmm . what do you do , grad e: it 's actually a lot more comfortable then if you try to put it over your temples , grad f: test , test test . professor b: you do it higher ? grad e: so professor b: mm - hmm . phd d: adam 's just trying to generate good uh data for the recognizer there . postdoc g: yeah , i think we 're supposed to that 's right . grad e: and then also , for for all of them , if your boom is adjustable , the boom should be towards the corner of your mouth , grad f: test test . phd a: by the way , there was a bug . yeah , i it was n't using the proper phd d: oh it was . grad e: and about a uh a thumb to a thumb and a half distance away from your mouth , phd a: basically it was n't adapting anything . phd d: oh . grad e: so about like i 'm wearing it now . phd d: oh that 's interesting . so why did n't you get the same results and the unadapted ? grad e: so so jane , you could actually do even a little closer to your mouth , phd h: it 's not always possible . phd a: hmm ? phd d: why did n't you get the same results and the unadapted ? postdoc g: i could can this be adjuste like this ? grad e: but phd a: oh , because when it estimates the transformer pro produces like a single matrix or something . grad e: yep . postdoc g: is that @ @ ? ok , thank you . grad f: adam , i 'm not phd d: o oh oh i see . grad f: uh , looks kinda low on channel five phd d: i see , i see . professor b: ok . grad f: no ? grad e: channel five , s speak again . grad f: maybe not . postdoc g: hello . phd a: basically there were no counts grad e: yeah , that 's alright . grad f: hello ? grad e: i mean , we could we could up the gain slightly if you wanted to . grad f: it 's ok ? phd h: yeah . grad f: is this ok ? phd h: ok . phd d: i see what you mean . phd c: who 's channel b ? grad e: but uh , channel b is probably liz . phd c: uh oh . phd h: uh channel b i am channel b . professor b: you wan na close this , postdoc g: channel eight , eight . professor b: or phd c: no i grad e: thank you . phd h: no , channel b . phd a: hello , hello . phd c: yeah , yeah , you 're channel b . phd h: yeah , yeah . phd c: so can you talk a bit ? i thought it might be too phd h: ok , yeah , channel b , one two three four five . phd c: ok . grad e: yeah , it 's alright . so , the gain is n't real good . professor b: we 're recording , phd c: ok . professor b: right ? grad e: ok , so we are recording . phd h: ah . professor b: yeah . phd a: ok . grad e: um everyone should have at least two forms possibly three in front of you depending on who you are . grad f: oh . grad e: um we we 're doing a new speaker form and you only have to spea fill out the speaker form once but everyone does need to do it . and so that 's the name , sex , email , et cetera . phd h: mm - hmm . grad e: we we had a lot of discussion about the variety of english and so on so if you do n't know what to put just leave it blank . um i i designed the form and i do n't know what to put for my own region , phd a: mmm . grad e: so phd d: california . phd a: i think grad e: california . phd h: california . phd a: um may i make one suggestion ? instead of age put date of uh year of birth grad e: sure . phd a: because age will change , but the year of birth changes , you know , stays the same , usually . grad e: oh . phd c: a actually , wait a minute , grad e: birth year ? postdoc g: although on phd a: yeah . phd c: should n't it be the other way around ? phd d: not for me . postdoc g: course on the other on the other hand you could you view it as the age at the time of the phd c: on the other side , phd a: well the thing is , if ten years from now you look at this form knowing that phd c: yeah . postdoc g: yes , but what we care about is the age at at the recording date rather than the phd c: o yeah . phd d: but there 's no other date on the form . phd c: w we do n't care how they old they really are . phd a: well well i do n't know . postdoc g: yes . unless we wan na send them a card . grad e: well i guess it depends on how long the corpus is gon na be collected for . phd a: anyway . postdoc g: yeah , that 's true . phd c: i still do n't see the problem . grad e: either way yeah i think i think age is alright phd a: ok . grad e: and then um there will be attached to this a point or two these forms uh so that you 'll be able to extract the date off that phd a: mm - hmm . grad e: so , anyway . and so then you also have a digits form which needs to be filled out every time , the speaker form only once , the digit form every time even if you do n't read the digits you have to fill out the digits form so that we know that you were at the meeting . ok ? and then also if you have n't filled one out already you do have to fill out a consent form . and that should just be one person whose name i do n't know . ok ? grad f: do you want this adam ? grad e: uh sure . thank you . professor b: so uh grad e: ok so should we do agenda items ? professor b: uh oh that 's a good idea . i should n't run the meeting . grad e: uh well i have i wan na talk about new microphones and wireless stuff . postdoc g: mmm . grad e: and i 'm sure liz and andreas wan na talk about recognition results . anything else ? phd c: i guess what time do we have to leave ? three thirty ? phd a: yeah . phd c: yeah , grad e: why do n't you go first then . phd c: so . professor b: yeah , good idea . phd a: ok . phd c: um well , i i sent out an email s couple hours ago so um with andreas ' help um andreas put together a sort of no frills recognizer which is uh gender - dependent but like no adaptation , no cross - word models , no trigrams a bigram recognizer and that 's trained on switchboard which is telephone conversations . um and thanks to don 's help wh who don took the first meeting that jane had transcribed and um you know separated used the individual channels we segmented it in into the segments that jane had used and uh don sampled that so so eight k um and then we ran up to i guess the first twenty minutes , up to synch time of one two zero zero so is that that 's twenty minutes or so ? um yeah because i guess there 's some , grad e: or so . phd c: and don can talk to jane about this , there 's some bug in the actual synch time file that ah uh i 'm we 're not sure where it came from but stuff after that was a little messier . anyway so it 's twenty minutes and i actually grad e: hmm . phd c: um grad e: i was that did that did that recording have the glitch in the middle ? postdoc g: i 'm puzzled by that . i oh oh , i see . phd c: there 's there 's a postdoc g: oh there was a glitch somewhere . phd c: yeah , so that actually um grad f: was it twenty minutes in , phd c: if it was twenty minutes in then i do n't know postdoc g: i forgot about that . grad f: i thought phd a: well it was interesting , postdoc g: well , i mean , they phd a: suddenly the the overall error rate when we first ran it was like eighty percent grad e: i do n't remember when it is . postdoc g: but i was able to can transcribe phd a: but i looking at the first sentences looked much better than that and then suddenly it turned very bad and then we noticed that the reference was always one off with the it was actually recognized phd c: wel grad e: oh no . grad f: yeah , that might be that might be that might be my fault . postdoc g: wow . phd a: so grad e: oh so that was just a parsing mismatch . grad f: i 'm not phd a: ok . phd c: no actually it was yeah i it was a complicated bug because they were sometimes one off and then sometimes totally random so um grad f: yeah , i was pretty certain that it worked up until that time , postdoc g: oh . that 's not good . phd c: yeah phd a: ok . phd c: so that 's what we have grad e: alright . grad f: so phd c: but that that will be completely gone if this synch time problem postdoc g: yeah . grad e: the the glitch phd a: so so we have everything recognized but we scored only the first uh whatever , up to that time to postdoc g: and the only glitch grad e: yeah . postdoc g: yeah . phd c: so you guys know . professor b: s sorry i have n't seen the email , phd c: yeah . grad e: th - the postdoc g: the the well wait professor b: what was the score ? phd c: so here 's the actual copy of the email postdoc g: we should say something about the glitch . he he can say something about the glitch . phd c: um oh ok grad e: yeah . postdoc g: cuz it 's it 's it 's h it 's it 's very small phd c: so does this glitch occur at other grad e: there there there 's an acoustic glitch that occurs where um the channels get slightly asynchronized postdoc g: very small . yep . phd c: oh . phd a: mmm . phd c: right . grad e: so the that that problem has gone away in the original driver believe it or not when the ssh key gen ran the driver paused for a fraction of a second professor b: hmm . grad f: hmm . grad e: and so the channels get a little asynchronous and so if you listen to it in the middle there 's a little part where it starts doing doing click sounds . professor b: so phd c: and is it only once that that happens ? grad e: but yeah phd c: ok . grad e: it right once in the middle . phd c: there 's the previous page has some more information about sort of what was wrong professor b: so so un unsurprisingly adam is the golden voice , phd c: but grad e: um but that should n't affect anything phd c: ok so that 's actually postdoc g: s and it professor b: you see this here ? phd c: it y it 's grad e: yeah yeah `` bah `` phd c: ok no phd a: oh , and phd c: what happens is it actually affects the script that don phd d: huh . phd c: i mean if we know about it then i guess it could always be checked for it grad e: well the acoustic one should n't do anything . phd c: but they grad f: yeah , i do n't know exactly what affected it postdoc g: i agree . i agree . phd a: i i have grad f: but i 'll i 'll talk to you about it , phd a: yeah . grad e: but i i do remember phd c: yeah . grad f: i 'll show you the point . postdoc g: yeah . it it had no effect on my transcription , phd a: mmm . postdoc g: you know , i mean i i had no trouble hearing it and and having time bins grad e: i do remember seeing once the transcriber produce an incorrect xml file where one of the synch numbers was incorrect . postdoc g: but there was a oh . phd c: well , the the synch time the synch numbers have more significant digits than they should , grad f: that 's what happened . postdoc g: oh . phd h: yeah . grad e: where where they were n't monotonic . grad f: there was yeah , i mean phd c: right ? there 's things that are l in smaller increments than a frame . phd h: yeah . postdoc g: oh , interesting . phd c: and so then , i mean you look at that and it 's got you know more than three significant digits in a synch time then that ca n't be right grad e: oh ok so that 's grad f: hmm . postdoc g: oh . phd a: mmm . phd c: so anyway it 's it 's just grad e: yeah sounds like a bug . postdoc g: yeah . phd c: that 's why we only have twenty minutes but there 's a significant amount of grad f: non - zero ? um there are like more cuz there 's a lot of zeros i tacked on just because of the way the script ran , grad e: the other one i saw was that it yeah . grad f: i mean but there were there was a point . phd c: yeah that was fine . that that was ok . grad e: the other one i saw was non non - monotonic synch times grad f: ok . grad e: and that definitely indicra indicates a bug . grad f: uh . phd c: well that would really be a problem , yeah . so anyway these are just the ones that are the prebug for one meeting . grad f: yeah . phd c: um and what 's which grad e: so that 's very encouraging . phd c: this is really encouraging cuz this is free recognition , professor b: hmm . phd h: yeah . professor b: cool . phd a: mmm . phd c: there 's no i mean the language model for switchboard is totally different so you can see some like this trent lott which phd d: trent lott . phd c: um i mean these are sort of funny ones , phd d: it 'll get those though . phd c: there 's a lot of perfect ones and good ones and all the references , i mean you can read them and when we get more results you can look through and see grad e: i and as i said i would like to look at the lattices phd a: mm - hmm . phd c: but um it 's pretty good . grad e: because it sounded like even the ones it got wrong it sort of got it right ? phd c: well so i guess we can generate grad e: sounds likes ? phd a: there are a fair number of errors that are , you know where got the plural s wrong or the inflection on the verb wrong . postdoc g: mm - hmm . phd c: um grad e: yeah , and who cares ? and and there were lots of of course the `` uh uh `` - s , `` in on `` - s `` of uh `` - s . phd a: mmm , so if phd c: there 's no those are actually phd a: yeah . phd c: a lot of the errors i think are out of vocabulary , phd a: mm - hmm . phd c: so is it like pzm is three words , it 's pzm , phd a: mm - hmm . phd c: i mean there 's nothing there 's no language model for pzm or grad e: right . ri - ri right . phd c: um grad e: did you say there 's no language for pzm ? phd c: no language model , i mean those grad e: do you mean so every time someone says pzm it 's an error ? maybe we should n't say pzm in these meetings . phd c: well well there 's all kinds of other stuff like jimlet and i mean um anyway there grad e: yeah , that 's right , jimlet . professor b: well , we do n't even know what that means , phd c: so but this is really encouraging because professor b: so i grad e: yeah , that 's right . phd c: so , i mean the bottom line is even though it 's not a huge amount of data um it should be uh reasonable to actually run recognition and be like within the scope of of r reasonable s you know switchboard this is like h about how well we do on switchboard - two data with the switchboard - one trained mostly trained recognizer grad e: right . phd c: and switchboard - two is got sort of a different population of speakers and a different topic grad e: excellent . phd c: and they 're talking about things in the news that happened after switchboard - one so there was @ @ so that 's great . professor b: yeah . yeah so we 're in better shape than we were say when we did had the ninety - three workshop phd c: um professor b: and we were all getting like seventy percent error on switchboard . phd a: mm - hmm . phd c: oh yeah professor b: you know phd c: i mean this is really , phd a: mmm . phd c: and thanks to andreas who , i mean this is a phd a: mmm . grad e: well especially for the very first run , i mean you phd a: oh it 's the professor b: yeah . phd c: eh um professor b: yeah . phd c: yeah grad e: the first run i ran of switchboard i got a hundred twenty percent word error but phd c: so and what al also this means is that postdoc g: right . phd c: um grad e: not switchboard , phd a: well it 's phd c: i mean there 's a bunch of things in this note to various people grad e: uh broadcast news . phd c: especially i guess um with jane that that would help for since we have this new data now uh in order to go from the transcripts more easily to um just the words that the recognizer would use for scoring . i had to deal with some of it by hand but i think a lot of it can be automated s by professor b: oh one thing i guess i did n't get so you know the language model was straight from from bigram from switchboard the acoustic models were also from switchboard or or phd a: yeah . phd c: yeah . professor b: so they did n't have anything from this acoustic data in yet ? postdoc g: that 's amazing . grad e: yeah , so that 's great . phd c: no . professor b: ok . phd c: and actually we actually um used switchboard telephone bandwidth models postdoc g: that 's amazing . phd a: well that 's those are the only we ones there are , professor b: yeah . phd c: which i guess phd d: i was just gon na say , phd c: so that 's the on that 's the only acoustic training data that we have a lot of phd d: yeah . phd a: i mean grad e: yeah . phd a: right . phd c: and i guess ramana , so a guy at sri said that um there 's not a huge amount of difference going from professor b: right . phd c: it 's it 's not like we probably lose a huge amount but we wo n't know because we do n't have any full band models for s conversational speech . phd d: it 's probably not as bad as going f using full band models on telephone band speech phd c: so . phd a: oh yeah . phd c: right . phd d: right ? phd a: yeah . professor b: yeah , phd c: right , so it 's so professor b: but for broadcast news when we we played around between the two there was n't a huge loss . grad e: right , it was not a big deal . phd c: yeah phd a: i should i should say that the language model is not just switchboard phd c: so i wou so that 's good . grad e: although combining em worked well . phd a: it 's also i mean there 's uh actually more data is from broadcast news but with a little less weight phd c: yeah . phd a: uh because professor b: uh - huh . phd c: like trent lott must have been from phd a: mm - hmm , right . phd c: i guess switchboard was before phd a: um by the way just for fun we also ran , phd c: uh . professor b: good point . phd a: i mean our complete system starts by doing ge a gender detection professor b: mm - hmm . phd a: so just for the heck of it i ran that grad e: and it said a hundred percent male ? phd a: um and it might be reassuring for everybody to know that it got all the genders right . phd c: the j phd a: yeah so grad e: oh it did ? postdoc g: oh that 's i 'm glad . grad e: it got all two genders ? phd c: yeah but you know jane and adam have you kn about equal performance phd a: yeah . yes . phd c: and uh and that 's interesting cuz i think the their language models are quite different so and i i 'm pretty sure from listening to eric that , you know given the words he was saying and given his pronunciation that the reason that he 's so much worse is the lapel . professor b: yeah . grad e: right . postdoc g: that makes a lot of sense , phd c: so it 's nice now if we can just sort of eliminate the lapel one when when we get new microphones postdoc g: yeah . very possible . professor b: yeah i i i would bet on that too phd c: that would be worth it professor b: cuz he certainly in that when as a as a burp user he was he was a pretty uh strong one . phd c: um yeah grad e: sheep . phd c: he he he sounded to me just from he sounded like a , professor b: yeah . phd c: what 's it a sheep or a goat ? professor b: sheep . grad e: a sheep . phd c: sheep , grad e: baah . professor b: yeah . sheep is good . phd c: right . sounded good . professor b: yeah . phd c: right so um so i guess the good news is that postdoc g: mm - hmm . phd c: and and again this is without a lot of the sort of bells and whistles that we c can do with the sri system and we 'll have more data and we can also start to maybe adapt the language models once we have enough meetings . so this is only twenty minutes of one meeting with no no tailoring at all . phd a: i mean clearly there are um with just a small amount of uh actual meeting transcriptions uh thrown into the language model you can probably do quite a bit better because the phd c: yeah . the voca the vocabulary especially grad e: or just dictionary . phd c: yeah . phd a: not that much the vocabulary actually phd c: yeah , so . phd a: i think um well we have to see but it 's uh phd c: yeah . it 's pretty good um so then professor b: have to add pzm and so on grad e: and i have to try it on the far field mike professor b: but phd c: pzm grad e: yeah . phd c: and then there 's things like for the transcription i got when someone has a digit in the transcript i do n't know if they said , you know one one or eleven and i do n't know if they said tcl or tcl . there 's things like that where , you know the um we 'll probably have to ask the transcribers to indicate some of those kinds of things but in general it was really good and i 'm hoping and this is this is good news because that means the force alignments should be good and if the force alignments , i mean it 's good news anyway but if the force alignments are good we can get all kinds of information . for example about , you know prosodic information and speaker overlaps and so forth directly from the aligned times . um so that 'll be something that actually in order to assess the forced alignment um we need s some linguists or some people to look at it and say are these boundaries in about the right place . because it 's just gon na give us time marks phd d: but you know grad e: well we 've done that for one meeting . phd c: so . for forced alignment . grad e: uh oh oh f not for words phd c: ye - right . grad e: i 'm sorry just for overlaps is we did it for not not for words . phd c: right . so this would be like if you take the words um you know and force align them on all the individual close talk uh close talking mikes then how good are these sort of in reality grad e: right . phd c: and then i was thinking it grad e: so we might want to take twenty minutes and do a closer word level transcription . maybe actually mark the word boundaries . phd c: oh or i have someone look at the alignments uh maybe a linguist who can say um you know roughly if these are ok and how far away they are . professor b: yeah . phd c: um but i think it 's got ta be pretty good because otherwise the word recognition would be really b crummy . grad e: right , right . phd c: it would n't necessarily be the other way around , if the wor word recognition was crummy the alignment might be ok but if the word recognition is this good the alignment should be pretty good . so that 's about it . professor b: i r phd d: i wonder if this is a good thing or a bad thing though , i mean if we 're pr grad e: that we 're starting so well ? phd d: yeah if we 're producing a database that everybody 's gon na do well on professor b: oh grad e: do n't worry about it w d that 's that 's the close talking mikes . try it on the p z ms and and professor b: yeah , which i would which well n n n n phd d: so the real value of the database is these ? phd h: yeah , yeah , yeah , yeah . grad e: yeah , abso well no but professor b: i mean there 's still just the w the percentages and , i mean they 're not a as we 've talked about before there 's probably overlaps phd c: this i yeah . this is not that good . professor b: there 's probably overlaps in in uh in fair number in switchboard as well so but but there 's other phenomena , it 's a meeting , it 's a different thing and there 's lots of stuff to learn with the close talking mikes but uh yeah certainly i 'd like to see as soon as we could , i mean maybe get some of the glitches out of the way but soon as we could how well it does with say with the p z ms or maybe even one of the phd c: right . professor b: and uh see if it 's , you know is it a hundred twenty percent or maybe it 's not maybe if with some adaptation you get this down to fifty percent or forty - five percent or something and and then if for the pzm it 's seventy or something like that that 's actually something we could sort of work with a little bit phd c: yeah . professor b: so phd c: no i think it 's really , i mean this way we least have a baseline we know that for instance the transcripts are very good so once you can get to the words that the recognizer which is a total subset of the things you need to understand the the text um yeah they 're pretty good so and and it 's converting automatically from the xml to the chopping up the wave forms and so forth it 's not the case that the end of one utterance is in the next segment and things like that which we had more problems with in switchboard so that 's good . and um let 's see there was one more thing i wanted to to mention i ca n't remember um sorry ca n't remember . anyway it 's postdoc g: congratulations is really great . professor b: yeah . phd c: well it was , i mean i really did n't do this myself grad e: yeah , it 's really good . phd c: so andreas set up this recognizer and by the way the recognizer all the files i 'm moving to sri and running everything there so i brought back just these result files and people can look at them um so phd a: we we talked about setting up the sri recognizer here . that 's you know if if there are more machines um uh here plus people can could run their own uh you know variants of of of the recognition runs um certainly doable . um . professor b: yeah and well certainly if the recognition as opposed to training , yeah . phd a: yeah . professor b: seems reasonable . postdoc g: i need t hmm . i need to ask one question . phd a: yeah . postdoc g: which is um so this issue of the uh legalistic aspects of the pre - sent you know pre - adapted yeah , well , so what i mean is um the uh the data that you take into sri , first first question , you 're maintaining it in in a place that would n't be publicly readable that that kind of stuff , right ? phd a: u um phd c: from the outside world or postdoc g: by uh people uh who are not associated with this project . phd a: oh . grad e: it 's human subjects issues , i told you about that . phd c: um oh . postdoc g: exactly . phd c: well ok we have n no names . although i sh um grad e: that that 's not the issue , phd c: de audio data itself ? grad e: it 's just the audio data itself , until people have a chance to edit it . postdoc g: mm - hmm , exactly . phd c: uh so well i can i can protect my directories through there . postdoc g: yeah . phd c: right now they 're not they 're in the speech group directories which so i will postdoc g: great . phd c: i did n't know that actually . professor b: yeah so we just have to go through this process of having people approve the transcriptions , phd c: yeah ok . professor b: say it 's ok . phd c: right ok . postdoc g: yeah , we had to get them to approve em and then i cuz cuz the other question i was gon na ask is if we 're having um you know it 's but this this meeting that you have , no problem cuz i i well i mean i i speak for myself grad e: it 's us . postdoc g: but but i think that we did n't do anything that but well anyway so uh i would n't be too concerned about it with respect to that although we should clear it with eric and dan of course but these results are based on data which have n't had the uh have n't had the chance to be reviewed by the subjects phd c: that 's true . postdoc g: and i do n't know how that stands , i mean if you if you get fantastic results and it 's involving { comment } data which which later end up being lessened by , you know certain elisions , then i do n't know but i wanted to raise that issue , professor b: well we , postdoc g: that 's all . professor b: i mean once we get all this streamlined it may be sh it hopefully it will be fairly quick but we get the transcriptions , people approve them and so on it 's just that we 're grad e: alright we need to work at a system for doing that approval so that we can send people the transcripts postdoc g: great . phd a: mmm . postdoc g: yeah . grad e: and get back any bleeps that they want phd c: yeah actually the bleeps are also an issue i thought . professor b: it 's gon na be a rare thing that there 's a bleep for the most part . phd a: u uh actually i had a question about the downsampling , um i do n't know who , i mean how this was done but is is there are there any um issues with downsampling phd c: don did this . phd a: because i know that the recognizer um that we use h can do it sort of on the fly um so we would n't have to have it eh you know do it uh explicitly beforehand . and is there any um i are there other d sev uh is there more than one way to do the downsampling where one might be better than another ? grad f: there are lots of w there are lots of ways to do the downsampling um different filters to put on , phd a: ok . right . ok . grad f: like anti - aliasing stuff . phd a: so so the th grad e: i do n't think we even know which one i assume you 're using syncat to do it ? grad f: no , i 'm using uh sn snd uh are resample . grad e: or sound resample ? phd c: re - re ref grad e: resample . phd c: yeah . grad e: yeah and dan 's archaic acronyms . grad f: rsmp . yeah , i do n't really . phd c: missing all the vowels . grad f: i just yeah i found it . phd c: some of the vowels , grad e: not all of them . phd c: almost all the vowels , that 's the hard part . phd a: so so the other thing we should try is to just take the original wave forms , grad e: and a few of the consonants . phd a: i mean segment them but not downsample them . phd c: yeah we could we could try that and and compare phd a: and and feed them to feed them to the sri recognizer and see if if the sri front - end does something . grad f: yeah , that 's phd c: yeah . grad e: i suspect that 's sort of premature optimization , but sure . phd c: we can try it . i i only downsampled them first cuz i was phd a: well grad f: i mean that 's just one line that 's one line of code to comment at phd c: yeah phd a: right and and it does n't is no more work for um you know for us . grad f: so grad e: mm - hmm . grad f: yeah . phd c: well they 're just bigger to transfer , that 's why i s downsampled them before but phd a: well but they 're only twice as big so phd c: well i mean that was if it 's the same then we can downsample here phd a: i mean it 's it 's just a phd c: but if it 's grad f: although those eighty meg files take a while to copy into my directories phd c: yeah . grad f: so , but no , i mean it 's not i it would n't be a problem if you 're interested in it phd c: we could try that . phd a: yeah i mean it would be uh you know it would probably take uh about um you know grad f: it would phd a: minus the transfer time it would it would take uh you know ten minutes to try and and and grad f: yeah . grad e: it 's about a fifty minute drive , right ? phd a: and and if for some reason we see that it works better then we might investigate why phd c: well it takes more disk space too so i was just phd a: and , you know , what yeah . grad f: mmm . in the front - end we could do that . phd a: yeah . professor b: so you just train just different filters grad f: yeah , i professor b: and so you 're just wondering whether the filter is grad f: yeah , i can imagine it would be phd a: right . right . phd c: so we could try that with this particular twenty minutes of speech and sort of see if there 's any differences . grad f: i mean i guess there 's some phd a: you know a at some point someone might have optimized whatever filtering is done for the actual recognition um performance . grad f: hmm . phd a: so in other words right , professor b: right . phd a: so grad e: it just seems to me that , you know small changes to the language model and the vocabulary will so swamp that that it may be premature to worry about that . i mean so one is a half a percent better than the other i do n't think that gives you any information . phd c: well it 's just as easy to to give you the sixteen k individual , grad e: yep . phd c: it was just more disk space you know for storing them professor b: are you are you using uh uh mel cepstrum or plp over there ? phd c: so phd a: mel cepstrum . professor b: so probably does n't matter . phd c: well we could try . grad f: there 's there 's your answer . professor b: but but it would n't hurt to try , phd c: could easily try phd a: that 's what i would assume but you never know , professor b: yeah . phd c: so phd a: you know . professor b: sure . no the reason i say this postdoc g: just mm - hmm . professor b: plp uses uh auto - regressive filtering and uh modeling and so it can be sensitive to the kind of filtering that you 're doing phd a: mm - hmm . professor b: but uh uh mel cepstrum uh might not b you would n't expect to be so much but phd c: well we can try it if you generate like the same set of files just up to that point where we stopped anyway and just sti stick them somewhere grad f: yeah , it 's it 's really not a problem . phd a: actually , no . phd c: and i 'll rerun it with phd a: do n't stop . do n't stop at that part because we 're actually using the entire conversation to estimate the speaker parameters , grad f: keep going . yeah . phd a: so should n't use you should s you know , get grad f: yeah , i mean i 'll i have to do is eh e the reference file would stay the same , phd c: ok . phd a: right . grad f: it 's just the individual segments would be approximately twice as long phd a: mmm . phd c: right . right . grad f: and i could just replace them with the bigger ones in the directory , phd a: right . phd c: i mean i corrected all grad e: yeah . grad f: that 's not a problem . phd c: i mean i hand - edited the whole the whole meeting so that can be run it 's just once we get the the bug out . phd a: mmm . postdoc g: one one question which is i i had the impression { comment } from this from this meeting that w that i transcribed that um that there was already automatic downsampling occurring , phd a: yeah . mm - hmm . postdoc g: is that i thought that in order to grad e: yep . postdoc g: so it was so it 's like there 's already down grad e: there 's one level that 's already happening right here . professor b: this is being recorded at forty - eight kilohertz . which is more that anybody needs postdoc g: ok . grad e: right . grad f: oh . grad e: and it gets downsampled to sixteen . postdoc g: ok . professor b: so phd c: and that 's actually said in your meeting , grad f: hmm . postdoc g: oh ok . phd c: that 's how i know that . postdoc g: that 's exactly , and that 's how i know it . professor b: yeah . phd c: i i it 's like are we downsampling to sixteen ? professor b: it 's a digital audio orientation for the board phd c: right . phd a: mmm . professor b: it 's in the monitor so it 's phd c: thank god it 's not more than that . grad e: so professor b: yeah . grad e: and i have no idea what filter it 's using , grad f: is eight kilohertz is is eighty kilohertz generally accepted as like standard for voice ? grad e: so professor b: for telephone stuff . grad e: telephone . phd d: telephone . grad f: yeah that 's what i was gon na say , i mean like professor b: so it 's it 's it 's just that they were operating from switchboard which was a completely telephone database grad f: so oh , i see , so . professor b: and so that was a standard for that sixteen s grad f: ok . grad e: so sixteen seems to be pretty typical for with this sort of thing . professor b: sixteen is more common for for uh broadband stuff that is n't grad f: right . grad e: that is n't music . professor b: that is n't music and is n't telephone , phd c: and i guess if you 're comparing like uh if you wan na run recognition on the pzm stuff you would want you do n't want to downsample the wh that professor b: yeah . grad e: why is that ? professor b: i do n't know . phd c: right ? well i don i mean if it 's any better professor b: no actually i would think that you would you would get better you 'd get better high frequencies in the local mike . grad e: all the way around i 'd think . professor b: uh but who knows ? i mean we do we we we we we wan na find all this stuff out , phd c: yeah well we could try it . grad e: yeah . professor b: we do n't know . grad e: we 're gon na have plenty of low frequency on the p z ms with the fans . phd c: ok . yeah . professor b: uh yeah . yeah . phd c: oh yeah there was just one more thing i wanted to say which is totally unrelated to the recognition except that um well well it 's sort of related but um good news also uh i got well chuck fillmore agreed to record meetings but he had too many people in his meetings and that 's too bad cuz they 're very animated and but uh jerry also agreed so uh we 're starting on on phd a: they 're less animated . phd c: well but he has fewer he he wo n't have more than eight and it 's a meeting on even deeper understanding , edu , so that sounds interesting . as a compliment to our front - end meeting grad e: dot edu ? phd c: and um so that 's gon na start monday and one of the things that i was realizing is um it would be really great if anyone has any ideas on some kind of time synchronous way that people in the meeting can make a comment to the person whose gon na transcribe it or or put a push a button or something when they wan na make a note about `` oh boy you should probably erase those last few `` or uh `` wait i want this not to be recorded now `` or uh something like that s professor b: were n't we gon na do something with a pad at one point ? postdoc g: the cross pads ? grad e: yeah , we could do it with the cross pads . phd c: cuz i was thinking you know if if the person who sets up the meeting is n't there and it 's a group that we do n't know um and this came up talking to to jerry also that you know is there any way for them to indicate to make sure that the qu request that they have that they make explicitly get addressed somehow professor b: yeah . phd c: so i do n't know if anyone has ideas or you could even write down `` oh it 's about three twenty five and `` professor b: well what i was just suggesting is is we have these this cross pad just for this purpose grad e: yeah , and use that . professor b: and just use that grad e: not a bad idea . professor b: and if we sink it in phd c: that would be great . professor b: the other thing is eh phd c: that be great . professor b: i do n't know if you know this or if it 's a question for the mail to dan but is this thing of two eight channel boards a maximum for this setup or could we go to a third board ? grad e: i do n't know . i do n't know . i 'll send mail to dan and ask . i i think that it 's the maximum we can do without a lot of effort because it 's one board with two digital channels . professor b: oh it is one board . grad e: e eight each . so it it takes two fibers in to the one board . and so w i think if we wan na do that more than that we 'd have to have two boards , and then you have the synchronization issue . professor b: but that 's a question because that would if it was possible cuz it is i you know already we have a a a group of people in this room that can not all be miked grad e: right . professor b: and it 's not just cuz we have n't been to the store , right it 's phd d: what is the limit on each of those f fiber channels , is it the grad e: eight . phd d: it just it 's eight channels come in , does it have do with the sampling rate ? grad e: it 's eight . i have no idea . but each each fiber channel has eight eight channels and there are two ch two fibers that go in to the card . professor b: it might be a hard limitation , grad e: so professor b: i mean one thing is it the whole thing as i said is is all structured in terms of forty - eight kilohertz sampling so that pushes requirements up a bit grad e: yeah . professor b: but phd d: i was just wondering if if that could change . grad e: i mean then we 'd also have to get another add and another mixer and all that sort of stuff . phd d: if we could drop that . professor b: yeah . grad e: so i i 'll send a mail to dan and ask him . professor b: yeah . grad e: ok on the uh are we done with that ? so the oth topic is uh getting more mikes and different mikes , so i got a quote um we can fit we have room for one more wireless and the wireless , this unit here is three fifty three hundred fifty dollars , it i did n't realize but we also have to get a tuner the receiver the other end , that 's uh four thirty um and then also phd c: for for each ? phd d: wow . phd c: i mean the tuner is four thirty for each . grad e: yep . phd c: wow . grad e: and we just need one more so so professor b: yeah at least w we got the good ones . grad e: yeah . so that 's you know something like seven hundred eighty bucks for one more of these . professor b: yeah . ok . grad e: um and then also um it turns out that the connector that this thing uses is proprietary of sony phd d: oh . grad e: believe it or not and sony only sells this headset . postdoc g: mmm . grad e: so if we wan na use a different set headset the solution that the guy suggested and they apparently lots of people have done is sony will sell you the jack with just wires coming out the end and then you can buy a headset that has pigtail and solder it yourself . and that 's the other solution and so the jacks are forty bucks apiece and the he recommended um a crown cm three eleven ae headset for two hundred bucks apiece . professor b: there is n't this some sort of thing that plugs in , you actually have to go and do the soldering yourself ? grad e: becau - the reason is the only only thing you can get that will plug into this is this mike or just the connector . professor b: no i understand . the reason i ask is these sort of handmade uh wiring jobs fall apart in use so the other thing is to see if we can uh get them to do a custom job and put it together for this . grad e: oh i 'm sure they would , they would just charge us , phd d: well , and they 'd probably want quantity too , grad e: so . professor b: well phd d: they 'd professor b: no they 'll just charge us more , so it 's this phd d: mmm . grad e: so so my question is should we go ahead and get na nine identical head - mounted crown mikes ? professor b: not before having one come here and have some people try it out . grad e: ok . professor b: because there 's no point in doing that if it 's not gon na be any better . grad e: so why do n't we get one of these with the crown with a different headset ? professor b: yeah . grad e: and and see if that works . professor b: and see if it 's preferable and if it is then we 'll get more . phd c: comfort . grad e: yeah . professor b: yeah . phd c: cuz i mean i think the microphones are ok it 's just the the grad e: right , it 's just they 're not comfortable to wear . professor b: right . phd c: could make our own handbands and grad e: um , and he said they do n't have any of these in stock but they have them in la and so it will take about a week to get here . professor b: yeah well it 's grad e: um so ok to just go order ? professor b: we 're in this for the long term , yeah . just order it . grad e: ok phd c: it 's a lot of money for a handband . grad e: and who is the contact if i wan na do an invoice grad f: yeah . grad e: cuz i think that 's how we did it before . professor b: uh we 'll do this off - line , yeah . grad f: it 's a long time to get from la . grad e: ok . and then nine channels is the maximum we can do , so . professor b: uh y right cuz so one is for the daisy chain so that 's fifteen instead of sixteen grad e: without getting more stuff . professor b: and there 's six on the table so that 's nine . grad e: right . phd c: can i ask a really dumb question ? professor b: yeah . phd c: is is there any way we can have you know like a a wireless microphone that you pass around to the people who you know the extra people for the times they wan na talk that grad e: probably . professor b: that 's a good idea . phd c: i mean professor b: that 's not a dumb question , it 's a good idea , phd c: well i mean phd a: like uh like you know jerry springer thing , professor b: yeah . grad e: i 'm just not sure how we would handle that in the grad f: that 's like the conch . phd c: well but phd d: like at conferences phd a: you know r phd c: well but there might be a way to say that there are gon na be these different people grad f: see , look . phd c: um and i do n't know identifying somehow ? phd d: so nail the chairs down . phd a: yeah . grad e: yeah , somehow . phd c: you know i was just thinking of jerry springer . grad e: it 's not a bad idea . professor b: no that no no phd a:  professor b: that 's a very if we ca n't get another board and even if we can i have a feeling they 'll be some work . phd d: the springer mike . phd c: i mean for the few times that you might wan na have that . professor b: let 's figure that we have eight which are set up and then there 's a ninth which is passed around to grad e: a hand - held , yeah . professor b: that 's a good idea phd d: infinite expansion . professor b: right . kind of rules out overlap but but uh phd c: well or also for you know if people are not professor b: yeah . grad e: well we could just hand around the lapel . professor b: uh no no that 's grad e: rather than get a phd c: no not the lapel . grad e: do you want a handset ? professor b: no . grad e: well i mean is the is the hand - held really any better ? phd d: liz hates the lapel . professor b: yes . phd c: i do n't know grad e: ok . phd c: but i d i know the lapel is really suboptimal . professor b: no it no it depends on the hand - held grad e: is awful ? professor b: but hand many hand - helds are built wi with sort of uh anti - shock sort of things so that it it is less uh susceptible to hand noises . if you hold the lapel mike i you just get all k sorts of junk . phd d: mm - hmm . phd c: right . i mean the ones they really pass around must be sort of ok . grad e: ok . professor b: so grad e: so i wonder if they have one that will hook up . professor b: yeah . they have what ? grad e: i wonder if they have one that will hook up to this or whether again we 'll have to wire it ourselves . phd d: well , you would n't want it to hook there you 'd just want it to hook into the receiver in the other room , right ? professor b: no that 's uh you need a transmitter . grad e: what ? phd d: is th is n't that built into the mike ? professor b: oh i see . get a get a different radio , yeah . phd c: yeah just these ones that they pass around with no you know wireless professor b: yeah . but you need a ra but it has to correspond to the receiver . phd d: have a little antenna coming out the bottom . grad e: it 's gon na be much easier to get one of these and just plug in a mike , is n't it ? phd d: but then the mike has to h phd a: do you have to hand it around and if you have two pieces of professor b: no no phd c: right . grad f: yeah . phd a:  professor b: so right , so this is a good point , so yeah you have these these mikes with a little antenna on the end right ? grad e: ok . and do you think you would be able to use the same receiver ? professor b: i do n't know . you 'll have to check with them , grad e: ok i 'll i 'll ask . professor b: yeah . but that 's that 's a great idea phd d: it 's just a frequency . grad e: yeah . professor b: and then just sort of have that as the and then you can have groups of twenty people or whatever and and uh phd c: yeah because there 's only i mean as andreas pointed out actually i think in the large the larger the group the less interaction the less people are talking um over each other phd a: pretty soon . phd d: mmm , yeah . phd c: it just there might be a lot of people that speak once or twice and professor b: right . phd a: um got ta go . professor b: off you go , yeah . grad e: ok so i guess people who have to leave can leave and do we have anything else to discuss or should we just do digits ? postdoc g: i i thought of some extra a couple of extra things i 'd like to mention . grad e: ok . postdoc g: one of them is to give you a status in terms of the transcriptions so far . so um as of last night um i 'd assigned twelve hours and they 'd finished nine grad e: uh yep , postdoc g: and my goal was to have eleven done by the end of the month , i think that by tomorrow we 'll have ten . phd c: uh it 's great professor b: pretty close , postdoc g: so they 're still working . professor b: that 's good . phd c: i j and this i got this email from jane at like two in the morning or something phd d: wow . grad e: that 's good . phd c: so it 's really great postdoc g: it 's working out , thanks . phd c: it 's really great . postdoc g: thanks . and then um also an idea for another meeting , which would be to have the transcribers talk about the data it 's sort of a a little bit a little bit phd c: that 's a great idea . professor b: super idea . grad e: yep , that 'd be very interesting . phd c: that 's a great idea cuz i 'd like to g have it recorded so that we can remember all the little things , grad f: yeah . grad e: i 'd love to hear what they have to say . postdoc g: yeah . phd c: that 's a great idea . phd d: so if we got them to talk about this meeting , it would be a meta meta meeting . postdoc g: yeah . yeah , exa exactly i guess nested several layers , professor b: now you have eight transcribers and there 's ten of us postdoc g: but professor b: so how do we do this , is the only thing . phd c: or just have them talk amongst themselves . phd d: have them have their own meeting . phd c: and have postdoc g: well that 's what i 'm thinking , professor b: oh . postdoc g: yeah . have them talk about the data and they and they 've made observations to me phd c: that would be great . postdoc g: like they say uh you know this meeting that we think has so much overlap , in fact it does but there are other groups of similar size that have very little , you know it 's part of it 's it 's the norm of the group and all that and they have various observations that would be fun , i think . phd c: that 's a great idea . grad e: yeah , i 'd like to hear what they s say . postdoc g: yeah . phd c: be great . professor b: so maybe we could they could have a meeting more or less without us that to do this and we should record it postdoc g: ok . professor b: and then maybe one or two of them could come to one of these meetings and and could you know could tell us about it . postdoc g: yeah . grad e: give us a status . phd c: yeah . postdoc g: oh good . ok . professor b: yeah . phd c: it 's they will get to transcribe their own meeting but they also get paid for having a break grad e: that would be weird . postdoc g: what what yeah that 's right . phd c: and i think that 's a good idea , postdoc g: yeah exactly , yeah . professor b: yeah . phd c: get them involved . postdoc g: great . phd c: um that 's a great idea . postdoc g: great . professor b: super . phd c: i 'm really sorry i have to g no i have to go as well . professor b: ok . postdoc g: and then i wanted to also um say something about the fiscus uh uh john john fiscus visit tomorrow . and which is to say that w it 'll be from nine to one that i 'm going to uh uh offer the organization allow him to uh adjust it if he wishes but to be basically in three parts , the acoustic part coming first which would be basically the room engineering aspects um other things and he 'll be also presenting what nist is doing and and uh then uh number two would be sort of a the the transcription process so this would be a focus on like presegmentation and the modifications to the the multitrans interface which allows more refined encoding of the beginnings and ends of the overlapping segments which uh dave gelbart 's been doing and then um uh and of course the presegmentation thilo 's been doing and then um the third part would and again he has some stuff that 's i relevant with respect to nist and then the third one would be focus on transcription standards so at nist he 's interested in this establishment of a global encoding standard i guess i would say and i want it , you know k yeah see what they 're doing and also present what what we 've chosen as ours and and discuss that kind of thing . and so but he 's only here until until one and actually we 're thinking of noon being uh lunch time so basically hoping that we can get as much of this done as possible before noon . s professor b: ok . postdoc g: and everybody who wants to attend is welcome . so grad e: oh , where you 're gon na meet ? postdoc g: yeah . here mostly but i 've also reserved the barco room um eh to figure out how that works in terms of like maybe having a live demonstration . professor b: ok but the nine o ' cl nine o ' clock will be i be in here . yeah , ok . postdoc g: yeah . mm - hmm . grad e: i assume we 're not gon na try to record it ? postdoc g: oh i think that would be hard , yeah . professor b: yeah , i think just adds grad e: alright . postdoc g: yeah . professor b: um good . postdoc g: thank you though , uh - huh . professor b: so maybe do digits and recess ? grad e: unless there 's anything else ? postdoc g: yeah . yeah . phd d: do digital ones ? professor b: uh ok . postdoc g: yeah . grad e: uh should y we make him wear andreas ' mike or would that just be too confusing ? professor b: yeah . no i do n't think it 's confusing . well , it does n't confuse me . postdoc g: when we do this in the key in the key in the key it has to indicate that channel change , phd d: does it mess up the forms ? postdoc g: right ? grad e: uh yeah i just do n't know how we would do that , so . i mean other than free free form . postdoc g: well i have a time mark . phd d: the on switch is here on the on the top there . postdoc g: yeah . professor b: ok . grad e: and just clip it to your collar . professor b: that 's fine . grad j: ok , my name is uh espen eriksen . i 'm a norwegian . um uh this is my second semester at berkeley . currently i 'm taking uh my first graduate level courses in dsp and um when i come back to norway i 'm gon na continue with the more of a research project work kind of work . so this semester i 'm starting up with a with a small project through uh dave gelbart which i 'm taking a course with i got in touch with him and he told me about this project . so with the help of uh dan ellis i 'm gon na do small project associated to this . what i 'm gon na try to do is uh use use ech echo cancellation to uh to handle the periods where you have overlapping talk . to try to do something about that . so currently i 'm um i 'm just reading up on echo cancellation , s looking into the theory behind that and then uh hopefully i get some results . so it it 's a it 's a project goes over the course of one semester . grad e: great . grad j: so i 'm just here today to introduce myself . tell about i 'll be i 'll be working on this . grad e: and are you staying at berkeley or is are you just here a semester ? grad j: this is my second semester and last . grad e: ah second and last , professor b: yeah . grad e: ok . grad j: so i leave professor b: he 's in the he 's in the cour two two five d course . grad j: yeah , i 'm in morgan 's course , professor b: so , yeah . grad j: yeah . grad e: good . phd d: welcome . postdoc g: then you then you go back to norway , that 's ok . grad j: yeah . grad f: we were just talking about something like this yesterday or yeah yesterday with liz . about doing some of the echo cancellation stuff or possibly the spectroanalysis over the overlaps , so . cool . grad j: yeah . professor b: ok , grad e: digits ? professor b: let 's do digits . ok . grad e: and stop .","output":"the group decided to purchase one additional head-mounted crown microphone . a tentative decision was also made to acquire a hand-held wireless microphone to pass around to additional meeting participants should the installation of more close-talking microphones prove too difficult ."},{"instruction":"what was the meeting about ?","input":"grad b: what things to talk about . grad f: i 'm what ? really ? oh , that 's horrible ! disincentive ! grad a: ok , we 're recording . grad f: hello ? grad b: check check check check . grad d: uh , yeah . grad f: hello ? which am i ? professor c: oh right . grad b: alright . good . grad f: channel fi ok . ok . are you doing something ? ok , then i guess i 'm doing something . so , um , so basically the result of m much thinking since the last time we met , um , but not as much writing , um , is a sheet that i have a lot of , like , thoughts and justification of comments on but i 'll just pass out as is right now . so , um , here . if you could pass this around ? and there 's two things . and so one on one side is on one side is a sort of the revised sort of updated semantic specification . grad d: um the wait . grad f: and the other side is , um , sort of a revised construction formalism . grad e: this is just one sheet , right ? grad d: ah ! just one sheet . grad f: it 's just one sheet . grad d: ok . grad f: it 's just a nothing else . grad d: front , back . grad f: um , enough to go around ? ok . and in some ways it 's it 's it 's very similar to there are very few changes in some ways from what we 've , um , uh , b done before but i do n't think everyone here has seen all of this . so , uh , i 'm not sure where to begin . um , as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . grad e: mm - hmm . grad f: and , um , after a little bit more discussion and especially like keith and i i have more linguistic things to settle in the next few days , um , it 'll probably change again some more . grad e: yeah . grad f: um , maybe i will let 's start b let 's start on number two actually on the notation , um , because that 's , i 'm thinking , possibly a little more familiar to , um to people . ok , so the top block is just sort of a sort of abstract nota it 's sort of like , um , listings of the kinds of things that we can have . and certain things that have , um , changed , have changed back to this . there there 's been a little bit of , um , going back and forth . but basically obviously all constructions have some kind of name . i forgot to include that you could have a type included in this line . professor c: what i was gon na right . grad f: so something like , um well , there 's an example the textual example at the end has clausal construction . so , um , just to show it does n't have to be beautiful it could be , you know , simple old text as well . um , there are a couple of uh , these three have various ways of doing certain things . so i 'll just try to go through them . so they could all have a type at the beginning . um , and then they say the key word construction professor c: oh , i see . grad f: and they have some name . professor c: so so the current syntax is if it s if there 's a type it 's before construct grad f: yeah , right . professor c: ok , that 's fine . grad f: ok , and then it has a block that is constituents . and as usual i guess all the constructions her all the examples here have only , um , tsk { comment } one type of constituent , that is a constructional constituent . i think that 's actually gon na turn out to m be certainly the most common kind . but in general instead of the word `` construct `` , th here you might have `` meaning `` or `` form `` as well . ok ? so if there 's some element that does n't that is n't yet constructional in the sense that it maps form and meaning . ok , um , the main change with the constructs which each of which has , um , the key word `` construct `` and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that you know what kind of construction it is . so for example whatever i have here is gon na be a form of the word `` throw `` , or it 's gon na be a form of the word , you know , i do n't know , `` happy `` , or something like that . or , you know , some it 'll be a specific word or maybe you 'll have the type . you 'll say `` i need a p uh spatial relation phrase here `` or `` i need a directional specifier here `` . so - uh you could have a j a actual type here . um , or you could just say in the second case that you only know the meaning type . so a very common example of this is that , you know , in directed motion , the first person to do something should be an agent of some kind , often a human . right ? so if i you know , the um , uh , run down the street then i i i run down the street , it 's typed , uh , `` i `` , meaning category is what 's there . the the new kind is this one that is sort of a pair and , um , sort of skipping fonts and whatever . the idea is that sometimes there are , um , general constructions that you know , that you 're going to need . it 's it 's the equivalent of a noun phrase or a prepositional phrase , or something like that there . grad e: mm - hmm . grad f: and usually it has formal um , considerations that will go along with it . professor c: mm - hmm . grad f: and then uh , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , you know , um , `` the big th `` , you you know , `` the big the tall dark man `` , you know , `` walked into the room `` . grad e: mm - hmm . grad f: but because of the nature of this particular construction you know not just that it 's nominal of some kind but in particular , that it 's some kind of animate nominal , and which will apply just as well to like , you know , a per you know , a simple proper noun or to some complicated expression . um , so i do n't know if the syntax will hold but something that gives you a way to do both constructional and meaning types . so . ok , then i do n't think the , { comment } um at least yeah . { comment } none of these examples have anything different for formal constraints ? but you can refer to any of the , um , sort of available elements and scope , right ? which here are the constructs , { comment } to say something about the relation . and i think i if you not if you compare like the top block and the textual block , um , we dropped like the little f subscript . the f subscripts refer to the `` form `` piece of the construct . professor c: good . grad f: and i think that , um , in general it 'll be unambiguous . like if you were giving a formal constraint then you 're referring to the formal pole of that . so so by saying if i just said `` name one `` then that means name one formal and we 're talking about formal struc { comment } which which makes sense . uh , there are certain times when we 'll have an exception to that , in which case you could just indicate `` here i mean the meaningful for some reason `` . right ? or actually it 's more often that , only to handle this one special case of , you know , `` george and jerry walk into the room in that order `` . grad e: mm - hmm . grad f: so we have a few funny things where something in the meaning might refer to something in the form . but but s we 're not gon na really worry about that for right now and there are way we can be more specific if we have to later on . ok , and so in terms of the the relations , you know , as usual they 're before and ends . i should have put an example in of something that is n't an interval relation but in form you might also have a value binding . you know , you could say that , um , you know , `` name - one dot `` , t you know , `` number equals `` , you know , a plural or something like that . grad e: mm - hmm . grad f: there are certain things that are attribute - value , similar to the bindings below but i mean they 're just us usually they 're going to be value value fillers , right ? ok , and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and i i you you and i can like fight about that if you like ? but about changing it to `` semantic n effects `` , which i thought was a little bit too order - biased grad b: well th grad f: and `` semantic bindings `` , which i thought might be too restrictive in case we do n't have only bindings . and so it was an issue whether constraints um , there were some linguists who reacted against `` constraints `` , saying , `` oh , if it 's not used for matching , then it should n't be called a constraint `` . but i think we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are i think we thought of some situations where it would be useful to use whatever the c bindings are , for actual , you know , sort of like modified constraining purposes . professor c: well , you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification , i grad e: yeah . grad f: yeah , yeah . it 's used should n't matter , right ? mm - hmm . professor c: s for sure . i mean , i do n't know what , uh , term we want to use grad f: mm - hmm . professor c: but we do n't want to grad f: yeah , uh , there was one time when when hans explained why `` constraints `` was a misleading word for him . professor c: yep . grad f: and i think the reason that he gave was similar to the reason why johno thought it was a misleading term , which was just an interesting coincidence . um , but , uh and so i was like , `` ok , well both of you do n't like it ? professor c: it 's g it 's gone . grad f: fine , we can change it `` . but i i i 'm starting to like it again . grad b: but grad f: so that that 's why { comment } that 's why i 'll stick with it . grad a: well , you know what ? grad f: so grad a: if you have an `` if - then `` phrase , do you know what the `` then `` phrase is called ? professor c: th grad f: what ? con - uh , a consequent ? grad a: yeah . grad f: yeah , but it 's not an `` if - then `` . grad a: no , but professor c: i know . anyway , so the other the other strategy you guys could consider is when you do n't know what word to put , you could put no word , grad f: mm - hmm . professor c: just meaning . ok ? and the then let grad e: yeah . grad f: yeah , that 's true . grad b: so that 's why you put semantic constraints up top and meaning bindings down down here ? grad f: oh , oops ! no . that was just a mistake of cut and paste from when i was going with it . grad b: ok . professor c: ok . grad f: so , i 'm sorry . i did n't mean that one 's an in unintentional . grad b: so this should be semantic and grad f: sometimes i 'm intentionally inconsistent grad b:  grad f: cuz i 'm not sure yet . here , i actually it was just a mistake . grad b: th - so this definitely should be `` semantic constraints `` down at the bottom ? grad e: sure . grad f: yeah . grad b: ok . grad f: well , unless i go with `` meaning `` but i i mean , i kind of like `` meaning `` better than `` semantic `` grad b: or professor c: oh , whatever . grad f: but i think there 's vestiges of other people 's biases . professor c: or wh that - b grad f: like professor c: right . minor min problem grad f: minor point . professor c: ok . grad e: extremely . grad f: ok , um , so i think the middle block does n't really give you any more information , ex than the top block . and the bottom block similarly only just illus you know , all it does is illustrate that you can drop the subscripts and and that you can drop the , um uh , that you can give dual types . oh , one thing i should mention is about `` designates `` . i think i 'm actually inconsistent across these as well . so , um , strike out the m subscript on the middle block . professor c: mm - hmm . grad f: so basically now , um , this is actually this little change actually goes along with a big linguistic change , which is that `` designates `` is n't only something for the semantics to worry about now . professor c: good . grad f: so we want s `` designates `` to actually know one of the constituents which acts like a head in some respects but is sort of , um , really important for say composition later on . so for instance , if some other construction says , you know , `` are you of type is this part of type whatever `` , um , the `` designates `` tells you which sort of part is the meaning part . ok , so if you have like `` the big red ball `` , you know , you wan na know if there 's an object or a noun . well , ball is going to be the designated sort of element of that kind of phrase . grad e: mmm . grad f: um , there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , um to talk about there also being a designated object and we think that that 'll be the same one , right ? so the ball is the head of the phrase , `` the r the `` , um , `` big red ball `` , and the entity denoted by the word `` ball `` is sort of the semantic head in some ways of of this sort of , um , in interesting larger element . professor c: a a and the yeah . and there 's uh there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if i understand you right . grad e: yeah . grad f: mm - hmm . grad e: yeah . grad f: right , right . grad e: that 's the idea . professor c: yeah yeah . grad e: yeah . grad f: and , uh , you might be able to say things like if the head has to go last in a head - final language , you can refer to the head as a p the , you know the formal head as opposed to the rest of the form having to be at the end of that decision . professor c: right . grad f: so that 's a useful thing so that you can get some internal structural constraints in . professor c: ok , so that all looks good . let me oh , w oh . i do n't know . were you finished ? grad f: um , there was a list of things that is n't included but you you can you can ask a question . that might @ @ it . professor c: ok . so , i if i understand this the aside from , uh , construed and all that sort of stuff , the the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for a type grad f: mm - hmm . professor c: or actually gone back to , grad f: right . professor c: if we go back far enough grad f: well , except for their construction meaning , so it 's not clear that , uh well , right now it 's a c uh contr construction type and meaning type . so i do n't know what a form type is . professor c: oh , i see . yeah , yeah , yeah . i 'm sorry , you 're right . grad f: yeah . professor c: a construction type . uh , that 's fine . but it , um grad f: right . a well , and a previous , um , you know , version of the notation certainly allowed you to single out the meaning bit by it . so you could say `` construct of type whatever designates something `` . professor c: yeah . grad f: but that was mostly for reference purposes , just to refer to the meaning pole . i do n't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time i think . professor c: mm - hmm . grad f: um , i i do n't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , you know that 's kind of weird . professor c: no , no , no , i do n't think so . i think that you 'll you 'll do fine . grad e: i professor c: in fact , these are , um , as long as as mark is n't around , these are form constraints . so a nominal expression is uh , the fact that it 's animate , is semantic . the fact that it 's n uh , a nominal expression i would say on most people 's notion of of f you know , higher form types , this i this is one . grad f: mm - hmm . grad e: yeah . grad f: right , right . professor c: and i think that 's just fine . grad e: yeah , yeah . grad f: which is fine , yeah . professor c: yeah . grad e: it 's that now , um , i 'm mentioned this , i i do n't know if i ever explained this but the point of , um , i mentioned in the last meeting , { comment } the point of having something called `` nominal expression `` is , um , because it seems like having the verb subcategorize for , you know , like say taking as its object just some expression which , um , designates an object or designates a thing , or whatever , um , that leads to some syntactic problems basically ? so you wan na , you know you sort of have this problem like `` ok , well , i 'll put the word `` , uh , let 's say , the word `` dog `` , you know . and that has to come right after the verb grad f: mm - hmm . grad e: cuz we know verb meets its object . and then we have a construction that says , oh , you can have `` the `` preceding a noun . and so you 'd have this sort of problem that the verb has to meet the designatum . professor c: right . grad e: and you could get , you know , `` the kicked dog `` or something like that , meaning `` kicked the dog `` . professor c: right . grad e: um , so you kind of have to let this phrase idea in there professor c: that i i have no problem with it at all . grad e: but it - it professor c: i think it 's fine . grad e: yeah . grad f: yeah . right , n s you may be you may not be like everyone else in in berkeley , grad e: yeah . yeah . grad f: but that 's ok . grad e: i mean , we we we sort of thought we were getting away with , uh with , a p grad f: uh , we do n't mind either , so grad e: i mean , this is not reverting to the x - bar theory of of phrase structure . professor c: right . grad e: but , uh , grad f: right . grad e: i just know that this is like , we did n't originally have in mind that , uh that verbs would subcategorize for a particular sort of form . grad f: mm - hmm . professor c: but they do . grad e: um , but they does . grad f: well , there 's an alternative to this grad e: at least in english . grad f: which is , um the question was did we want directed motion , professor c: yeah . grad f: which is an argument structure construction professor c: mm - hmm . grad e: yeah . grad f: did we want it to worry about , um , anything more than the fact that it , you know , has semantic you know , it 's sort of frame - based construction . so one option that , you know , keith had mentioned also was like , well if you have more abstract constructions such as subject , predicate , basically things like grammatical relations , grad e: mm - hmm . grad f: those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob you know , verb object would require that those things that f fill a subject and object are nom expressions . professor c: right . grad f: and that would be a little bit cleaner in some way . but you know , for now , i mean , professor c: yeah . but it y y it 's yeah , just moving it moving the c the cons the constraints around . grad f: uh , you know . m moving it to another place , right . grad e: yeah . professor c: ok , so that 's grad f: but there does basically , the point is there has to be that constraint somewhere , right ? professor c: right . grad f: so , yeah . professor c: and so that was the grad f: robert 's not happy now ? grad a: no ! grad f: oh , ok . professor c: ok , and sort of going with that is that the designatum also now is a pair . grad f: yes . professor c: instead of just the meaning . grad f: mm - hmm . professor c: and that aside from some terminology , that 's basically it . grad f: right . professor c: i just want to b i 'm i 'm asking . grad e: mm - hmm . grad f: yep . grad e: yeah . grad f: yeah , um , the un sort of the un - addressed questions in this , um , definitely would for instance be semantic constraints we talked about . professor c: yeah . grad f: here are just bindings but , right ? we might want to introduce mental spaces you know , there 's all these things that we do n't professor c: the whole the mental space thing is clearly not here . grad f: right ? so there 's going to be some extra you know , definitely other notation we 'll need for that which we skip for now . grad e: mm - hmm . professor c: by the way , i do want to get on that as soon as robert gets back . grad f: uh yeah . professor c: so , uh , the the mental space thing . grad f: ok . professor c: um , obviously , construal is a b is a b is a big component of that grad e: mm - hmm . professor c: so this probably not worth trying to do anything till he gets back . but sort of as soon as he gets back i think um , we ought to grad f: mm - hmm . mm - hmm . grad e: so what 's the what 's the time frame ? i forgot again when you 're going away for how long ? grad a: just , uh , as a sort of a mental bridge , i 'm not i 'm skipping fourth of july . so , uh , right afterwards i 'm back . grad e: ok . ok . grad f: what ? you 're missing like the premier american holiday ? what 's the point of spending a year here ? grad a: uh , i 've had it often enough . grad f: so , anyway . grad b: well he w he went to college here . grad f: oh , yeah , i forgot . oops . { comment } sorry . professor c: yeah . grad f: ok . professor c: and furthermore it 's well worth missing . grad f: not in california . grad e: yes . grad f: yeah , that 's true . i like i i like spending fourth of july in other countries , whenever i can . professor c: right . grad f: um professor c: ok , so that 's great . grad f: construal , ok , so oh , so there was one question that came out . i hate this thing . sorry . um , which is , so something like `` past `` which i you know , we think is a very simple uh , we 've often just stuck it in as a feature , professor c: right . right . grad f: you know , `` oh , this event takes place before speech time `` , { comment } ok , is what this means . um , it 's often thought of as it is also considered a mental space , professor c: right . grad f: you know , by , you know , lots of people around here . professor c: right . grad f: so there 's this issue of well sometimes there are really exotic explicit space builders that say `` in france , blah - blah - blah `` , grad e: mm - hmm . grad f: and you have to build up you ha you would imagine that would require you , you know , to be very specific about the machinery , whereas past is a very conventionalized one and we sort of know what it means but it we does n't do n't necessarily want to , you know , unload all the notation every time we see that it 's past tense . professor c: right . grad f: so , you know , we could think of our uh , just like x - schema `` walk `` refers to this complicated structure , past refers to , you know , a certain configuration of this thing with respect to it . professor c: i think that 's exactly right . grad f: so so we 're kind of like having our cake and eating it professor c: yeah . grad f: you know , having it both ways , right ? professor c: yeah . no , i think i think that i we 'll have to see how it works out when we do the details grad f: so , i i mm - hmm . professor c: but my intuition would be that that 's right . grad f: mm - hmm . yeah , ok . grad a: do you want to do the same for space ? grad f: wha - sorry ? grad a: space ? grad f: space ? grad a: here ? now ? grad f: oh , oh , oh , oh , instead of just time ? grad a: mm - hmm . grad f: yeah , yeah , yeah . same thing . so there are very conventionalized like deictic ones , right ? and then i think for other spaces that you introduce , you could just attach y whatever grad a: hmm . grad f: you could build up an appropriately uh , appropriate structure according to the l the sentence . professor c: yeah . grad a: hmm , well this this basically would involve everything you can imagine to fit under your c dot something grad e: n grad a: you know , where where it 's contextually dependent , grad f: yeah . right . grad a: `` what is now , what was past , grad f: mm - hmm . grad a: what is in the future , where is this , what is here , what is there , what is `` grad f: mm - hmm . yeah . so time and space . um , we 'll we 'll get that on the other side a little , like very minimally . there 's a sort of there 's a slot for setting time and setting place . professor c: good . grad f: and you know , you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , { comment } there are relative things that , you know , you relate the event in time and space to where you are now . if there 's something a lot more complicated like , or so hypothetical or whatever , then you have to do your job , grad e: mm - hmm . grad f: like or somebody 's job anyway . grad e: yeah . grad f: i 'm gon na point to at random . grad e: yeah . i mean , i 'm i 'm s curious about how much of the mental i mean , i 'm not sure that the formalism , sort of the grammatical side of things , { comment } is gon na have that much going on in terms of the mental space stuff . you know , um , basically all of these so - called space builders that are in the sentence are going to sort of i think of it as , sort of giving you the coordinates of , you know assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , um the construction that you actually get is just gon na sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to . grad f: mm - hmm . grad e: so `` in france , uh , watergate would n't have hurt nixon `` or something like that . um , well , you say , `` alright , i 'm supposed to add some structure to my model of this hypothetical past france universe `` or something like that . the information in the sentence tells you that much but it does n't tell you like exactly what it what the point of doing so is . so for example , depending on the linguistic con uh , context it could be like the question is for example , what does `` watergate `` refer to there ? does it , you know does it refer to , um if you just hear that sentence cold , the assumption is that when you say `` watergate `` you 're referring to `` a watergate - like scandal as we might imagine it happening in france `` . but in a different context , `` oh , you know , if nixon had apologized right away it would n't you know , watergate would n't have hurt him so badly in the us and in france it would n't have hurt him at all `` . now we 're s now that `` watergate `` we 're now talking about the real one , grad f: they 're real , right . grad e: and the `` would `` sort of it 's a sort of different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . grad f: i see right . grad e: in the first case , hypothetically we 're imagining that watergate happened in france . grad f: hmm . grad e: in the second case we 're imagining hypothetically that nixon had apologized right away grad f: mm - hmm . grad e: or something . right ? grad f: right . grad e: so a lot of this is n't happening at the grammatical level . professor c: correct . grad e: uh , um , and so grad f: mm - hmm . grad e: i do n't know where that sits then , grad a: hmm . grad e: sort of the idea of sorting out what the person meant . grad f: it seems like , um , the grammatical things such as the auxiliaries that you know introduce these conditionals , whatever , give you sort of the the most basi grad e: mm - hmm . grad f: th those we i think we can figure out what the possibilities are , right ? grad e: mm - hmm . grad f: there are sort of a relatively limited number . and then how they interact with some extra thing like `` in france `` or `` if such - and - such `` , that 's like there are certain ways that they c they can grad e: yeah . grad f: you know , one is a more specific version of the general pattern that the grammat grammar gives you . grad e: yeah . grad f: i think . but , you know , whatever , professor c: yeah , in the short run all we need is a enough mechanism on the form side to get things going . grad f: we we 're grad e: mm - hmm . yeah . professor c: uh , i uh , you you grad e: but the whole point of the whole point of what fauconnier and turner have to say about , uh , mental spaces , and blending , and all that stuff is that you do n't really get that much out of the sentence . you know , there 's not that much information contained in the sentence . it just says , `` here . add this structure to this space . `` and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean a hundred different things depending on , quote , `` what the space configuration is at the time of utterance `` . grad f: mm - hmm . mm - hmm . grad e: and so somebody 's gon na have to be doing a whole lot of work but not me , i think . professor c: well i think that 's right . oh , i yeah , i , uh , uh i think that 's not k i th i do n't think it 's completely right . i mean , in fact a sentence examples you gave in f did constrain the meaning b the form did constrain the meaning , grad e: yeah . professor c: and so , um , it is n't , uh grad e: sure , but like what what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really . grad f: that 's ok . we usually do n't know the point of the sentence at all . grad e: yeah . grad f: but we know what it 's trying to say . professor c: yeah . grad e: y yeah . grad f: we we know that it 's what predication it 's setting up . professor c: but but bottom line , i agree with you , grad e: yeah . grad f: that 's all . professor c: that that that we 're not expecting much out of the , uh f grad e: yeah . grad f: purely linguistic cues , right ? professor c: uh , the purely form cues , yeah . grad f: so . professor c: and , um i mean , you 're you 're the linguist grad f: mmm . professor c: but , uh , it seems to me that th these we we you know , we 've talked about maybe a half a dozen linguistics theses in the last few minutes or something . grad e: yeah , yeah . professor c: yeah , i mean grad e: yeah . oh , yeah . professor c: uh , i i mean , that that 's my feeling that that these are really hard uh , problems that decide exactly what what 's going on . grad e: mm - hmm . yeah . yeah . professor c: ok . grad f: ok , so , um , one other thing i just want to point out is there 's a lot of confusion about the terms like `` profile , designate , focus `` , et cetera , et cetera . professor c: uh , right , right , right . grad e: mm - hmm . grad f: um , for now i 'm gon na say like `` profile `` 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so `` hypotenuse `` , you profiled this guy against the background of the right t right triangle . grad e: mm - hmm . grad f: ok . and the second use , um , is in framenet . it 's slightly different . oh , i was asking hans about this . they use it to really mean , um , this in a frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which i 'm not saying one and two are mutually exclusive but they 're they 're different meanings . professor c: right . grad e: mm - hmm . grad f: so the closest thing so i was thinking about how it relates to this notation . for us , um ok , so how is it professor c: does that is that really what they mean in in grad f: so `` designate `` framenet ? professor c: i did n't know that . grad f: framenet ? yeah , yeah . i i mean , i i was a little bit surprised about it too . professor c: yeah . grad f: i knew that i thought that that would be something like there 's another term that i 've heard for that thing professor c: right , ok . grad f: but they i mean uh , well , at least hans says they use it that way . and professor c: well , i 'll check . grad f: and may maybe he 's wrong . anyway , so i think the the `` designate `` that we have in terms of meaning is really the `` highlight this thing with respect to everything else `` . ok ? professor c: right . grad f: so this is what what it means . but the second one seems to be useful but we might not need a notation for it ? we do n't have a notation for it but we might want one . so for example we 've talked about if you 're talking about the lexical item `` walk `` , you know it 's an action . well , it also has this idea it carries along with it the idea of an actor or somebody 's gon na do the walking . or if you talk about an adjective `` red `` , it carries along the idea of the thing that has the property of having color red . so we used to use the notation `` with `` for this professor c: right . grad f: and i think that 's closest to their second one . so i d do n't yet know , i have no commitment , as to whether we need it . it might be it 's the kind of thing that w a parser might want to think about whether we require you know , these things are like it 's semantically part of it professor c: n no , no . well , uh , th critically they 're not required syntactically . often they 're pres presu presupposed and all that sort of stuff . grad f: right . right , right . yeah , um , definitely . so , um , `` in `` was a good example . if you walk `` in `` , like well , in what ? professor c: right , there 's grad f: you know , like you have to have the { comment } so so it 's only semantically is it it is still required , say , by simulation time though professor c: right . grad f: to have something . so it 's that i meant the idea of like that the semantic value is filled in by sim simulation . i do n't know if that 's something we need to spa to to like say ever as part of the requirement ? or the construction ? or not . we 'll we 'll again defer . professor c: or i mean , or or , uh so the grad f: have it construed , professor c: yeah , yeah . grad f: is that the idea ? just point at robert . whenever i 'm confused just point to him . professor c: right . it 's it 's his thesis , right ? grad f: you tell me . professor c: anyway , grad f: ok . professor c: right , yeah , w this is gon na be a b you 're right , this is a bit of in a mess and we still have emphasis as well , or stress , or whatever . grad f: ok , well we 'll get , uh uh , i we have thoughts about those as well . professor c: yeah . great . grad f: um , the i w i would just s some of this is just like my you know , by fiat . i 'm going to say , this is how we use these terms . i do n't - you know , there 's lots of different ways in the world that people use it . professor c: i that 's fine . grad e: yeah . grad f: i think that , um , the other terms that are related are like focus and stress . professor c: mm - hmm . grad f: so , s i think that the way i we would like to think , uh , i think is focus is something that comes up in , i mean , lots of basically this is the information structure . professor c: mm - hmm . grad f: ok , it 's like uh , it 's not it might be that there 's a syntactic , uh , device that you use to indicate focus or that there are things like , you know , i think keith was telling me , { comment } things toward the end of the sentence , post - verbal , tend to be the focused focused element , grad e: mmm . grad f: the new information . you know , if i `` i walked into the room `` , you tend to think that , whatever , `` into the room `` is sort of like the more focused kind of thing . grad e: mm - hmm . yeah . grad f: and when you , uh , uh , you have stress on something that might be , you know , a cue that the stressed element , or for instance , the negated element is kind of related to information structure . so that 's like the new the sort of like import or whatever of of this thing . uh , so so i think that 's kind of nice to keep `` focus `` being an information structure term . `` stress `` i th and then there are different kinds of focus that you can bring to it . so , um , like `` stress `` , th stress is kind of a pun on you might have like whatever , like , um , accent kind of stress . grad e: mm - hmm . grad f: and that 's just a uh , w we 'll want to distinguish stress as a form device . you know , like , oh , high volume or whatever . grad e: yeah . grad f: um , t uh , and distinguish that from it 's effect which is , `` oh , the kind of focus we have is we 're emphasizing this value often as opposed to other values `` , right ? so focus carries along a scope . like if you 're gon na focus on this thing and you wan na know it sort of evokes all the other possibilities that it was n't . grad e: mm - hmm . grad f: um , so my classic my now - classic example of saying , `` oh , he did go to the meeting ? `` , grad e: yeah . grad f: that was my way of saying as opposed to , you know , `` oh , he did n't g `` or `` there was a meeting ? `` grad e: yeah . grad f: i think that was the example that was caught on by the linguists immediately . grad e: yeah . grad f: and so , um , the like if you said he you know , there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , uh grad e: mm - hmm . grad f: `` he walked to the meeting `` as opposed to `` he ran `` , or `` he did walk to the meeting `` as opposed to `` he did n't walk `` . you know , grad e: mm - hmm . grad f: so we need to have a notation for that which , um , i think that 's still in progress . so , sort of i 'm still working it out . but it did one one implication it does f have for the other side , which we 'll get to in a minute is that i could n't think of a good way to say `` here are the possible things that you could focus on `` , cuz it seems like any entity in any sentence , you know , or any meaning component of anyth you know all the possible meanings you could have , any of them could be the subject of focus . professor c: mmm . grad f: but i think one the one thing you can schematize is the kind of focus , right ? so for instance , you could say it 's the the tense on this as opposed to , um , the the action . ok . or it 's uh , it 's an identity thing or a contrast with other things , or stress this value as opposed to other things . so , um , it 's it is kind of like a profile profile - background thing but i i ca n't think of like the limited set of possible meanings that you would that you would focu grad e: light up with focus , yeah . grad f: light highlight as opposed to other ones . so it has some certain complications for the , uh , uh later on . li - i mean , uh , the best thing i can come up with is that information has a list of focused elements . for instance , you oh , one other type that i forgot to mention is like query elements and that 's probably relevant for the like `` where is `` , you know , `` the castle `` kind of thing ? grad e: mm - hmm . grad f: because you might want to say that , um , location or cert certain wh words bring you know , sort of automatically focus in a , you know , `` i do n't know the identity of this thing `` kind of way on certain elements . so . ok . anyway . so that 's onl there are there are many more things that are uncl that are sort of like a little bit unstable about the notation but it 's most i think it 's this is , you know , the current current form . other things we did n't totally deal with , um , grad e: oh , there 's a bunch . grad f: well , we 've had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . grad e: yeah . grad f: you know , a a nominal expression . grad e: yeah . grad f: and , um , i mean , we should have put an example of this and we could do that later . grad e: yeah . grad f: but i think the not inherently like the general principles still work though , that , um , we can have constructions that have sort of constituent structure in that there is like , you know , for instance , one uh , you know , they they have constituents , right ? so you can like nest things when you need to , but they can also overlap in a sort of flatter way . so if you do n't have like a lot of grammar experience , then like this this might , you know , be a little o opaque . but , you know , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's i think that 's sort of the main thing we wanted to aim for grad e: mm - hmm . grad f: and so far it 's worked out ok . professor c: good . grad f: so . ok . grad a: i can say two things about the f grad f: yes . grad a: maybe you want to forget stress . this my f grad f: as a word ? grad a: no , as as just do n't do n't think about it . grad f: as a what 's that ? grad a: if grad f: sorry . grad a: canonically speaking you can if you look at a a curve over sentence , you can find out where a certain stress is and say , `` hey , that 's my focus exponent . `` grad e: right . grad f: mm - hmm . grad a: it does n't tell you anything what the focus is . if it 's just that thing , grad f: mm - hmm . or the constituent that it falls in . grad a: a little bit more or the whole phrase . grad e: mm - hmm . grad a: um grad f: you mean t forget about stress , the form cue ? grad a: the form bit grad e: yeah . grad a: because , uh , as a form cue , um , not even trained experts can always well , they can tell you where the focus exponent is sometimes . grad f: ok . grad a: and that 's also mostly true for read speech . in in real speech , um , people may put stress . it 's so d context dependent on what was there before , phrase ba breaks , um , restarts . grad f: yeah . mm - hmm . grad a: it 's just , um it 's absurd . it 's complicated . grad f: ok , grad a: and all grad e: yeah , i mean , i i 'm sort of inclined to say let 's worry about specifying the information structure focus of the sentence grad f: i believe you , yeah . grad e: and then , grad f: mm - hmm . ways that you can get it come from th grad e: hhh , { comment } the phonology component can handle actually assigning an intonation contour to that . grad f: right . grad e: you know , i mean , later on we 'll worry about exactly how grad a: or or map from the contour to to what the focus exponent is . grad e: y yeah . exactly . grad f: mm - hmm . grad e: but figure out how the grad a: but , uh , if you do n't know what you 're what you 're focus is then you 're you 're hopeless - uh - ly lost anyways , grad e: yeah . grad f: right . that 's fine , yeah . mm - hmm . grad a: and the only way of figuring out what that is , is , um , by sort of generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one does n't . grad f: mm - hmm . grad a: and then you 're left with a couple three . so , you know , again , that 's something that h humans can do , grad f: mm - hmm . grad a: um , but far outside the scope of of any anything . so . you know . it 's grad f: ok . well , uh , yeah , i would n't have assumed that it 's an easy problem in in absence of all the oth grad a: u u grad f: you need all the other information i guess . grad a: but it 's it 's what it uh , it 's pretty easy to put it in the formalism , though . i mean , because grad f: yeah . grad a: you can just say whatever stuff , `` i is the container being focused or the the entire whatever , both , and so forth . `` grad f: mm - hmm , mm - hmm . grad e: mm - hmm . grad f: yeah . exactly . so the sort of effect of it is something we want to be able to capture . professor c: yeah , so b b but i think the poi i 'm not sure i understand but here 's what i th think is going on . that if we do the constructions right when a particular construction matches , it the fact that it matches , does in fact specify the focus . grad f: w uh , i 'm not sure about that . professor c: ok . grad f: or it might limit it cert certainly constrains the possibilities of focus . professor c: uh k uh , at at the very least it constrai grad f: i think that 's that 's , th that 's certainly true . and depending on the construction it may or may not f specify the focus , right ? professor c: oh , uh , for sure , yes . there are constrai yeah , it 's not every but there are constructions , uh , where you t explicitly take into account those considerations grad f: yeah . mm - hmm . professor c: that you need to take into account in order to decide which what is being focused . grad f: mm - hmm . grad a: mm - hmm . so we talked about that a little bit this morning . `` john is on the bus , not nancy . `` grad f: mm - hmm . grad a: so that 's focuses on john . professor c: right . grad f: hmm . grad a: `` john is on the bus and not on the train . `` grad f: mm - hmm . grad a: `` john is on the bus `` versus `` john is on the train . `` professor c: right . grad f: right . grad a: and `` john is on the bus `` versus `` was `` , and e grad f: is on . `` john is on the bus `` . yeah . yeah . grad a: `` it 's the bu `` so e professor c: right . yeah , all all of those . grad a: all of these professor c: yeah . grad f: right . grad a: and will we have u is it all the same constructions ? just with a different foc focus constituent ? grad f: yeah , i would say that argument structure in terms of like the main like sort of , grad a: mm - hmm . grad f: i do n't know the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why i was talking about overlapping constructions . so , then you have a separate thing that picks out , you know , stress on something relative to everything else . professor c: yeah . so , the question is actually grad e: mm - hmm . professor c: oh , i 'm sorry , grad f: and it would professor c: go ahead , grad f: yeah , professor c: finish . grad f: and it w and that would have to uh it might be ambiguous as , uh , whether it picks up that element , or the phrase , or something like that . but it 's still is limited possibility . grad a: hmm . grad f: so that should , you know , interact with it should overlap with whatever other construction is there . grad a: yeah . professor c: s s the question is , do we have a way on the other page , uh , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , or something . grad f: mm - hmm . well , so that 's why i was saying how since i could n't think of an easy like limited way of doing it , um , all i can say is that information structure has a focused slot professor c: right . grad f: and i think that should be able to refer to professor c: so that 's down at the bottom here when we get over there . ok . grad f: yeah , and , infer and i do n't have i do n't have a great way or great examples professor c: i 'll - i 'll wait . ok . grad f: but i think that something like that is probably gon na be , uh , more more what we have to do . grad a: hmm . professor c: ok . grad f: but , um , grad a: so grad f: ok , that was one comment . and you had another one ? grad a: yeah , well the once you know what the focus is the everything else is background . how about `` topic - comment `` that 's the other side of information . grad f: how about what ? grad a: topic - comment . grad f: yeah , so that was the other thing . and so i did n't realize it before . it 's like , `` oh ! `` it was an epiphany that it you know , topic and focus are a contrast set . so topic is topic - focused seems to me like , um , background profile , ok , or a landmark trajector , or some something like that . there 's there 's definitely , um , that kind of thing going on . grad a: mmm . grad f: now i do n't know whether i n i do n't have as many great examples of like topic - indicating constructions on like focus , right ? um , topic it seems kind of you know , i think that might be an ongoing kind of thing . grad a: mm - hmm . grad e: japanese has this though . you know . grad f: topic marker ? grad a: yeah . grad e: yeah , that 's what `` wa `` is , uh , just to mark which thing is the topic . grad f: mm - hmm . grad e: it does n't always have to be the subject . grad f: mm - hmm . right . so again , information structure has a topic slot . and , you know , i stuck it in thinking that we might use it . grad a: mm - hmm . grad f: um , i think i stuck it in . professor c: yep , it 's there . grad f: um , and one thing that i did n't do consistently , um , is when we get there , is like indicate what kind of thing fits into every role . i think i have an idea of what it should be but th you know , so far we 've been getting away with like either a type constraint or , um , you know , whatever . i forg it 'll be a frame . you know , it 'll be it 'll be another predication or it 'll be , um , i do n't know , some value from from some something , some variable and scope or something like that , or a slot chain based on a variable and scope . ok , so well that 's should we flip over to the other side officially then ? grad a: mm - hmm , hmm . grad e: ok , side one . grad f: i keep , uh , like , pointing forward to it . yeah . now we 'll go back to s ok , so this does n't include something which mi mi may have some effect on on it , which is , um , the discourse situation context record , right ? so i did n't i i meant just like draw a line and like , you know , you also have , uh , some tracking of what was going on . professor c: right . grad f: and sort of this is a big scale comment before i , you know , look into the details of this . but for instance you could imagine instead of having i i changed the name of um it used to be `` entities `` . so you see it 's `` scenario `` , `` referent `` and `` discourse segment `` . and `` scenario `` is essentially what kind of what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw draw in order to paint your picture , a bunch of frames , bi and bindings , right ? um , and obviously there are other ones that are not included here , general cultural frames and general like , uh , other action f grad e: mm - hmm . grad f: you know , specific x - schema frames . ok , whatever . the middle thing used to be `` entities `` because you could imagine it should be like really a list where here was various information . and this is intended to be grammatically specifiable information about a referent uh , you know , about some entity that you were going to talk about . so `` harry walked into the room `` , `` harry `` and `` room `` , you know , the room th but they would be represented in this list somehow . and it could also have for instance , it has this category slot . um , it should be either category or in or instance . basically , it could be a pointer to ontology . so that everything you know about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , um ki the ones i included here are slightly arbitrary but you could imagine that , um , you need to figure out wheth if it 's a group whether , um , some event is happening , linear time , linear spaces , like , you know , are are they doing something serially or is it like , um , uh i 'm i 'm not sure . because this partly came from , uh , talmy 's schema and i 'm not sure we 'll need all of these actually . but um , and then the `` status `` i used was like , again , in some languages , you know , like for instance in child language you might distinguish between different status . so , th the the big com and and finally `` discourse segment `` is about sort of speech - act - y information structure - y , like utterance - specific kinds of things . so the comment i was going to make about , um , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have a set of entities that you 're sort of referring to . and you might that might be sort of a general , i do n't know , database of all the things in this discourse that you could refer to . and i changed to `` reference `` cuz i would say , for a particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . for instance , i know it 's going to be plural . i know it 's gon na be feminine or something like that . and and these could actually just point to , you know , the the id in my other list of enti active entities , right ? so , um , uh , th there 's there 's all this stuff about discourse status . we 've talked about . i almost listed `` discourse status `` as a slot where you could say it 's active . you know , there 's this , um , hierarchy uh there 's a schematization of , you know , things can be active or they can be , um , accessible , inaccessible . grad e: yeah . grad f: it was the one that , you know , keith , um , emailed to us once , to some of us , not all of us . and the thing is that that i noticed that that , um , list was sort of discourse dependent . it was like in this particular set , s you know , instance , it has been referred to recently or it has n't been , grad e: yeah . grad f: or this is something that 's like in my world knowledge but not active . professor c: this uh yeah , well there there seems to be context properties . grad f: so . professor c: yeah . grad f: yeah , they 're contex and for instance , i used to have a location thing there but actually that 's a property of the situation . and it 's again , time , you know at cert certain points things are located , you know , near or far from you professor c: well , uh , uh , this is recursive grad f: and professor c: cuz until we do the uh , mental space story , we 're not quite sure { comment } th - th grad f: yeah . professor c: which is fine . we 'll just we 'll j grad f: yeah , yeah . so some of these are , uh professor c: we just do n't know yet . grad f: right . so i so for now i thought , well maybe i 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . um , and i left the slot , `` predications `` , open because you can have , um , things like `` the guy i know from school `` . grad e: mm - hmm . grad f: or , you know , like your referring expression might be constrained by certain like unbounded na amounts of prep you know , predications that you might make . and it 's unclear whether i mean , you could just have in your scenario , `` here are some extra few things that are true `` , right ? grad e: mm - hmm . grad f: and then you could just sort of not have this slot here . right ? you 're but but it 's used for identification purposes . professor c: right . grad e: yeah . grad f: so it 's it 's a little bit different from just saying `` all these things are true from my utterance `` . grad e: yeah . grad f: um . grad e: right , `` this guy i know from school came for dinner `` does not mean , um , `` there 's a guy , i know him from school , and he came over for dinner `` . that 's not the same effect . grad f: yeah , it 's a little bit it 's a little bit different . right ? so or maybe that 's like a restrictive , non - restrictive grad e: yeah . grad f: you know , it 's like it gets into that kind of thing for um , but maybe i 'm mixing , you know this is kind of like the final result after parsing the sentence . grad e: mm - hmm . grad f: so you might imagine that the information you pass to , you know in identifying a particular referent would be , `` oh , some `` you know , `` it 's a guy and it 's someone i know from school `` . grad e: yeah . grad f: so maybe that would , you know , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find you know , either create this reference , grad e: mm - hmm . grad f: in which case it 'd be created here , and you know , so so you could imagine that this might not so , uh , i 'm uncommitted to a couple of these things . grad a: but to make it m precise at least in my mind , uh , it 's not precise . grad f: um . grad a: so `` house `` is gender neuter ? in reality grad f: um , it could be in grad a: or in professor c: semantically . grad a: semantically . grad f: semantically , yeah . yeah . grad a: so grad f: so it uh , uh , a table . you know , a thing that c does n't have a gender . so . uh , it could be that i mean , maybe you 'd maybe not all these i mean , i wou i would say that i tried to keep slots here that were potentially relevant to most most things . grad a: no , just to make sure that we everybody that 's completely agreed that it it has nothing to do with , uh , form . grad f: yeah . ok , that is semantic as opposed to yeah . yeah . that 's right . um . grad a: then `` predications `` makes sense to to have it open for something like , uh , accessibility or not . grad f: s so again open to various things . grad a: yeah . grad f: right . ok , so . let 's see . so maybe having made that big sca sort of like large scale comment , should i just go through each of these slots uh , each of these blocks , um , a little bit ? grad e: sure . grad f: um , mostly the top one is sort of image schematic . and just a note , which was that , um s so when we actually ha so for instance , um , some of them seem more inherently static , ok , like a container or sort of support - ish . and others are a little bit seemingly inherently dynamic like `` source , path , goal `` is often thought of that way or `` force `` , or something like that . but in actual fact , i think that they 're intended to be sort of neutral with respect to that . and different x - schemas use them in a way that 's either static or dynamic . so `` path `` , you could just be talking about the path between this and this . grad e: mmm . grad f: and you know , `` container `` that you can go in and out . all of these things . and so , um , i think this came up when , uh , ben and i were working with the spaniards , um , the other day the `` spaniettes `` , as we called them um , to decide like how you want to split up , like , s image schematic contributions versus , like , x - schematic contributions . how do you link them up . and i think again , um , it 's gon na be something in the x - schema that tells you `` is this static or is this dynamic `` . so we definitely need that sort of aspectual type gives you some of that . um , that , you know , is it , uh , a state or is it a change of state , or is it a , um , action of some kind ? grad a: uh , i i i is there any meaning to when you have sort of parameters behind it and when you do n't ? grad f: uh . yeah . grad a: just means grad f: oh , oh ! you mean , in the slot ? grad a: mm - hmm . grad f: um , no , it 's like x - sc it 's it 's like i was thinking of type constraints but x - schema , well it obviously has to be an x - schema . `` agent `` , i mean , the the performer of the x - schema , that s depends on the x - schema . you know , and i in general it would probably be , you know grad e: so the difference is basically whether you thought it was obvious what the possible fillers were . grad f: yeah , basically . grad a: mm - hmm . grad e: ok . grad f: um , `` aspectual type `` probably is n't obvious but i should have so , i just neglected to stick something in . `` perspective `` , `` actor `` , `` undergoer `` , `` observer `` , um , grad b: mmm . grad f: i think we 've often used `` agent `` , `` patient `` , obser grad e: `` whee ! `` that 's that one , right ? grad f: yeah , exactly . exactly . um , and so one nice thing that , uh , we had talked about is this example { comment } of like , if you have a passive construction then one thing it does is ch you know definitely , it is one way to for you to , you know , specifically take the perspective of the undergoing kind of object . and so then we talked about , you know , whether well , does that specify topic as well ? well , maybe there are other things . you know , now that it 's subject is more like a topic . and now that , you know anyway . so . sorry . i 'm gon na trail off on that one cuz it 's not that f important right now . professor c: n now , for the moment we just need the ability to l l write it down if if somebody figured out what the rules were . grad f: um , to know how yeah . yeah . exactly . professor c: yeah . grad f: um , some of these other ones , let 's see . so , uh , one thing i 'm uncertain about is how polarity interacts . professor c: mm - hmm . grad f: so polarity , uh , is using for like action did not take place for instance . so by default it 'll be like `` true `` , i guess , you know , if you 're specifying events that did happen . you could imagine that you skip out this you know , leave off this polarity , you know , not do n't have it here . and then have it part of the speech - act in some way . professor c: mm - hmm . grad f: there 's some negation . but the reason why i left it in is cuz you might have a change of state , let 's say , where some state holds and then some state does n't hold , and you 're just talking , you know if you 're trying to have the nuts and bolts of simulation you need to know that , you know , whatever , the holder does n't and professor c: no , i th i think at this lev which is it should be where you have it . grad f: ok , it 's so it 's it 's it 's fine where it is . professor c: i mean , how you get it may may in will often involve the discourse grad f: so , ok . may come from a few places . professor c: but but by the time you 're simulating you sh y you should know that . grad f: right . right . grad e: so , i 'm still just really not clear on what i 'm looking at . the `` scenario `` box , like , what does that look like for an example ? like , not all of these things are gon na be here . grad f: yeah . professor c: correct . grad e: this is just basically says grad f: mm - hmm . it 's a grab bag of grad e: `` part of what i 'm going to hand you is a whole bunch of s uh , schemas , image , and x - schemas . here are some examples of the sorts of things you might have in there `` . grad f: so that 's exactly what it is . grad e: ok . grad f: and for a particular instance which i will , you know , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , you know , `` into `` you know , definition . grad e: mm - hmm . mm - hmm . grad f: so you would eventually have instances filled in with various various values for all the different slots . grad e: mm - hmm . grad f: and they 're bound up in , you know , their bindings and and and values . professor c: w it c grad e: ok . do you have to say about the binding in your is there a slot in here for that tells you how the bindings are done ? professor c: no , no , no . i let 's see , i think we 're we 're not i do n't think we have it quite right yet . so , uh , what this is , grad e: ok . professor c: let 's suppose for the moment it 's complete . ok , uh , then this says that when an analysis is finished , the whole analysis is finished , { comment } you 'll have as a result , uh , some s resulting s semspec for that utterance in context , grad e: ok . mm - hmm . professor c: which is made up entirely of these things and , uh , bindings among them . and bindings to ontology items . grad e: mm - hmm . professor c: so that that the who that this is the tool kit under whi out of which you can make a semantic specification . grad e: mm - hmm . mm - hmm . professor c: so that 's a . but b , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . grad e: ok . mm - hmm . professor c: so this is an that anything you have , in the party line , { comment } anything you have as the semantic side of constructions comes , from pieces of this ignoring li grad e: ok . professor c: i mean , in general , you ignore lots of it . grad e: right . professor c: but it 's got to be pieces of this along with constraints among them . grad e: ok . professor c: uh , so that the , you know , goal of the , uh uh , `` source , path , goal `` has to be the landmark of the conta you know , the interior of this container . grad e: mm - hmm . professor c: or whate whatever . grad e: yeah . professor c: so those constraints appear in constructions grad e: mm - hmm . professor c: but pretty much this is the full range of semantic structures available to you . grad e: ok . grad f: except for `` cause `` , that i forgot . but anyway , there 's som some kind of causal structure for composite events . grad e: yeah . professor c: ok , good . let 's let 's mark that . so we need a c grad f: uh , i mean , so it gets a little funny . these are all so far these structures , especially from `` path `` and on down , these are sort of relatively familiar , um , image schematic kind of slots . now with `` cause `` , uh , the fillers will actually be themselves frames . right ? professor c: right . grad e: mm - hmm . grad f: so you 'll say , `` event one causes event b professor c: and and and and this this this again may ge our , um and we and and , of course , worlds . grad f: uh , event two `` , and grad e: mm - hmm . grad f: yeah . so that 's , uh these are all implicitly one within , uh within one world . um , even though saying that place takes place , whatever . uh , if y if i said `` time `` is , you know , `` past `` , that would say `` set that this world `` , you know , `` somewhere , before the world that corresponds to our current speech time `` . grad e: mm - hmm . mm - hmm . yeah . grad f: so . but that that that 's sort of ok . the the within the event it 's st it 's still one world . um . yeah , so `` cause `` and other frames that could come in i mean , unfortunately you could bring in say for instance , um , uh , `` desire `` or something like that , grad e: mm - hmm . grad f: like `` want `` . and actually there is right now under `` discourse segments `` , um , `` attitude `` ? grad e: mm - hmm . grad f: `` volition `` ? could fill that . so there are a couple things where i like , `` oh , i 'm not sure if i wanted to have it there grad e: well that 's grad f: or `` basically there was a whole list of of possible speaker attitudes that like say talmy listed . and , like , well , i do n't you know , it was like `` hope , wish . desire `` , professor c: right . grad e: uh - huh . grad f: blah - blah - blah . and it 's like , well , i feel like if i wanted to have an extra meaning i do n't know if those are grammatically marked in the first place . so they 're more lexically marked , right ? grad e: mmm . grad f: at least in english . so if i wanted to i would stick in an extra frame in my meaning , saying , e so th it 'd be a hierarchical frame them , right ? you know , like `` naomi wants wants su a certain situation and that situation itself is a state of affairs `` . professor c: s right . so so , `` want `` itself can be i i i i i grad f: u can be just another frame that 's part of your professor c: well , and it i basically it 's an action . in in our s in our in our grad f: yeah . situation . { comment } right , right . professor c: in in our in our s terminology , `` want `` can be an action and `` what you want `` is a world . grad f: mm - hmm . grad b: hmm . professor c: so that 's i mean , it 's certainly one way to do it . grad f: mmm . professor c: yeah , there there are other things . grad e: mm - hmm . professor c: causal stuff we absolutely need . mental space we need . grad f: mm - hmm . professor c: the context we need . um , so anyway , keith so is this comfortable to you that , uh , once we have this defined , it is your tool kit for building the semantic part of constructions . grad e: mm - hmm . professor c: and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . grad e: mm - hmm . professor c: and that 's the wh and and i mean , that according to the party line , that 's the whole story . grad e: yeah . mm - hmm . yeah . um . y right . that makes sense . so i mean , there 's this stuff in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and i guess that some of the discourse segment stuff is that where you would sa grad f: mm - hmm . grad e: i mean , that 's ok , that 's where the information structure is which sort of is a kind of profiling on different parts of , um , of this . grad f: right . exactly . grad e: i mean , what 's interesting is that the information structure stuff hmm . there 's almost i mean , we keep coming back to how focus is like this this , uh , trajector - landmark thing . grad f: yeah . grad e: so if i say , um , you know , `` in france it 's like this `` . you know , great , we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like `` in france it 's like this `` . and therefore you 're supposed to say , `` boy , life sure `` grad f: right . grad e: you know , `` in france kids are allowed to drink at age three `` . and w you 're that 's not just a fact about france . you also conclude something about how boring it is here in the u s . right ? grad f: right , right . professor c: right . grad e: and so grad f: s so i would prefer not to worry about that for right now grad e: ok . grad f: and to think that there are , um , grad e: that comes in and , uh grad f: discourse level constructions in a sense , topic topic - focus constructions that would say , `` oh , when you focus something `` then grad e: mm - hmm . yeah . grad f: just done the same way just actually in the same way as the lower level . if you stressed , you know , `` john went to the `` , you know , `` the bar `` whatever , you 're focusing that grad e: mm - hmm . grad f: and a in a possible inference is `` in contrast to other things `` . grad e: yeah . grad f: so similarly for a whole sentence , you know , `` in france such - and - such happens `` . grad e: yeah . yeah , yeah . grad f: so the whole thing is sort of like again implicitly as opposed to other things that are possible . grad e: yeah . grad a: uh , just just , uh , look read uh even sem semi formal mats rooth . grad f: i mean yeah . grad a: if you have n't read it . it 's nice . grad f: uh - huh . grad a: and just pick any paper on alternative semantics . grad f: uh - huh . grad e: ok . grad a: so that 's his that 's the best way of talking about focus , is i think his way . grad e: ok , what was the name ? grad a: mats . mats . rooth . grad e: ok . grad a: i think two o 's , yes , th . grad e: ok . grad a: i never know how to pronounce his name because he 's sort of , professor c: s swede ? grad a: uh , he is dutch professor c: dutch ? grad a: and , um but very confused background i think . professor c: oh , dutch . grad e: yeah . professor c: uh - huh . grad a: so and , um , grad e: mats gould . grad a: and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . grad e: hmm . grad a: but , um i do n't know where he is right now but alternative semantics is if you type that into an , uh , uh , browser or search engine you 'll get tons of stuff . grad e: ok . ok . ok , thanks . grad a: and what i 'm kind of confused about is is what the speaker and the hearer is is sort of doing there . grad f: so for a particular segment it 's really just a reference to some other entity again in the situation , right ? so for a particular segment the speaker might be you or might be me . grad a: yeah . grad f: um , hearer is a little bit harder . it could be like multiple people . i guess that that that that 's not very clear from here grad a: yeah , but you do n't we ultimately want to handle that analogously to the way we handle time and place , grad f: i mean , that 's not allowed here . grad a: because `` you `` , `` me `` , `` he `` , `` they `` , you know , `` these guys `` , all these expressions , nuh , are in in much the same way contextually dependent as `` here , `` and `` now , `` and `` there `` grad f: mm - hmm . professor c: now , this is this is assuming you 've already solved that . grad f: ye - yeah . professor c: so it 's it 's fred and mary , grad f: so th professor c: so the speaker would be fred and the grad a: ah ! grad f: right , so the constructions might of course will refer , using pronouns or whatever . grad a: mm - hmm . grad f: in which case they have to check to see , uh , who the , uh , speaker in here wa in order to resolve those . but when you actually say that `` he walked into `` , whatever , um , the `` he `` will refer to a particular you you will already have figured who `` he `` or `` you `` , mmm , or `` i `` , maybe is a bett better example , who `` i `` refers to . um , and then you 'd just be able to refer to harry , you know , in wherever that person whatever role that person was playing in the event . grad a: mmm . that 's up at the reference part . grad f: yeah , yeah . grad a: and down there in the speaker - hearer part ? grad f: s so , that 's i think that 's just n for instance , speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is i mean , you know who the speaker is . in fact , that 's kind of constraining how in some ways you know this before you get to the you fill in all the rest of it . i think . professor c: mmm . grad f: i mean , how else would you um grad a: you know , uh , uh , it 's the speaker may in english is allowed to say `` i . `` professor c: yeah . well , here grad a: uh , among the twenty - five percent most used words . grad f: yeah . right . grad a: but would n't the `` i `` then set up the the s s referent that happens to be the speaker this time grad f: mm - hmm . grad a: and not `` they , `` whoever they are . grad f: right , right . grad a: or `` you `` grad f: so grad a: much like the `` you `` could n grad f: s so ok , so i would say ref under referent should be something that corresponds to `` i `` . and maybe each referent should probably have a list of way whatever , the way it was referred to . so that 's `` i `` but , uh , uh , should we say it it refers to , what ? uh , if it were `` harry `` it would refer to like some ontology thing . if it were if it 's `` i `` it would refer to the current speaker , ok , which is given to be like , you know , whoever it is . grad a: well , not not always . i mean , so there 's `` and then he said , i w `` uh - huh . professor c: uh grad f: `` i `` within the current world . grad a: yeah . professor c: yeah . that 's right . so so again , this uh , this this is gon na to get us into the mental space stuff grad f: yeah , yeah , yeah , yeah . professor c: and t because you know , `` fred said that mary said `` , and whatever . grad e: mmm . grad f: mm - hmm . professor c: and and so we 're , uh gon na have to , um , chain those as well . grad a: mm - hmm . twhhh - whhh . but grad f: mm - hmm . so this entire thing is inside a world , professor c: right . right . grad f: not just like the top part . professor c: i i think , uh grad f: that 's grad a: mm - hmm . professor c: except s it 's it 's trickier than that because um , the reference for example so he where it gets really tricky is there 's some things , grad f: yeah . professor c: and this is where blends and all terribl so , some things which really are meant to be identified and some things which are n't . grad f: yeah . right . professor c: and again , all we need for the moment is some way to say that . grad f: right . so i thought of having like for each referent , having the list of of the things t with which it is identified . you know , which which , uh you know , you you you professor c: you could do that . grad f: for instance , um so , i guess , it sort of depends on if it is a referring exp if it 's identifiable already or it 's a new thing . grad e: mm - hmm . grad f: if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , um , usually w something in a situation , right ? or something in ontology . professor c: uh - huh . grad f: so , there 's a you know , whatever , it c it could point at one of these . professor c: i just had a i just had an an idea that would be very nice if it works . grad f: for what ? professor c: uh , uh , uh , i have n't told you what it is yet . grad f: if it works . professor c: this was my build - up . grad f: mm - hmm . mmm . professor c: an i an idea that would be nice i grad f: yeah . ok , we 're crossing our fingers . professor c: right . grad b: so we 're building a mental space , good . professor c: if it worked . yeah . grad f: ok . professor c: right , it was a space builder . um , we might be able to handle context in the same way that we handle mental spaces because , uh , you have somewhat the same things going on of , uh , things being accessible or not . grad f: mm - hmm . professor c: and so , i grad f: yep . professor c: it c it it , uh i think if we did it right we might be able to get at least a lot of the same structure . grad f: use the same { comment } yep . professor c: so that pulling something out of a discourse context is i think similar to other kinds of , uh , mental space phenomena . grad b: i see . grad f: mm - hmm . and and professor c: uh , i 've i 've i 've never seen anybody write that up but maybe they did . i do n't know . that may be all over the literature . grad f: yeah . grad e: there 's things like ther you know , there 's all kinds of stuff like , um , in i think i mentioned last time in czech if you have a a verb of saying then grad f: so so by default grad e: um , you know , you say something like or or i was thinking you can say something like , `` oh , i thought , uh , you are a republican `` or something like that . where as in english you would say , `` i thought you were `` . professor c: right . grad e: um , you know , sort of the past tense being copied onto the lower verb does n't happen there , so you have to say something about , you know , tense is determined relative to current blah - blah - blah . grad f: mm - hmm . grad e: same things happens with pronouns . grad f: mm - hmm . grad e: there 's languages where , um , if you have a verb of saying then , ehhh , where ok , so a situation like `` bob said he was going to the movies `` , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have `` i `` there . grad f: mm - hmm . professor c: mm - hmm . grad e: um , and it 's sort of in an extended function professor c: so we would have it be in quotes in english . grad e: yeah . grad b: right . grad e: but it 's not perceived as a quotative construction . grad f: right . professor c: yeah . grad e: i mean , it 's been analyzed by the formalists as being a logophoric pronoun , um which means a pronoun which refers back to the person who is speaking or that sort of thing , right ? professor c: ok . grad f: oh , right . yeah , that makes sense . grad e: um , but uh , that happens to sound like the word for `` i `` but is actually semantically unrelated to it . grad f: oh , no ! professor c: oh , good , i love the formali grad e: um , grad f: really ? grad e: yeah . yeah . grad f: you 're kidding . grad e: there 's a whole book which basically operates on this assumption . uh , mary dalrymple , uh , this book , a ninety - three book on , uh on pronoun stuff . grad f: no , that 's horrible . ok . that 's horrible . { comment } ok . grad e: well , yeah . and then the same thing for asl where , you know , you 're signing and someone says something . and then , you know , so `` he say `` , and then you sort of do a role shift . and then you sign `` i , this , that , and the other `` . grad f: uh - huh . grad e: and you know , `` i did this `` . that 's also been analyzed as logophoric and having nothing to do with `` i `` . and the role shift thing is completely left out and so on . so , i mean , the point is that pronoun references , uh , you know , sort of ties in with all this mental space stuff and so on , and so forth . grad f: uh - huh . grad e: and so , yeah , i mean grad f: yeah . professor c: so that that d that does sound like it 's co consistent with what we 're saying , yeah . grad e: right . yeah . grad f: ok , so it 's kind of like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the h you know , depending on the construction or the whatever , um , you you you 're scope is m might extend out to the the base one . grad e: mm - hmm . professor c: mm - hmm . grad e: yeah . grad f: it would be nice to actually use the same , um , mechanism since there are so many cases where you actually need it 'll be one or the other . grad e: yeah . grad f: it 's like , oh , actually , it 's the same same operation . professor c: oh , ok , so this this is worth some thought . grad f: so . grad e: it 's like it 's like what 's happening that , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ? grad f: yeah , yeah . grad e: so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . grad f: mm - hmm . grad e: and so , grad f: mm - hmm . grad e: um , things like pronoun reference and tense which we 're thinking of as being these discourse - y things actually are relative to a bayes space which can change . grad f: mm - hmm , grad e: and we need all the same machinery . grad f: right . grad a: mm - hmm . grad f: robert . professor c: well , but , uh , this is very good actually grad e: schade . professor c: cuz it it it to the extent that it works , it y grad f: ties it all into it . professor c: it it ties together several of of these things . grad f: yeah . yep . grad a: mm - hmm . mm - hmm . and i 'm sure gon na read the transcript of this one . so . but the , uh , but it 's too bad that we do n't have a camera . you know , all the pointing is gon na be lost . grad e: yeah . grad f: oh , yeah . grad b: well every time nancy giggles it means it means that it 's your job . grad f: yeah , that 's why i said `` point to robert `` , when i did it . grad a: uh . yeah . mmm , is n't i mean , i 'm i was sort of dubious why why he even introduces this sort of reality , you know , as your basic mental space and then builds up grad e: mm - hmm . grad a: d does n't start with some because it 's so obvi it should be so obvious , at least it is to me , { comment } that whenever i say something i could preface that with `` i think . `` nuh ? grad e: yeah . grad a: so there should be no categorical difference between your base and all the others that ensue . grad e: yeah . professor c: no , but there 's there 's a gricean thing going on there , that when you say `` i think `` you 're actually hedging . grad e: yeah , i mean grad f: mmm . it 's like i do n't totally think professor c: right . grad e: yeah . y grad f: i mostly think , uh grad a: yeah , it 's absolutely . grad e: yeah , it 's an it 's an evidential . it 's sort of semi - grammaticalized . people have talked about it this way . and you know , you can do sort of special things . you can , th put just the phrase `` i think `` as a parenthetical in the middle of a sentence and so on , and so forth . grad a: yeah . grad e: so grad f: actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any kind of interesting embedded ways just to mark , you know , uncertainty or something like that . grad e: yeah . grad f: so . grad a: yeah , but about linguistic hedges , i mean , those those tend to be , um , funky anyways because they blur professor c: so we do n't have that in here either do we ? grad e: yeah . grad f: hedges ? professor c: yeah , yeah . grad f: hhh , { comment } i there used to be a slot for speaker , um , it was something like factivity . i could n't really remember what it meant grad e: yeah . grad f: so i took it out . grad e: um . grad f: but it 's something grad e: well we were just talking about this sort of evidentiality and stuff like that , right ? grad f: we we were talking about sarcasm too , right ? oh , oh . grad e: i mean , grad f: oh , yeah , yeah , right . grad e: that 's what i think is , um , sort of telling you what percent reality you should give this professor c: so we probably should . grad f: yeah . grad a: mm - hmm . grad e: or the , you know professor c: confidence or something like that . grad e: yeah , and the fact that i 'm , you know the fact maybe if i think it versus he thinks that might , you know , depending on how much you trust the two of us or whatever , grad f: yeah . grad a: uh great word in the english language is called `` about `` . grad e: you know grad a: if you study how people use that it 's also grad f: what 's the word ? grad a: `` about . `` it 's about professor c: about . grad a: clever . professor c: oh , that in that use of `` about `` , yeah . grad f: oh , oh , oh , as a hedge . grad e: yeah . professor c: and i think and i think y if you want us to spend a pleasant six or seven hours you could get george started on that . grad e: he wrote a paper about thirty - five years ago on that one . grad b: i r i read that paper , professor c: yeah . grad b: the hedges paper ? i read some of that paper actually . grad e: yeah . professor c: yeah . grad e: would you believe that that paper lead directly to the development of anti - lock brakes ? grad f: what ? professor c: no . grad e: ask me about it later i 'll tell you how . when we 're not on tape . grad f: i 'd love to know . grad b: oh , man . grad f: so , and and i think , uh , someone had raised like sarcasm as a complication at some point . professor c: there 's all that stuff . yeah , let 's i i do n't i think grad f: and we just wo n't deal with sarcastic people . professor c: yeah , i mean grad e: i do n't really know what like we we do n't have to care too much about the speaker attitude , right ? like there 's not so many different hhh , { comment } i do n't know , m grad f: certainly not as some well , they 're intonational markers i think for the most part . grad e: yeah . grad f: i do n't know too much about the like grammatical grad e: i just mean there 's lots of different attitudes that that the speaker could have and that we can clearly identify , and so on , and so forth . grad f: yeah . grad e: but like what are the distinctions among those that we actually care about for our current purposes ? professor c: right . right , so , uh , this this raises the question of what are our current purposes . grad f: mm - hmm . professor c: right ? grad e: oh , shoot . grad f: oh , yeah , do we have any ? grad e: here it is three - fifteen already . grad a: mmm . yeah . professor c: uh , so , um , i i do n't know the answer but but , um , it does seem that , you know , this is this is coming along . i think it 's it 's converging . it 's as far as i can tell there 's this one major thing we have to do which is the mental the whole s mental space thing . and then there 's some other minor things . grad f: mm - hmm . professor c: um , and we 're going to have to s sort of bound the complexity . i mean , if we get everything that anybody ever thought about you know , w we 'll go nuts . grad e: yeah . professor c: so we had started with the idea that the actual , uh , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and were n't trying to d you know , there 's all sorts of god knows , irony , and stuff like which you is n't probably of much use in dealing with a tourist guide . grad e: yeah . professor c: yeah ? grad e: yeah . professor c: uh . grad f: m mockery . professor c: right . whatever . so y uh , no end of things th that that , you know , we do n't deal with . grad a: but it professor c: and grad a: i is n't that part easy though professor c: go ahead . grad a: because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to sort of negate whatever the content of that is in terms of irony grad e: yeah . professor c: n no . grad f: mmm . grad a: or professor c: no . grad e: right . grad f: maybe . professor c: no . grad f: yeah , in model theory cuz the semantics is always like `` speaker believes not - p `` , you know ? professor c: right . grad f: like `` the speaker says p and believes not - p `` . grad e: we have a theoretical model of sarcasm now . grad f: but professor c: right . grad e: yeah , right , i mean . professor c: no , no . grad f: right , right , but , professor c: anyway , so so , um , i guess uh , let me make a proposal on how to proceed on that , which is that , um , it was keith 's , uh , sort of job over the summer to come up with this set of constructions . uh , and my suggestion to keith is that you , over the next couple weeks , n grad e: mmm . professor c: do n't try to do them in detail or formally but just try to describe which ones you think we ought to have . grad e: ok . professor c: uh , and then when robert gets back we 'll look at the set of them . grad e: ok . professor c: just just sort of , you know , define your space . grad e: yeah , ok . professor c: and , um , so th these are this is a set of things that i think we ought to deal with . grad e: yeah . professor c: and then we 'll we 'll we 'll go back over it and w people will will give feedback on it . grad e: ok . professor c: and then then we 'll have a at least initial spec of of what we 're actually trying to do . grad e: yeah . professor c: and that 'll also be useful for anybody who 's trying to write a parser . grad e: mm - hmm . professor c: knowing uh grad e: in case there 's any around . grad f: if we knew anybody like that . professor c: right , `` who might want `` et cetera . so , uh grad e: ok . professor c: so a and we get this this , uh , portals fixed and then we have an idea of the sort of initial range . and then of course nancy you 're gon na have to , uh , do your set of but you have to do that anyway . grad f: for the same , yeah , data . yeah , mm - hmm . professor c: so so we 're gon na get the w we 're basically dealing with two domains , the tourist domain and the and the child language learning . grad b: mmm . professor c: and we 'll see what we need for those two . and then my proposal would be to , um , not totally cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . grad e: mm - hmm . professor c: and then as a kind of separate thread , think about the more general things and and all that . grad e: mm - hmm . mm - hmm . grad a: well , i also think the detailed discussion will hit you know , bring us to problems that are of a general nature and maybe even professor c: uh , without doubt . yeah . grad f: yeah . grad a: even suggest some solutions . professor c: but what i want to do is is is to to constrain the things that we really feel responsible for . grad a: yeah . mmm . professor c: so that that we say these are the things we 're really gon na try do by the end of the summer grad e: mm - hmm . professor c: and other things we 'll put on a list of of research problems or something , because you can easily get to the point where nothing gets done because every time you start to do something you say , `` oh , yeah , but what about this case ? `` grad e: mm - hmm . professor c: this is this is called being a linguist . grad a: mmm . grad e: yeah . professor c: and , uh , grad e: basically . grad f: or me . professor c: huh ? grad f: or me . anyways grad b: there 's that quote in jurafsky and martin where where it goes where some guy goes , `` every time i fire a linguist the performance of the recognizer goes up . `` professor c: right . grad f: yeah . grad e: exactly . professor c: right . but anyway . so , is is that does that make sense as a , uh a general way to proceed ? grad f: sure , yeah . grad e: yeah , yeah , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it . professor c: exactly right . grad a: mmm . grad e: got it . grad a: mmm . grad e: ok . grad a: we have a little bit of news , uh , just minor stuff . the one big grad b: ooo , can i ask a grad e: you ran out of power . grad a: huh ? grad b: can i ask a quick question about this side ? grad a: yeah . grad f: yes . grad b: is this , uh was it intentional to leave off things like `` inherits `` and grad f: oops . um , grad e: no . grad f: not really just on the constructions , right ? grad b: yeah , like constructions can inherit from other things , grad f: um , grad b: am i right ? grad f: yeah . grad b: yeah . grad f: i did n't want to think too much about that for for now . grad b: ok . professor c: yeah . grad f: so , uh , maybe it was subconsciously intentional . professor c: yeah , uh yeah . grad e: um , yeah , there should be i i wanted to s find out someday if there was gon na be some way of dealing with , uh , if this is the right term , multiple inheritance , professor c: mm - hmm . grad e: where one construction is inheriting from , uh from both parents , grad f: uh - huh . yep . grad e: uh , or different ones , or three or four different ones . professor c: yeah . so let me grad e: cuz the problem is that then you have to grad f: yeah . grad e: which of you know , which are how they 're getting bound together . grad f: refer to them . professor c: yeah , right , right , right . yeah , yeah , yeah . grad f: yeah , and and there are certainly cases like that . even with just semantic schemas we have some examples . professor c: right . grad f: so , and we 've been talking a little bit about that anyway . professor c: yeah . so what i would like to do is separate that problem out . grad f: inherits . professor c: so um , grad e: ok . professor c: my argument is there 's nothing you can do with that that you ca n't do by just having more constructions . grad e: yeah , yes . professor c: it 's uglier and it d does n't have the deep linguistic insights and stuff . grad e: that 's right . professor c: uh , grad e: but whatever . professor c: right . grad e: yeah , no , no , no no . grad f: uh , those are over rated . grad e: no , by all means , professor c: and so i what i 'd like to do is is in the short run focus on getting it right . grad e: right . uh , sure . professor c: and when we think we have it right then saying , `` aha ! , grad e: yeah . professor c: can we make it more elegant ? `` grad e: yeah , that 's professor c: can can we , uh what are the generalizations , and stuff ? grad e: yeah . connect the dots . yeah . professor c: but rather than try to guess a inheritance structure and all that sort of stuff before we know what we 're doing . grad e: yep . yeah . professor c: so i would say in the short run we 're not gon na b grad e: yeah . professor c: first of all , we 're not doing them yet at all . and and it could be that half way through we say , `` aha ! , we we now see how we want to clean it up . `` grad e: mm - hmm . professor c: uh , and inheritance is only one i mean , that 's one way to organize it but there are others . and it may or may not be the best way . grad e: yeah . grad a: mmm . professor c: i 'm sorry , you had news . grad a: oh , just small stuff . um , thanks to eva on our web site we can now , if you want to run javabayes , uh , you could see get download these classes . and then it will enable you she modified the gui so it has now a m a m a button menu item for saving it into the embedded javabayes format . grad d: mm - hmm . grad b: mmm . grad a: so that 's wonderful . professor c: great . grad a: and , um and she , a you tested it out . do you want to say something about that , that it works , right ? with the grad d: i was just checking like , when we wan na , um , get the posterior probability of , like , variables . you know how you asked whether we can , like , just observe all the variables like in the same list ? you ca n't . grad a: uh - huh . grad d: you have to make separate queries every time . grad a: ok , that 's that 's a bit unfortunate grad d: so yeah . grad a: but for the time being it 's it 's it 's fine to do it grad d: you just have to have a long list of , you know , all the variables . grad a: yeah . but uh grad d: basically . grad f: uh , all the things you want to query , you just have to like ask for separately . grad d: yeah , yeah . grad a: well that 's probably maybe in the long term that 's good news because it forces us to think a little bit more carefully how how we want to get an out output . um , but that 's a different discussion for a different time . and , um , i do n't know . we 're really running late , so i had , uh , an idea yesterday but , uh , i do n't know whether we should even start discussing . professor c: w what yeah , sure , tell us what it is . grad a: um , the construal bit that , um , has been pointed to but has n't been , um , made precise by any means , um , may w may work as follows . i thought that we would , uh that the following thing would be in incredibly nice and i have no clue whether it will work at all or nothing . so that 's just a tangent , a couple of mental disclaimers here . um , imagine you you write a bayes - net , um grad f: bayes ? grad a: bayes - net , grad f: ok . grad a: um , completely from scratch every time you do construal . so you have nothing . just a white piece of paper . professor c: mmm , right . grad a: you consult consult your ontology which will tell you a bunch of stuff , and parts , and properties , uh - uh - uh grad f: grout out the things that that you need . professor c: right . grad a: then y you 'd simply write , uh , these into onto your your white piece of paper . and you will get a lot of notes and stuff out of there . you wo n't get you wo n't really get any c p t 's , therefore we need everything that that configures to what the situation is , ie , the context dependent stuff . so you get whatever comes from discourse but also filtered . uh , so only the ontology relevant stuff from the discourse plus the situation and the user model . grad f: mm - hmm . grad a: and that fills in your cpt 's with which you can then query , um , the the net that you just wrote and find out how thing x is construed as an utterance u . and the embedded javabayes works exactly like that , that once you we have , you know , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the the nice thing about this idea is that you do n't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the the initial notes . but it 's in that respect it 's completely scalable . because it does n't have any prior , um , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work at all , that 'd be kind of funky . professor c: um , it sounds to me like you want p r grad a: p r ms - uh , prm i mean , since you can unfold a prm into a straightforward bayes - net professor c: beca - because it b because no , no , you ca n't . see the the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it . grad a: then you can . mm - hmm , yeah . no , i was m using it generic . so , uh , probabilistic , whatever , relational models . whatever you write it . in professor c: well , no , but it matters a lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case . grad a: and then then instantiate them . that 's ma maybe the the way the only way it works . professor c: yeah , and that 's grad a:  professor c: yeah , that 's the only way it could work . i we have a our local expert on p r uh , but my guess is that they 're not currently good enough to do that . but we 'll we 'll have to see . grad a: but , uh , professor c: uh yes . this is that 's that would be a good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , uh grad a: except there 's no no theorem prover involved . grad f: best explanation . professor c: no , there is n't a theorem prover but there but but the , um , the cove the the p r ms are like rules of inference and you 're you 're coupling a bunch of them together . grad a: mm - hmm , yeah . professor c: and then ins instead of proving you 're trying to , you know , compute the most likely . uh tricky . but you yeah , it 's a good it 's a it 's a good thing to put in your thesis proposal . grad a: what 's it ? professor c: so are you gon na write something for us before you go ? grad a: yes . um . professor c: oh , you have something . grad a: in the process thereof , or whatever . professor c: ok . so , what 's what when are we gon na meet again ? grad f: when are you leaving ? grad a: fri - uh , grad f: thursday , friday ? grad a: thursday 's my last day here . grad d: fri professor c: yeah . grad f: ok . grad a: so i would suggest as soon as possible . do you mean by we , the whole ben gang ? professor c: n no , i did n't mean y just the two of us . we obviously we can we can do this . but the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal and get , uh , another session on feedback on that ? or grad a: we can do it th - thursday again . yeah . grad e: fine with me . should we do the one pm time for thursday since we were on that before or ? grad a: sure . grad e: ok . professor c: alright . grad d: hmm . grad a: thursday at one ? i can also maybe then sort of run through the , uh the talk i have to give at eml which highlights all of our work . professor c: ok . grad a: and we can make some last minute changes on that . professor c: ok . grad b: you can just give him the abstract that we wrote for the paper . professor c: that - that 'll tell him exactly what 's going on . yeah , that alright . grad f: can we do can we do one - thirty ? grad a: no . grad f: oh , you already told me no . grad a: but we can do four . grad f: one , ok , it 's fine . i can do one . it 's fine . it 's fine . grad a: one or four . i do n't care . grad e: to me this is equal . i do n't care . grad a: if it 's equal for all ? what should we do ? grad f: yeah , it 's fine . grad a: four ? grad f: fine . yeah no , no , no , uh , i do n't care . it 's fine . grad a: it 's equal to all of us , so you can decide one or four . grad b: the pressure 's on you nancy . grad a: liz actually said she likes four because it forces the meeting recorder people to cut , you know the discussions short . grad f: ok . ok , four . grad e: well , if you insist , then . grad f: ok ? ok . i am .","output":"the revised semantic specification and construction formalism are more stable than the previous versions . semantic constraints also come into play . the semantic specification , on the other hand , is split into three levels : `` scenario '' is a list of schemas and bindings between them , which describes the current event in terms of source-path-goal , container , etc . ; `` referent '' is about the entities in the discourse and includes grammatical information and pointers to the ontology ; `` discourse segment '' comprises utterance-specific things . apart from the presentation , javabayes can now run through the modified web page of the project ."},{"instruction":"what was concluded on semantic specification ?","input":"grad b: what things to talk about . grad f: i 'm what ? really ? oh , that 's horrible ! disincentive ! grad a: ok , we 're recording . grad f: hello ? grad b: check check check check . grad d: uh , yeah . grad f: hello ? which am i ? professor c: oh right . grad b: alright . good . grad f: channel fi ok . ok . are you doing something ? ok , then i guess i 'm doing something . so , um , so basically the result of m much thinking since the last time we met , um , but not as much writing , um , is a sheet that i have a lot of , like , thoughts and justification of comments on but i 'll just pass out as is right now . so , um , here . if you could pass this around ? and there 's two things . and so one on one side is on one side is a sort of the revised sort of updated semantic specification . grad d: um the wait . grad f: and the other side is , um , sort of a revised construction formalism . grad e: this is just one sheet , right ? grad d: ah ! just one sheet . grad f: it 's just one sheet . grad d: ok . grad f: it 's just a nothing else . grad d: front , back . grad f: um , enough to go around ? ok . and in some ways it 's it 's it 's very similar to there are very few changes in some ways from what we 've , um , uh , b done before but i do n't think everyone here has seen all of this . so , uh , i 'm not sure where to begin . um , as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . grad e: mm - hmm . grad f: and , um , after a little bit more discussion and especially like keith and i i have more linguistic things to settle in the next few days , um , it 'll probably change again some more . grad e: yeah . grad f: um , maybe i will let 's start b let 's start on number two actually on the notation , um , because that 's , i 'm thinking , possibly a little more familiar to , um to people . ok , so the top block is just sort of a sort of abstract nota it 's sort of like , um , listings of the kinds of things that we can have . and certain things that have , um , changed , have changed back to this . there there 's been a little bit of , um , going back and forth . but basically obviously all constructions have some kind of name . i forgot to include that you could have a type included in this line . professor c: what i was gon na right . grad f: so something like , um well , there 's an example the textual example at the end has clausal construction . so , um , just to show it does n't have to be beautiful it could be , you know , simple old text as well . um , there are a couple of uh , these three have various ways of doing certain things . so i 'll just try to go through them . so they could all have a type at the beginning . um , and then they say the key word construction professor c: oh , i see . grad f: and they have some name . professor c: so so the current syntax is if it s if there 's a type it 's before construct grad f: yeah , right . professor c: ok , that 's fine . grad f: ok , and then it has a block that is constituents . and as usual i guess all the constructions her all the examples here have only , um , tsk { comment } one type of constituent , that is a constructional constituent . i think that 's actually gon na turn out to m be certainly the most common kind . but in general instead of the word `` construct `` , th here you might have `` meaning `` or `` form `` as well . ok ? so if there 's some element that does n't that is n't yet constructional in the sense that it maps form and meaning . ok , um , the main change with the constructs which each of which has , um , the key word `` construct `` and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that you know what kind of construction it is . so for example whatever i have here is gon na be a form of the word `` throw `` , or it 's gon na be a form of the word , you know , i do n't know , `` happy `` , or something like that . or , you know , some it 'll be a specific word or maybe you 'll have the type . you 'll say `` i need a p uh spatial relation phrase here `` or `` i need a directional specifier here `` . so - uh you could have a j a actual type here . um , or you could just say in the second case that you only know the meaning type . so a very common example of this is that , you know , in directed motion , the first person to do something should be an agent of some kind , often a human . right ? so if i you know , the um , uh , run down the street then i i i run down the street , it 's typed , uh , `` i `` , meaning category is what 's there . the the new kind is this one that is sort of a pair and , um , sort of skipping fonts and whatever . the idea is that sometimes there are , um , general constructions that you know , that you 're going to need . it 's it 's the equivalent of a noun phrase or a prepositional phrase , or something like that there . grad e: mm - hmm . grad f: and usually it has formal um , considerations that will go along with it . professor c: mm - hmm . grad f: and then uh , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , you know , um , `` the big th `` , you you know , `` the big the tall dark man `` , you know , `` walked into the room `` . grad e: mm - hmm . grad f: but because of the nature of this particular construction you know not just that it 's nominal of some kind but in particular , that it 's some kind of animate nominal , and which will apply just as well to like , you know , a per you know , a simple proper noun or to some complicated expression . um , so i do n't know if the syntax will hold but something that gives you a way to do both constructional and meaning types . so . ok , then i do n't think the , { comment } um at least yeah . { comment } none of these examples have anything different for formal constraints ? but you can refer to any of the , um , sort of available elements and scope , right ? which here are the constructs , { comment } to say something about the relation . and i think i if you not if you compare like the top block and the textual block , um , we dropped like the little f subscript . the f subscripts refer to the `` form `` piece of the construct . professor c: good . grad f: and i think that , um , in general it 'll be unambiguous . like if you were giving a formal constraint then you 're referring to the formal pole of that . so so by saying if i just said `` name one `` then that means name one formal and we 're talking about formal struc { comment } which which makes sense . uh , there are certain times when we 'll have an exception to that , in which case you could just indicate `` here i mean the meaningful for some reason `` . right ? or actually it 's more often that , only to handle this one special case of , you know , `` george and jerry walk into the room in that order `` . grad e: mm - hmm . grad f: so we have a few funny things where something in the meaning might refer to something in the form . but but s we 're not gon na really worry about that for right now and there are way we can be more specific if we have to later on . ok , and so in terms of the the relations , you know , as usual they 're before and ends . i should have put an example in of something that is n't an interval relation but in form you might also have a value binding . you know , you could say that , um , you know , `` name - one dot `` , t you know , `` number equals `` , you know , a plural or something like that . grad e: mm - hmm . grad f: there are certain things that are attribute - value , similar to the bindings below but i mean they 're just us usually they 're going to be value value fillers , right ? ok , and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and i i you you and i can like fight about that if you like ? but about changing it to `` semantic n effects `` , which i thought was a little bit too order - biased grad b: well th grad f: and `` semantic bindings `` , which i thought might be too restrictive in case we do n't have only bindings . and so it was an issue whether constraints um , there were some linguists who reacted against `` constraints `` , saying , `` oh , if it 's not used for matching , then it should n't be called a constraint `` . but i think we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are i think we thought of some situations where it would be useful to use whatever the c bindings are , for actual , you know , sort of like modified constraining purposes . professor c: well , you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification , i grad e: yeah . grad f: yeah , yeah . it 's used should n't matter , right ? mm - hmm . professor c: s for sure . i mean , i do n't know what , uh , term we want to use grad f: mm - hmm . professor c: but we do n't want to grad f: yeah , uh , there was one time when when hans explained why `` constraints `` was a misleading word for him . professor c: yep . grad f: and i think the reason that he gave was similar to the reason why johno thought it was a misleading term , which was just an interesting coincidence . um , but , uh and so i was like , `` ok , well both of you do n't like it ? professor c: it 's g it 's gone . grad f: fine , we can change it `` . but i i i 'm starting to like it again . grad b: but grad f: so that that 's why { comment } that 's why i 'll stick with it . grad a: well , you know what ? grad f: so grad a: if you have an `` if - then `` phrase , do you know what the `` then `` phrase is called ? professor c: th grad f: what ? con - uh , a consequent ? grad a: yeah . grad f: yeah , but it 's not an `` if - then `` . grad a: no , but professor c: i know . anyway , so the other the other strategy you guys could consider is when you do n't know what word to put , you could put no word , grad f: mm - hmm . professor c: just meaning . ok ? and the then let grad e: yeah . grad f: yeah , that 's true . grad b: so that 's why you put semantic constraints up top and meaning bindings down down here ? grad f: oh , oops ! no . that was just a mistake of cut and paste from when i was going with it . grad b: ok . professor c: ok . grad f: so , i 'm sorry . i did n't mean that one 's an in unintentional . grad b: so this should be semantic and grad f: sometimes i 'm intentionally inconsistent grad b:  grad f: cuz i 'm not sure yet . here , i actually it was just a mistake . grad b: th - so this definitely should be `` semantic constraints `` down at the bottom ? grad e: sure . grad f: yeah . grad b: ok . grad f: well , unless i go with `` meaning `` but i i mean , i kind of like `` meaning `` better than `` semantic `` grad b: or professor c: oh , whatever . grad f: but i think there 's vestiges of other people 's biases . professor c: or wh that - b grad f: like professor c: right . minor min problem grad f: minor point . professor c: ok . grad e: extremely . grad f: ok , um , so i think the middle block does n't really give you any more information , ex than the top block . and the bottom block similarly only just illus you know , all it does is illustrate that you can drop the subscripts and and that you can drop the , um uh , that you can give dual types . oh , one thing i should mention is about `` designates `` . i think i 'm actually inconsistent across these as well . so , um , strike out the m subscript on the middle block . professor c: mm - hmm . grad f: so basically now , um , this is actually this little change actually goes along with a big linguistic change , which is that `` designates `` is n't only something for the semantics to worry about now . professor c: good . grad f: so we want s `` designates `` to actually know one of the constituents which acts like a head in some respects but is sort of , um , really important for say composition later on . so for instance , if some other construction says , you know , `` are you of type is this part of type whatever `` , um , the `` designates `` tells you which sort of part is the meaning part . ok , so if you have like `` the big red ball `` , you know , you wan na know if there 's an object or a noun . well , ball is going to be the designated sort of element of that kind of phrase . grad e: mmm . grad f: um , there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , um to talk about there also being a designated object and we think that that 'll be the same one , right ? so the ball is the head of the phrase , `` the r the `` , um , `` big red ball `` , and the entity denoted by the word `` ball `` is sort of the semantic head in some ways of of this sort of , um , in interesting larger element . professor c: a a and the yeah . and there 's uh there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if i understand you right . grad e: yeah . grad f: mm - hmm . grad e: yeah . grad f: right , right . grad e: that 's the idea . professor c: yeah yeah . grad e: yeah . grad f: and , uh , you might be able to say things like if the head has to go last in a head - final language , you can refer to the head as a p the , you know the formal head as opposed to the rest of the form having to be at the end of that decision . professor c: right . grad f: so that 's a useful thing so that you can get some internal structural constraints in . professor c: ok , so that all looks good . let me oh , w oh . i do n't know . were you finished ? grad f: um , there was a list of things that is n't included but you you can you can ask a question . that might @ @ it . professor c: ok . so , i if i understand this the aside from , uh , construed and all that sort of stuff , the the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for a type grad f: mm - hmm . professor c: or actually gone back to , grad f: right . professor c: if we go back far enough grad f: well , except for their construction meaning , so it 's not clear that , uh well , right now it 's a c uh contr construction type and meaning type . so i do n't know what a form type is . professor c: oh , i see . yeah , yeah , yeah . i 'm sorry , you 're right . grad f: yeah . professor c: a construction type . uh , that 's fine . but it , um grad f: right . a well , and a previous , um , you know , version of the notation certainly allowed you to single out the meaning bit by it . so you could say `` construct of type whatever designates something `` . professor c: yeah . grad f: but that was mostly for reference purposes , just to refer to the meaning pole . i do n't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time i think . professor c: mm - hmm . grad f: um , i i do n't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , you know that 's kind of weird . professor c: no , no , no , i do n't think so . i think that you 'll you 'll do fine . grad e: i professor c: in fact , these are , um , as long as as mark is n't around , these are form constraints . so a nominal expression is uh , the fact that it 's animate , is semantic . the fact that it 's n uh , a nominal expression i would say on most people 's notion of of f you know , higher form types , this i this is one . grad f: mm - hmm . grad e: yeah . grad f: right , right . professor c: and i think that 's just fine . grad e: yeah , yeah . grad f: which is fine , yeah . professor c: yeah . grad e: it 's that now , um , i 'm mentioned this , i i do n't know if i ever explained this but the point of , um , i mentioned in the last meeting , { comment } the point of having something called `` nominal expression `` is , um , because it seems like having the verb subcategorize for , you know , like say taking as its object just some expression which , um , designates an object or designates a thing , or whatever , um , that leads to some syntactic problems basically ? so you wan na , you know you sort of have this problem like `` ok , well , i 'll put the word `` , uh , let 's say , the word `` dog `` , you know . and that has to come right after the verb grad f: mm - hmm . grad e: cuz we know verb meets its object . and then we have a construction that says , oh , you can have `` the `` preceding a noun . and so you 'd have this sort of problem that the verb has to meet the designatum . professor c: right . grad e: and you could get , you know , `` the kicked dog `` or something like that , meaning `` kicked the dog `` . professor c: right . grad e: um , so you kind of have to let this phrase idea in there professor c: that i i have no problem with it at all . grad e: but it - it professor c: i think it 's fine . grad e: yeah . grad f: yeah . right , n s you may be you may not be like everyone else in in berkeley , grad e: yeah . yeah . grad f: but that 's ok . grad e: i mean , we we we sort of thought we were getting away with , uh with , a p grad f: uh , we do n't mind either , so grad e: i mean , this is not reverting to the x - bar theory of of phrase structure . professor c: right . grad e: but , uh , grad f: right . grad e: i just know that this is like , we did n't originally have in mind that , uh that verbs would subcategorize for a particular sort of form . grad f: mm - hmm . professor c: but they do . grad e: um , but they does . grad f: well , there 's an alternative to this grad e: at least in english . grad f: which is , um the question was did we want directed motion , professor c: yeah . grad f: which is an argument structure construction professor c: mm - hmm . grad e: yeah . grad f: did we want it to worry about , um , anything more than the fact that it , you know , has semantic you know , it 's sort of frame - based construction . so one option that , you know , keith had mentioned also was like , well if you have more abstract constructions such as subject , predicate , basically things like grammatical relations , grad e: mm - hmm . grad f: those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob you know , verb object would require that those things that f fill a subject and object are nom expressions . professor c: right . grad f: and that would be a little bit cleaner in some way . but you know , for now , i mean , professor c: yeah . but it y y it 's yeah , just moving it moving the c the cons the constraints around . grad f: uh , you know . m moving it to another place , right . grad e: yeah . professor c: ok , so that 's grad f: but there does basically , the point is there has to be that constraint somewhere , right ? professor c: right . grad f: so , yeah . professor c: and so that was the grad f: robert 's not happy now ? grad a: no ! grad f: oh , ok . professor c: ok , and sort of going with that is that the designatum also now is a pair . grad f: yes . professor c: instead of just the meaning . grad f: mm - hmm . professor c: and that aside from some terminology , that 's basically it . grad f: right . professor c: i just want to b i 'm i 'm asking . grad e: mm - hmm . grad f: yep . grad e: yeah . grad f: yeah , um , the un sort of the un - addressed questions in this , um , definitely would for instance be semantic constraints we talked about . professor c: yeah . grad f: here are just bindings but , right ? we might want to introduce mental spaces you know , there 's all these things that we do n't professor c: the whole the mental space thing is clearly not here . grad f: right ? so there 's going to be some extra you know , definitely other notation we 'll need for that which we skip for now . grad e: mm - hmm . professor c: by the way , i do want to get on that as soon as robert gets back . grad f: uh yeah . professor c: so , uh , the the mental space thing . grad f: ok . professor c: um , obviously , construal is a b is a b is a big component of that grad e: mm - hmm . professor c: so this probably not worth trying to do anything till he gets back . but sort of as soon as he gets back i think um , we ought to grad f: mm - hmm . mm - hmm . grad e: so what 's the what 's the time frame ? i forgot again when you 're going away for how long ? grad a: just , uh , as a sort of a mental bridge , i 'm not i 'm skipping fourth of july . so , uh , right afterwards i 'm back . grad e: ok . ok . grad f: what ? you 're missing like the premier american holiday ? what 's the point of spending a year here ? grad a: uh , i 've had it often enough . grad f: so , anyway . grad b: well he w he went to college here . grad f: oh , yeah , i forgot . oops . { comment } sorry . professor c: yeah . grad f: ok . professor c: and furthermore it 's well worth missing . grad f: not in california . grad e: yes . grad f: yeah , that 's true . i like i i like spending fourth of july in other countries , whenever i can . professor c: right . grad f: um professor c: ok , so that 's great . grad f: construal , ok , so oh , so there was one question that came out . i hate this thing . sorry . um , which is , so something like `` past `` which i you know , we think is a very simple uh , we 've often just stuck it in as a feature , professor c: right . right . grad f: you know , `` oh , this event takes place before speech time `` , { comment } ok , is what this means . um , it 's often thought of as it is also considered a mental space , professor c: right . grad f: you know , by , you know , lots of people around here . professor c: right . grad f: so there 's this issue of well sometimes there are really exotic explicit space builders that say `` in france , blah - blah - blah `` , grad e: mm - hmm . grad f: and you have to build up you ha you would imagine that would require you , you know , to be very specific about the machinery , whereas past is a very conventionalized one and we sort of know what it means but it we does n't do n't necessarily want to , you know , unload all the notation every time we see that it 's past tense . professor c: right . grad f: so , you know , we could think of our uh , just like x - schema `` walk `` refers to this complicated structure , past refers to , you know , a certain configuration of this thing with respect to it . professor c: i think that 's exactly right . grad f: so so we 're kind of like having our cake and eating it professor c: yeah . grad f: you know , having it both ways , right ? professor c: yeah . no , i think i think that i we 'll have to see how it works out when we do the details grad f: so , i i mm - hmm . professor c: but my intuition would be that that 's right . grad f: mm - hmm . yeah , ok . grad a: do you want to do the same for space ? grad f: wha - sorry ? grad a: space ? grad f: space ? grad a: here ? now ? grad f: oh , oh , oh , oh , instead of just time ? grad a: mm - hmm . grad f: yeah , yeah , yeah . same thing . so there are very conventionalized like deictic ones , right ? and then i think for other spaces that you introduce , you could just attach y whatever grad a: hmm . grad f: you could build up an appropriately uh , appropriate structure according to the l the sentence . professor c: yeah . grad a: hmm , well this this basically would involve everything you can imagine to fit under your c dot something grad e: n grad a: you know , where where it 's contextually dependent , grad f: yeah . right . grad a: `` what is now , what was past , grad f: mm - hmm . grad a: what is in the future , where is this , what is here , what is there , what is `` grad f: mm - hmm . yeah . so time and space . um , we 'll we 'll get that on the other side a little , like very minimally . there 's a sort of there 's a slot for setting time and setting place . professor c: good . grad f: and you know , you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , { comment } there are relative things that , you know , you relate the event in time and space to where you are now . if there 's something a lot more complicated like , or so hypothetical or whatever , then you have to do your job , grad e: mm - hmm . grad f: like or somebody 's job anyway . grad e: yeah . grad f: i 'm gon na point to at random . grad e: yeah . i mean , i 'm i 'm s curious about how much of the mental i mean , i 'm not sure that the formalism , sort of the grammatical side of things , { comment } is gon na have that much going on in terms of the mental space stuff . you know , um , basically all of these so - called space builders that are in the sentence are going to sort of i think of it as , sort of giving you the coordinates of , you know assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , um the construction that you actually get is just gon na sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to . grad f: mm - hmm . grad e: so `` in france , uh , watergate would n't have hurt nixon `` or something like that . um , well , you say , `` alright , i 'm supposed to add some structure to my model of this hypothetical past france universe `` or something like that . the information in the sentence tells you that much but it does n't tell you like exactly what it what the point of doing so is . so for example , depending on the linguistic con uh , context it could be like the question is for example , what does `` watergate `` refer to there ? does it , you know does it refer to , um if you just hear that sentence cold , the assumption is that when you say `` watergate `` you 're referring to `` a watergate - like scandal as we might imagine it happening in france `` . but in a different context , `` oh , you know , if nixon had apologized right away it would n't you know , watergate would n't have hurt him so badly in the us and in france it would n't have hurt him at all `` . now we 're s now that `` watergate `` we 're now talking about the real one , grad f: they 're real , right . grad e: and the `` would `` sort of it 's a sort of different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . grad f: i see right . grad e: in the first case , hypothetically we 're imagining that watergate happened in france . grad f: hmm . grad e: in the second case we 're imagining hypothetically that nixon had apologized right away grad f: mm - hmm . grad e: or something . right ? grad f: right . grad e: so a lot of this is n't happening at the grammatical level . professor c: correct . grad e: uh , um , and so grad f: mm - hmm . grad e: i do n't know where that sits then , grad a: hmm . grad e: sort of the idea of sorting out what the person meant . grad f: it seems like , um , the grammatical things such as the auxiliaries that you know introduce these conditionals , whatever , give you sort of the the most basi grad e: mm - hmm . grad f: th those we i think we can figure out what the possibilities are , right ? grad e: mm - hmm . grad f: there are sort of a relatively limited number . and then how they interact with some extra thing like `` in france `` or `` if such - and - such `` , that 's like there are certain ways that they c they can grad e: yeah . grad f: you know , one is a more specific version of the general pattern that the grammat grammar gives you . grad e: yeah . grad f: i think . but , you know , whatever , professor c: yeah , in the short run all we need is a enough mechanism on the form side to get things going . grad f: we we 're grad e: mm - hmm . yeah . professor c: uh , i uh , you you grad e: but the whole point of the whole point of what fauconnier and turner have to say about , uh , mental spaces , and blending , and all that stuff is that you do n't really get that much out of the sentence . you know , there 's not that much information contained in the sentence . it just says , `` here . add this structure to this space . `` and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean a hundred different things depending on , quote , `` what the space configuration is at the time of utterance `` . grad f: mm - hmm . mm - hmm . grad e: and so somebody 's gon na have to be doing a whole lot of work but not me , i think . professor c: well i think that 's right . oh , i yeah , i , uh , uh i think that 's not k i th i do n't think it 's completely right . i mean , in fact a sentence examples you gave in f did constrain the meaning b the form did constrain the meaning , grad e: yeah . professor c: and so , um , it is n't , uh grad e: sure , but like what what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really . grad f: that 's ok . we usually do n't know the point of the sentence at all . grad e: yeah . grad f: but we know what it 's trying to say . professor c: yeah . grad e: y yeah . grad f: we we know that it 's what predication it 's setting up . professor c: but but bottom line , i agree with you , grad e: yeah . grad f: that 's all . professor c: that that that we 're not expecting much out of the , uh f grad e: yeah . grad f: purely linguistic cues , right ? professor c: uh , the purely form cues , yeah . grad f: so . professor c: and , um i mean , you 're you 're the linguist grad f: mmm . professor c: but , uh , it seems to me that th these we we you know , we 've talked about maybe a half a dozen linguistics theses in the last few minutes or something . grad e: yeah , yeah . professor c: yeah , i mean grad e: yeah . oh , yeah . professor c: uh , i i mean , that that 's my feeling that that these are really hard uh , problems that decide exactly what what 's going on . grad e: mm - hmm . yeah . yeah . professor c: ok . grad f: ok , so , um , one other thing i just want to point out is there 's a lot of confusion about the terms like `` profile , designate , focus `` , et cetera , et cetera . professor c: uh , right , right , right . grad e: mm - hmm . grad f: um , for now i 'm gon na say like `` profile `` 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so `` hypotenuse `` , you profiled this guy against the background of the right t right triangle . grad e: mm - hmm . grad f: ok . and the second use , um , is in framenet . it 's slightly different . oh , i was asking hans about this . they use it to really mean , um , this in a frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which i 'm not saying one and two are mutually exclusive but they 're they 're different meanings . professor c: right . grad e: mm - hmm . grad f: so the closest thing so i was thinking about how it relates to this notation . for us , um ok , so how is it professor c: does that is that really what they mean in in grad f: so `` designate `` framenet ? professor c: i did n't know that . grad f: framenet ? yeah , yeah . i i mean , i i was a little bit surprised about it too . professor c: yeah . grad f: i knew that i thought that that would be something like there 's another term that i 've heard for that thing professor c: right , ok . grad f: but they i mean uh , well , at least hans says they use it that way . and professor c: well , i 'll check . grad f: and may maybe he 's wrong . anyway , so i think the the `` designate `` that we have in terms of meaning is really the `` highlight this thing with respect to everything else `` . ok ? professor c: right . grad f: so this is what what it means . but the second one seems to be useful but we might not need a notation for it ? we do n't have a notation for it but we might want one . so for example we 've talked about if you 're talking about the lexical item `` walk `` , you know it 's an action . well , it also has this idea it carries along with it the idea of an actor or somebody 's gon na do the walking . or if you talk about an adjective `` red `` , it carries along the idea of the thing that has the property of having color red . so we used to use the notation `` with `` for this professor c: right . grad f: and i think that 's closest to their second one . so i d do n't yet know , i have no commitment , as to whether we need it . it might be it 's the kind of thing that w a parser might want to think about whether we require you know , these things are like it 's semantically part of it professor c: n no , no . well , uh , th critically they 're not required syntactically . often they 're pres presu presupposed and all that sort of stuff . grad f: right . right , right . yeah , um , definitely . so , um , `` in `` was a good example . if you walk `` in `` , like well , in what ? professor c: right , there 's grad f: you know , like you have to have the { comment } so so it 's only semantically is it it is still required , say , by simulation time though professor c: right . grad f: to have something . so it 's that i meant the idea of like that the semantic value is filled in by sim simulation . i do n't know if that 's something we need to spa to to like say ever as part of the requirement ? or the construction ? or not . we 'll we 'll again defer . professor c: or i mean , or or , uh so the grad f: have it construed , professor c: yeah , yeah . grad f: is that the idea ? just point at robert . whenever i 'm confused just point to him . professor c: right . it 's it 's his thesis , right ? grad f: you tell me . professor c: anyway , grad f: ok . professor c: right , yeah , w this is gon na be a b you 're right , this is a bit of in a mess and we still have emphasis as well , or stress , or whatever . grad f: ok , well we 'll get , uh uh , i we have thoughts about those as well . professor c: yeah . great . grad f: um , the i w i would just s some of this is just like my you know , by fiat . i 'm going to say , this is how we use these terms . i do n't - you know , there 's lots of different ways in the world that people use it . professor c: i that 's fine . grad e: yeah . grad f: i think that , um , the other terms that are related are like focus and stress . professor c: mm - hmm . grad f: so , s i think that the way i we would like to think , uh , i think is focus is something that comes up in , i mean , lots of basically this is the information structure . professor c: mm - hmm . grad f: ok , it 's like uh , it 's not it might be that there 's a syntactic , uh , device that you use to indicate focus or that there are things like , you know , i think keith was telling me , { comment } things toward the end of the sentence , post - verbal , tend to be the focused focused element , grad e: mmm . grad f: the new information . you know , if i `` i walked into the room `` , you tend to think that , whatever , `` into the room `` is sort of like the more focused kind of thing . grad e: mm - hmm . yeah . grad f: and when you , uh , uh , you have stress on something that might be , you know , a cue that the stressed element , or for instance , the negated element is kind of related to information structure . so that 's like the new the sort of like import or whatever of of this thing . uh , so so i think that 's kind of nice to keep `` focus `` being an information structure term . `` stress `` i th and then there are different kinds of focus that you can bring to it . so , um , like `` stress `` , th stress is kind of a pun on you might have like whatever , like , um , accent kind of stress . grad e: mm - hmm . grad f: and that 's just a uh , w we 'll want to distinguish stress as a form device . you know , like , oh , high volume or whatever . grad e: yeah . grad f: um , t uh , and distinguish that from it 's effect which is , `` oh , the kind of focus we have is we 're emphasizing this value often as opposed to other values `` , right ? so focus carries along a scope . like if you 're gon na focus on this thing and you wan na know it sort of evokes all the other possibilities that it was n't . grad e: mm - hmm . grad f: um , so my classic my now - classic example of saying , `` oh , he did go to the meeting ? `` , grad e: yeah . grad f: that was my way of saying as opposed to , you know , `` oh , he did n't g `` or `` there was a meeting ? `` grad e: yeah . grad f: i think that was the example that was caught on by the linguists immediately . grad e: yeah . grad f: and so , um , the like if you said he you know , there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , uh grad e: mm - hmm . grad f: `` he walked to the meeting `` as opposed to `` he ran `` , or `` he did walk to the meeting `` as opposed to `` he did n't walk `` . you know , grad e: mm - hmm . grad f: so we need to have a notation for that which , um , i think that 's still in progress . so , sort of i 'm still working it out . but it did one one implication it does f have for the other side , which we 'll get to in a minute is that i could n't think of a good way to say `` here are the possible things that you could focus on `` , cuz it seems like any entity in any sentence , you know , or any meaning component of anyth you know all the possible meanings you could have , any of them could be the subject of focus . professor c: mmm . grad f: but i think one the one thing you can schematize is the kind of focus , right ? so for instance , you could say it 's the the tense on this as opposed to , um , the the action . ok . or it 's uh , it 's an identity thing or a contrast with other things , or stress this value as opposed to other things . so , um , it 's it is kind of like a profile profile - background thing but i i ca n't think of like the limited set of possible meanings that you would that you would focu grad e: light up with focus , yeah . grad f: light highlight as opposed to other ones . so it has some certain complications for the , uh , uh later on . li - i mean , uh , the best thing i can come up with is that information has a list of focused elements . for instance , you oh , one other type that i forgot to mention is like query elements and that 's probably relevant for the like `` where is `` , you know , `` the castle `` kind of thing ? grad e: mm - hmm . grad f: because you might want to say that , um , location or cert certain wh words bring you know , sort of automatically focus in a , you know , `` i do n't know the identity of this thing `` kind of way on certain elements . so . ok . anyway . so that 's onl there are there are many more things that are uncl that are sort of like a little bit unstable about the notation but it 's most i think it 's this is , you know , the current current form . other things we did n't totally deal with , um , grad e: oh , there 's a bunch . grad f: well , we 've had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . grad e: yeah . grad f: you know , a a nominal expression . grad e: yeah . grad f: and , um , i mean , we should have put an example of this and we could do that later . grad e: yeah . grad f: but i think the not inherently like the general principles still work though , that , um , we can have constructions that have sort of constituent structure in that there is like , you know , for instance , one uh , you know , they they have constituents , right ? so you can like nest things when you need to , but they can also overlap in a sort of flatter way . so if you do n't have like a lot of grammar experience , then like this this might , you know , be a little o opaque . but , you know , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's i think that 's sort of the main thing we wanted to aim for grad e: mm - hmm . grad f: and so far it 's worked out ok . professor c: good . grad f: so . ok . grad a: i can say two things about the f grad f: yes . grad a: maybe you want to forget stress . this my f grad f: as a word ? grad a: no , as as just do n't do n't think about it . grad f: as a what 's that ? grad a: if grad f: sorry . grad a: canonically speaking you can if you look at a a curve over sentence , you can find out where a certain stress is and say , `` hey , that 's my focus exponent . `` grad e: right . grad f: mm - hmm . grad a: it does n't tell you anything what the focus is . if it 's just that thing , grad f: mm - hmm . or the constituent that it falls in . grad a: a little bit more or the whole phrase . grad e: mm - hmm . grad a: um grad f: you mean t forget about stress , the form cue ? grad a: the form bit grad e: yeah . grad a: because , uh , as a form cue , um , not even trained experts can always well , they can tell you where the focus exponent is sometimes . grad f: ok . grad a: and that 's also mostly true for read speech . in in real speech , um , people may put stress . it 's so d context dependent on what was there before , phrase ba breaks , um , restarts . grad f: yeah . mm - hmm . grad a: it 's just , um it 's absurd . it 's complicated . grad f: ok , grad a: and all grad e: yeah , i mean , i i 'm sort of inclined to say let 's worry about specifying the information structure focus of the sentence grad f: i believe you , yeah . grad e: and then , grad f: mm - hmm . ways that you can get it come from th grad e: hhh , { comment } the phonology component can handle actually assigning an intonation contour to that . grad f: right . grad e: you know , i mean , later on we 'll worry about exactly how grad a: or or map from the contour to to what the focus exponent is . grad e: y yeah . exactly . grad f: mm - hmm . grad e: but figure out how the grad a: but , uh , if you do n't know what you 're what you 're focus is then you 're you 're hopeless - uh - ly lost anyways , grad e: yeah . grad f: right . that 's fine , yeah . mm - hmm . grad a: and the only way of figuring out what that is , is , um , by sort of generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one does n't . grad f: mm - hmm . grad a: and then you 're left with a couple three . so , you know , again , that 's something that h humans can do , grad f: mm - hmm . grad a: um , but far outside the scope of of any anything . so . you know . it 's grad f: ok . well , uh , yeah , i would n't have assumed that it 's an easy problem in in absence of all the oth grad a: u u grad f: you need all the other information i guess . grad a: but it 's it 's what it uh , it 's pretty easy to put it in the formalism , though . i mean , because grad f: yeah . grad a: you can just say whatever stuff , `` i is the container being focused or the the entire whatever , both , and so forth . `` grad f: mm - hmm , mm - hmm . grad e: mm - hmm . grad f: yeah . exactly . so the sort of effect of it is something we want to be able to capture . professor c: yeah , so b b but i think the poi i 'm not sure i understand but here 's what i th think is going on . that if we do the constructions right when a particular construction matches , it the fact that it matches , does in fact specify the focus . grad f: w uh , i 'm not sure about that . professor c: ok . grad f: or it might limit it cert certainly constrains the possibilities of focus . professor c: uh k uh , at at the very least it constrai grad f: i think that 's that 's , th that 's certainly true . and depending on the construction it may or may not f specify the focus , right ? professor c: oh , uh , for sure , yes . there are constrai yeah , it 's not every but there are constructions , uh , where you t explicitly take into account those considerations grad f: yeah . mm - hmm . professor c: that you need to take into account in order to decide which what is being focused . grad f: mm - hmm . grad a: mm - hmm . so we talked about that a little bit this morning . `` john is on the bus , not nancy . `` grad f: mm - hmm . grad a: so that 's focuses on john . professor c: right . grad f: hmm . grad a: `` john is on the bus and not on the train . `` grad f: mm - hmm . grad a: `` john is on the bus `` versus `` john is on the train . `` professor c: right . grad f: right . grad a: and `` john is on the bus `` versus `` was `` , and e grad f: is on . `` john is on the bus `` . yeah . yeah . grad a: `` it 's the bu `` so e professor c: right . yeah , all all of those . grad a: all of these professor c: yeah . grad f: right . grad a: and will we have u is it all the same constructions ? just with a different foc focus constituent ? grad f: yeah , i would say that argument structure in terms of like the main like sort of , grad a: mm - hmm . grad f: i do n't know the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why i was talking about overlapping constructions . so , then you have a separate thing that picks out , you know , stress on something relative to everything else . professor c: yeah . so , the question is actually grad e: mm - hmm . professor c: oh , i 'm sorry , grad f: and it would professor c: go ahead , grad f: yeah , professor c: finish . grad f: and it w and that would have to uh it might be ambiguous as , uh , whether it picks up that element , or the phrase , or something like that . but it 's still is limited possibility . grad a: hmm . grad f: so that should , you know , interact with it should overlap with whatever other construction is there . grad a: yeah . professor c: s s the question is , do we have a way on the other page , uh , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , or something . grad f: mm - hmm . well , so that 's why i was saying how since i could n't think of an easy like limited way of doing it , um , all i can say is that information structure has a focused slot professor c: right . grad f: and i think that should be able to refer to professor c: so that 's down at the bottom here when we get over there . ok . grad f: yeah , and , infer and i do n't have i do n't have a great way or great examples professor c: i 'll - i 'll wait . ok . grad f: but i think that something like that is probably gon na be , uh , more more what we have to do . grad a: hmm . professor c: ok . grad f: but , um , grad a: so grad f: ok , that was one comment . and you had another one ? grad a: yeah , well the once you know what the focus is the everything else is background . how about `` topic - comment `` that 's the other side of information . grad f: how about what ? grad a: topic - comment . grad f: yeah , so that was the other thing . and so i did n't realize it before . it 's like , `` oh ! `` it was an epiphany that it you know , topic and focus are a contrast set . so topic is topic - focused seems to me like , um , background profile , ok , or a landmark trajector , or some something like that . there 's there 's definitely , um , that kind of thing going on . grad a: mmm . grad f: now i do n't know whether i n i do n't have as many great examples of like topic - indicating constructions on like focus , right ? um , topic it seems kind of you know , i think that might be an ongoing kind of thing . grad a: mm - hmm . grad e: japanese has this though . you know . grad f: topic marker ? grad a: yeah . grad e: yeah , that 's what `` wa `` is , uh , just to mark which thing is the topic . grad f: mm - hmm . grad e: it does n't always have to be the subject . grad f: mm - hmm . right . so again , information structure has a topic slot . and , you know , i stuck it in thinking that we might use it . grad a: mm - hmm . grad f: um , i think i stuck it in . professor c: yep , it 's there . grad f: um , and one thing that i did n't do consistently , um , is when we get there , is like indicate what kind of thing fits into every role . i think i have an idea of what it should be but th you know , so far we 've been getting away with like either a type constraint or , um , you know , whatever . i forg it 'll be a frame . you know , it 'll be it 'll be another predication or it 'll be , um , i do n't know , some value from from some something , some variable and scope or something like that , or a slot chain based on a variable and scope . ok , so well that 's should we flip over to the other side officially then ? grad a: mm - hmm , hmm . grad e: ok , side one . grad f: i keep , uh , like , pointing forward to it . yeah . now we 'll go back to s ok , so this does n't include something which mi mi may have some effect on on it , which is , um , the discourse situation context record , right ? so i did n't i i meant just like draw a line and like , you know , you also have , uh , some tracking of what was going on . professor c: right . grad f: and sort of this is a big scale comment before i , you know , look into the details of this . but for instance you could imagine instead of having i i changed the name of um it used to be `` entities `` . so you see it 's `` scenario `` , `` referent `` and `` discourse segment `` . and `` scenario `` is essentially what kind of what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw draw in order to paint your picture , a bunch of frames , bi and bindings , right ? um , and obviously there are other ones that are not included here , general cultural frames and general like , uh , other action f grad e: mm - hmm . grad f: you know , specific x - schema frames . ok , whatever . the middle thing used to be `` entities `` because you could imagine it should be like really a list where here was various information . and this is intended to be grammatically specifiable information about a referent uh , you know , about some entity that you were going to talk about . so `` harry walked into the room `` , `` harry `` and `` room `` , you know , the room th but they would be represented in this list somehow . and it could also have for instance , it has this category slot . um , it should be either category or in or instance . basically , it could be a pointer to ontology . so that everything you know about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , um ki the ones i included here are slightly arbitrary but you could imagine that , um , you need to figure out wheth if it 's a group whether , um , some event is happening , linear time , linear spaces , like , you know , are are they doing something serially or is it like , um , uh i 'm i 'm not sure . because this partly came from , uh , talmy 's schema and i 'm not sure we 'll need all of these actually . but um , and then the `` status `` i used was like , again , in some languages , you know , like for instance in child language you might distinguish between different status . so , th the the big com and and finally `` discourse segment `` is about sort of speech - act - y information structure - y , like utterance - specific kinds of things . so the comment i was going to make about , um , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have a set of entities that you 're sort of referring to . and you might that might be sort of a general , i do n't know , database of all the things in this discourse that you could refer to . and i changed to `` reference `` cuz i would say , for a particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . for instance , i know it 's going to be plural . i know it 's gon na be feminine or something like that . and and these could actually just point to , you know , the the id in my other list of enti active entities , right ? so , um , uh , th there 's there 's all this stuff about discourse status . we 've talked about . i almost listed `` discourse status `` as a slot where you could say it 's active . you know , there 's this , um , hierarchy uh there 's a schematization of , you know , things can be active or they can be , um , accessible , inaccessible . grad e: yeah . grad f: it was the one that , you know , keith , um , emailed to us once , to some of us , not all of us . and the thing is that that i noticed that that , um , list was sort of discourse dependent . it was like in this particular set , s you know , instance , it has been referred to recently or it has n't been , grad e: yeah . grad f: or this is something that 's like in my world knowledge but not active . professor c: this uh yeah , well there there seems to be context properties . grad f: so . professor c: yeah . grad f: yeah , they 're contex and for instance , i used to have a location thing there but actually that 's a property of the situation . and it 's again , time , you know at cert certain points things are located , you know , near or far from you professor c: well , uh , uh , this is recursive grad f: and professor c: cuz until we do the uh , mental space story , we 're not quite sure { comment } th - th grad f: yeah . professor c: which is fine . we 'll just we 'll j grad f: yeah , yeah . so some of these are , uh professor c: we just do n't know yet . grad f: right . so i so for now i thought , well maybe i 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . um , and i left the slot , `` predications `` , open because you can have , um , things like `` the guy i know from school `` . grad e: mm - hmm . grad f: or , you know , like your referring expression might be constrained by certain like unbounded na amounts of prep you know , predications that you might make . and it 's unclear whether i mean , you could just have in your scenario , `` here are some extra few things that are true `` , right ? grad e: mm - hmm . grad f: and then you could just sort of not have this slot here . right ? you 're but but it 's used for identification purposes . professor c: right . grad e: yeah . grad f: so it 's it 's a little bit different from just saying `` all these things are true from my utterance `` . grad e: yeah . grad f: um . grad e: right , `` this guy i know from school came for dinner `` does not mean , um , `` there 's a guy , i know him from school , and he came over for dinner `` . that 's not the same effect . grad f: yeah , it 's a little bit it 's a little bit different . right ? so or maybe that 's like a restrictive , non - restrictive grad e: yeah . grad f: you know , it 's like it gets into that kind of thing for um , but maybe i 'm mixing , you know this is kind of like the final result after parsing the sentence . grad e: mm - hmm . grad f: so you might imagine that the information you pass to , you know in identifying a particular referent would be , `` oh , some `` you know , `` it 's a guy and it 's someone i know from school `` . grad e: yeah . grad f: so maybe that would , you know , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find you know , either create this reference , grad e: mm - hmm . grad f: in which case it 'd be created here , and you know , so so you could imagine that this might not so , uh , i 'm uncommitted to a couple of these things . grad a: but to make it m precise at least in my mind , uh , it 's not precise . grad f: um . grad a: so `` house `` is gender neuter ? in reality grad f: um , it could be in grad a: or in professor c: semantically . grad a: semantically . grad f: semantically , yeah . yeah . grad a: so grad f: so it uh , uh , a table . you know , a thing that c does n't have a gender . so . uh , it could be that i mean , maybe you 'd maybe not all these i mean , i wou i would say that i tried to keep slots here that were potentially relevant to most most things . grad a: no , just to make sure that we everybody that 's completely agreed that it it has nothing to do with , uh , form . grad f: yeah . ok , that is semantic as opposed to yeah . yeah . that 's right . um . grad a: then `` predications `` makes sense to to have it open for something like , uh , accessibility or not . grad f: s so again open to various things . grad a: yeah . grad f: right . ok , so . let 's see . so maybe having made that big sca sort of like large scale comment , should i just go through each of these slots uh , each of these blocks , um , a little bit ? grad e: sure . grad f: um , mostly the top one is sort of image schematic . and just a note , which was that , um s so when we actually ha so for instance , um , some of them seem more inherently static , ok , like a container or sort of support - ish . and others are a little bit seemingly inherently dynamic like `` source , path , goal `` is often thought of that way or `` force `` , or something like that . but in actual fact , i think that they 're intended to be sort of neutral with respect to that . and different x - schemas use them in a way that 's either static or dynamic . so `` path `` , you could just be talking about the path between this and this . grad e: mmm . grad f: and you know , `` container `` that you can go in and out . all of these things . and so , um , i think this came up when , uh , ben and i were working with the spaniards , um , the other day the `` spaniettes `` , as we called them um , to decide like how you want to split up , like , s image schematic contributions versus , like , x - schematic contributions . how do you link them up . and i think again , um , it 's gon na be something in the x - schema that tells you `` is this static or is this dynamic `` . so we definitely need that sort of aspectual type gives you some of that . um , that , you know , is it , uh , a state or is it a change of state , or is it a , um , action of some kind ? grad a: uh , i i i is there any meaning to when you have sort of parameters behind it and when you do n't ? grad f: uh . yeah . grad a: just means grad f: oh , oh ! you mean , in the slot ? grad a: mm - hmm . grad f: um , no , it 's like x - sc it 's it 's like i was thinking of type constraints but x - schema , well it obviously has to be an x - schema . `` agent `` , i mean , the the performer of the x - schema , that s depends on the x - schema . you know , and i in general it would probably be , you know grad e: so the difference is basically whether you thought it was obvious what the possible fillers were . grad f: yeah , basically . grad a: mm - hmm . grad e: ok . grad f: um , `` aspectual type `` probably is n't obvious but i should have so , i just neglected to stick something in . `` perspective `` , `` actor `` , `` undergoer `` , `` observer `` , um , grad b: mmm . grad f: i think we 've often used `` agent `` , `` patient `` , obser grad e: `` whee ! `` that 's that one , right ? grad f: yeah , exactly . exactly . um , and so one nice thing that , uh , we had talked about is this example { comment } of like , if you have a passive construction then one thing it does is ch you know definitely , it is one way to for you to , you know , specifically take the perspective of the undergoing kind of object . and so then we talked about , you know , whether well , does that specify topic as well ? well , maybe there are other things . you know , now that it 's subject is more like a topic . and now that , you know anyway . so . sorry . i 'm gon na trail off on that one cuz it 's not that f important right now . professor c: n now , for the moment we just need the ability to l l write it down if if somebody figured out what the rules were . grad f: um , to know how yeah . yeah . exactly . professor c: yeah . grad f: um , some of these other ones , let 's see . so , uh , one thing i 'm uncertain about is how polarity interacts . professor c: mm - hmm . grad f: so polarity , uh , is using for like action did not take place for instance . so by default it 'll be like `` true `` , i guess , you know , if you 're specifying events that did happen . you could imagine that you skip out this you know , leave off this polarity , you know , not do n't have it here . and then have it part of the speech - act in some way . professor c: mm - hmm . grad f: there 's some negation . but the reason why i left it in is cuz you might have a change of state , let 's say , where some state holds and then some state does n't hold , and you 're just talking , you know if you 're trying to have the nuts and bolts of simulation you need to know that , you know , whatever , the holder does n't and professor c: no , i th i think at this lev which is it should be where you have it . grad f: ok , it 's so it 's it 's it 's fine where it is . professor c: i mean , how you get it may may in will often involve the discourse grad f: so , ok . may come from a few places . professor c: but but by the time you 're simulating you sh y you should know that . grad f: right . right . grad e: so , i 'm still just really not clear on what i 'm looking at . the `` scenario `` box , like , what does that look like for an example ? like , not all of these things are gon na be here . grad f: yeah . professor c: correct . grad e: this is just basically says grad f: mm - hmm . it 's a grab bag of grad e: `` part of what i 'm going to hand you is a whole bunch of s uh , schemas , image , and x - schemas . here are some examples of the sorts of things you might have in there `` . grad f: so that 's exactly what it is . grad e: ok . grad f: and for a particular instance which i will , you know , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , you know , `` into `` you know , definition . grad e: mm - hmm . mm - hmm . grad f: so you would eventually have instances filled in with various various values for all the different slots . grad e: mm - hmm . grad f: and they 're bound up in , you know , their bindings and and and values . professor c: w it c grad e: ok . do you have to say about the binding in your is there a slot in here for that tells you how the bindings are done ? professor c: no , no , no . i let 's see , i think we 're we 're not i do n't think we have it quite right yet . so , uh , what this is , grad e: ok . professor c: let 's suppose for the moment it 's complete . ok , uh , then this says that when an analysis is finished , the whole analysis is finished , { comment } you 'll have as a result , uh , some s resulting s semspec for that utterance in context , grad e: ok . mm - hmm . professor c: which is made up entirely of these things and , uh , bindings among them . and bindings to ontology items . grad e: mm - hmm . professor c: so that that the who that this is the tool kit under whi out of which you can make a semantic specification . grad e: mm - hmm . mm - hmm . professor c: so that 's a . but b , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . grad e: ok . mm - hmm . professor c: so this is an that anything you have , in the party line , { comment } anything you have as the semantic side of constructions comes , from pieces of this ignoring li grad e: ok . professor c: i mean , in general , you ignore lots of it . grad e: right . professor c: but it 's got to be pieces of this along with constraints among them . grad e: ok . professor c: uh , so that the , you know , goal of the , uh uh , `` source , path , goal `` has to be the landmark of the conta you know , the interior of this container . grad e: mm - hmm . professor c: or whate whatever . grad e: yeah . professor c: so those constraints appear in constructions grad e: mm - hmm . professor c: but pretty much this is the full range of semantic structures available to you . grad e: ok . grad f: except for `` cause `` , that i forgot . but anyway , there 's som some kind of causal structure for composite events . grad e: yeah . professor c: ok , good . let 's let 's mark that . so we need a c grad f: uh , i mean , so it gets a little funny . these are all so far these structures , especially from `` path `` and on down , these are sort of relatively familiar , um , image schematic kind of slots . now with `` cause `` , uh , the fillers will actually be themselves frames . right ? professor c: right . grad e: mm - hmm . grad f: so you 'll say , `` event one causes event b professor c: and and and and this this this again may ge our , um and we and and , of course , worlds . grad f: uh , event two `` , and grad e: mm - hmm . grad f: yeah . so that 's , uh these are all implicitly one within , uh within one world . um , even though saying that place takes place , whatever . uh , if y if i said `` time `` is , you know , `` past `` , that would say `` set that this world `` , you know , `` somewhere , before the world that corresponds to our current speech time `` . grad e: mm - hmm . mm - hmm . yeah . grad f: so . but that that that 's sort of ok . the the within the event it 's st it 's still one world . um . yeah , so `` cause `` and other frames that could come in i mean , unfortunately you could bring in say for instance , um , uh , `` desire `` or something like that , grad e: mm - hmm . grad f: like `` want `` . and actually there is right now under `` discourse segments `` , um , `` attitude `` ? grad e: mm - hmm . grad f: `` volition `` ? could fill that . so there are a couple things where i like , `` oh , i 'm not sure if i wanted to have it there grad e: well that 's grad f: or `` basically there was a whole list of of possible speaker attitudes that like say talmy listed . and , like , well , i do n't you know , it was like `` hope , wish . desire `` , professor c: right . grad e: uh - huh . grad f: blah - blah - blah . and it 's like , well , i feel like if i wanted to have an extra meaning i do n't know if those are grammatically marked in the first place . so they 're more lexically marked , right ? grad e: mmm . grad f: at least in english . so if i wanted to i would stick in an extra frame in my meaning , saying , e so th it 'd be a hierarchical frame them , right ? you know , like `` naomi wants wants su a certain situation and that situation itself is a state of affairs `` . professor c: s right . so so , `` want `` itself can be i i i i i grad f: u can be just another frame that 's part of your professor c: well , and it i basically it 's an action . in in our s in our in our grad f: yeah . situation . { comment } right , right . professor c: in in our in our s terminology , `` want `` can be an action and `` what you want `` is a world . grad f: mm - hmm . grad b: hmm . professor c: so that 's i mean , it 's certainly one way to do it . grad f: mmm . professor c: yeah , there there are other things . grad e: mm - hmm . professor c: causal stuff we absolutely need . mental space we need . grad f: mm - hmm . professor c: the context we need . um , so anyway , keith so is this comfortable to you that , uh , once we have this defined , it is your tool kit for building the semantic part of constructions . grad e: mm - hmm . professor c: and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . grad e: mm - hmm . professor c: and that 's the wh and and i mean , that according to the party line , that 's the whole story . grad e: yeah . mm - hmm . yeah . um . y right . that makes sense . so i mean , there 's this stuff in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and i guess that some of the discourse segment stuff is that where you would sa grad f: mm - hmm . grad e: i mean , that 's ok , that 's where the information structure is which sort of is a kind of profiling on different parts of , um , of this . grad f: right . exactly . grad e: i mean , what 's interesting is that the information structure stuff hmm . there 's almost i mean , we keep coming back to how focus is like this this , uh , trajector - landmark thing . grad f: yeah . grad e: so if i say , um , you know , `` in france it 's like this `` . you know , great , we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like `` in france it 's like this `` . and therefore you 're supposed to say , `` boy , life sure `` grad f: right . grad e: you know , `` in france kids are allowed to drink at age three `` . and w you 're that 's not just a fact about france . you also conclude something about how boring it is here in the u s . right ? grad f: right , right . professor c: right . grad e: and so grad f: s so i would prefer not to worry about that for right now grad e: ok . grad f: and to think that there are , um , grad e: that comes in and , uh grad f: discourse level constructions in a sense , topic topic - focus constructions that would say , `` oh , when you focus something `` then grad e: mm - hmm . yeah . grad f: just done the same way just actually in the same way as the lower level . if you stressed , you know , `` john went to the `` , you know , `` the bar `` whatever , you 're focusing that grad e: mm - hmm . grad f: and a in a possible inference is `` in contrast to other things `` . grad e: yeah . grad f: so similarly for a whole sentence , you know , `` in france such - and - such happens `` . grad e: yeah . yeah , yeah . grad f: so the whole thing is sort of like again implicitly as opposed to other things that are possible . grad e: yeah . grad a: uh , just just , uh , look read uh even sem semi formal mats rooth . grad f: i mean yeah . grad a: if you have n't read it . it 's nice . grad f: uh - huh . grad a: and just pick any paper on alternative semantics . grad f: uh - huh . grad e: ok . grad a: so that 's his that 's the best way of talking about focus , is i think his way . grad e: ok , what was the name ? grad a: mats . mats . rooth . grad e: ok . grad a: i think two o 's , yes , th . grad e: ok . grad a: i never know how to pronounce his name because he 's sort of , professor c: s swede ? grad a: uh , he is dutch professor c: dutch ? grad a: and , um but very confused background i think . professor c: oh , dutch . grad e: yeah . professor c: uh - huh . grad a: so and , um , grad e: mats gould . grad a: and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . grad e: hmm . grad a: but , um i do n't know where he is right now but alternative semantics is if you type that into an , uh , uh , browser or search engine you 'll get tons of stuff . grad e: ok . ok . ok , thanks . grad a: and what i 'm kind of confused about is is what the speaker and the hearer is is sort of doing there . grad f: so for a particular segment it 's really just a reference to some other entity again in the situation , right ? so for a particular segment the speaker might be you or might be me . grad a: yeah . grad f: um , hearer is a little bit harder . it could be like multiple people . i guess that that that that 's not very clear from here grad a: yeah , but you do n't we ultimately want to handle that analogously to the way we handle time and place , grad f: i mean , that 's not allowed here . grad a: because `` you `` , `` me `` , `` he `` , `` they `` , you know , `` these guys `` , all these expressions , nuh , are in in much the same way contextually dependent as `` here , `` and `` now , `` and `` there `` grad f: mm - hmm . professor c: now , this is this is assuming you 've already solved that . grad f: ye - yeah . professor c: so it 's it 's fred and mary , grad f: so th professor c: so the speaker would be fred and the grad a: ah ! grad f: right , so the constructions might of course will refer , using pronouns or whatever . grad a: mm - hmm . grad f: in which case they have to check to see , uh , who the , uh , speaker in here wa in order to resolve those . but when you actually say that `` he walked into `` , whatever , um , the `` he `` will refer to a particular you you will already have figured who `` he `` or `` you `` , mmm , or `` i `` , maybe is a bett better example , who `` i `` refers to . um , and then you 'd just be able to refer to harry , you know , in wherever that person whatever role that person was playing in the event . grad a: mmm . that 's up at the reference part . grad f: yeah , yeah . grad a: and down there in the speaker - hearer part ? grad f: s so , that 's i think that 's just n for instance , speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is i mean , you know who the speaker is . in fact , that 's kind of constraining how in some ways you know this before you get to the you fill in all the rest of it . i think . professor c: mmm . grad f: i mean , how else would you um grad a: you know , uh , uh , it 's the speaker may in english is allowed to say `` i . `` professor c: yeah . well , here grad a: uh , among the twenty - five percent most used words . grad f: yeah . right . grad a: but would n't the `` i `` then set up the the s s referent that happens to be the speaker this time grad f: mm - hmm . grad a: and not `` they , `` whoever they are . grad f: right , right . grad a: or `` you `` grad f: so grad a: much like the `` you `` could n grad f: s so ok , so i would say ref under referent should be something that corresponds to `` i `` . and maybe each referent should probably have a list of way whatever , the way it was referred to . so that 's `` i `` but , uh , uh , should we say it it refers to , what ? uh , if it were `` harry `` it would refer to like some ontology thing . if it were if it 's `` i `` it would refer to the current speaker , ok , which is given to be like , you know , whoever it is . grad a: well , not not always . i mean , so there 's `` and then he said , i w `` uh - huh . professor c: uh grad f: `` i `` within the current world . grad a: yeah . professor c: yeah . that 's right . so so again , this uh , this this is gon na to get us into the mental space stuff grad f: yeah , yeah , yeah , yeah . professor c: and t because you know , `` fred said that mary said `` , and whatever . grad e: mmm . grad f: mm - hmm . professor c: and and so we 're , uh gon na have to , um , chain those as well . grad a: mm - hmm . twhhh - whhh . but grad f: mm - hmm . so this entire thing is inside a world , professor c: right . right . grad f: not just like the top part . professor c: i i think , uh grad f: that 's grad a: mm - hmm . professor c: except s it 's it 's trickier than that because um , the reference for example so he where it gets really tricky is there 's some things , grad f: yeah . professor c: and this is where blends and all terribl so , some things which really are meant to be identified and some things which are n't . grad f: yeah . right . professor c: and again , all we need for the moment is some way to say that . grad f: right . so i thought of having like for each referent , having the list of of the things t with which it is identified . you know , which which , uh you know , you you you professor c: you could do that . grad f: for instance , um so , i guess , it sort of depends on if it is a referring exp if it 's identifiable already or it 's a new thing . grad e: mm - hmm . grad f: if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , um , usually w something in a situation , right ? or something in ontology . professor c: uh - huh . grad f: so , there 's a you know , whatever , it c it could point at one of these . professor c: i just had a i just had an an idea that would be very nice if it works . grad f: for what ? professor c: uh , uh , uh , i have n't told you what it is yet . grad f: if it works . professor c: this was my build - up . grad f: mm - hmm . mmm . professor c: an i an idea that would be nice i grad f: yeah . ok , we 're crossing our fingers . professor c: right . grad b: so we 're building a mental space , good . professor c: if it worked . yeah . grad f: ok . professor c: right , it was a space builder . um , we might be able to handle context in the same way that we handle mental spaces because , uh , you have somewhat the same things going on of , uh , things being accessible or not . grad f: mm - hmm . professor c: and so , i grad f: yep . professor c: it c it it , uh i think if we did it right we might be able to get at least a lot of the same structure . grad f: use the same { comment } yep . professor c: so that pulling something out of a discourse context is i think similar to other kinds of , uh , mental space phenomena . grad b: i see . grad f: mm - hmm . and and professor c: uh , i 've i 've i 've never seen anybody write that up but maybe they did . i do n't know . that may be all over the literature . grad f: yeah . grad e: there 's things like ther you know , there 's all kinds of stuff like , um , in i think i mentioned last time in czech if you have a a verb of saying then grad f: so so by default grad e: um , you know , you say something like or or i was thinking you can say something like , `` oh , i thought , uh , you are a republican `` or something like that . where as in english you would say , `` i thought you were `` . professor c: right . grad e: um , you know , sort of the past tense being copied onto the lower verb does n't happen there , so you have to say something about , you know , tense is determined relative to current blah - blah - blah . grad f: mm - hmm . grad e: same things happens with pronouns . grad f: mm - hmm . grad e: there 's languages where , um , if you have a verb of saying then , ehhh , where ok , so a situation like `` bob said he was going to the movies `` , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have `` i `` there . grad f: mm - hmm . professor c: mm - hmm . grad e: um , and it 's sort of in an extended function professor c: so we would have it be in quotes in english . grad e: yeah . grad b: right . grad e: but it 's not perceived as a quotative construction . grad f: right . professor c: yeah . grad e: i mean , it 's been analyzed by the formalists as being a logophoric pronoun , um which means a pronoun which refers back to the person who is speaking or that sort of thing , right ? professor c: ok . grad f: oh , right . yeah , that makes sense . grad e: um , but uh , that happens to sound like the word for `` i `` but is actually semantically unrelated to it . grad f: oh , no ! professor c: oh , good , i love the formali grad e: um , grad f: really ? grad e: yeah . yeah . grad f: you 're kidding . grad e: there 's a whole book which basically operates on this assumption . uh , mary dalrymple , uh , this book , a ninety - three book on , uh on pronoun stuff . grad f: no , that 's horrible . ok . that 's horrible . { comment } ok . grad e: well , yeah . and then the same thing for asl where , you know , you 're signing and someone says something . and then , you know , so `` he say `` , and then you sort of do a role shift . and then you sign `` i , this , that , and the other `` . grad f: uh - huh . grad e: and you know , `` i did this `` . that 's also been analyzed as logophoric and having nothing to do with `` i `` . and the role shift thing is completely left out and so on . so , i mean , the point is that pronoun references , uh , you know , sort of ties in with all this mental space stuff and so on , and so forth . grad f: uh - huh . grad e: and so , yeah , i mean grad f: yeah . professor c: so that that d that does sound like it 's co consistent with what we 're saying , yeah . grad e: right . yeah . grad f: ok , so it 's kind of like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the h you know , depending on the construction or the whatever , um , you you you 're scope is m might extend out to the the base one . grad e: mm - hmm . professor c: mm - hmm . grad e: yeah . grad f: it would be nice to actually use the same , um , mechanism since there are so many cases where you actually need it 'll be one or the other . grad e: yeah . grad f: it 's like , oh , actually , it 's the same same operation . professor c: oh , ok , so this this is worth some thought . grad f: so . grad e: it 's like it 's like what 's happening that , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ? grad f: yeah , yeah . grad e: so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . grad f: mm - hmm . grad e: and so , grad f: mm - hmm . grad e: um , things like pronoun reference and tense which we 're thinking of as being these discourse - y things actually are relative to a bayes space which can change . grad f: mm - hmm , grad e: and we need all the same machinery . grad f: right . grad a: mm - hmm . grad f: robert . professor c: well , but , uh , this is very good actually grad e: schade . professor c: cuz it it it to the extent that it works , it y grad f: ties it all into it . professor c: it it ties together several of of these things . grad f: yeah . yep . grad a: mm - hmm . mm - hmm . and i 'm sure gon na read the transcript of this one . so . but the , uh , but it 's too bad that we do n't have a camera . you know , all the pointing is gon na be lost . grad e: yeah . grad f: oh , yeah . grad b: well every time nancy giggles it means it means that it 's your job . grad f: yeah , that 's why i said `` point to robert `` , when i did it . grad a: uh . yeah . mmm , is n't i mean , i 'm i was sort of dubious why why he even introduces this sort of reality , you know , as your basic mental space and then builds up grad e: mm - hmm . grad a: d does n't start with some because it 's so obvi it should be so obvious , at least it is to me , { comment } that whenever i say something i could preface that with `` i think . `` nuh ? grad e: yeah . grad a: so there should be no categorical difference between your base and all the others that ensue . grad e: yeah . professor c: no , but there 's there 's a gricean thing going on there , that when you say `` i think `` you 're actually hedging . grad e: yeah , i mean grad f: mmm . it 's like i do n't totally think professor c: right . grad e: yeah . y grad f: i mostly think , uh grad a: yeah , it 's absolutely . grad e: yeah , it 's an it 's an evidential . it 's sort of semi - grammaticalized . people have talked about it this way . and you know , you can do sort of special things . you can , th put just the phrase `` i think `` as a parenthetical in the middle of a sentence and so on , and so forth . grad a: yeah . grad e: so grad f: actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any kind of interesting embedded ways just to mark , you know , uncertainty or something like that . grad e: yeah . grad f: so . grad a: yeah , but about linguistic hedges , i mean , those those tend to be , um , funky anyways because they blur professor c: so we do n't have that in here either do we ? grad e: yeah . grad f: hedges ? professor c: yeah , yeah . grad f: hhh , { comment } i there used to be a slot for speaker , um , it was something like factivity . i could n't really remember what it meant grad e: yeah . grad f: so i took it out . grad e: um . grad f: but it 's something grad e: well we were just talking about this sort of evidentiality and stuff like that , right ? grad f: we we were talking about sarcasm too , right ? oh , oh . grad e: i mean , grad f: oh , yeah , yeah , right . grad e: that 's what i think is , um , sort of telling you what percent reality you should give this professor c: so we probably should . grad f: yeah . grad a: mm - hmm . grad e: or the , you know professor c: confidence or something like that . grad e: yeah , and the fact that i 'm , you know the fact maybe if i think it versus he thinks that might , you know , depending on how much you trust the two of us or whatever , grad f: yeah . grad a: uh great word in the english language is called `` about `` . grad e: you know grad a: if you study how people use that it 's also grad f: what 's the word ? grad a: `` about . `` it 's about professor c: about . grad a: clever . professor c: oh , that in that use of `` about `` , yeah . grad f: oh , oh , oh , as a hedge . grad e: yeah . professor c: and i think and i think y if you want us to spend a pleasant six or seven hours you could get george started on that . grad e: he wrote a paper about thirty - five years ago on that one . grad b: i r i read that paper , professor c: yeah . grad b: the hedges paper ? i read some of that paper actually . grad e: yeah . professor c: yeah . grad e: would you believe that that paper lead directly to the development of anti - lock brakes ? grad f: what ? professor c: no . grad e: ask me about it later i 'll tell you how . when we 're not on tape . grad f: i 'd love to know . grad b: oh , man . grad f: so , and and i think , uh , someone had raised like sarcasm as a complication at some point . professor c: there 's all that stuff . yeah , let 's i i do n't i think grad f: and we just wo n't deal with sarcastic people . professor c: yeah , i mean grad e: i do n't really know what like we we do n't have to care too much about the speaker attitude , right ? like there 's not so many different hhh , { comment } i do n't know , m grad f: certainly not as some well , they 're intonational markers i think for the most part . grad e: yeah . grad f: i do n't know too much about the like grammatical grad e: i just mean there 's lots of different attitudes that that the speaker could have and that we can clearly identify , and so on , and so forth . grad f: yeah . grad e: but like what are the distinctions among those that we actually care about for our current purposes ? professor c: right . right , so , uh , this this raises the question of what are our current purposes . grad f: mm - hmm . professor c: right ? grad e: oh , shoot . grad f: oh , yeah , do we have any ? grad e: here it is three - fifteen already . grad a: mmm . yeah . professor c: uh , so , um , i i do n't know the answer but but , um , it does seem that , you know , this is this is coming along . i think it 's it 's converging . it 's as far as i can tell there 's this one major thing we have to do which is the mental the whole s mental space thing . and then there 's some other minor things . grad f: mm - hmm . professor c: um , and we 're going to have to s sort of bound the complexity . i mean , if we get everything that anybody ever thought about you know , w we 'll go nuts . grad e: yeah . professor c: so we had started with the idea that the actual , uh , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and were n't trying to d you know , there 's all sorts of god knows , irony , and stuff like which you is n't probably of much use in dealing with a tourist guide . grad e: yeah . professor c: yeah ? grad e: yeah . professor c: uh . grad f: m mockery . professor c: right . whatever . so y uh , no end of things th that that , you know , we do n't deal with . grad a: but it professor c: and grad a: i is n't that part easy though professor c: go ahead . grad a: because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to sort of negate whatever the content of that is in terms of irony grad e: yeah . professor c: n no . grad f: mmm . grad a: or professor c: no . grad e: right . grad f: maybe . professor c: no . grad f: yeah , in model theory cuz the semantics is always like `` speaker believes not - p `` , you know ? professor c: right . grad f: like `` the speaker says p and believes not - p `` . grad e: we have a theoretical model of sarcasm now . grad f: but professor c: right . grad e: yeah , right , i mean . professor c: no , no . grad f: right , right , but , professor c: anyway , so so , um , i guess uh , let me make a proposal on how to proceed on that , which is that , um , it was keith 's , uh , sort of job over the summer to come up with this set of constructions . uh , and my suggestion to keith is that you , over the next couple weeks , n grad e: mmm . professor c: do n't try to do them in detail or formally but just try to describe which ones you think we ought to have . grad e: ok . professor c: uh , and then when robert gets back we 'll look at the set of them . grad e: ok . professor c: just just sort of , you know , define your space . grad e: yeah , ok . professor c: and , um , so th these are this is a set of things that i think we ought to deal with . grad e: yeah . professor c: and then we 'll we 'll we 'll go back over it and w people will will give feedback on it . grad e: ok . professor c: and then then we 'll have a at least initial spec of of what we 're actually trying to do . grad e: yeah . professor c: and that 'll also be useful for anybody who 's trying to write a parser . grad e: mm - hmm . professor c: knowing uh grad e: in case there 's any around . grad f: if we knew anybody like that . professor c: right , `` who might want `` et cetera . so , uh grad e: ok . professor c: so a and we get this this , uh , portals fixed and then we have an idea of the sort of initial range . and then of course nancy you 're gon na have to , uh , do your set of but you have to do that anyway . grad f: for the same , yeah , data . yeah , mm - hmm . professor c: so so we 're gon na get the w we 're basically dealing with two domains , the tourist domain and the and the child language learning . grad b: mmm . professor c: and we 'll see what we need for those two . and then my proposal would be to , um , not totally cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . grad e: mm - hmm . professor c: and then as a kind of separate thread , think about the more general things and and all that . grad e: mm - hmm . mm - hmm . grad a: well , i also think the detailed discussion will hit you know , bring us to problems that are of a general nature and maybe even professor c: uh , without doubt . yeah . grad f: yeah . grad a: even suggest some solutions . professor c: but what i want to do is is is to to constrain the things that we really feel responsible for . grad a: yeah . mmm . professor c: so that that we say these are the things we 're really gon na try do by the end of the summer grad e: mm - hmm . professor c: and other things we 'll put on a list of of research problems or something , because you can easily get to the point where nothing gets done because every time you start to do something you say , `` oh , yeah , but what about this case ? `` grad e: mm - hmm . professor c: this is this is called being a linguist . grad a: mmm . grad e: yeah . professor c: and , uh , grad e: basically . grad f: or me . professor c: huh ? grad f: or me . anyways grad b: there 's that quote in jurafsky and martin where where it goes where some guy goes , `` every time i fire a linguist the performance of the recognizer goes up . `` professor c: right . grad f: yeah . grad e: exactly . professor c: right . but anyway . so , is is that does that make sense as a , uh a general way to proceed ? grad f: sure , yeah . grad e: yeah , yeah , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it . professor c: exactly right . grad a: mmm . grad e: got it . grad a: mmm . grad e: ok . grad a: we have a little bit of news , uh , just minor stuff . the one big grad b: ooo , can i ask a grad e: you ran out of power . grad a: huh ? grad b: can i ask a quick question about this side ? grad a: yeah . grad f: yes . grad b: is this , uh was it intentional to leave off things like `` inherits `` and grad f: oops . um , grad e: no . grad f: not really just on the constructions , right ? grad b: yeah , like constructions can inherit from other things , grad f: um , grad b: am i right ? grad f: yeah . grad b: yeah . grad f: i did n't want to think too much about that for for now . grad b: ok . professor c: yeah . grad f: so , uh , maybe it was subconsciously intentional . professor c: yeah , uh yeah . grad e: um , yeah , there should be i i wanted to s find out someday if there was gon na be some way of dealing with , uh , if this is the right term , multiple inheritance , professor c: mm - hmm . grad e: where one construction is inheriting from , uh from both parents , grad f: uh - huh . yep . grad e: uh , or different ones , or three or four different ones . professor c: yeah . so let me grad e: cuz the problem is that then you have to grad f: yeah . grad e: which of you know , which are how they 're getting bound together . grad f: refer to them . professor c: yeah , right , right , right . yeah , yeah , yeah . grad f: yeah , and and there are certainly cases like that . even with just semantic schemas we have some examples . professor c: right . grad f: so , and we 've been talking a little bit about that anyway . professor c: yeah . so what i would like to do is separate that problem out . grad f: inherits . professor c: so um , grad e: ok . professor c: my argument is there 's nothing you can do with that that you ca n't do by just having more constructions . grad e: yeah , yes . professor c: it 's uglier and it d does n't have the deep linguistic insights and stuff . grad e: that 's right . professor c: uh , grad e: but whatever . professor c: right . grad e: yeah , no , no , no no . grad f: uh , those are over rated . grad e: no , by all means , professor c: and so i what i 'd like to do is is in the short run focus on getting it right . grad e: right . uh , sure . professor c: and when we think we have it right then saying , `` aha ! , grad e: yeah . professor c: can we make it more elegant ? `` grad e: yeah , that 's professor c: can can we , uh what are the generalizations , and stuff ? grad e: yeah . connect the dots . yeah . professor c: but rather than try to guess a inheritance structure and all that sort of stuff before we know what we 're doing . grad e: yep . yeah . professor c: so i would say in the short run we 're not gon na b grad e: yeah . professor c: first of all , we 're not doing them yet at all . and and it could be that half way through we say , `` aha ! , we we now see how we want to clean it up . `` grad e: mm - hmm . professor c: uh , and inheritance is only one i mean , that 's one way to organize it but there are others . and it may or may not be the best way . grad e: yeah . grad a: mmm . professor c: i 'm sorry , you had news . grad a: oh , just small stuff . um , thanks to eva on our web site we can now , if you want to run javabayes , uh , you could see get download these classes . and then it will enable you she modified the gui so it has now a m a m a button menu item for saving it into the embedded javabayes format . grad d: mm - hmm . grad b: mmm . grad a: so that 's wonderful . professor c: great . grad a: and , um and she , a you tested it out . do you want to say something about that , that it works , right ? with the grad d: i was just checking like , when we wan na , um , get the posterior probability of , like , variables . you know how you asked whether we can , like , just observe all the variables like in the same list ? you ca n't . grad a: uh - huh . grad d: you have to make separate queries every time . grad a: ok , that 's that 's a bit unfortunate grad d: so yeah . grad a: but for the time being it 's it 's it 's fine to do it grad d: you just have to have a long list of , you know , all the variables . grad a: yeah . but uh grad d: basically . grad f: uh , all the things you want to query , you just have to like ask for separately . grad d: yeah , yeah . grad a: well that 's probably maybe in the long term that 's good news because it forces us to think a little bit more carefully how how we want to get an out output . um , but that 's a different discussion for a different time . and , um , i do n't know . we 're really running late , so i had , uh , an idea yesterday but , uh , i do n't know whether we should even start discussing . professor c: w what yeah , sure , tell us what it is . grad a: um , the construal bit that , um , has been pointed to but has n't been , um , made precise by any means , um , may w may work as follows . i thought that we would , uh that the following thing would be in incredibly nice and i have no clue whether it will work at all or nothing . so that 's just a tangent , a couple of mental disclaimers here . um , imagine you you write a bayes - net , um grad f: bayes ? grad a: bayes - net , grad f: ok . grad a: um , completely from scratch every time you do construal . so you have nothing . just a white piece of paper . professor c: mmm , right . grad a: you consult consult your ontology which will tell you a bunch of stuff , and parts , and properties , uh - uh - uh grad f: grout out the things that that you need . professor c: right . grad a: then y you 'd simply write , uh , these into onto your your white piece of paper . and you will get a lot of notes and stuff out of there . you wo n't get you wo n't really get any c p t 's , therefore we need everything that that configures to what the situation is , ie , the context dependent stuff . so you get whatever comes from discourse but also filtered . uh , so only the ontology relevant stuff from the discourse plus the situation and the user model . grad f: mm - hmm . grad a: and that fills in your cpt 's with which you can then query , um , the the net that you just wrote and find out how thing x is construed as an utterance u . and the embedded javabayes works exactly like that , that once you we have , you know , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the the nice thing about this idea is that you do n't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the the initial notes . but it 's in that respect it 's completely scalable . because it does n't have any prior , um , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work at all , that 'd be kind of funky . professor c: um , it sounds to me like you want p r grad a: p r ms - uh , prm i mean , since you can unfold a prm into a straightforward bayes - net professor c: beca - because it b because no , no , you ca n't . see the the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it . grad a: then you can . mm - hmm , yeah . no , i was m using it generic . so , uh , probabilistic , whatever , relational models . whatever you write it . in professor c: well , no , but it matters a lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case . grad a: and then then instantiate them . that 's ma maybe the the way the only way it works . professor c: yeah , and that 's grad a:  professor c: yeah , that 's the only way it could work . i we have a our local expert on p r uh , but my guess is that they 're not currently good enough to do that . but we 'll we 'll have to see . grad a: but , uh , professor c: uh yes . this is that 's that would be a good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , uh grad a: except there 's no no theorem prover involved . grad f: best explanation . professor c: no , there is n't a theorem prover but there but but the , um , the cove the the p r ms are like rules of inference and you 're you 're coupling a bunch of them together . grad a: mm - hmm , yeah . professor c: and then ins instead of proving you 're trying to , you know , compute the most likely . uh tricky . but you yeah , it 's a good it 's a it 's a good thing to put in your thesis proposal . grad a: what 's it ? professor c: so are you gon na write something for us before you go ? grad a: yes . um . professor c: oh , you have something . grad a: in the process thereof , or whatever . professor c: ok . so , what 's what when are we gon na meet again ? grad f: when are you leaving ? grad a: fri - uh , grad f: thursday , friday ? grad a: thursday 's my last day here . grad d: fri professor c: yeah . grad f: ok . grad a: so i would suggest as soon as possible . do you mean by we , the whole ben gang ? professor c: n no , i did n't mean y just the two of us . we obviously we can we can do this . but the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal and get , uh , another session on feedback on that ? or grad a: we can do it th - thursday again . yeah . grad e: fine with me . should we do the one pm time for thursday since we were on that before or ? grad a: sure . grad e: ok . professor c: alright . grad d: hmm . grad a: thursday at one ? i can also maybe then sort of run through the , uh the talk i have to give at eml which highlights all of our work . professor c: ok . grad a: and we can make some last minute changes on that . professor c: ok . grad b: you can just give him the abstract that we wrote for the paper . professor c: that - that 'll tell him exactly what 's going on . yeah , that alright . grad f: can we do can we do one - thirty ? grad a: no . grad f: oh , you already told me no . grad a: but we can do four . grad f: one , ok , it 's fine . i can do one . it 's fine . it 's fine . grad a: one or four . i do n't care . grad e: to me this is equal . i do n't care . grad a: if it 's equal for all ? what should we do ? grad f: yeah , it 's fine . grad a: four ? grad f: fine . yeah no , no , no , uh , i do n't care . it 's fine . grad a: it 's equal to all of us , so you can decide one or four . grad b: the pressure 's on you nancy . grad a: liz actually said she likes four because it forces the meeting recorder people to cut , you know the discussions short . grad f: ok . ok , four . grad e: well , if you insist , then . grad f: ok ? ok . i am .","output":"the revised semantic specification and construction formalism are more stable than the previous versions . in the latter , we find both construction types and meaning types along with formal considerations like verb subcategorization , or the ones a `` directed motion '' construction would dictate ."},{"instruction":"please describe the semantic specification","input":"grad b: what things to talk about . grad f: i 'm what ? really ? oh , that 's horrible ! disincentive ! grad a: ok , we 're recording . grad f: hello ? grad b: check check check check . grad d: uh , yeah . grad f: hello ? which am i ? professor c: oh right . grad b: alright . good . grad f: channel fi ok . ok . are you doing something ? ok , then i guess i 'm doing something . so , um , so basically the result of m much thinking since the last time we met , um , but not as much writing , um , is a sheet that i have a lot of , like , thoughts and justification of comments on but i 'll just pass out as is right now . so , um , here . if you could pass this around ? and there 's two things . and so one on one side is on one side is a sort of the revised sort of updated semantic specification . grad d: um the wait . grad f: and the other side is , um , sort of a revised construction formalism . grad e: this is just one sheet , right ? grad d: ah ! just one sheet . grad f: it 's just one sheet . grad d: ok . grad f: it 's just a nothing else . grad d: front , back . grad f: um , enough to go around ? ok . and in some ways it 's it 's it 's very similar to there are very few changes in some ways from what we 've , um , uh , b done before but i do n't think everyone here has seen all of this . so , uh , i 'm not sure where to begin . um , as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . grad e: mm - hmm . grad f: and , um , after a little bit more discussion and especially like keith and i i have more linguistic things to settle in the next few days , um , it 'll probably change again some more . grad e: yeah . grad f: um , maybe i will let 's start b let 's start on number two actually on the notation , um , because that 's , i 'm thinking , possibly a little more familiar to , um to people . ok , so the top block is just sort of a sort of abstract nota it 's sort of like , um , listings of the kinds of things that we can have . and certain things that have , um , changed , have changed back to this . there there 's been a little bit of , um , going back and forth . but basically obviously all constructions have some kind of name . i forgot to include that you could have a type included in this line . professor c: what i was gon na right . grad f: so something like , um well , there 's an example the textual example at the end has clausal construction . so , um , just to show it does n't have to be beautiful it could be , you know , simple old text as well . um , there are a couple of uh , these three have various ways of doing certain things . so i 'll just try to go through them . so they could all have a type at the beginning . um , and then they say the key word construction professor c: oh , i see . grad f: and they have some name . professor c: so so the current syntax is if it s if there 's a type it 's before construct grad f: yeah , right . professor c: ok , that 's fine . grad f: ok , and then it has a block that is constituents . and as usual i guess all the constructions her all the examples here have only , um , tsk { comment } one type of constituent , that is a constructional constituent . i think that 's actually gon na turn out to m be certainly the most common kind . but in general instead of the word `` construct `` , th here you might have `` meaning `` or `` form `` as well . ok ? so if there 's some element that does n't that is n't yet constructional in the sense that it maps form and meaning . ok , um , the main change with the constructs which each of which has , um , the key word `` construct `` and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that you know what kind of construction it is . so for example whatever i have here is gon na be a form of the word `` throw `` , or it 's gon na be a form of the word , you know , i do n't know , `` happy `` , or something like that . or , you know , some it 'll be a specific word or maybe you 'll have the type . you 'll say `` i need a p uh spatial relation phrase here `` or `` i need a directional specifier here `` . so - uh you could have a j a actual type here . um , or you could just say in the second case that you only know the meaning type . so a very common example of this is that , you know , in directed motion , the first person to do something should be an agent of some kind , often a human . right ? so if i you know , the um , uh , run down the street then i i i run down the street , it 's typed , uh , `` i `` , meaning category is what 's there . the the new kind is this one that is sort of a pair and , um , sort of skipping fonts and whatever . the idea is that sometimes there are , um , general constructions that you know , that you 're going to need . it 's it 's the equivalent of a noun phrase or a prepositional phrase , or something like that there . grad e: mm - hmm . grad f: and usually it has formal um , considerations that will go along with it . professor c: mm - hmm . grad f: and then uh , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , you know , um , `` the big th `` , you you know , `` the big the tall dark man `` , you know , `` walked into the room `` . grad e: mm - hmm . grad f: but because of the nature of this particular construction you know not just that it 's nominal of some kind but in particular , that it 's some kind of animate nominal , and which will apply just as well to like , you know , a per you know , a simple proper noun or to some complicated expression . um , so i do n't know if the syntax will hold but something that gives you a way to do both constructional and meaning types . so . ok , then i do n't think the , { comment } um at least yeah . { comment } none of these examples have anything different for formal constraints ? but you can refer to any of the , um , sort of available elements and scope , right ? which here are the constructs , { comment } to say something about the relation . and i think i if you not if you compare like the top block and the textual block , um , we dropped like the little f subscript . the f subscripts refer to the `` form `` piece of the construct . professor c: good . grad f: and i think that , um , in general it 'll be unambiguous . like if you were giving a formal constraint then you 're referring to the formal pole of that . so so by saying if i just said `` name one `` then that means name one formal and we 're talking about formal struc { comment } which which makes sense . uh , there are certain times when we 'll have an exception to that , in which case you could just indicate `` here i mean the meaningful for some reason `` . right ? or actually it 's more often that , only to handle this one special case of , you know , `` george and jerry walk into the room in that order `` . grad e: mm - hmm . grad f: so we have a few funny things where something in the meaning might refer to something in the form . but but s we 're not gon na really worry about that for right now and there are way we can be more specific if we have to later on . ok , and so in terms of the the relations , you know , as usual they 're before and ends . i should have put an example in of something that is n't an interval relation but in form you might also have a value binding . you know , you could say that , um , you know , `` name - one dot `` , t you know , `` number equals `` , you know , a plural or something like that . grad e: mm - hmm . grad f: there are certain things that are attribute - value , similar to the bindings below but i mean they 're just us usually they 're going to be value value fillers , right ? ok , and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and i i you you and i can like fight about that if you like ? but about changing it to `` semantic n effects `` , which i thought was a little bit too order - biased grad b: well th grad f: and `` semantic bindings `` , which i thought might be too restrictive in case we do n't have only bindings . and so it was an issue whether constraints um , there were some linguists who reacted against `` constraints `` , saying , `` oh , if it 's not used for matching , then it should n't be called a constraint `` . but i think we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are i think we thought of some situations where it would be useful to use whatever the c bindings are , for actual , you know , sort of like modified constraining purposes . professor c: well , you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification , i grad e: yeah . grad f: yeah , yeah . it 's used should n't matter , right ? mm - hmm . professor c: s for sure . i mean , i do n't know what , uh , term we want to use grad f: mm - hmm . professor c: but we do n't want to grad f: yeah , uh , there was one time when when hans explained why `` constraints `` was a misleading word for him . professor c: yep . grad f: and i think the reason that he gave was similar to the reason why johno thought it was a misleading term , which was just an interesting coincidence . um , but , uh and so i was like , `` ok , well both of you do n't like it ? professor c: it 's g it 's gone . grad f: fine , we can change it `` . but i i i 'm starting to like it again . grad b: but grad f: so that that 's why { comment } that 's why i 'll stick with it . grad a: well , you know what ? grad f: so grad a: if you have an `` if - then `` phrase , do you know what the `` then `` phrase is called ? professor c: th grad f: what ? con - uh , a consequent ? grad a: yeah . grad f: yeah , but it 's not an `` if - then `` . grad a: no , but professor c: i know . anyway , so the other the other strategy you guys could consider is when you do n't know what word to put , you could put no word , grad f: mm - hmm . professor c: just meaning . ok ? and the then let grad e: yeah . grad f: yeah , that 's true . grad b: so that 's why you put semantic constraints up top and meaning bindings down down here ? grad f: oh , oops ! no . that was just a mistake of cut and paste from when i was going with it . grad b: ok . professor c: ok . grad f: so , i 'm sorry . i did n't mean that one 's an in unintentional . grad b: so this should be semantic and grad f: sometimes i 'm intentionally inconsistent grad b:  grad f: cuz i 'm not sure yet . here , i actually it was just a mistake . grad b: th - so this definitely should be `` semantic constraints `` down at the bottom ? grad e: sure . grad f: yeah . grad b: ok . grad f: well , unless i go with `` meaning `` but i i mean , i kind of like `` meaning `` better than `` semantic `` grad b: or professor c: oh , whatever . grad f: but i think there 's vestiges of other people 's biases . professor c: or wh that - b grad f: like professor c: right . minor min problem grad f: minor point . professor c: ok . grad e: extremely . grad f: ok , um , so i think the middle block does n't really give you any more information , ex than the top block . and the bottom block similarly only just illus you know , all it does is illustrate that you can drop the subscripts and and that you can drop the , um uh , that you can give dual types . oh , one thing i should mention is about `` designates `` . i think i 'm actually inconsistent across these as well . so , um , strike out the m subscript on the middle block . professor c: mm - hmm . grad f: so basically now , um , this is actually this little change actually goes along with a big linguistic change , which is that `` designates `` is n't only something for the semantics to worry about now . professor c: good . grad f: so we want s `` designates `` to actually know one of the constituents which acts like a head in some respects but is sort of , um , really important for say composition later on . so for instance , if some other construction says , you know , `` are you of type is this part of type whatever `` , um , the `` designates `` tells you which sort of part is the meaning part . ok , so if you have like `` the big red ball `` , you know , you wan na know if there 's an object or a noun . well , ball is going to be the designated sort of element of that kind of phrase . grad e: mmm . grad f: um , there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , um to talk about there also being a designated object and we think that that 'll be the same one , right ? so the ball is the head of the phrase , `` the r the `` , um , `` big red ball `` , and the entity denoted by the word `` ball `` is sort of the semantic head in some ways of of this sort of , um , in interesting larger element . professor c: a a and the yeah . and there 's uh there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if i understand you right . grad e: yeah . grad f: mm - hmm . grad e: yeah . grad f: right , right . grad e: that 's the idea . professor c: yeah yeah . grad e: yeah . grad f: and , uh , you might be able to say things like if the head has to go last in a head - final language , you can refer to the head as a p the , you know the formal head as opposed to the rest of the form having to be at the end of that decision . professor c: right . grad f: so that 's a useful thing so that you can get some internal structural constraints in . professor c: ok , so that all looks good . let me oh , w oh . i do n't know . were you finished ? grad f: um , there was a list of things that is n't included but you you can you can ask a question . that might @ @ it . professor c: ok . so , i if i understand this the aside from , uh , construed and all that sort of stuff , the the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for a type grad f: mm - hmm . professor c: or actually gone back to , grad f: right . professor c: if we go back far enough grad f: well , except for their construction meaning , so it 's not clear that , uh well , right now it 's a c uh contr construction type and meaning type . so i do n't know what a form type is . professor c: oh , i see . yeah , yeah , yeah . i 'm sorry , you 're right . grad f: yeah . professor c: a construction type . uh , that 's fine . but it , um grad f: right . a well , and a previous , um , you know , version of the notation certainly allowed you to single out the meaning bit by it . so you could say `` construct of type whatever designates something `` . professor c: yeah . grad f: but that was mostly for reference purposes , just to refer to the meaning pole . i do n't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time i think . professor c: mm - hmm . grad f: um , i i do n't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , you know that 's kind of weird . professor c: no , no , no , i do n't think so . i think that you 'll you 'll do fine . grad e: i professor c: in fact , these are , um , as long as as mark is n't around , these are form constraints . so a nominal expression is uh , the fact that it 's animate , is semantic . the fact that it 's n uh , a nominal expression i would say on most people 's notion of of f you know , higher form types , this i this is one . grad f: mm - hmm . grad e: yeah . grad f: right , right . professor c: and i think that 's just fine . grad e: yeah , yeah . grad f: which is fine , yeah . professor c: yeah . grad e: it 's that now , um , i 'm mentioned this , i i do n't know if i ever explained this but the point of , um , i mentioned in the last meeting , { comment } the point of having something called `` nominal expression `` is , um , because it seems like having the verb subcategorize for , you know , like say taking as its object just some expression which , um , designates an object or designates a thing , or whatever , um , that leads to some syntactic problems basically ? so you wan na , you know you sort of have this problem like `` ok , well , i 'll put the word `` , uh , let 's say , the word `` dog `` , you know . and that has to come right after the verb grad f: mm - hmm . grad e: cuz we know verb meets its object . and then we have a construction that says , oh , you can have `` the `` preceding a noun . and so you 'd have this sort of problem that the verb has to meet the designatum . professor c: right . grad e: and you could get , you know , `` the kicked dog `` or something like that , meaning `` kicked the dog `` . professor c: right . grad e: um , so you kind of have to let this phrase idea in there professor c: that i i have no problem with it at all . grad e: but it - it professor c: i think it 's fine . grad e: yeah . grad f: yeah . right , n s you may be you may not be like everyone else in in berkeley , grad e: yeah . yeah . grad f: but that 's ok . grad e: i mean , we we we sort of thought we were getting away with , uh with , a p grad f: uh , we do n't mind either , so grad e: i mean , this is not reverting to the x - bar theory of of phrase structure . professor c: right . grad e: but , uh , grad f: right . grad e: i just know that this is like , we did n't originally have in mind that , uh that verbs would subcategorize for a particular sort of form . grad f: mm - hmm . professor c: but they do . grad e: um , but they does . grad f: well , there 's an alternative to this grad e: at least in english . grad f: which is , um the question was did we want directed motion , professor c: yeah . grad f: which is an argument structure construction professor c: mm - hmm . grad e: yeah . grad f: did we want it to worry about , um , anything more than the fact that it , you know , has semantic you know , it 's sort of frame - based construction . so one option that , you know , keith had mentioned also was like , well if you have more abstract constructions such as subject , predicate , basically things like grammatical relations , grad e: mm - hmm . grad f: those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob you know , verb object would require that those things that f fill a subject and object are nom expressions . professor c: right . grad f: and that would be a little bit cleaner in some way . but you know , for now , i mean , professor c: yeah . but it y y it 's yeah , just moving it moving the c the cons the constraints around . grad f: uh , you know . m moving it to another place , right . grad e: yeah . professor c: ok , so that 's grad f: but there does basically , the point is there has to be that constraint somewhere , right ? professor c: right . grad f: so , yeah . professor c: and so that was the grad f: robert 's not happy now ? grad a: no ! grad f: oh , ok . professor c: ok , and sort of going with that is that the designatum also now is a pair . grad f: yes . professor c: instead of just the meaning . grad f: mm - hmm . professor c: and that aside from some terminology , that 's basically it . grad f: right . professor c: i just want to b i 'm i 'm asking . grad e: mm - hmm . grad f: yep . grad e: yeah . grad f: yeah , um , the un sort of the un - addressed questions in this , um , definitely would for instance be semantic constraints we talked about . professor c: yeah . grad f: here are just bindings but , right ? we might want to introduce mental spaces you know , there 's all these things that we do n't professor c: the whole the mental space thing is clearly not here . grad f: right ? so there 's going to be some extra you know , definitely other notation we 'll need for that which we skip for now . grad e: mm - hmm . professor c: by the way , i do want to get on that as soon as robert gets back . grad f: uh yeah . professor c: so , uh , the the mental space thing . grad f: ok . professor c: um , obviously , construal is a b is a b is a big component of that grad e: mm - hmm . professor c: so this probably not worth trying to do anything till he gets back . but sort of as soon as he gets back i think um , we ought to grad f: mm - hmm . mm - hmm . grad e: so what 's the what 's the time frame ? i forgot again when you 're going away for how long ? grad a: just , uh , as a sort of a mental bridge , i 'm not i 'm skipping fourth of july . so , uh , right afterwards i 'm back . grad e: ok . ok . grad f: what ? you 're missing like the premier american holiday ? what 's the point of spending a year here ? grad a: uh , i 've had it often enough . grad f: so , anyway . grad b: well he w he went to college here . grad f: oh , yeah , i forgot . oops . { comment } sorry . professor c: yeah . grad f: ok . professor c: and furthermore it 's well worth missing . grad f: not in california . grad e: yes . grad f: yeah , that 's true . i like i i like spending fourth of july in other countries , whenever i can . professor c: right . grad f: um professor c: ok , so that 's great . grad f: construal , ok , so oh , so there was one question that came out . i hate this thing . sorry . um , which is , so something like `` past `` which i you know , we think is a very simple uh , we 've often just stuck it in as a feature , professor c: right . right . grad f: you know , `` oh , this event takes place before speech time `` , { comment } ok , is what this means . um , it 's often thought of as it is also considered a mental space , professor c: right . grad f: you know , by , you know , lots of people around here . professor c: right . grad f: so there 's this issue of well sometimes there are really exotic explicit space builders that say `` in france , blah - blah - blah `` , grad e: mm - hmm . grad f: and you have to build up you ha you would imagine that would require you , you know , to be very specific about the machinery , whereas past is a very conventionalized one and we sort of know what it means but it we does n't do n't necessarily want to , you know , unload all the notation every time we see that it 's past tense . professor c: right . grad f: so , you know , we could think of our uh , just like x - schema `` walk `` refers to this complicated structure , past refers to , you know , a certain configuration of this thing with respect to it . professor c: i think that 's exactly right . grad f: so so we 're kind of like having our cake and eating it professor c: yeah . grad f: you know , having it both ways , right ? professor c: yeah . no , i think i think that i we 'll have to see how it works out when we do the details grad f: so , i i mm - hmm . professor c: but my intuition would be that that 's right . grad f: mm - hmm . yeah , ok . grad a: do you want to do the same for space ? grad f: wha - sorry ? grad a: space ? grad f: space ? grad a: here ? now ? grad f: oh , oh , oh , oh , instead of just time ? grad a: mm - hmm . grad f: yeah , yeah , yeah . same thing . so there are very conventionalized like deictic ones , right ? and then i think for other spaces that you introduce , you could just attach y whatever grad a: hmm . grad f: you could build up an appropriately uh , appropriate structure according to the l the sentence . professor c: yeah . grad a: hmm , well this this basically would involve everything you can imagine to fit under your c dot something grad e: n grad a: you know , where where it 's contextually dependent , grad f: yeah . right . grad a: `` what is now , what was past , grad f: mm - hmm . grad a: what is in the future , where is this , what is here , what is there , what is `` grad f: mm - hmm . yeah . so time and space . um , we 'll we 'll get that on the other side a little , like very minimally . there 's a sort of there 's a slot for setting time and setting place . professor c: good . grad f: and you know , you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , { comment } there are relative things that , you know , you relate the event in time and space to where you are now . if there 's something a lot more complicated like , or so hypothetical or whatever , then you have to do your job , grad e: mm - hmm . grad f: like or somebody 's job anyway . grad e: yeah . grad f: i 'm gon na point to at random . grad e: yeah . i mean , i 'm i 'm s curious about how much of the mental i mean , i 'm not sure that the formalism , sort of the grammatical side of things , { comment } is gon na have that much going on in terms of the mental space stuff . you know , um , basically all of these so - called space builders that are in the sentence are going to sort of i think of it as , sort of giving you the coordinates of , you know assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , um the construction that you actually get is just gon na sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to . grad f: mm - hmm . grad e: so `` in france , uh , watergate would n't have hurt nixon `` or something like that . um , well , you say , `` alright , i 'm supposed to add some structure to my model of this hypothetical past france universe `` or something like that . the information in the sentence tells you that much but it does n't tell you like exactly what it what the point of doing so is . so for example , depending on the linguistic con uh , context it could be like the question is for example , what does `` watergate `` refer to there ? does it , you know does it refer to , um if you just hear that sentence cold , the assumption is that when you say `` watergate `` you 're referring to `` a watergate - like scandal as we might imagine it happening in france `` . but in a different context , `` oh , you know , if nixon had apologized right away it would n't you know , watergate would n't have hurt him so badly in the us and in france it would n't have hurt him at all `` . now we 're s now that `` watergate `` we 're now talking about the real one , grad f: they 're real , right . grad e: and the `` would `` sort of it 's a sort of different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . grad f: i see right . grad e: in the first case , hypothetically we 're imagining that watergate happened in france . grad f: hmm . grad e: in the second case we 're imagining hypothetically that nixon had apologized right away grad f: mm - hmm . grad e: or something . right ? grad f: right . grad e: so a lot of this is n't happening at the grammatical level . professor c: correct . grad e: uh , um , and so grad f: mm - hmm . grad e: i do n't know where that sits then , grad a: hmm . grad e: sort of the idea of sorting out what the person meant . grad f: it seems like , um , the grammatical things such as the auxiliaries that you know introduce these conditionals , whatever , give you sort of the the most basi grad e: mm - hmm . grad f: th those we i think we can figure out what the possibilities are , right ? grad e: mm - hmm . grad f: there are sort of a relatively limited number . and then how they interact with some extra thing like `` in france `` or `` if such - and - such `` , that 's like there are certain ways that they c they can grad e: yeah . grad f: you know , one is a more specific version of the general pattern that the grammat grammar gives you . grad e: yeah . grad f: i think . but , you know , whatever , professor c: yeah , in the short run all we need is a enough mechanism on the form side to get things going . grad f: we we 're grad e: mm - hmm . yeah . professor c: uh , i uh , you you grad e: but the whole point of the whole point of what fauconnier and turner have to say about , uh , mental spaces , and blending , and all that stuff is that you do n't really get that much out of the sentence . you know , there 's not that much information contained in the sentence . it just says , `` here . add this structure to this space . `` and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean a hundred different things depending on , quote , `` what the space configuration is at the time of utterance `` . grad f: mm - hmm . mm - hmm . grad e: and so somebody 's gon na have to be doing a whole lot of work but not me , i think . professor c: well i think that 's right . oh , i yeah , i , uh , uh i think that 's not k i th i do n't think it 's completely right . i mean , in fact a sentence examples you gave in f did constrain the meaning b the form did constrain the meaning , grad e: yeah . professor c: and so , um , it is n't , uh grad e: sure , but like what what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really . grad f: that 's ok . we usually do n't know the point of the sentence at all . grad e: yeah . grad f: but we know what it 's trying to say . professor c: yeah . grad e: y yeah . grad f: we we know that it 's what predication it 's setting up . professor c: but but bottom line , i agree with you , grad e: yeah . grad f: that 's all . professor c: that that that we 're not expecting much out of the , uh f grad e: yeah . grad f: purely linguistic cues , right ? professor c: uh , the purely form cues , yeah . grad f: so . professor c: and , um i mean , you 're you 're the linguist grad f: mmm . professor c: but , uh , it seems to me that th these we we you know , we 've talked about maybe a half a dozen linguistics theses in the last few minutes or something . grad e: yeah , yeah . professor c: yeah , i mean grad e: yeah . oh , yeah . professor c: uh , i i mean , that that 's my feeling that that these are really hard uh , problems that decide exactly what what 's going on . grad e: mm - hmm . yeah . yeah . professor c: ok . grad f: ok , so , um , one other thing i just want to point out is there 's a lot of confusion about the terms like `` profile , designate , focus `` , et cetera , et cetera . professor c: uh , right , right , right . grad e: mm - hmm . grad f: um , for now i 'm gon na say like `` profile `` 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so `` hypotenuse `` , you profiled this guy against the background of the right t right triangle . grad e: mm - hmm . grad f: ok . and the second use , um , is in framenet . it 's slightly different . oh , i was asking hans about this . they use it to really mean , um , this in a frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which i 'm not saying one and two are mutually exclusive but they 're they 're different meanings . professor c: right . grad e: mm - hmm . grad f: so the closest thing so i was thinking about how it relates to this notation . for us , um ok , so how is it professor c: does that is that really what they mean in in grad f: so `` designate `` framenet ? professor c: i did n't know that . grad f: framenet ? yeah , yeah . i i mean , i i was a little bit surprised about it too . professor c: yeah . grad f: i knew that i thought that that would be something like there 's another term that i 've heard for that thing professor c: right , ok . grad f: but they i mean uh , well , at least hans says they use it that way . and professor c: well , i 'll check . grad f: and may maybe he 's wrong . anyway , so i think the the `` designate `` that we have in terms of meaning is really the `` highlight this thing with respect to everything else `` . ok ? professor c: right . grad f: so this is what what it means . but the second one seems to be useful but we might not need a notation for it ? we do n't have a notation for it but we might want one . so for example we 've talked about if you 're talking about the lexical item `` walk `` , you know it 's an action . well , it also has this idea it carries along with it the idea of an actor or somebody 's gon na do the walking . or if you talk about an adjective `` red `` , it carries along the idea of the thing that has the property of having color red . so we used to use the notation `` with `` for this professor c: right . grad f: and i think that 's closest to their second one . so i d do n't yet know , i have no commitment , as to whether we need it . it might be it 's the kind of thing that w a parser might want to think about whether we require you know , these things are like it 's semantically part of it professor c: n no , no . well , uh , th critically they 're not required syntactically . often they 're pres presu presupposed and all that sort of stuff . grad f: right . right , right . yeah , um , definitely . so , um , `` in `` was a good example . if you walk `` in `` , like well , in what ? professor c: right , there 's grad f: you know , like you have to have the { comment } so so it 's only semantically is it it is still required , say , by simulation time though professor c: right . grad f: to have something . so it 's that i meant the idea of like that the semantic value is filled in by sim simulation . i do n't know if that 's something we need to spa to to like say ever as part of the requirement ? or the construction ? or not . we 'll we 'll again defer . professor c: or i mean , or or , uh so the grad f: have it construed , professor c: yeah , yeah . grad f: is that the idea ? just point at robert . whenever i 'm confused just point to him . professor c: right . it 's it 's his thesis , right ? grad f: you tell me . professor c: anyway , grad f: ok . professor c: right , yeah , w this is gon na be a b you 're right , this is a bit of in a mess and we still have emphasis as well , or stress , or whatever . grad f: ok , well we 'll get , uh uh , i we have thoughts about those as well . professor c: yeah . great . grad f: um , the i w i would just s some of this is just like my you know , by fiat . i 'm going to say , this is how we use these terms . i do n't - you know , there 's lots of different ways in the world that people use it . professor c: i that 's fine . grad e: yeah . grad f: i think that , um , the other terms that are related are like focus and stress . professor c: mm - hmm . grad f: so , s i think that the way i we would like to think , uh , i think is focus is something that comes up in , i mean , lots of basically this is the information structure . professor c: mm - hmm . grad f: ok , it 's like uh , it 's not it might be that there 's a syntactic , uh , device that you use to indicate focus or that there are things like , you know , i think keith was telling me , { comment } things toward the end of the sentence , post - verbal , tend to be the focused focused element , grad e: mmm . grad f: the new information . you know , if i `` i walked into the room `` , you tend to think that , whatever , `` into the room `` is sort of like the more focused kind of thing . grad e: mm - hmm . yeah . grad f: and when you , uh , uh , you have stress on something that might be , you know , a cue that the stressed element , or for instance , the negated element is kind of related to information structure . so that 's like the new the sort of like import or whatever of of this thing . uh , so so i think that 's kind of nice to keep `` focus `` being an information structure term . `` stress `` i th and then there are different kinds of focus that you can bring to it . so , um , like `` stress `` , th stress is kind of a pun on you might have like whatever , like , um , accent kind of stress . grad e: mm - hmm . grad f: and that 's just a uh , w we 'll want to distinguish stress as a form device . you know , like , oh , high volume or whatever . grad e: yeah . grad f: um , t uh , and distinguish that from it 's effect which is , `` oh , the kind of focus we have is we 're emphasizing this value often as opposed to other values `` , right ? so focus carries along a scope . like if you 're gon na focus on this thing and you wan na know it sort of evokes all the other possibilities that it was n't . grad e: mm - hmm . grad f: um , so my classic my now - classic example of saying , `` oh , he did go to the meeting ? `` , grad e: yeah . grad f: that was my way of saying as opposed to , you know , `` oh , he did n't g `` or `` there was a meeting ? `` grad e: yeah . grad f: i think that was the example that was caught on by the linguists immediately . grad e: yeah . grad f: and so , um , the like if you said he you know , there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , uh grad e: mm - hmm . grad f: `` he walked to the meeting `` as opposed to `` he ran `` , or `` he did walk to the meeting `` as opposed to `` he did n't walk `` . you know , grad e: mm - hmm . grad f: so we need to have a notation for that which , um , i think that 's still in progress . so , sort of i 'm still working it out . but it did one one implication it does f have for the other side , which we 'll get to in a minute is that i could n't think of a good way to say `` here are the possible things that you could focus on `` , cuz it seems like any entity in any sentence , you know , or any meaning component of anyth you know all the possible meanings you could have , any of them could be the subject of focus . professor c: mmm . grad f: but i think one the one thing you can schematize is the kind of focus , right ? so for instance , you could say it 's the the tense on this as opposed to , um , the the action . ok . or it 's uh , it 's an identity thing or a contrast with other things , or stress this value as opposed to other things . so , um , it 's it is kind of like a profile profile - background thing but i i ca n't think of like the limited set of possible meanings that you would that you would focu grad e: light up with focus , yeah . grad f: light highlight as opposed to other ones . so it has some certain complications for the , uh , uh later on . li - i mean , uh , the best thing i can come up with is that information has a list of focused elements . for instance , you oh , one other type that i forgot to mention is like query elements and that 's probably relevant for the like `` where is `` , you know , `` the castle `` kind of thing ? grad e: mm - hmm . grad f: because you might want to say that , um , location or cert certain wh words bring you know , sort of automatically focus in a , you know , `` i do n't know the identity of this thing `` kind of way on certain elements . so . ok . anyway . so that 's onl there are there are many more things that are uncl that are sort of like a little bit unstable about the notation but it 's most i think it 's this is , you know , the current current form . other things we did n't totally deal with , um , grad e: oh , there 's a bunch . grad f: well , we 've had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . grad e: yeah . grad f: you know , a a nominal expression . grad e: yeah . grad f: and , um , i mean , we should have put an example of this and we could do that later . grad e: yeah . grad f: but i think the not inherently like the general principles still work though , that , um , we can have constructions that have sort of constituent structure in that there is like , you know , for instance , one uh , you know , they they have constituents , right ? so you can like nest things when you need to , but they can also overlap in a sort of flatter way . so if you do n't have like a lot of grammar experience , then like this this might , you know , be a little o opaque . but , you know , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's i think that 's sort of the main thing we wanted to aim for grad e: mm - hmm . grad f: and so far it 's worked out ok . professor c: good . grad f: so . ok . grad a: i can say two things about the f grad f: yes . grad a: maybe you want to forget stress . this my f grad f: as a word ? grad a: no , as as just do n't do n't think about it . grad f: as a what 's that ? grad a: if grad f: sorry . grad a: canonically speaking you can if you look at a a curve over sentence , you can find out where a certain stress is and say , `` hey , that 's my focus exponent . `` grad e: right . grad f: mm - hmm . grad a: it does n't tell you anything what the focus is . if it 's just that thing , grad f: mm - hmm . or the constituent that it falls in . grad a: a little bit more or the whole phrase . grad e: mm - hmm . grad a: um grad f: you mean t forget about stress , the form cue ? grad a: the form bit grad e: yeah . grad a: because , uh , as a form cue , um , not even trained experts can always well , they can tell you where the focus exponent is sometimes . grad f: ok . grad a: and that 's also mostly true for read speech . in in real speech , um , people may put stress . it 's so d context dependent on what was there before , phrase ba breaks , um , restarts . grad f: yeah . mm - hmm . grad a: it 's just , um it 's absurd . it 's complicated . grad f: ok , grad a: and all grad e: yeah , i mean , i i 'm sort of inclined to say let 's worry about specifying the information structure focus of the sentence grad f: i believe you , yeah . grad e: and then , grad f: mm - hmm . ways that you can get it come from th grad e: hhh , { comment } the phonology component can handle actually assigning an intonation contour to that . grad f: right . grad e: you know , i mean , later on we 'll worry about exactly how grad a: or or map from the contour to to what the focus exponent is . grad e: y yeah . exactly . grad f: mm - hmm . grad e: but figure out how the grad a: but , uh , if you do n't know what you 're what you 're focus is then you 're you 're hopeless - uh - ly lost anyways , grad e: yeah . grad f: right . that 's fine , yeah . mm - hmm . grad a: and the only way of figuring out what that is , is , um , by sort of generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one does n't . grad f: mm - hmm . grad a: and then you 're left with a couple three . so , you know , again , that 's something that h humans can do , grad f: mm - hmm . grad a: um , but far outside the scope of of any anything . so . you know . it 's grad f: ok . well , uh , yeah , i would n't have assumed that it 's an easy problem in in absence of all the oth grad a: u u grad f: you need all the other information i guess . grad a: but it 's it 's what it uh , it 's pretty easy to put it in the formalism , though . i mean , because grad f: yeah . grad a: you can just say whatever stuff , `` i is the container being focused or the the entire whatever , both , and so forth . `` grad f: mm - hmm , mm - hmm . grad e: mm - hmm . grad f: yeah . exactly . so the sort of effect of it is something we want to be able to capture . professor c: yeah , so b b but i think the poi i 'm not sure i understand but here 's what i th think is going on . that if we do the constructions right when a particular construction matches , it the fact that it matches , does in fact specify the focus . grad f: w uh , i 'm not sure about that . professor c: ok . grad f: or it might limit it cert certainly constrains the possibilities of focus . professor c: uh k uh , at at the very least it constrai grad f: i think that 's that 's , th that 's certainly true . and depending on the construction it may or may not f specify the focus , right ? professor c: oh , uh , for sure , yes . there are constrai yeah , it 's not every but there are constructions , uh , where you t explicitly take into account those considerations grad f: yeah . mm - hmm . professor c: that you need to take into account in order to decide which what is being focused . grad f: mm - hmm . grad a: mm - hmm . so we talked about that a little bit this morning . `` john is on the bus , not nancy . `` grad f: mm - hmm . grad a: so that 's focuses on john . professor c: right . grad f: hmm . grad a: `` john is on the bus and not on the train . `` grad f: mm - hmm . grad a: `` john is on the bus `` versus `` john is on the train . `` professor c: right . grad f: right . grad a: and `` john is on the bus `` versus `` was `` , and e grad f: is on . `` john is on the bus `` . yeah . yeah . grad a: `` it 's the bu `` so e professor c: right . yeah , all all of those . grad a: all of these professor c: yeah . grad f: right . grad a: and will we have u is it all the same constructions ? just with a different foc focus constituent ? grad f: yeah , i would say that argument structure in terms of like the main like sort of , grad a: mm - hmm . grad f: i do n't know the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why i was talking about overlapping constructions . so , then you have a separate thing that picks out , you know , stress on something relative to everything else . professor c: yeah . so , the question is actually grad e: mm - hmm . professor c: oh , i 'm sorry , grad f: and it would professor c: go ahead , grad f: yeah , professor c: finish . grad f: and it w and that would have to uh it might be ambiguous as , uh , whether it picks up that element , or the phrase , or something like that . but it 's still is limited possibility . grad a: hmm . grad f: so that should , you know , interact with it should overlap with whatever other construction is there . grad a: yeah . professor c: s s the question is , do we have a way on the other page , uh , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , or something . grad f: mm - hmm . well , so that 's why i was saying how since i could n't think of an easy like limited way of doing it , um , all i can say is that information structure has a focused slot professor c: right . grad f: and i think that should be able to refer to professor c: so that 's down at the bottom here when we get over there . ok . grad f: yeah , and , infer and i do n't have i do n't have a great way or great examples professor c: i 'll - i 'll wait . ok . grad f: but i think that something like that is probably gon na be , uh , more more what we have to do . grad a: hmm . professor c: ok . grad f: but , um , grad a: so grad f: ok , that was one comment . and you had another one ? grad a: yeah , well the once you know what the focus is the everything else is background . how about `` topic - comment `` that 's the other side of information . grad f: how about what ? grad a: topic - comment . grad f: yeah , so that was the other thing . and so i did n't realize it before . it 's like , `` oh ! `` it was an epiphany that it you know , topic and focus are a contrast set . so topic is topic - focused seems to me like , um , background profile , ok , or a landmark trajector , or some something like that . there 's there 's definitely , um , that kind of thing going on . grad a: mmm . grad f: now i do n't know whether i n i do n't have as many great examples of like topic - indicating constructions on like focus , right ? um , topic it seems kind of you know , i think that might be an ongoing kind of thing . grad a: mm - hmm . grad e: japanese has this though . you know . grad f: topic marker ? grad a: yeah . grad e: yeah , that 's what `` wa `` is , uh , just to mark which thing is the topic . grad f: mm - hmm . grad e: it does n't always have to be the subject . grad f: mm - hmm . right . so again , information structure has a topic slot . and , you know , i stuck it in thinking that we might use it . grad a: mm - hmm . grad f: um , i think i stuck it in . professor c: yep , it 's there . grad f: um , and one thing that i did n't do consistently , um , is when we get there , is like indicate what kind of thing fits into every role . i think i have an idea of what it should be but th you know , so far we 've been getting away with like either a type constraint or , um , you know , whatever . i forg it 'll be a frame . you know , it 'll be it 'll be another predication or it 'll be , um , i do n't know , some value from from some something , some variable and scope or something like that , or a slot chain based on a variable and scope . ok , so well that 's should we flip over to the other side officially then ? grad a: mm - hmm , hmm . grad e: ok , side one . grad f: i keep , uh , like , pointing forward to it . yeah . now we 'll go back to s ok , so this does n't include something which mi mi may have some effect on on it , which is , um , the discourse situation context record , right ? so i did n't i i meant just like draw a line and like , you know , you also have , uh , some tracking of what was going on . professor c: right . grad f: and sort of this is a big scale comment before i , you know , look into the details of this . but for instance you could imagine instead of having i i changed the name of um it used to be `` entities `` . so you see it 's `` scenario `` , `` referent `` and `` discourse segment `` . and `` scenario `` is essentially what kind of what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw draw in order to paint your picture , a bunch of frames , bi and bindings , right ? um , and obviously there are other ones that are not included here , general cultural frames and general like , uh , other action f grad e: mm - hmm . grad f: you know , specific x - schema frames . ok , whatever . the middle thing used to be `` entities `` because you could imagine it should be like really a list where here was various information . and this is intended to be grammatically specifiable information about a referent uh , you know , about some entity that you were going to talk about . so `` harry walked into the room `` , `` harry `` and `` room `` , you know , the room th but they would be represented in this list somehow . and it could also have for instance , it has this category slot . um , it should be either category or in or instance . basically , it could be a pointer to ontology . so that everything you know about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , um ki the ones i included here are slightly arbitrary but you could imagine that , um , you need to figure out wheth if it 's a group whether , um , some event is happening , linear time , linear spaces , like , you know , are are they doing something serially or is it like , um , uh i 'm i 'm not sure . because this partly came from , uh , talmy 's schema and i 'm not sure we 'll need all of these actually . but um , and then the `` status `` i used was like , again , in some languages , you know , like for instance in child language you might distinguish between different status . so , th the the big com and and finally `` discourse segment `` is about sort of speech - act - y information structure - y , like utterance - specific kinds of things . so the comment i was going to make about , um , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have a set of entities that you 're sort of referring to . and you might that might be sort of a general , i do n't know , database of all the things in this discourse that you could refer to . and i changed to `` reference `` cuz i would say , for a particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . for instance , i know it 's going to be plural . i know it 's gon na be feminine or something like that . and and these could actually just point to , you know , the the id in my other list of enti active entities , right ? so , um , uh , th there 's there 's all this stuff about discourse status . we 've talked about . i almost listed `` discourse status `` as a slot where you could say it 's active . you know , there 's this , um , hierarchy uh there 's a schematization of , you know , things can be active or they can be , um , accessible , inaccessible . grad e: yeah . grad f: it was the one that , you know , keith , um , emailed to us once , to some of us , not all of us . and the thing is that that i noticed that that , um , list was sort of discourse dependent . it was like in this particular set , s you know , instance , it has been referred to recently or it has n't been , grad e: yeah . grad f: or this is something that 's like in my world knowledge but not active . professor c: this uh yeah , well there there seems to be context properties . grad f: so . professor c: yeah . grad f: yeah , they 're contex and for instance , i used to have a location thing there but actually that 's a property of the situation . and it 's again , time , you know at cert certain points things are located , you know , near or far from you professor c: well , uh , uh , this is recursive grad f: and professor c: cuz until we do the uh , mental space story , we 're not quite sure { comment } th - th grad f: yeah . professor c: which is fine . we 'll just we 'll j grad f: yeah , yeah . so some of these are , uh professor c: we just do n't know yet . grad f: right . so i so for now i thought , well maybe i 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . um , and i left the slot , `` predications `` , open because you can have , um , things like `` the guy i know from school `` . grad e: mm - hmm . grad f: or , you know , like your referring expression might be constrained by certain like unbounded na amounts of prep you know , predications that you might make . and it 's unclear whether i mean , you could just have in your scenario , `` here are some extra few things that are true `` , right ? grad e: mm - hmm . grad f: and then you could just sort of not have this slot here . right ? you 're but but it 's used for identification purposes . professor c: right . grad e: yeah . grad f: so it 's it 's a little bit different from just saying `` all these things are true from my utterance `` . grad e: yeah . grad f: um . grad e: right , `` this guy i know from school came for dinner `` does not mean , um , `` there 's a guy , i know him from school , and he came over for dinner `` . that 's not the same effect . grad f: yeah , it 's a little bit it 's a little bit different . right ? so or maybe that 's like a restrictive , non - restrictive grad e: yeah . grad f: you know , it 's like it gets into that kind of thing for um , but maybe i 'm mixing , you know this is kind of like the final result after parsing the sentence . grad e: mm - hmm . grad f: so you might imagine that the information you pass to , you know in identifying a particular referent would be , `` oh , some `` you know , `` it 's a guy and it 's someone i know from school `` . grad e: yeah . grad f: so maybe that would , you know , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find you know , either create this reference , grad e: mm - hmm . grad f: in which case it 'd be created here , and you know , so so you could imagine that this might not so , uh , i 'm uncommitted to a couple of these things . grad a: but to make it m precise at least in my mind , uh , it 's not precise . grad f: um . grad a: so `` house `` is gender neuter ? in reality grad f: um , it could be in grad a: or in professor c: semantically . grad a: semantically . grad f: semantically , yeah . yeah . grad a: so grad f: so it uh , uh , a table . you know , a thing that c does n't have a gender . so . uh , it could be that i mean , maybe you 'd maybe not all these i mean , i wou i would say that i tried to keep slots here that were potentially relevant to most most things . grad a: no , just to make sure that we everybody that 's completely agreed that it it has nothing to do with , uh , form . grad f: yeah . ok , that is semantic as opposed to yeah . yeah . that 's right . um . grad a: then `` predications `` makes sense to to have it open for something like , uh , accessibility or not . grad f: s so again open to various things . grad a: yeah . grad f: right . ok , so . let 's see . so maybe having made that big sca sort of like large scale comment , should i just go through each of these slots uh , each of these blocks , um , a little bit ? grad e: sure . grad f: um , mostly the top one is sort of image schematic . and just a note , which was that , um s so when we actually ha so for instance , um , some of them seem more inherently static , ok , like a container or sort of support - ish . and others are a little bit seemingly inherently dynamic like `` source , path , goal `` is often thought of that way or `` force `` , or something like that . but in actual fact , i think that they 're intended to be sort of neutral with respect to that . and different x - schemas use them in a way that 's either static or dynamic . so `` path `` , you could just be talking about the path between this and this . grad e: mmm . grad f: and you know , `` container `` that you can go in and out . all of these things . and so , um , i think this came up when , uh , ben and i were working with the spaniards , um , the other day the `` spaniettes `` , as we called them um , to decide like how you want to split up , like , s image schematic contributions versus , like , x - schematic contributions . how do you link them up . and i think again , um , it 's gon na be something in the x - schema that tells you `` is this static or is this dynamic `` . so we definitely need that sort of aspectual type gives you some of that . um , that , you know , is it , uh , a state or is it a change of state , or is it a , um , action of some kind ? grad a: uh , i i i is there any meaning to when you have sort of parameters behind it and when you do n't ? grad f: uh . yeah . grad a: just means grad f: oh , oh ! you mean , in the slot ? grad a: mm - hmm . grad f: um , no , it 's like x - sc it 's it 's like i was thinking of type constraints but x - schema , well it obviously has to be an x - schema . `` agent `` , i mean , the the performer of the x - schema , that s depends on the x - schema . you know , and i in general it would probably be , you know grad e: so the difference is basically whether you thought it was obvious what the possible fillers were . grad f: yeah , basically . grad a: mm - hmm . grad e: ok . grad f: um , `` aspectual type `` probably is n't obvious but i should have so , i just neglected to stick something in . `` perspective `` , `` actor `` , `` undergoer `` , `` observer `` , um , grad b: mmm . grad f: i think we 've often used `` agent `` , `` patient `` , obser grad e: `` whee ! `` that 's that one , right ? grad f: yeah , exactly . exactly . um , and so one nice thing that , uh , we had talked about is this example { comment } of like , if you have a passive construction then one thing it does is ch you know definitely , it is one way to for you to , you know , specifically take the perspective of the undergoing kind of object . and so then we talked about , you know , whether well , does that specify topic as well ? well , maybe there are other things . you know , now that it 's subject is more like a topic . and now that , you know anyway . so . sorry . i 'm gon na trail off on that one cuz it 's not that f important right now . professor c: n now , for the moment we just need the ability to l l write it down if if somebody figured out what the rules were . grad f: um , to know how yeah . yeah . exactly . professor c: yeah . grad f: um , some of these other ones , let 's see . so , uh , one thing i 'm uncertain about is how polarity interacts . professor c: mm - hmm . grad f: so polarity , uh , is using for like action did not take place for instance . so by default it 'll be like `` true `` , i guess , you know , if you 're specifying events that did happen . you could imagine that you skip out this you know , leave off this polarity , you know , not do n't have it here . and then have it part of the speech - act in some way . professor c: mm - hmm . grad f: there 's some negation . but the reason why i left it in is cuz you might have a change of state , let 's say , where some state holds and then some state does n't hold , and you 're just talking , you know if you 're trying to have the nuts and bolts of simulation you need to know that , you know , whatever , the holder does n't and professor c: no , i th i think at this lev which is it should be where you have it . grad f: ok , it 's so it 's it 's it 's fine where it is . professor c: i mean , how you get it may may in will often involve the discourse grad f: so , ok . may come from a few places . professor c: but but by the time you 're simulating you sh y you should know that . grad f: right . right . grad e: so , i 'm still just really not clear on what i 'm looking at . the `` scenario `` box , like , what does that look like for an example ? like , not all of these things are gon na be here . grad f: yeah . professor c: correct . grad e: this is just basically says grad f: mm - hmm . it 's a grab bag of grad e: `` part of what i 'm going to hand you is a whole bunch of s uh , schemas , image , and x - schemas . here are some examples of the sorts of things you might have in there `` . grad f: so that 's exactly what it is . grad e: ok . grad f: and for a particular instance which i will , you know , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , you know , `` into `` you know , definition . grad e: mm - hmm . mm - hmm . grad f: so you would eventually have instances filled in with various various values for all the different slots . grad e: mm - hmm . grad f: and they 're bound up in , you know , their bindings and and and values . professor c: w it c grad e: ok . do you have to say about the binding in your is there a slot in here for that tells you how the bindings are done ? professor c: no , no , no . i let 's see , i think we 're we 're not i do n't think we have it quite right yet . so , uh , what this is , grad e: ok . professor c: let 's suppose for the moment it 's complete . ok , uh , then this says that when an analysis is finished , the whole analysis is finished , { comment } you 'll have as a result , uh , some s resulting s semspec for that utterance in context , grad e: ok . mm - hmm . professor c: which is made up entirely of these things and , uh , bindings among them . and bindings to ontology items . grad e: mm - hmm . professor c: so that that the who that this is the tool kit under whi out of which you can make a semantic specification . grad e: mm - hmm . mm - hmm . professor c: so that 's a . but b , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . grad e: ok . mm - hmm . professor c: so this is an that anything you have , in the party line , { comment } anything you have as the semantic side of constructions comes , from pieces of this ignoring li grad e: ok . professor c: i mean , in general , you ignore lots of it . grad e: right . professor c: but it 's got to be pieces of this along with constraints among them . grad e: ok . professor c: uh , so that the , you know , goal of the , uh uh , `` source , path , goal `` has to be the landmark of the conta you know , the interior of this container . grad e: mm - hmm . professor c: or whate whatever . grad e: yeah . professor c: so those constraints appear in constructions grad e: mm - hmm . professor c: but pretty much this is the full range of semantic structures available to you . grad e: ok . grad f: except for `` cause `` , that i forgot . but anyway , there 's som some kind of causal structure for composite events . grad e: yeah . professor c: ok , good . let 's let 's mark that . so we need a c grad f: uh , i mean , so it gets a little funny . these are all so far these structures , especially from `` path `` and on down , these are sort of relatively familiar , um , image schematic kind of slots . now with `` cause `` , uh , the fillers will actually be themselves frames . right ? professor c: right . grad e: mm - hmm . grad f: so you 'll say , `` event one causes event b professor c: and and and and this this this again may ge our , um and we and and , of course , worlds . grad f: uh , event two `` , and grad e: mm - hmm . grad f: yeah . so that 's , uh these are all implicitly one within , uh within one world . um , even though saying that place takes place , whatever . uh , if y if i said `` time `` is , you know , `` past `` , that would say `` set that this world `` , you know , `` somewhere , before the world that corresponds to our current speech time `` . grad e: mm - hmm . mm - hmm . yeah . grad f: so . but that that that 's sort of ok . the the within the event it 's st it 's still one world . um . yeah , so `` cause `` and other frames that could come in i mean , unfortunately you could bring in say for instance , um , uh , `` desire `` or something like that , grad e: mm - hmm . grad f: like `` want `` . and actually there is right now under `` discourse segments `` , um , `` attitude `` ? grad e: mm - hmm . grad f: `` volition `` ? could fill that . so there are a couple things where i like , `` oh , i 'm not sure if i wanted to have it there grad e: well that 's grad f: or `` basically there was a whole list of of possible speaker attitudes that like say talmy listed . and , like , well , i do n't you know , it was like `` hope , wish . desire `` , professor c: right . grad e: uh - huh . grad f: blah - blah - blah . and it 's like , well , i feel like if i wanted to have an extra meaning i do n't know if those are grammatically marked in the first place . so they 're more lexically marked , right ? grad e: mmm . grad f: at least in english . so if i wanted to i would stick in an extra frame in my meaning , saying , e so th it 'd be a hierarchical frame them , right ? you know , like `` naomi wants wants su a certain situation and that situation itself is a state of affairs `` . professor c: s right . so so , `` want `` itself can be i i i i i grad f: u can be just another frame that 's part of your professor c: well , and it i basically it 's an action . in in our s in our in our grad f: yeah . situation . { comment } right , right . professor c: in in our in our s terminology , `` want `` can be an action and `` what you want `` is a world . grad f: mm - hmm . grad b: hmm . professor c: so that 's i mean , it 's certainly one way to do it . grad f: mmm . professor c: yeah , there there are other things . grad e: mm - hmm . professor c: causal stuff we absolutely need . mental space we need . grad f: mm - hmm . professor c: the context we need . um , so anyway , keith so is this comfortable to you that , uh , once we have this defined , it is your tool kit for building the semantic part of constructions . grad e: mm - hmm . professor c: and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . grad e: mm - hmm . professor c: and that 's the wh and and i mean , that according to the party line , that 's the whole story . grad e: yeah . mm - hmm . yeah . um . y right . that makes sense . so i mean , there 's this stuff in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and i guess that some of the discourse segment stuff is that where you would sa grad f: mm - hmm . grad e: i mean , that 's ok , that 's where the information structure is which sort of is a kind of profiling on different parts of , um , of this . grad f: right . exactly . grad e: i mean , what 's interesting is that the information structure stuff hmm . there 's almost i mean , we keep coming back to how focus is like this this , uh , trajector - landmark thing . grad f: yeah . grad e: so if i say , um , you know , `` in france it 's like this `` . you know , great , we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like `` in france it 's like this `` . and therefore you 're supposed to say , `` boy , life sure `` grad f: right . grad e: you know , `` in france kids are allowed to drink at age three `` . and w you 're that 's not just a fact about france . you also conclude something about how boring it is here in the u s . right ? grad f: right , right . professor c: right . grad e: and so grad f: s so i would prefer not to worry about that for right now grad e: ok . grad f: and to think that there are , um , grad e: that comes in and , uh grad f: discourse level constructions in a sense , topic topic - focus constructions that would say , `` oh , when you focus something `` then grad e: mm - hmm . yeah . grad f: just done the same way just actually in the same way as the lower level . if you stressed , you know , `` john went to the `` , you know , `` the bar `` whatever , you 're focusing that grad e: mm - hmm . grad f: and a in a possible inference is `` in contrast to other things `` . grad e: yeah . grad f: so similarly for a whole sentence , you know , `` in france such - and - such happens `` . grad e: yeah . yeah , yeah . grad f: so the whole thing is sort of like again implicitly as opposed to other things that are possible . grad e: yeah . grad a: uh , just just , uh , look read uh even sem semi formal mats rooth . grad f: i mean yeah . grad a: if you have n't read it . it 's nice . grad f: uh - huh . grad a: and just pick any paper on alternative semantics . grad f: uh - huh . grad e: ok . grad a: so that 's his that 's the best way of talking about focus , is i think his way . grad e: ok , what was the name ? grad a: mats . mats . rooth . grad e: ok . grad a: i think two o 's , yes , th . grad e: ok . grad a: i never know how to pronounce his name because he 's sort of , professor c: s swede ? grad a: uh , he is dutch professor c: dutch ? grad a: and , um but very confused background i think . professor c: oh , dutch . grad e: yeah . professor c: uh - huh . grad a: so and , um , grad e: mats gould . grad a: and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . grad e: hmm . grad a: but , um i do n't know where he is right now but alternative semantics is if you type that into an , uh , uh , browser or search engine you 'll get tons of stuff . grad e: ok . ok . ok , thanks . grad a: and what i 'm kind of confused about is is what the speaker and the hearer is is sort of doing there . grad f: so for a particular segment it 's really just a reference to some other entity again in the situation , right ? so for a particular segment the speaker might be you or might be me . grad a: yeah . grad f: um , hearer is a little bit harder . it could be like multiple people . i guess that that that that 's not very clear from here grad a: yeah , but you do n't we ultimately want to handle that analogously to the way we handle time and place , grad f: i mean , that 's not allowed here . grad a: because `` you `` , `` me `` , `` he `` , `` they `` , you know , `` these guys `` , all these expressions , nuh , are in in much the same way contextually dependent as `` here , `` and `` now , `` and `` there `` grad f: mm - hmm . professor c: now , this is this is assuming you 've already solved that . grad f: ye - yeah . professor c: so it 's it 's fred and mary , grad f: so th professor c: so the speaker would be fred and the grad a: ah ! grad f: right , so the constructions might of course will refer , using pronouns or whatever . grad a: mm - hmm . grad f: in which case they have to check to see , uh , who the , uh , speaker in here wa in order to resolve those . but when you actually say that `` he walked into `` , whatever , um , the `` he `` will refer to a particular you you will already have figured who `` he `` or `` you `` , mmm , or `` i `` , maybe is a bett better example , who `` i `` refers to . um , and then you 'd just be able to refer to harry , you know , in wherever that person whatever role that person was playing in the event . grad a: mmm . that 's up at the reference part . grad f: yeah , yeah . grad a: and down there in the speaker - hearer part ? grad f: s so , that 's i think that 's just n for instance , speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is i mean , you know who the speaker is . in fact , that 's kind of constraining how in some ways you know this before you get to the you fill in all the rest of it . i think . professor c: mmm . grad f: i mean , how else would you um grad a: you know , uh , uh , it 's the speaker may in english is allowed to say `` i . `` professor c: yeah . well , here grad a: uh , among the twenty - five percent most used words . grad f: yeah . right . grad a: but would n't the `` i `` then set up the the s s referent that happens to be the speaker this time grad f: mm - hmm . grad a: and not `` they , `` whoever they are . grad f: right , right . grad a: or `` you `` grad f: so grad a: much like the `` you `` could n grad f: s so ok , so i would say ref under referent should be something that corresponds to `` i `` . and maybe each referent should probably have a list of way whatever , the way it was referred to . so that 's `` i `` but , uh , uh , should we say it it refers to , what ? uh , if it were `` harry `` it would refer to like some ontology thing . if it were if it 's `` i `` it would refer to the current speaker , ok , which is given to be like , you know , whoever it is . grad a: well , not not always . i mean , so there 's `` and then he said , i w `` uh - huh . professor c: uh grad f: `` i `` within the current world . grad a: yeah . professor c: yeah . that 's right . so so again , this uh , this this is gon na to get us into the mental space stuff grad f: yeah , yeah , yeah , yeah . professor c: and t because you know , `` fred said that mary said `` , and whatever . grad e: mmm . grad f: mm - hmm . professor c: and and so we 're , uh gon na have to , um , chain those as well . grad a: mm - hmm . twhhh - whhh . but grad f: mm - hmm . so this entire thing is inside a world , professor c: right . right . grad f: not just like the top part . professor c: i i think , uh grad f: that 's grad a: mm - hmm . professor c: except s it 's it 's trickier than that because um , the reference for example so he where it gets really tricky is there 's some things , grad f: yeah . professor c: and this is where blends and all terribl so , some things which really are meant to be identified and some things which are n't . grad f: yeah . right . professor c: and again , all we need for the moment is some way to say that . grad f: right . so i thought of having like for each referent , having the list of of the things t with which it is identified . you know , which which , uh you know , you you you professor c: you could do that . grad f: for instance , um so , i guess , it sort of depends on if it is a referring exp if it 's identifiable already or it 's a new thing . grad e: mm - hmm . grad f: if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , um , usually w something in a situation , right ? or something in ontology . professor c: uh - huh . grad f: so , there 's a you know , whatever , it c it could point at one of these . professor c: i just had a i just had an an idea that would be very nice if it works . grad f: for what ? professor c: uh , uh , uh , i have n't told you what it is yet . grad f: if it works . professor c: this was my build - up . grad f: mm - hmm . mmm . professor c: an i an idea that would be nice i grad f: yeah . ok , we 're crossing our fingers . professor c: right . grad b: so we 're building a mental space , good . professor c: if it worked . yeah . grad f: ok . professor c: right , it was a space builder . um , we might be able to handle context in the same way that we handle mental spaces because , uh , you have somewhat the same things going on of , uh , things being accessible or not . grad f: mm - hmm . professor c: and so , i grad f: yep . professor c: it c it it , uh i think if we did it right we might be able to get at least a lot of the same structure . grad f: use the same { comment } yep . professor c: so that pulling something out of a discourse context is i think similar to other kinds of , uh , mental space phenomena . grad b: i see . grad f: mm - hmm . and and professor c: uh , i 've i 've i 've never seen anybody write that up but maybe they did . i do n't know . that may be all over the literature . grad f: yeah . grad e: there 's things like ther you know , there 's all kinds of stuff like , um , in i think i mentioned last time in czech if you have a a verb of saying then grad f: so so by default grad e: um , you know , you say something like or or i was thinking you can say something like , `` oh , i thought , uh , you are a republican `` or something like that . where as in english you would say , `` i thought you were `` . professor c: right . grad e: um , you know , sort of the past tense being copied onto the lower verb does n't happen there , so you have to say something about , you know , tense is determined relative to current blah - blah - blah . grad f: mm - hmm . grad e: same things happens with pronouns . grad f: mm - hmm . grad e: there 's languages where , um , if you have a verb of saying then , ehhh , where ok , so a situation like `` bob said he was going to the movies `` , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have `` i `` there . grad f: mm - hmm . professor c: mm - hmm . grad e: um , and it 's sort of in an extended function professor c: so we would have it be in quotes in english . grad e: yeah . grad b: right . grad e: but it 's not perceived as a quotative construction . grad f: right . professor c: yeah . grad e: i mean , it 's been analyzed by the formalists as being a logophoric pronoun , um which means a pronoun which refers back to the person who is speaking or that sort of thing , right ? professor c: ok . grad f: oh , right . yeah , that makes sense . grad e: um , but uh , that happens to sound like the word for `` i `` but is actually semantically unrelated to it . grad f: oh , no ! professor c: oh , good , i love the formali grad e: um , grad f: really ? grad e: yeah . yeah . grad f: you 're kidding . grad e: there 's a whole book which basically operates on this assumption . uh , mary dalrymple , uh , this book , a ninety - three book on , uh on pronoun stuff . grad f: no , that 's horrible . ok . that 's horrible . { comment } ok . grad e: well , yeah . and then the same thing for asl where , you know , you 're signing and someone says something . and then , you know , so `` he say `` , and then you sort of do a role shift . and then you sign `` i , this , that , and the other `` . grad f: uh - huh . grad e: and you know , `` i did this `` . that 's also been analyzed as logophoric and having nothing to do with `` i `` . and the role shift thing is completely left out and so on . so , i mean , the point is that pronoun references , uh , you know , sort of ties in with all this mental space stuff and so on , and so forth . grad f: uh - huh . grad e: and so , yeah , i mean grad f: yeah . professor c: so that that d that does sound like it 's co consistent with what we 're saying , yeah . grad e: right . yeah . grad f: ok , so it 's kind of like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the h you know , depending on the construction or the whatever , um , you you you 're scope is m might extend out to the the base one . grad e: mm - hmm . professor c: mm - hmm . grad e: yeah . grad f: it would be nice to actually use the same , um , mechanism since there are so many cases where you actually need it 'll be one or the other . grad e: yeah . grad f: it 's like , oh , actually , it 's the same same operation . professor c: oh , ok , so this this is worth some thought . grad f: so . grad e: it 's like it 's like what 's happening that , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ? grad f: yeah , yeah . grad e: so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . grad f: mm - hmm . grad e: and so , grad f: mm - hmm . grad e: um , things like pronoun reference and tense which we 're thinking of as being these discourse - y things actually are relative to a bayes space which can change . grad f: mm - hmm , grad e: and we need all the same machinery . grad f: right . grad a: mm - hmm . grad f: robert . professor c: well , but , uh , this is very good actually grad e: schade . professor c: cuz it it it to the extent that it works , it y grad f: ties it all into it . professor c: it it ties together several of of these things . grad f: yeah . yep . grad a: mm - hmm . mm - hmm . and i 'm sure gon na read the transcript of this one . so . but the , uh , but it 's too bad that we do n't have a camera . you know , all the pointing is gon na be lost . grad e: yeah . grad f: oh , yeah . grad b: well every time nancy giggles it means it means that it 's your job . grad f: yeah , that 's why i said `` point to robert `` , when i did it . grad a: uh . yeah . mmm , is n't i mean , i 'm i was sort of dubious why why he even introduces this sort of reality , you know , as your basic mental space and then builds up grad e: mm - hmm . grad a: d does n't start with some because it 's so obvi it should be so obvious , at least it is to me , { comment } that whenever i say something i could preface that with `` i think . `` nuh ? grad e: yeah . grad a: so there should be no categorical difference between your base and all the others that ensue . grad e: yeah . professor c: no , but there 's there 's a gricean thing going on there , that when you say `` i think `` you 're actually hedging . grad e: yeah , i mean grad f: mmm . it 's like i do n't totally think professor c: right . grad e: yeah . y grad f: i mostly think , uh grad a: yeah , it 's absolutely . grad e: yeah , it 's an it 's an evidential . it 's sort of semi - grammaticalized . people have talked about it this way . and you know , you can do sort of special things . you can , th put just the phrase `` i think `` as a parenthetical in the middle of a sentence and so on , and so forth . grad a: yeah . grad e: so grad f: actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any kind of interesting embedded ways just to mark , you know , uncertainty or something like that . grad e: yeah . grad f: so . grad a: yeah , but about linguistic hedges , i mean , those those tend to be , um , funky anyways because they blur professor c: so we do n't have that in here either do we ? grad e: yeah . grad f: hedges ? professor c: yeah , yeah . grad f: hhh , { comment } i there used to be a slot for speaker , um , it was something like factivity . i could n't really remember what it meant grad e: yeah . grad f: so i took it out . grad e: um . grad f: but it 's something grad e: well we were just talking about this sort of evidentiality and stuff like that , right ? grad f: we we were talking about sarcasm too , right ? oh , oh . grad e: i mean , grad f: oh , yeah , yeah , right . grad e: that 's what i think is , um , sort of telling you what percent reality you should give this professor c: so we probably should . grad f: yeah . grad a: mm - hmm . grad e: or the , you know professor c: confidence or something like that . grad e: yeah , and the fact that i 'm , you know the fact maybe if i think it versus he thinks that might , you know , depending on how much you trust the two of us or whatever , grad f: yeah . grad a: uh great word in the english language is called `` about `` . grad e: you know grad a: if you study how people use that it 's also grad f: what 's the word ? grad a: `` about . `` it 's about professor c: about . grad a: clever . professor c: oh , that in that use of `` about `` , yeah . grad f: oh , oh , oh , as a hedge . grad e: yeah . professor c: and i think and i think y if you want us to spend a pleasant six or seven hours you could get george started on that . grad e: he wrote a paper about thirty - five years ago on that one . grad b: i r i read that paper , professor c: yeah . grad b: the hedges paper ? i read some of that paper actually . grad e: yeah . professor c: yeah . grad e: would you believe that that paper lead directly to the development of anti - lock brakes ? grad f: what ? professor c: no . grad e: ask me about it later i 'll tell you how . when we 're not on tape . grad f: i 'd love to know . grad b: oh , man . grad f: so , and and i think , uh , someone had raised like sarcasm as a complication at some point . professor c: there 's all that stuff . yeah , let 's i i do n't i think grad f: and we just wo n't deal with sarcastic people . professor c: yeah , i mean grad e: i do n't really know what like we we do n't have to care too much about the speaker attitude , right ? like there 's not so many different hhh , { comment } i do n't know , m grad f: certainly not as some well , they 're intonational markers i think for the most part . grad e: yeah . grad f: i do n't know too much about the like grammatical grad e: i just mean there 's lots of different attitudes that that the speaker could have and that we can clearly identify , and so on , and so forth . grad f: yeah . grad e: but like what are the distinctions among those that we actually care about for our current purposes ? professor c: right . right , so , uh , this this raises the question of what are our current purposes . grad f: mm - hmm . professor c: right ? grad e: oh , shoot . grad f: oh , yeah , do we have any ? grad e: here it is three - fifteen already . grad a: mmm . yeah . professor c: uh , so , um , i i do n't know the answer but but , um , it does seem that , you know , this is this is coming along . i think it 's it 's converging . it 's as far as i can tell there 's this one major thing we have to do which is the mental the whole s mental space thing . and then there 's some other minor things . grad f: mm - hmm . professor c: um , and we 're going to have to s sort of bound the complexity . i mean , if we get everything that anybody ever thought about you know , w we 'll go nuts . grad e: yeah . professor c: so we had started with the idea that the actual , uh , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and were n't trying to d you know , there 's all sorts of god knows , irony , and stuff like which you is n't probably of much use in dealing with a tourist guide . grad e: yeah . professor c: yeah ? grad e: yeah . professor c: uh . grad f: m mockery . professor c: right . whatever . so y uh , no end of things th that that , you know , we do n't deal with . grad a: but it professor c: and grad a: i is n't that part easy though professor c: go ahead . grad a: because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to sort of negate whatever the content of that is in terms of irony grad e: yeah . professor c: n no . grad f: mmm . grad a: or professor c: no . grad e: right . grad f: maybe . professor c: no . grad f: yeah , in model theory cuz the semantics is always like `` speaker believes not - p `` , you know ? professor c: right . grad f: like `` the speaker says p and believes not - p `` . grad e: we have a theoretical model of sarcasm now . grad f: but professor c: right . grad e: yeah , right , i mean . professor c: no , no . grad f: right , right , but , professor c: anyway , so so , um , i guess uh , let me make a proposal on how to proceed on that , which is that , um , it was keith 's , uh , sort of job over the summer to come up with this set of constructions . uh , and my suggestion to keith is that you , over the next couple weeks , n grad e: mmm . professor c: do n't try to do them in detail or formally but just try to describe which ones you think we ought to have . grad e: ok . professor c: uh , and then when robert gets back we 'll look at the set of them . grad e: ok . professor c: just just sort of , you know , define your space . grad e: yeah , ok . professor c: and , um , so th these are this is a set of things that i think we ought to deal with . grad e: yeah . professor c: and then we 'll we 'll we 'll go back over it and w people will will give feedback on it . grad e: ok . professor c: and then then we 'll have a at least initial spec of of what we 're actually trying to do . grad e: yeah . professor c: and that 'll also be useful for anybody who 's trying to write a parser . grad e: mm - hmm . professor c: knowing uh grad e: in case there 's any around . grad f: if we knew anybody like that . professor c: right , `` who might want `` et cetera . so , uh grad e: ok . professor c: so a and we get this this , uh , portals fixed and then we have an idea of the sort of initial range . and then of course nancy you 're gon na have to , uh , do your set of but you have to do that anyway . grad f: for the same , yeah , data . yeah , mm - hmm . professor c: so so we 're gon na get the w we 're basically dealing with two domains , the tourist domain and the and the child language learning . grad b: mmm . professor c: and we 'll see what we need for those two . and then my proposal would be to , um , not totally cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . grad e: mm - hmm . professor c: and then as a kind of separate thread , think about the more general things and and all that . grad e: mm - hmm . mm - hmm . grad a: well , i also think the detailed discussion will hit you know , bring us to problems that are of a general nature and maybe even professor c: uh , without doubt . yeah . grad f: yeah . grad a: even suggest some solutions . professor c: but what i want to do is is is to to constrain the things that we really feel responsible for . grad a: yeah . mmm . professor c: so that that we say these are the things we 're really gon na try do by the end of the summer grad e: mm - hmm . professor c: and other things we 'll put on a list of of research problems or something , because you can easily get to the point where nothing gets done because every time you start to do something you say , `` oh , yeah , but what about this case ? `` grad e: mm - hmm . professor c: this is this is called being a linguist . grad a: mmm . grad e: yeah . professor c: and , uh , grad e: basically . grad f: or me . professor c: huh ? grad f: or me . anyways grad b: there 's that quote in jurafsky and martin where where it goes where some guy goes , `` every time i fire a linguist the performance of the recognizer goes up . `` professor c: right . grad f: yeah . grad e: exactly . professor c: right . but anyway . so , is is that does that make sense as a , uh a general way to proceed ? grad f: sure , yeah . grad e: yeah , yeah , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it . professor c: exactly right . grad a: mmm . grad e: got it . grad a: mmm . grad e: ok . grad a: we have a little bit of news , uh , just minor stuff . the one big grad b: ooo , can i ask a grad e: you ran out of power . grad a: huh ? grad b: can i ask a quick question about this side ? grad a: yeah . grad f: yes . grad b: is this , uh was it intentional to leave off things like `` inherits `` and grad f: oops . um , grad e: no . grad f: not really just on the constructions , right ? grad b: yeah , like constructions can inherit from other things , grad f: um , grad b: am i right ? grad f: yeah . grad b: yeah . grad f: i did n't want to think too much about that for for now . grad b: ok . professor c: yeah . grad f: so , uh , maybe it was subconsciously intentional . professor c: yeah , uh yeah . grad e: um , yeah , there should be i i wanted to s find out someday if there was gon na be some way of dealing with , uh , if this is the right term , multiple inheritance , professor c: mm - hmm . grad e: where one construction is inheriting from , uh from both parents , grad f: uh - huh . yep . grad e: uh , or different ones , or three or four different ones . professor c: yeah . so let me grad e: cuz the problem is that then you have to grad f: yeah . grad e: which of you know , which are how they 're getting bound together . grad f: refer to them . professor c: yeah , right , right , right . yeah , yeah , yeah . grad f: yeah , and and there are certainly cases like that . even with just semantic schemas we have some examples . professor c: right . grad f: so , and we 've been talking a little bit about that anyway . professor c: yeah . so what i would like to do is separate that problem out . grad f: inherits . professor c: so um , grad e: ok . professor c: my argument is there 's nothing you can do with that that you ca n't do by just having more constructions . grad e: yeah , yes . professor c: it 's uglier and it d does n't have the deep linguistic insights and stuff . grad e: that 's right . professor c: uh , grad e: but whatever . professor c: right . grad e: yeah , no , no , no no . grad f: uh , those are over rated . grad e: no , by all means , professor c: and so i what i 'd like to do is is in the short run focus on getting it right . grad e: right . uh , sure . professor c: and when we think we have it right then saying , `` aha ! , grad e: yeah . professor c: can we make it more elegant ? `` grad e: yeah , that 's professor c: can can we , uh what are the generalizations , and stuff ? grad e: yeah . connect the dots . yeah . professor c: but rather than try to guess a inheritance structure and all that sort of stuff before we know what we 're doing . grad e: yep . yeah . professor c: so i would say in the short run we 're not gon na b grad e: yeah . professor c: first of all , we 're not doing them yet at all . and and it could be that half way through we say , `` aha ! , we we now see how we want to clean it up . `` grad e: mm - hmm . professor c: uh , and inheritance is only one i mean , that 's one way to organize it but there are others . and it may or may not be the best way . grad e: yeah . grad a: mmm . professor c: i 'm sorry , you had news . grad a: oh , just small stuff . um , thanks to eva on our web site we can now , if you want to run javabayes , uh , you could see get download these classes . and then it will enable you she modified the gui so it has now a m a m a button menu item for saving it into the embedded javabayes format . grad d: mm - hmm . grad b: mmm . grad a: so that 's wonderful . professor c: great . grad a: and , um and she , a you tested it out . do you want to say something about that , that it works , right ? with the grad d: i was just checking like , when we wan na , um , get the posterior probability of , like , variables . you know how you asked whether we can , like , just observe all the variables like in the same list ? you ca n't . grad a: uh - huh . grad d: you have to make separate queries every time . grad a: ok , that 's that 's a bit unfortunate grad d: so yeah . grad a: but for the time being it 's it 's it 's fine to do it grad d: you just have to have a long list of , you know , all the variables . grad a: yeah . but uh grad d: basically . grad f: uh , all the things you want to query , you just have to like ask for separately . grad d: yeah , yeah . grad a: well that 's probably maybe in the long term that 's good news because it forces us to think a little bit more carefully how how we want to get an out output . um , but that 's a different discussion for a different time . and , um , i do n't know . we 're really running late , so i had , uh , an idea yesterday but , uh , i do n't know whether we should even start discussing . professor c: w what yeah , sure , tell us what it is . grad a: um , the construal bit that , um , has been pointed to but has n't been , um , made precise by any means , um , may w may work as follows . i thought that we would , uh that the following thing would be in incredibly nice and i have no clue whether it will work at all or nothing . so that 's just a tangent , a couple of mental disclaimers here . um , imagine you you write a bayes - net , um grad f: bayes ? grad a: bayes - net , grad f: ok . grad a: um , completely from scratch every time you do construal . so you have nothing . just a white piece of paper . professor c: mmm , right . grad a: you consult consult your ontology which will tell you a bunch of stuff , and parts , and properties , uh - uh - uh grad f: grout out the things that that you need . professor c: right . grad a: then y you 'd simply write , uh , these into onto your your white piece of paper . and you will get a lot of notes and stuff out of there . you wo n't get you wo n't really get any c p t 's , therefore we need everything that that configures to what the situation is , ie , the context dependent stuff . so you get whatever comes from discourse but also filtered . uh , so only the ontology relevant stuff from the discourse plus the situation and the user model . grad f: mm - hmm . grad a: and that fills in your cpt 's with which you can then query , um , the the net that you just wrote and find out how thing x is construed as an utterance u . and the embedded javabayes works exactly like that , that once you we have , you know , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the the nice thing about this idea is that you do n't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the the initial notes . but it 's in that respect it 's completely scalable . because it does n't have any prior , um , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work at all , that 'd be kind of funky . professor c: um , it sounds to me like you want p r grad a: p r ms - uh , prm i mean , since you can unfold a prm into a straightforward bayes - net professor c: beca - because it b because no , no , you ca n't . see the the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it . grad a: then you can . mm - hmm , yeah . no , i was m using it generic . so , uh , probabilistic , whatever , relational models . whatever you write it . in professor c: well , no , but it matters a lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case . grad a: and then then instantiate them . that 's ma maybe the the way the only way it works . professor c: yeah , and that 's grad a:  professor c: yeah , that 's the only way it could work . i we have a our local expert on p r uh , but my guess is that they 're not currently good enough to do that . but we 'll we 'll have to see . grad a: but , uh , professor c: uh yes . this is that 's that would be a good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , uh grad a: except there 's no no theorem prover involved . grad f: best explanation . professor c: no , there is n't a theorem prover but there but but the , um , the cove the the p r ms are like rules of inference and you 're you 're coupling a bunch of them together . grad a: mm - hmm , yeah . professor c: and then ins instead of proving you 're trying to , you know , compute the most likely . uh tricky . but you yeah , it 's a good it 's a it 's a good thing to put in your thesis proposal . grad a: what 's it ? professor c: so are you gon na write something for us before you go ? grad a: yes . um . professor c: oh , you have something . grad a: in the process thereof , or whatever . professor c: ok . so , what 's what when are we gon na meet again ? grad f: when are you leaving ? grad a: fri - uh , grad f: thursday , friday ? grad a: thursday 's my last day here . grad d: fri professor c: yeah . grad f: ok . grad a: so i would suggest as soon as possible . do you mean by we , the whole ben gang ? professor c: n no , i did n't mean y just the two of us . we obviously we can we can do this . but the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal and get , uh , another session on feedback on that ? or grad a: we can do it th - thursday again . yeah . grad e: fine with me . should we do the one pm time for thursday since we were on that before or ? grad a: sure . grad e: ok . professor c: alright . grad d: hmm . grad a: thursday at one ? i can also maybe then sort of run through the , uh the talk i have to give at eml which highlights all of our work . professor c: ok . grad a: and we can make some last minute changes on that . professor c: ok . grad b: you can just give him the abstract that we wrote for the paper . professor c: that - that 'll tell him exactly what 's going on . yeah , that alright . grad f: can we do can we do one - thirty ? grad a: no . grad f: oh , you already told me no . grad a: but we can do four . grad f: one , ok , it 's fine . i can do one . it 's fine . it 's fine . grad a: one or four . i do n't care . grad e: to me this is equal . i do n't care . grad a: if it 's equal for all ? what should we do ? grad f: yeah , it 's fine . grad a: four ? grad f: fine . yeah no , no , no , uh , i do n't care . it 's fine . grad a: it 's equal to all of us , so you can decide one or four . grad b: the pressure 's on you nancy . grad a: liz actually said she likes four because it forces the meeting recorder people to cut , you know the discussions short . grad f: ok . ok , four . grad e: well , if you insist , then . grad f: ok ? ok . i am .","output":"the semantic specification , on the other hand , is split into three levels : `` scenario '' is a list of schemas and bindings between them , which describes the current event in terms of source-path-goal , container , etc . ; `` referent '' is about the entities in the discourse and includes grammatical information and pointers to the ontology ; `` discourse segment '' comprises utterance-specific things ."},{"instruction":"how would the mental spaces operate ?","input":"grad b: what things to talk about . grad f: i 'm what ? really ? oh , that 's horrible ! disincentive ! grad a: ok , we 're recording . grad f: hello ? grad b: check check check check . grad d: uh , yeah . grad f: hello ? which am i ? professor c: oh right . grad b: alright . good . grad f: channel fi ok . ok . are you doing something ? ok , then i guess i 'm doing something . so , um , so basically the result of m much thinking since the last time we met , um , but not as much writing , um , is a sheet that i have a lot of , like , thoughts and justification of comments on but i 'll just pass out as is right now . so , um , here . if you could pass this around ? and there 's two things . and so one on one side is on one side is a sort of the revised sort of updated semantic specification . grad d: um the wait . grad f: and the other side is , um , sort of a revised construction formalism . grad e: this is just one sheet , right ? grad d: ah ! just one sheet . grad f: it 's just one sheet . grad d: ok . grad f: it 's just a nothing else . grad d: front , back . grad f: um , enough to go around ? ok . and in some ways it 's it 's it 's very similar to there are very few changes in some ways from what we 've , um , uh , b done before but i do n't think everyone here has seen all of this . so , uh , i 'm not sure where to begin . um , as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . grad e: mm - hmm . grad f: and , um , after a little bit more discussion and especially like keith and i i have more linguistic things to settle in the next few days , um , it 'll probably change again some more . grad e: yeah . grad f: um , maybe i will let 's start b let 's start on number two actually on the notation , um , because that 's , i 'm thinking , possibly a little more familiar to , um to people . ok , so the top block is just sort of a sort of abstract nota it 's sort of like , um , listings of the kinds of things that we can have . and certain things that have , um , changed , have changed back to this . there there 's been a little bit of , um , going back and forth . but basically obviously all constructions have some kind of name . i forgot to include that you could have a type included in this line . professor c: what i was gon na right . grad f: so something like , um well , there 's an example the textual example at the end has clausal construction . so , um , just to show it does n't have to be beautiful it could be , you know , simple old text as well . um , there are a couple of uh , these three have various ways of doing certain things . so i 'll just try to go through them . so they could all have a type at the beginning . um , and then they say the key word construction professor c: oh , i see . grad f: and they have some name . professor c: so so the current syntax is if it s if there 's a type it 's before construct grad f: yeah , right . professor c: ok , that 's fine . grad f: ok , and then it has a block that is constituents . and as usual i guess all the constructions her all the examples here have only , um , tsk { comment } one type of constituent , that is a constructional constituent . i think that 's actually gon na turn out to m be certainly the most common kind . but in general instead of the word `` construct `` , th here you might have `` meaning `` or `` form `` as well . ok ? so if there 's some element that does n't that is n't yet constructional in the sense that it maps form and meaning . ok , um , the main change with the constructs which each of which has , um , the key word `` construct `` and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that you know what kind of construction it is . so for example whatever i have here is gon na be a form of the word `` throw `` , or it 's gon na be a form of the word , you know , i do n't know , `` happy `` , or something like that . or , you know , some it 'll be a specific word or maybe you 'll have the type . you 'll say `` i need a p uh spatial relation phrase here `` or `` i need a directional specifier here `` . so - uh you could have a j a actual type here . um , or you could just say in the second case that you only know the meaning type . so a very common example of this is that , you know , in directed motion , the first person to do something should be an agent of some kind , often a human . right ? so if i you know , the um , uh , run down the street then i i i run down the street , it 's typed , uh , `` i `` , meaning category is what 's there . the the new kind is this one that is sort of a pair and , um , sort of skipping fonts and whatever . the idea is that sometimes there are , um , general constructions that you know , that you 're going to need . it 's it 's the equivalent of a noun phrase or a prepositional phrase , or something like that there . grad e: mm - hmm . grad f: and usually it has formal um , considerations that will go along with it . professor c: mm - hmm . grad f: and then uh , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , you know , um , `` the big th `` , you you know , `` the big the tall dark man `` , you know , `` walked into the room `` . grad e: mm - hmm . grad f: but because of the nature of this particular construction you know not just that it 's nominal of some kind but in particular , that it 's some kind of animate nominal , and which will apply just as well to like , you know , a per you know , a simple proper noun or to some complicated expression . um , so i do n't know if the syntax will hold but something that gives you a way to do both constructional and meaning types . so . ok , then i do n't think the , { comment } um at least yeah . { comment } none of these examples have anything different for formal constraints ? but you can refer to any of the , um , sort of available elements and scope , right ? which here are the constructs , { comment } to say something about the relation . and i think i if you not if you compare like the top block and the textual block , um , we dropped like the little f subscript . the f subscripts refer to the `` form `` piece of the construct . professor c: good . grad f: and i think that , um , in general it 'll be unambiguous . like if you were giving a formal constraint then you 're referring to the formal pole of that . so so by saying if i just said `` name one `` then that means name one formal and we 're talking about formal struc { comment } which which makes sense . uh , there are certain times when we 'll have an exception to that , in which case you could just indicate `` here i mean the meaningful for some reason `` . right ? or actually it 's more often that , only to handle this one special case of , you know , `` george and jerry walk into the room in that order `` . grad e: mm - hmm . grad f: so we have a few funny things where something in the meaning might refer to something in the form . but but s we 're not gon na really worry about that for right now and there are way we can be more specific if we have to later on . ok , and so in terms of the the relations , you know , as usual they 're before and ends . i should have put an example in of something that is n't an interval relation but in form you might also have a value binding . you know , you could say that , um , you know , `` name - one dot `` , t you know , `` number equals `` , you know , a plural or something like that . grad e: mm - hmm . grad f: there are certain things that are attribute - value , similar to the bindings below but i mean they 're just us usually they 're going to be value value fillers , right ? ok , and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and i i you you and i can like fight about that if you like ? but about changing it to `` semantic n effects `` , which i thought was a little bit too order - biased grad b: well th grad f: and `` semantic bindings `` , which i thought might be too restrictive in case we do n't have only bindings . and so it was an issue whether constraints um , there were some linguists who reacted against `` constraints `` , saying , `` oh , if it 's not used for matching , then it should n't be called a constraint `` . but i think we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are i think we thought of some situations where it would be useful to use whatever the c bindings are , for actual , you know , sort of like modified constraining purposes . professor c: well , you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification , i grad e: yeah . grad f: yeah , yeah . it 's used should n't matter , right ? mm - hmm . professor c: s for sure . i mean , i do n't know what , uh , term we want to use grad f: mm - hmm . professor c: but we do n't want to grad f: yeah , uh , there was one time when when hans explained why `` constraints `` was a misleading word for him . professor c: yep . grad f: and i think the reason that he gave was similar to the reason why johno thought it was a misleading term , which was just an interesting coincidence . um , but , uh and so i was like , `` ok , well both of you do n't like it ? professor c: it 's g it 's gone . grad f: fine , we can change it `` . but i i i 'm starting to like it again . grad b: but grad f: so that that 's why { comment } that 's why i 'll stick with it . grad a: well , you know what ? grad f: so grad a: if you have an `` if - then `` phrase , do you know what the `` then `` phrase is called ? professor c: th grad f: what ? con - uh , a consequent ? grad a: yeah . grad f: yeah , but it 's not an `` if - then `` . grad a: no , but professor c: i know . anyway , so the other the other strategy you guys could consider is when you do n't know what word to put , you could put no word , grad f: mm - hmm . professor c: just meaning . ok ? and the then let grad e: yeah . grad f: yeah , that 's true . grad b: so that 's why you put semantic constraints up top and meaning bindings down down here ? grad f: oh , oops ! no . that was just a mistake of cut and paste from when i was going with it . grad b: ok . professor c: ok . grad f: so , i 'm sorry . i did n't mean that one 's an in unintentional . grad b: so this should be semantic and grad f: sometimes i 'm intentionally inconsistent grad b:  grad f: cuz i 'm not sure yet . here , i actually it was just a mistake . grad b: th - so this definitely should be `` semantic constraints `` down at the bottom ? grad e: sure . grad f: yeah . grad b: ok . grad f: well , unless i go with `` meaning `` but i i mean , i kind of like `` meaning `` better than `` semantic `` grad b: or professor c: oh , whatever . grad f: but i think there 's vestiges of other people 's biases . professor c: or wh that - b grad f: like professor c: right . minor min problem grad f: minor point . professor c: ok . grad e: extremely . grad f: ok , um , so i think the middle block does n't really give you any more information , ex than the top block . and the bottom block similarly only just illus you know , all it does is illustrate that you can drop the subscripts and and that you can drop the , um uh , that you can give dual types . oh , one thing i should mention is about `` designates `` . i think i 'm actually inconsistent across these as well . so , um , strike out the m subscript on the middle block . professor c: mm - hmm . grad f: so basically now , um , this is actually this little change actually goes along with a big linguistic change , which is that `` designates `` is n't only something for the semantics to worry about now . professor c: good . grad f: so we want s `` designates `` to actually know one of the constituents which acts like a head in some respects but is sort of , um , really important for say composition later on . so for instance , if some other construction says , you know , `` are you of type is this part of type whatever `` , um , the `` designates `` tells you which sort of part is the meaning part . ok , so if you have like `` the big red ball `` , you know , you wan na know if there 's an object or a noun . well , ball is going to be the designated sort of element of that kind of phrase . grad e: mmm . grad f: um , there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , um to talk about there also being a designated object and we think that that 'll be the same one , right ? so the ball is the head of the phrase , `` the r the `` , um , `` big red ball `` , and the entity denoted by the word `` ball `` is sort of the semantic head in some ways of of this sort of , um , in interesting larger element . professor c: a a and the yeah . and there 's uh there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if i understand you right . grad e: yeah . grad f: mm - hmm . grad e: yeah . grad f: right , right . grad e: that 's the idea . professor c: yeah yeah . grad e: yeah . grad f: and , uh , you might be able to say things like if the head has to go last in a head - final language , you can refer to the head as a p the , you know the formal head as opposed to the rest of the form having to be at the end of that decision . professor c: right . grad f: so that 's a useful thing so that you can get some internal structural constraints in . professor c: ok , so that all looks good . let me oh , w oh . i do n't know . were you finished ? grad f: um , there was a list of things that is n't included but you you can you can ask a question . that might @ @ it . professor c: ok . so , i if i understand this the aside from , uh , construed and all that sort of stuff , the the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for a type grad f: mm - hmm . professor c: or actually gone back to , grad f: right . professor c: if we go back far enough grad f: well , except for their construction meaning , so it 's not clear that , uh well , right now it 's a c uh contr construction type and meaning type . so i do n't know what a form type is . professor c: oh , i see . yeah , yeah , yeah . i 'm sorry , you 're right . grad f: yeah . professor c: a construction type . uh , that 's fine . but it , um grad f: right . a well , and a previous , um , you know , version of the notation certainly allowed you to single out the meaning bit by it . so you could say `` construct of type whatever designates something `` . professor c: yeah . grad f: but that was mostly for reference purposes , just to refer to the meaning pole . i do n't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time i think . professor c: mm - hmm . grad f: um , i i do n't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , you know that 's kind of weird . professor c: no , no , no , i do n't think so . i think that you 'll you 'll do fine . grad e: i professor c: in fact , these are , um , as long as as mark is n't around , these are form constraints . so a nominal expression is uh , the fact that it 's animate , is semantic . the fact that it 's n uh , a nominal expression i would say on most people 's notion of of f you know , higher form types , this i this is one . grad f: mm - hmm . grad e: yeah . grad f: right , right . professor c: and i think that 's just fine . grad e: yeah , yeah . grad f: which is fine , yeah . professor c: yeah . grad e: it 's that now , um , i 'm mentioned this , i i do n't know if i ever explained this but the point of , um , i mentioned in the last meeting , { comment } the point of having something called `` nominal expression `` is , um , because it seems like having the verb subcategorize for , you know , like say taking as its object just some expression which , um , designates an object or designates a thing , or whatever , um , that leads to some syntactic problems basically ? so you wan na , you know you sort of have this problem like `` ok , well , i 'll put the word `` , uh , let 's say , the word `` dog `` , you know . and that has to come right after the verb grad f: mm - hmm . grad e: cuz we know verb meets its object . and then we have a construction that says , oh , you can have `` the `` preceding a noun . and so you 'd have this sort of problem that the verb has to meet the designatum . professor c: right . grad e: and you could get , you know , `` the kicked dog `` or something like that , meaning `` kicked the dog `` . professor c: right . grad e: um , so you kind of have to let this phrase idea in there professor c: that i i have no problem with it at all . grad e: but it - it professor c: i think it 's fine . grad e: yeah . grad f: yeah . right , n s you may be you may not be like everyone else in in berkeley , grad e: yeah . yeah . grad f: but that 's ok . grad e: i mean , we we we sort of thought we were getting away with , uh with , a p grad f: uh , we do n't mind either , so grad e: i mean , this is not reverting to the x - bar theory of of phrase structure . professor c: right . grad e: but , uh , grad f: right . grad e: i just know that this is like , we did n't originally have in mind that , uh that verbs would subcategorize for a particular sort of form . grad f: mm - hmm . professor c: but they do . grad e: um , but they does . grad f: well , there 's an alternative to this grad e: at least in english . grad f: which is , um the question was did we want directed motion , professor c: yeah . grad f: which is an argument structure construction professor c: mm - hmm . grad e: yeah . grad f: did we want it to worry about , um , anything more than the fact that it , you know , has semantic you know , it 's sort of frame - based construction . so one option that , you know , keith had mentioned also was like , well if you have more abstract constructions such as subject , predicate , basically things like grammatical relations , grad e: mm - hmm . grad f: those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob you know , verb object would require that those things that f fill a subject and object are nom expressions . professor c: right . grad f: and that would be a little bit cleaner in some way . but you know , for now , i mean , professor c: yeah . but it y y it 's yeah , just moving it moving the c the cons the constraints around . grad f: uh , you know . m moving it to another place , right . grad e: yeah . professor c: ok , so that 's grad f: but there does basically , the point is there has to be that constraint somewhere , right ? professor c: right . grad f: so , yeah . professor c: and so that was the grad f: robert 's not happy now ? grad a: no ! grad f: oh , ok . professor c: ok , and sort of going with that is that the designatum also now is a pair . grad f: yes . professor c: instead of just the meaning . grad f: mm - hmm . professor c: and that aside from some terminology , that 's basically it . grad f: right . professor c: i just want to b i 'm i 'm asking . grad e: mm - hmm . grad f: yep . grad e: yeah . grad f: yeah , um , the un sort of the un - addressed questions in this , um , definitely would for instance be semantic constraints we talked about . professor c: yeah . grad f: here are just bindings but , right ? we might want to introduce mental spaces you know , there 's all these things that we do n't professor c: the whole the mental space thing is clearly not here . grad f: right ? so there 's going to be some extra you know , definitely other notation we 'll need for that which we skip for now . grad e: mm - hmm . professor c: by the way , i do want to get on that as soon as robert gets back . grad f: uh yeah . professor c: so , uh , the the mental space thing . grad f: ok . professor c: um , obviously , construal is a b is a b is a big component of that grad e: mm - hmm . professor c: so this probably not worth trying to do anything till he gets back . but sort of as soon as he gets back i think um , we ought to grad f: mm - hmm . mm - hmm . grad e: so what 's the what 's the time frame ? i forgot again when you 're going away for how long ? grad a: just , uh , as a sort of a mental bridge , i 'm not i 'm skipping fourth of july . so , uh , right afterwards i 'm back . grad e: ok . ok . grad f: what ? you 're missing like the premier american holiday ? what 's the point of spending a year here ? grad a: uh , i 've had it often enough . grad f: so , anyway . grad b: well he w he went to college here . grad f: oh , yeah , i forgot . oops . { comment } sorry . professor c: yeah . grad f: ok . professor c: and furthermore it 's well worth missing . grad f: not in california . grad e: yes . grad f: yeah , that 's true . i like i i like spending fourth of july in other countries , whenever i can . professor c: right . grad f: um professor c: ok , so that 's great . grad f: construal , ok , so oh , so there was one question that came out . i hate this thing . sorry . um , which is , so something like `` past `` which i you know , we think is a very simple uh , we 've often just stuck it in as a feature , professor c: right . right . grad f: you know , `` oh , this event takes place before speech time `` , { comment } ok , is what this means . um , it 's often thought of as it is also considered a mental space , professor c: right . grad f: you know , by , you know , lots of people around here . professor c: right . grad f: so there 's this issue of well sometimes there are really exotic explicit space builders that say `` in france , blah - blah - blah `` , grad e: mm - hmm . grad f: and you have to build up you ha you would imagine that would require you , you know , to be very specific about the machinery , whereas past is a very conventionalized one and we sort of know what it means but it we does n't do n't necessarily want to , you know , unload all the notation every time we see that it 's past tense . professor c: right . grad f: so , you know , we could think of our uh , just like x - schema `` walk `` refers to this complicated structure , past refers to , you know , a certain configuration of this thing with respect to it . professor c: i think that 's exactly right . grad f: so so we 're kind of like having our cake and eating it professor c: yeah . grad f: you know , having it both ways , right ? professor c: yeah . no , i think i think that i we 'll have to see how it works out when we do the details grad f: so , i i mm - hmm . professor c: but my intuition would be that that 's right . grad f: mm - hmm . yeah , ok . grad a: do you want to do the same for space ? grad f: wha - sorry ? grad a: space ? grad f: space ? grad a: here ? now ? grad f: oh , oh , oh , oh , instead of just time ? grad a: mm - hmm . grad f: yeah , yeah , yeah . same thing . so there are very conventionalized like deictic ones , right ? and then i think for other spaces that you introduce , you could just attach y whatever grad a: hmm . grad f: you could build up an appropriately uh , appropriate structure according to the l the sentence . professor c: yeah . grad a: hmm , well this this basically would involve everything you can imagine to fit under your c dot something grad e: n grad a: you know , where where it 's contextually dependent , grad f: yeah . right . grad a: `` what is now , what was past , grad f: mm - hmm . grad a: what is in the future , where is this , what is here , what is there , what is `` grad f: mm - hmm . yeah . so time and space . um , we 'll we 'll get that on the other side a little , like very minimally . there 's a sort of there 's a slot for setting time and setting place . professor c: good . grad f: and you know , you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , { comment } there are relative things that , you know , you relate the event in time and space to where you are now . if there 's something a lot more complicated like , or so hypothetical or whatever , then you have to do your job , grad e: mm - hmm . grad f: like or somebody 's job anyway . grad e: yeah . grad f: i 'm gon na point to at random . grad e: yeah . i mean , i 'm i 'm s curious about how much of the mental i mean , i 'm not sure that the formalism , sort of the grammatical side of things , { comment } is gon na have that much going on in terms of the mental space stuff . you know , um , basically all of these so - called space builders that are in the sentence are going to sort of i think of it as , sort of giving you the coordinates of , you know assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , um the construction that you actually get is just gon na sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to . grad f: mm - hmm . grad e: so `` in france , uh , watergate would n't have hurt nixon `` or something like that . um , well , you say , `` alright , i 'm supposed to add some structure to my model of this hypothetical past france universe `` or something like that . the information in the sentence tells you that much but it does n't tell you like exactly what it what the point of doing so is . so for example , depending on the linguistic con uh , context it could be like the question is for example , what does `` watergate `` refer to there ? does it , you know does it refer to , um if you just hear that sentence cold , the assumption is that when you say `` watergate `` you 're referring to `` a watergate - like scandal as we might imagine it happening in france `` . but in a different context , `` oh , you know , if nixon had apologized right away it would n't you know , watergate would n't have hurt him so badly in the us and in france it would n't have hurt him at all `` . now we 're s now that `` watergate `` we 're now talking about the real one , grad f: they 're real , right . grad e: and the `` would `` sort of it 's a sort of different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . grad f: i see right . grad e: in the first case , hypothetically we 're imagining that watergate happened in france . grad f: hmm . grad e: in the second case we 're imagining hypothetically that nixon had apologized right away grad f: mm - hmm . grad e: or something . right ? grad f: right . grad e: so a lot of this is n't happening at the grammatical level . professor c: correct . grad e: uh , um , and so grad f: mm - hmm . grad e: i do n't know where that sits then , grad a: hmm . grad e: sort of the idea of sorting out what the person meant . grad f: it seems like , um , the grammatical things such as the auxiliaries that you know introduce these conditionals , whatever , give you sort of the the most basi grad e: mm - hmm . grad f: th those we i think we can figure out what the possibilities are , right ? grad e: mm - hmm . grad f: there are sort of a relatively limited number . and then how they interact with some extra thing like `` in france `` or `` if such - and - such `` , that 's like there are certain ways that they c they can grad e: yeah . grad f: you know , one is a more specific version of the general pattern that the grammat grammar gives you . grad e: yeah . grad f: i think . but , you know , whatever , professor c: yeah , in the short run all we need is a enough mechanism on the form side to get things going . grad f: we we 're grad e: mm - hmm . yeah . professor c: uh , i uh , you you grad e: but the whole point of the whole point of what fauconnier and turner have to say about , uh , mental spaces , and blending , and all that stuff is that you do n't really get that much out of the sentence . you know , there 's not that much information contained in the sentence . it just says , `` here . add this structure to this space . `` and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean a hundred different things depending on , quote , `` what the space configuration is at the time of utterance `` . grad f: mm - hmm . mm - hmm . grad e: and so somebody 's gon na have to be doing a whole lot of work but not me , i think . professor c: well i think that 's right . oh , i yeah , i , uh , uh i think that 's not k i th i do n't think it 's completely right . i mean , in fact a sentence examples you gave in f did constrain the meaning b the form did constrain the meaning , grad e: yeah . professor c: and so , um , it is n't , uh grad e: sure , but like what what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really . grad f: that 's ok . we usually do n't know the point of the sentence at all . grad e: yeah . grad f: but we know what it 's trying to say . professor c: yeah . grad e: y yeah . grad f: we we know that it 's what predication it 's setting up . professor c: but but bottom line , i agree with you , grad e: yeah . grad f: that 's all . professor c: that that that we 're not expecting much out of the , uh f grad e: yeah . grad f: purely linguistic cues , right ? professor c: uh , the purely form cues , yeah . grad f: so . professor c: and , um i mean , you 're you 're the linguist grad f: mmm . professor c: but , uh , it seems to me that th these we we you know , we 've talked about maybe a half a dozen linguistics theses in the last few minutes or something . grad e: yeah , yeah . professor c: yeah , i mean grad e: yeah . oh , yeah . professor c: uh , i i mean , that that 's my feeling that that these are really hard uh , problems that decide exactly what what 's going on . grad e: mm - hmm . yeah . yeah . professor c: ok . grad f: ok , so , um , one other thing i just want to point out is there 's a lot of confusion about the terms like `` profile , designate , focus `` , et cetera , et cetera . professor c: uh , right , right , right . grad e: mm - hmm . grad f: um , for now i 'm gon na say like `` profile `` 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so `` hypotenuse `` , you profiled this guy against the background of the right t right triangle . grad e: mm - hmm . grad f: ok . and the second use , um , is in framenet . it 's slightly different . oh , i was asking hans about this . they use it to really mean , um , this in a frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which i 'm not saying one and two are mutually exclusive but they 're they 're different meanings . professor c: right . grad e: mm - hmm . grad f: so the closest thing so i was thinking about how it relates to this notation . for us , um ok , so how is it professor c: does that is that really what they mean in in grad f: so `` designate `` framenet ? professor c: i did n't know that . grad f: framenet ? yeah , yeah . i i mean , i i was a little bit surprised about it too . professor c: yeah . grad f: i knew that i thought that that would be something like there 's another term that i 've heard for that thing professor c: right , ok . grad f: but they i mean uh , well , at least hans says they use it that way . and professor c: well , i 'll check . grad f: and may maybe he 's wrong . anyway , so i think the the `` designate `` that we have in terms of meaning is really the `` highlight this thing with respect to everything else `` . ok ? professor c: right . grad f: so this is what what it means . but the second one seems to be useful but we might not need a notation for it ? we do n't have a notation for it but we might want one . so for example we 've talked about if you 're talking about the lexical item `` walk `` , you know it 's an action . well , it also has this idea it carries along with it the idea of an actor or somebody 's gon na do the walking . or if you talk about an adjective `` red `` , it carries along the idea of the thing that has the property of having color red . so we used to use the notation `` with `` for this professor c: right . grad f: and i think that 's closest to their second one . so i d do n't yet know , i have no commitment , as to whether we need it . it might be it 's the kind of thing that w a parser might want to think about whether we require you know , these things are like it 's semantically part of it professor c: n no , no . well , uh , th critically they 're not required syntactically . often they 're pres presu presupposed and all that sort of stuff . grad f: right . right , right . yeah , um , definitely . so , um , `` in `` was a good example . if you walk `` in `` , like well , in what ? professor c: right , there 's grad f: you know , like you have to have the { comment } so so it 's only semantically is it it is still required , say , by simulation time though professor c: right . grad f: to have something . so it 's that i meant the idea of like that the semantic value is filled in by sim simulation . i do n't know if that 's something we need to spa to to like say ever as part of the requirement ? or the construction ? or not . we 'll we 'll again defer . professor c: or i mean , or or , uh so the grad f: have it construed , professor c: yeah , yeah . grad f: is that the idea ? just point at robert . whenever i 'm confused just point to him . professor c: right . it 's it 's his thesis , right ? grad f: you tell me . professor c: anyway , grad f: ok . professor c: right , yeah , w this is gon na be a b you 're right , this is a bit of in a mess and we still have emphasis as well , or stress , or whatever . grad f: ok , well we 'll get , uh uh , i we have thoughts about those as well . professor c: yeah . great . grad f: um , the i w i would just s some of this is just like my you know , by fiat . i 'm going to say , this is how we use these terms . i do n't - you know , there 's lots of different ways in the world that people use it . professor c: i that 's fine . grad e: yeah . grad f: i think that , um , the other terms that are related are like focus and stress . professor c: mm - hmm . grad f: so , s i think that the way i we would like to think , uh , i think is focus is something that comes up in , i mean , lots of basically this is the information structure . professor c: mm - hmm . grad f: ok , it 's like uh , it 's not it might be that there 's a syntactic , uh , device that you use to indicate focus or that there are things like , you know , i think keith was telling me , { comment } things toward the end of the sentence , post - verbal , tend to be the focused focused element , grad e: mmm . grad f: the new information . you know , if i `` i walked into the room `` , you tend to think that , whatever , `` into the room `` is sort of like the more focused kind of thing . grad e: mm - hmm . yeah . grad f: and when you , uh , uh , you have stress on something that might be , you know , a cue that the stressed element , or for instance , the negated element is kind of related to information structure . so that 's like the new the sort of like import or whatever of of this thing . uh , so so i think that 's kind of nice to keep `` focus `` being an information structure term . `` stress `` i th and then there are different kinds of focus that you can bring to it . so , um , like `` stress `` , th stress is kind of a pun on you might have like whatever , like , um , accent kind of stress . grad e: mm - hmm . grad f: and that 's just a uh , w we 'll want to distinguish stress as a form device . you know , like , oh , high volume or whatever . grad e: yeah . grad f: um , t uh , and distinguish that from it 's effect which is , `` oh , the kind of focus we have is we 're emphasizing this value often as opposed to other values `` , right ? so focus carries along a scope . like if you 're gon na focus on this thing and you wan na know it sort of evokes all the other possibilities that it was n't . grad e: mm - hmm . grad f: um , so my classic my now - classic example of saying , `` oh , he did go to the meeting ? `` , grad e: yeah . grad f: that was my way of saying as opposed to , you know , `` oh , he did n't g `` or `` there was a meeting ? `` grad e: yeah . grad f: i think that was the example that was caught on by the linguists immediately . grad e: yeah . grad f: and so , um , the like if you said he you know , there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , uh grad e: mm - hmm . grad f: `` he walked to the meeting `` as opposed to `` he ran `` , or `` he did walk to the meeting `` as opposed to `` he did n't walk `` . you know , grad e: mm - hmm . grad f: so we need to have a notation for that which , um , i think that 's still in progress . so , sort of i 'm still working it out . but it did one one implication it does f have for the other side , which we 'll get to in a minute is that i could n't think of a good way to say `` here are the possible things that you could focus on `` , cuz it seems like any entity in any sentence , you know , or any meaning component of anyth you know all the possible meanings you could have , any of them could be the subject of focus . professor c: mmm . grad f: but i think one the one thing you can schematize is the kind of focus , right ? so for instance , you could say it 's the the tense on this as opposed to , um , the the action . ok . or it 's uh , it 's an identity thing or a contrast with other things , or stress this value as opposed to other things . so , um , it 's it is kind of like a profile profile - background thing but i i ca n't think of like the limited set of possible meanings that you would that you would focu grad e: light up with focus , yeah . grad f: light highlight as opposed to other ones . so it has some certain complications for the , uh , uh later on . li - i mean , uh , the best thing i can come up with is that information has a list of focused elements . for instance , you oh , one other type that i forgot to mention is like query elements and that 's probably relevant for the like `` where is `` , you know , `` the castle `` kind of thing ? grad e: mm - hmm . grad f: because you might want to say that , um , location or cert certain wh words bring you know , sort of automatically focus in a , you know , `` i do n't know the identity of this thing `` kind of way on certain elements . so . ok . anyway . so that 's onl there are there are many more things that are uncl that are sort of like a little bit unstable about the notation but it 's most i think it 's this is , you know , the current current form . other things we did n't totally deal with , um , grad e: oh , there 's a bunch . grad f: well , we 've had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . grad e: yeah . grad f: you know , a a nominal expression . grad e: yeah . grad f: and , um , i mean , we should have put an example of this and we could do that later . grad e: yeah . grad f: but i think the not inherently like the general principles still work though , that , um , we can have constructions that have sort of constituent structure in that there is like , you know , for instance , one uh , you know , they they have constituents , right ? so you can like nest things when you need to , but they can also overlap in a sort of flatter way . so if you do n't have like a lot of grammar experience , then like this this might , you know , be a little o opaque . but , you know , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's i think that 's sort of the main thing we wanted to aim for grad e: mm - hmm . grad f: and so far it 's worked out ok . professor c: good . grad f: so . ok . grad a: i can say two things about the f grad f: yes . grad a: maybe you want to forget stress . this my f grad f: as a word ? grad a: no , as as just do n't do n't think about it . grad f: as a what 's that ? grad a: if grad f: sorry . grad a: canonically speaking you can if you look at a a curve over sentence , you can find out where a certain stress is and say , `` hey , that 's my focus exponent . `` grad e: right . grad f: mm - hmm . grad a: it does n't tell you anything what the focus is . if it 's just that thing , grad f: mm - hmm . or the constituent that it falls in . grad a: a little bit more or the whole phrase . grad e: mm - hmm . grad a: um grad f: you mean t forget about stress , the form cue ? grad a: the form bit grad e: yeah . grad a: because , uh , as a form cue , um , not even trained experts can always well , they can tell you where the focus exponent is sometimes . grad f: ok . grad a: and that 's also mostly true for read speech . in in real speech , um , people may put stress . it 's so d context dependent on what was there before , phrase ba breaks , um , restarts . grad f: yeah . mm - hmm . grad a: it 's just , um it 's absurd . it 's complicated . grad f: ok , grad a: and all grad e: yeah , i mean , i i 'm sort of inclined to say let 's worry about specifying the information structure focus of the sentence grad f: i believe you , yeah . grad e: and then , grad f: mm - hmm . ways that you can get it come from th grad e: hhh , { comment } the phonology component can handle actually assigning an intonation contour to that . grad f: right . grad e: you know , i mean , later on we 'll worry about exactly how grad a: or or map from the contour to to what the focus exponent is . grad e: y yeah . exactly . grad f: mm - hmm . grad e: but figure out how the grad a: but , uh , if you do n't know what you 're what you 're focus is then you 're you 're hopeless - uh - ly lost anyways , grad e: yeah . grad f: right . that 's fine , yeah . mm - hmm . grad a: and the only way of figuring out what that is , is , um , by sort of generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one does n't . grad f: mm - hmm . grad a: and then you 're left with a couple three . so , you know , again , that 's something that h humans can do , grad f: mm - hmm . grad a: um , but far outside the scope of of any anything . so . you know . it 's grad f: ok . well , uh , yeah , i would n't have assumed that it 's an easy problem in in absence of all the oth grad a: u u grad f: you need all the other information i guess . grad a: but it 's it 's what it uh , it 's pretty easy to put it in the formalism , though . i mean , because grad f: yeah . grad a: you can just say whatever stuff , `` i is the container being focused or the the entire whatever , both , and so forth . `` grad f: mm - hmm , mm - hmm . grad e: mm - hmm . grad f: yeah . exactly . so the sort of effect of it is something we want to be able to capture . professor c: yeah , so b b but i think the poi i 'm not sure i understand but here 's what i th think is going on . that if we do the constructions right when a particular construction matches , it the fact that it matches , does in fact specify the focus . grad f: w uh , i 'm not sure about that . professor c: ok . grad f: or it might limit it cert certainly constrains the possibilities of focus . professor c: uh k uh , at at the very least it constrai grad f: i think that 's that 's , th that 's certainly true . and depending on the construction it may or may not f specify the focus , right ? professor c: oh , uh , for sure , yes . there are constrai yeah , it 's not every but there are constructions , uh , where you t explicitly take into account those considerations grad f: yeah . mm - hmm . professor c: that you need to take into account in order to decide which what is being focused . grad f: mm - hmm . grad a: mm - hmm . so we talked about that a little bit this morning . `` john is on the bus , not nancy . `` grad f: mm - hmm . grad a: so that 's focuses on john . professor c: right . grad f: hmm . grad a: `` john is on the bus and not on the train . `` grad f: mm - hmm . grad a: `` john is on the bus `` versus `` john is on the train . `` professor c: right . grad f: right . grad a: and `` john is on the bus `` versus `` was `` , and e grad f: is on . `` john is on the bus `` . yeah . yeah . grad a: `` it 's the bu `` so e professor c: right . yeah , all all of those . grad a: all of these professor c: yeah . grad f: right . grad a: and will we have u is it all the same constructions ? just with a different foc focus constituent ? grad f: yeah , i would say that argument structure in terms of like the main like sort of , grad a: mm - hmm . grad f: i do n't know the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why i was talking about overlapping constructions . so , then you have a separate thing that picks out , you know , stress on something relative to everything else . professor c: yeah . so , the question is actually grad e: mm - hmm . professor c: oh , i 'm sorry , grad f: and it would professor c: go ahead , grad f: yeah , professor c: finish . grad f: and it w and that would have to uh it might be ambiguous as , uh , whether it picks up that element , or the phrase , or something like that . but it 's still is limited possibility . grad a: hmm . grad f: so that should , you know , interact with it should overlap with whatever other construction is there . grad a: yeah . professor c: s s the question is , do we have a way on the other page , uh , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , or something . grad f: mm - hmm . well , so that 's why i was saying how since i could n't think of an easy like limited way of doing it , um , all i can say is that information structure has a focused slot professor c: right . grad f: and i think that should be able to refer to professor c: so that 's down at the bottom here when we get over there . ok . grad f: yeah , and , infer and i do n't have i do n't have a great way or great examples professor c: i 'll - i 'll wait . ok . grad f: but i think that something like that is probably gon na be , uh , more more what we have to do . grad a: hmm . professor c: ok . grad f: but , um , grad a: so grad f: ok , that was one comment . and you had another one ? grad a: yeah , well the once you know what the focus is the everything else is background . how about `` topic - comment `` that 's the other side of information . grad f: how about what ? grad a: topic - comment . grad f: yeah , so that was the other thing . and so i did n't realize it before . it 's like , `` oh ! `` it was an epiphany that it you know , topic and focus are a contrast set . so topic is topic - focused seems to me like , um , background profile , ok , or a landmark trajector , or some something like that . there 's there 's definitely , um , that kind of thing going on . grad a: mmm . grad f: now i do n't know whether i n i do n't have as many great examples of like topic - indicating constructions on like focus , right ? um , topic it seems kind of you know , i think that might be an ongoing kind of thing . grad a: mm - hmm . grad e: japanese has this though . you know . grad f: topic marker ? grad a: yeah . grad e: yeah , that 's what `` wa `` is , uh , just to mark which thing is the topic . grad f: mm - hmm . grad e: it does n't always have to be the subject . grad f: mm - hmm . right . so again , information structure has a topic slot . and , you know , i stuck it in thinking that we might use it . grad a: mm - hmm . grad f: um , i think i stuck it in . professor c: yep , it 's there . grad f: um , and one thing that i did n't do consistently , um , is when we get there , is like indicate what kind of thing fits into every role . i think i have an idea of what it should be but th you know , so far we 've been getting away with like either a type constraint or , um , you know , whatever . i forg it 'll be a frame . you know , it 'll be it 'll be another predication or it 'll be , um , i do n't know , some value from from some something , some variable and scope or something like that , or a slot chain based on a variable and scope . ok , so well that 's should we flip over to the other side officially then ? grad a: mm - hmm , hmm . grad e: ok , side one . grad f: i keep , uh , like , pointing forward to it . yeah . now we 'll go back to s ok , so this does n't include something which mi mi may have some effect on on it , which is , um , the discourse situation context record , right ? so i did n't i i meant just like draw a line and like , you know , you also have , uh , some tracking of what was going on . professor c: right . grad f: and sort of this is a big scale comment before i , you know , look into the details of this . but for instance you could imagine instead of having i i changed the name of um it used to be `` entities `` . so you see it 's `` scenario `` , `` referent `` and `` discourse segment `` . and `` scenario `` is essentially what kind of what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw draw in order to paint your picture , a bunch of frames , bi and bindings , right ? um , and obviously there are other ones that are not included here , general cultural frames and general like , uh , other action f grad e: mm - hmm . grad f: you know , specific x - schema frames . ok , whatever . the middle thing used to be `` entities `` because you could imagine it should be like really a list where here was various information . and this is intended to be grammatically specifiable information about a referent uh , you know , about some entity that you were going to talk about . so `` harry walked into the room `` , `` harry `` and `` room `` , you know , the room th but they would be represented in this list somehow . and it could also have for instance , it has this category slot . um , it should be either category or in or instance . basically , it could be a pointer to ontology . so that everything you know about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , um ki the ones i included here are slightly arbitrary but you could imagine that , um , you need to figure out wheth if it 's a group whether , um , some event is happening , linear time , linear spaces , like , you know , are are they doing something serially or is it like , um , uh i 'm i 'm not sure . because this partly came from , uh , talmy 's schema and i 'm not sure we 'll need all of these actually . but um , and then the `` status `` i used was like , again , in some languages , you know , like for instance in child language you might distinguish between different status . so , th the the big com and and finally `` discourse segment `` is about sort of speech - act - y information structure - y , like utterance - specific kinds of things . so the comment i was going to make about , um , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have a set of entities that you 're sort of referring to . and you might that might be sort of a general , i do n't know , database of all the things in this discourse that you could refer to . and i changed to `` reference `` cuz i would say , for a particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . for instance , i know it 's going to be plural . i know it 's gon na be feminine or something like that . and and these could actually just point to , you know , the the id in my other list of enti active entities , right ? so , um , uh , th there 's there 's all this stuff about discourse status . we 've talked about . i almost listed `` discourse status `` as a slot where you could say it 's active . you know , there 's this , um , hierarchy uh there 's a schematization of , you know , things can be active or they can be , um , accessible , inaccessible . grad e: yeah . grad f: it was the one that , you know , keith , um , emailed to us once , to some of us , not all of us . and the thing is that that i noticed that that , um , list was sort of discourse dependent . it was like in this particular set , s you know , instance , it has been referred to recently or it has n't been , grad e: yeah . grad f: or this is something that 's like in my world knowledge but not active . professor c: this uh yeah , well there there seems to be context properties . grad f: so . professor c: yeah . grad f: yeah , they 're contex and for instance , i used to have a location thing there but actually that 's a property of the situation . and it 's again , time , you know at cert certain points things are located , you know , near or far from you professor c: well , uh , uh , this is recursive grad f: and professor c: cuz until we do the uh , mental space story , we 're not quite sure { comment } th - th grad f: yeah . professor c: which is fine . we 'll just we 'll j grad f: yeah , yeah . so some of these are , uh professor c: we just do n't know yet . grad f: right . so i so for now i thought , well maybe i 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . um , and i left the slot , `` predications `` , open because you can have , um , things like `` the guy i know from school `` . grad e: mm - hmm . grad f: or , you know , like your referring expression might be constrained by certain like unbounded na amounts of prep you know , predications that you might make . and it 's unclear whether i mean , you could just have in your scenario , `` here are some extra few things that are true `` , right ? grad e: mm - hmm . grad f: and then you could just sort of not have this slot here . right ? you 're but but it 's used for identification purposes . professor c: right . grad e: yeah . grad f: so it 's it 's a little bit different from just saying `` all these things are true from my utterance `` . grad e: yeah . grad f: um . grad e: right , `` this guy i know from school came for dinner `` does not mean , um , `` there 's a guy , i know him from school , and he came over for dinner `` . that 's not the same effect . grad f: yeah , it 's a little bit it 's a little bit different . right ? so or maybe that 's like a restrictive , non - restrictive grad e: yeah . grad f: you know , it 's like it gets into that kind of thing for um , but maybe i 'm mixing , you know this is kind of like the final result after parsing the sentence . grad e: mm - hmm . grad f: so you might imagine that the information you pass to , you know in identifying a particular referent would be , `` oh , some `` you know , `` it 's a guy and it 's someone i know from school `` . grad e: yeah . grad f: so maybe that would , you know , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find you know , either create this reference , grad e: mm - hmm . grad f: in which case it 'd be created here , and you know , so so you could imagine that this might not so , uh , i 'm uncommitted to a couple of these things . grad a: but to make it m precise at least in my mind , uh , it 's not precise . grad f: um . grad a: so `` house `` is gender neuter ? in reality grad f: um , it could be in grad a: or in professor c: semantically . grad a: semantically . grad f: semantically , yeah . yeah . grad a: so grad f: so it uh , uh , a table . you know , a thing that c does n't have a gender . so . uh , it could be that i mean , maybe you 'd maybe not all these i mean , i wou i would say that i tried to keep slots here that were potentially relevant to most most things . grad a: no , just to make sure that we everybody that 's completely agreed that it it has nothing to do with , uh , form . grad f: yeah . ok , that is semantic as opposed to yeah . yeah . that 's right . um . grad a: then `` predications `` makes sense to to have it open for something like , uh , accessibility or not . grad f: s so again open to various things . grad a: yeah . grad f: right . ok , so . let 's see . so maybe having made that big sca sort of like large scale comment , should i just go through each of these slots uh , each of these blocks , um , a little bit ? grad e: sure . grad f: um , mostly the top one is sort of image schematic . and just a note , which was that , um s so when we actually ha so for instance , um , some of them seem more inherently static , ok , like a container or sort of support - ish . and others are a little bit seemingly inherently dynamic like `` source , path , goal `` is often thought of that way or `` force `` , or something like that . but in actual fact , i think that they 're intended to be sort of neutral with respect to that . and different x - schemas use them in a way that 's either static or dynamic . so `` path `` , you could just be talking about the path between this and this . grad e: mmm . grad f: and you know , `` container `` that you can go in and out . all of these things . and so , um , i think this came up when , uh , ben and i were working with the spaniards , um , the other day the `` spaniettes `` , as we called them um , to decide like how you want to split up , like , s image schematic contributions versus , like , x - schematic contributions . how do you link them up . and i think again , um , it 's gon na be something in the x - schema that tells you `` is this static or is this dynamic `` . so we definitely need that sort of aspectual type gives you some of that . um , that , you know , is it , uh , a state or is it a change of state , or is it a , um , action of some kind ? grad a: uh , i i i is there any meaning to when you have sort of parameters behind it and when you do n't ? grad f: uh . yeah . grad a: just means grad f: oh , oh ! you mean , in the slot ? grad a: mm - hmm . grad f: um , no , it 's like x - sc it 's it 's like i was thinking of type constraints but x - schema , well it obviously has to be an x - schema . `` agent `` , i mean , the the performer of the x - schema , that s depends on the x - schema . you know , and i in general it would probably be , you know grad e: so the difference is basically whether you thought it was obvious what the possible fillers were . grad f: yeah , basically . grad a: mm - hmm . grad e: ok . grad f: um , `` aspectual type `` probably is n't obvious but i should have so , i just neglected to stick something in . `` perspective `` , `` actor `` , `` undergoer `` , `` observer `` , um , grad b: mmm . grad f: i think we 've often used `` agent `` , `` patient `` , obser grad e: `` whee ! `` that 's that one , right ? grad f: yeah , exactly . exactly . um , and so one nice thing that , uh , we had talked about is this example { comment } of like , if you have a passive construction then one thing it does is ch you know definitely , it is one way to for you to , you know , specifically take the perspective of the undergoing kind of object . and so then we talked about , you know , whether well , does that specify topic as well ? well , maybe there are other things . you know , now that it 's subject is more like a topic . and now that , you know anyway . so . sorry . i 'm gon na trail off on that one cuz it 's not that f important right now . professor c: n now , for the moment we just need the ability to l l write it down if if somebody figured out what the rules were . grad f: um , to know how yeah . yeah . exactly . professor c: yeah . grad f: um , some of these other ones , let 's see . so , uh , one thing i 'm uncertain about is how polarity interacts . professor c: mm - hmm . grad f: so polarity , uh , is using for like action did not take place for instance . so by default it 'll be like `` true `` , i guess , you know , if you 're specifying events that did happen . you could imagine that you skip out this you know , leave off this polarity , you know , not do n't have it here . and then have it part of the speech - act in some way . professor c: mm - hmm . grad f: there 's some negation . but the reason why i left it in is cuz you might have a change of state , let 's say , where some state holds and then some state does n't hold , and you 're just talking , you know if you 're trying to have the nuts and bolts of simulation you need to know that , you know , whatever , the holder does n't and professor c: no , i th i think at this lev which is it should be where you have it . grad f: ok , it 's so it 's it 's it 's fine where it is . professor c: i mean , how you get it may may in will often involve the discourse grad f: so , ok . may come from a few places . professor c: but but by the time you 're simulating you sh y you should know that . grad f: right . right . grad e: so , i 'm still just really not clear on what i 'm looking at . the `` scenario `` box , like , what does that look like for an example ? like , not all of these things are gon na be here . grad f: yeah . professor c: correct . grad e: this is just basically says grad f: mm - hmm . it 's a grab bag of grad e: `` part of what i 'm going to hand you is a whole bunch of s uh , schemas , image , and x - schemas . here are some examples of the sorts of things you might have in there `` . grad f: so that 's exactly what it is . grad e: ok . grad f: and for a particular instance which i will , you know , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , you know , `` into `` you know , definition . grad e: mm - hmm . mm - hmm . grad f: so you would eventually have instances filled in with various various values for all the different slots . grad e: mm - hmm . grad f: and they 're bound up in , you know , their bindings and and and values . professor c: w it c grad e: ok . do you have to say about the binding in your is there a slot in here for that tells you how the bindings are done ? professor c: no , no , no . i let 's see , i think we 're we 're not i do n't think we have it quite right yet . so , uh , what this is , grad e: ok . professor c: let 's suppose for the moment it 's complete . ok , uh , then this says that when an analysis is finished , the whole analysis is finished , { comment } you 'll have as a result , uh , some s resulting s semspec for that utterance in context , grad e: ok . mm - hmm . professor c: which is made up entirely of these things and , uh , bindings among them . and bindings to ontology items . grad e: mm - hmm . professor c: so that that the who that this is the tool kit under whi out of which you can make a semantic specification . grad e: mm - hmm . mm - hmm . professor c: so that 's a . but b , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . grad e: ok . mm - hmm . professor c: so this is an that anything you have , in the party line , { comment } anything you have as the semantic side of constructions comes , from pieces of this ignoring li grad e: ok . professor c: i mean , in general , you ignore lots of it . grad e: right . professor c: but it 's got to be pieces of this along with constraints among them . grad e: ok . professor c: uh , so that the , you know , goal of the , uh uh , `` source , path , goal `` has to be the landmark of the conta you know , the interior of this container . grad e: mm - hmm . professor c: or whate whatever . grad e: yeah . professor c: so those constraints appear in constructions grad e: mm - hmm . professor c: but pretty much this is the full range of semantic structures available to you . grad e: ok . grad f: except for `` cause `` , that i forgot . but anyway , there 's som some kind of causal structure for composite events . grad e: yeah . professor c: ok , good . let 's let 's mark that . so we need a c grad f: uh , i mean , so it gets a little funny . these are all so far these structures , especially from `` path `` and on down , these are sort of relatively familiar , um , image schematic kind of slots . now with `` cause `` , uh , the fillers will actually be themselves frames . right ? professor c: right . grad e: mm - hmm . grad f: so you 'll say , `` event one causes event b professor c: and and and and this this this again may ge our , um and we and and , of course , worlds . grad f: uh , event two `` , and grad e: mm - hmm . grad f: yeah . so that 's , uh these are all implicitly one within , uh within one world . um , even though saying that place takes place , whatever . uh , if y if i said `` time `` is , you know , `` past `` , that would say `` set that this world `` , you know , `` somewhere , before the world that corresponds to our current speech time `` . grad e: mm - hmm . mm - hmm . yeah . grad f: so . but that that that 's sort of ok . the the within the event it 's st it 's still one world . um . yeah , so `` cause `` and other frames that could come in i mean , unfortunately you could bring in say for instance , um , uh , `` desire `` or something like that , grad e: mm - hmm . grad f: like `` want `` . and actually there is right now under `` discourse segments `` , um , `` attitude `` ? grad e: mm - hmm . grad f: `` volition `` ? could fill that . so there are a couple things where i like , `` oh , i 'm not sure if i wanted to have it there grad e: well that 's grad f: or `` basically there was a whole list of of possible speaker attitudes that like say talmy listed . and , like , well , i do n't you know , it was like `` hope , wish . desire `` , professor c: right . grad e: uh - huh . grad f: blah - blah - blah . and it 's like , well , i feel like if i wanted to have an extra meaning i do n't know if those are grammatically marked in the first place . so they 're more lexically marked , right ? grad e: mmm . grad f: at least in english . so if i wanted to i would stick in an extra frame in my meaning , saying , e so th it 'd be a hierarchical frame them , right ? you know , like `` naomi wants wants su a certain situation and that situation itself is a state of affairs `` . professor c: s right . so so , `` want `` itself can be i i i i i grad f: u can be just another frame that 's part of your professor c: well , and it i basically it 's an action . in in our s in our in our grad f: yeah . situation . { comment } right , right . professor c: in in our in our s terminology , `` want `` can be an action and `` what you want `` is a world . grad f: mm - hmm . grad b: hmm . professor c: so that 's i mean , it 's certainly one way to do it . grad f: mmm . professor c: yeah , there there are other things . grad e: mm - hmm . professor c: causal stuff we absolutely need . mental space we need . grad f: mm - hmm . professor c: the context we need . um , so anyway , keith so is this comfortable to you that , uh , once we have this defined , it is your tool kit for building the semantic part of constructions . grad e: mm - hmm . professor c: and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . grad e: mm - hmm . professor c: and that 's the wh and and i mean , that according to the party line , that 's the whole story . grad e: yeah . mm - hmm . yeah . um . y right . that makes sense . so i mean , there 's this stuff in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and i guess that some of the discourse segment stuff is that where you would sa grad f: mm - hmm . grad e: i mean , that 's ok , that 's where the information structure is which sort of is a kind of profiling on different parts of , um , of this . grad f: right . exactly . grad e: i mean , what 's interesting is that the information structure stuff hmm . there 's almost i mean , we keep coming back to how focus is like this this , uh , trajector - landmark thing . grad f: yeah . grad e: so if i say , um , you know , `` in france it 's like this `` . you know , great , we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like `` in france it 's like this `` . and therefore you 're supposed to say , `` boy , life sure `` grad f: right . grad e: you know , `` in france kids are allowed to drink at age three `` . and w you 're that 's not just a fact about france . you also conclude something about how boring it is here in the u s . right ? grad f: right , right . professor c: right . grad e: and so grad f: s so i would prefer not to worry about that for right now grad e: ok . grad f: and to think that there are , um , grad e: that comes in and , uh grad f: discourse level constructions in a sense , topic topic - focus constructions that would say , `` oh , when you focus something `` then grad e: mm - hmm . yeah . grad f: just done the same way just actually in the same way as the lower level . if you stressed , you know , `` john went to the `` , you know , `` the bar `` whatever , you 're focusing that grad e: mm - hmm . grad f: and a in a possible inference is `` in contrast to other things `` . grad e: yeah . grad f: so similarly for a whole sentence , you know , `` in france such - and - such happens `` . grad e: yeah . yeah , yeah . grad f: so the whole thing is sort of like again implicitly as opposed to other things that are possible . grad e: yeah . grad a: uh , just just , uh , look read uh even sem semi formal mats rooth . grad f: i mean yeah . grad a: if you have n't read it . it 's nice . grad f: uh - huh . grad a: and just pick any paper on alternative semantics . grad f: uh - huh . grad e: ok . grad a: so that 's his that 's the best way of talking about focus , is i think his way . grad e: ok , what was the name ? grad a: mats . mats . rooth . grad e: ok . grad a: i think two o 's , yes , th . grad e: ok . grad a: i never know how to pronounce his name because he 's sort of , professor c: s swede ? grad a: uh , he is dutch professor c: dutch ? grad a: and , um but very confused background i think . professor c: oh , dutch . grad e: yeah . professor c: uh - huh . grad a: so and , um , grad e: mats gould . grad a: and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . grad e: hmm . grad a: but , um i do n't know where he is right now but alternative semantics is if you type that into an , uh , uh , browser or search engine you 'll get tons of stuff . grad e: ok . ok . ok , thanks . grad a: and what i 'm kind of confused about is is what the speaker and the hearer is is sort of doing there . grad f: so for a particular segment it 's really just a reference to some other entity again in the situation , right ? so for a particular segment the speaker might be you or might be me . grad a: yeah . grad f: um , hearer is a little bit harder . it could be like multiple people . i guess that that that that 's not very clear from here grad a: yeah , but you do n't we ultimately want to handle that analogously to the way we handle time and place , grad f: i mean , that 's not allowed here . grad a: because `` you `` , `` me `` , `` he `` , `` they `` , you know , `` these guys `` , all these expressions , nuh , are in in much the same way contextually dependent as `` here , `` and `` now , `` and `` there `` grad f: mm - hmm . professor c: now , this is this is assuming you 've already solved that . grad f: ye - yeah . professor c: so it 's it 's fred and mary , grad f: so th professor c: so the speaker would be fred and the grad a: ah ! grad f: right , so the constructions might of course will refer , using pronouns or whatever . grad a: mm - hmm . grad f: in which case they have to check to see , uh , who the , uh , speaker in here wa in order to resolve those . but when you actually say that `` he walked into `` , whatever , um , the `` he `` will refer to a particular you you will already have figured who `` he `` or `` you `` , mmm , or `` i `` , maybe is a bett better example , who `` i `` refers to . um , and then you 'd just be able to refer to harry , you know , in wherever that person whatever role that person was playing in the event . grad a: mmm . that 's up at the reference part . grad f: yeah , yeah . grad a: and down there in the speaker - hearer part ? grad f: s so , that 's i think that 's just n for instance , speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is i mean , you know who the speaker is . in fact , that 's kind of constraining how in some ways you know this before you get to the you fill in all the rest of it . i think . professor c: mmm . grad f: i mean , how else would you um grad a: you know , uh , uh , it 's the speaker may in english is allowed to say `` i . `` professor c: yeah . well , here grad a: uh , among the twenty - five percent most used words . grad f: yeah . right . grad a: but would n't the `` i `` then set up the the s s referent that happens to be the speaker this time grad f: mm - hmm . grad a: and not `` they , `` whoever they are . grad f: right , right . grad a: or `` you `` grad f: so grad a: much like the `` you `` could n grad f: s so ok , so i would say ref under referent should be something that corresponds to `` i `` . and maybe each referent should probably have a list of way whatever , the way it was referred to . so that 's `` i `` but , uh , uh , should we say it it refers to , what ? uh , if it were `` harry `` it would refer to like some ontology thing . if it were if it 's `` i `` it would refer to the current speaker , ok , which is given to be like , you know , whoever it is . grad a: well , not not always . i mean , so there 's `` and then he said , i w `` uh - huh . professor c: uh grad f: `` i `` within the current world . grad a: yeah . professor c: yeah . that 's right . so so again , this uh , this this is gon na to get us into the mental space stuff grad f: yeah , yeah , yeah , yeah . professor c: and t because you know , `` fred said that mary said `` , and whatever . grad e: mmm . grad f: mm - hmm . professor c: and and so we 're , uh gon na have to , um , chain those as well . grad a: mm - hmm . twhhh - whhh . but grad f: mm - hmm . so this entire thing is inside a world , professor c: right . right . grad f: not just like the top part . professor c: i i think , uh grad f: that 's grad a: mm - hmm . professor c: except s it 's it 's trickier than that because um , the reference for example so he where it gets really tricky is there 's some things , grad f: yeah . professor c: and this is where blends and all terribl so , some things which really are meant to be identified and some things which are n't . grad f: yeah . right . professor c: and again , all we need for the moment is some way to say that . grad f: right . so i thought of having like for each referent , having the list of of the things t with which it is identified . you know , which which , uh you know , you you you professor c: you could do that . grad f: for instance , um so , i guess , it sort of depends on if it is a referring exp if it 's identifiable already or it 's a new thing . grad e: mm - hmm . grad f: if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , um , usually w something in a situation , right ? or something in ontology . professor c: uh - huh . grad f: so , there 's a you know , whatever , it c it could point at one of these . professor c: i just had a i just had an an idea that would be very nice if it works . grad f: for what ? professor c: uh , uh , uh , i have n't told you what it is yet . grad f: if it works . professor c: this was my build - up . grad f: mm - hmm . mmm . professor c: an i an idea that would be nice i grad f: yeah . ok , we 're crossing our fingers . professor c: right . grad b: so we 're building a mental space , good . professor c: if it worked . yeah . grad f: ok . professor c: right , it was a space builder . um , we might be able to handle context in the same way that we handle mental spaces because , uh , you have somewhat the same things going on of , uh , things being accessible or not . grad f: mm - hmm . professor c: and so , i grad f: yep . professor c: it c it it , uh i think if we did it right we might be able to get at least a lot of the same structure . grad f: use the same { comment } yep . professor c: so that pulling something out of a discourse context is i think similar to other kinds of , uh , mental space phenomena . grad b: i see . grad f: mm - hmm . and and professor c: uh , i 've i 've i 've never seen anybody write that up but maybe they did . i do n't know . that may be all over the literature . grad f: yeah . grad e: there 's things like ther you know , there 's all kinds of stuff like , um , in i think i mentioned last time in czech if you have a a verb of saying then grad f: so so by default grad e: um , you know , you say something like or or i was thinking you can say something like , `` oh , i thought , uh , you are a republican `` or something like that . where as in english you would say , `` i thought you were `` . professor c: right . grad e: um , you know , sort of the past tense being copied onto the lower verb does n't happen there , so you have to say something about , you know , tense is determined relative to current blah - blah - blah . grad f: mm - hmm . grad e: same things happens with pronouns . grad f: mm - hmm . grad e: there 's languages where , um , if you have a verb of saying then , ehhh , where ok , so a situation like `` bob said he was going to the movies `` , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have `` i `` there . grad f: mm - hmm . professor c: mm - hmm . grad e: um , and it 's sort of in an extended function professor c: so we would have it be in quotes in english . grad e: yeah . grad b: right . grad e: but it 's not perceived as a quotative construction . grad f: right . professor c: yeah . grad e: i mean , it 's been analyzed by the formalists as being a logophoric pronoun , um which means a pronoun which refers back to the person who is speaking or that sort of thing , right ? professor c: ok . grad f: oh , right . yeah , that makes sense . grad e: um , but uh , that happens to sound like the word for `` i `` but is actually semantically unrelated to it . grad f: oh , no ! professor c: oh , good , i love the formali grad e: um , grad f: really ? grad e: yeah . yeah . grad f: you 're kidding . grad e: there 's a whole book which basically operates on this assumption . uh , mary dalrymple , uh , this book , a ninety - three book on , uh on pronoun stuff . grad f: no , that 's horrible . ok . that 's horrible . { comment } ok . grad e: well , yeah . and then the same thing for asl where , you know , you 're signing and someone says something . and then , you know , so `` he say `` , and then you sort of do a role shift . and then you sign `` i , this , that , and the other `` . grad f: uh - huh . grad e: and you know , `` i did this `` . that 's also been analyzed as logophoric and having nothing to do with `` i `` . and the role shift thing is completely left out and so on . so , i mean , the point is that pronoun references , uh , you know , sort of ties in with all this mental space stuff and so on , and so forth . grad f: uh - huh . grad e: and so , yeah , i mean grad f: yeah . professor c: so that that d that does sound like it 's co consistent with what we 're saying , yeah . grad e: right . yeah . grad f: ok , so it 's kind of like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the h you know , depending on the construction or the whatever , um , you you you 're scope is m might extend out to the the base one . grad e: mm - hmm . professor c: mm - hmm . grad e: yeah . grad f: it would be nice to actually use the same , um , mechanism since there are so many cases where you actually need it 'll be one or the other . grad e: yeah . grad f: it 's like , oh , actually , it 's the same same operation . professor c: oh , ok , so this this is worth some thought . grad f: so . grad e: it 's like it 's like what 's happening that , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ? grad f: yeah , yeah . grad e: so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . grad f: mm - hmm . grad e: and so , grad f: mm - hmm . grad e: um , things like pronoun reference and tense which we 're thinking of as being these discourse - y things actually are relative to a bayes space which can change . grad f: mm - hmm , grad e: and we need all the same machinery . grad f: right . grad a: mm - hmm . grad f: robert . professor c: well , but , uh , this is very good actually grad e: schade . professor c: cuz it it it to the extent that it works , it y grad f: ties it all into it . professor c: it it ties together several of of these things . grad f: yeah . yep . grad a: mm - hmm . mm - hmm . and i 'm sure gon na read the transcript of this one . so . but the , uh , but it 's too bad that we do n't have a camera . you know , all the pointing is gon na be lost . grad e: yeah . grad f: oh , yeah . grad b: well every time nancy giggles it means it means that it 's your job . grad f: yeah , that 's why i said `` point to robert `` , when i did it . grad a: uh . yeah . mmm , is n't i mean , i 'm i was sort of dubious why why he even introduces this sort of reality , you know , as your basic mental space and then builds up grad e: mm - hmm . grad a: d does n't start with some because it 's so obvi it should be so obvious , at least it is to me , { comment } that whenever i say something i could preface that with `` i think . `` nuh ? grad e: yeah . grad a: so there should be no categorical difference between your base and all the others that ensue . grad e: yeah . professor c: no , but there 's there 's a gricean thing going on there , that when you say `` i think `` you 're actually hedging . grad e: yeah , i mean grad f: mmm . it 's like i do n't totally think professor c: right . grad e: yeah . y grad f: i mostly think , uh grad a: yeah , it 's absolutely . grad e: yeah , it 's an it 's an evidential . it 's sort of semi - grammaticalized . people have talked about it this way . and you know , you can do sort of special things . you can , th put just the phrase `` i think `` as a parenthetical in the middle of a sentence and so on , and so forth . grad a: yeah . grad e: so grad f: actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any kind of interesting embedded ways just to mark , you know , uncertainty or something like that . grad e: yeah . grad f: so . grad a: yeah , but about linguistic hedges , i mean , those those tend to be , um , funky anyways because they blur professor c: so we do n't have that in here either do we ? grad e: yeah . grad f: hedges ? professor c: yeah , yeah . grad f: hhh , { comment } i there used to be a slot for speaker , um , it was something like factivity . i could n't really remember what it meant grad e: yeah . grad f: so i took it out . grad e: um . grad f: but it 's something grad e: well we were just talking about this sort of evidentiality and stuff like that , right ? grad f: we we were talking about sarcasm too , right ? oh , oh . grad e: i mean , grad f: oh , yeah , yeah , right . grad e: that 's what i think is , um , sort of telling you what percent reality you should give this professor c: so we probably should . grad f: yeah . grad a: mm - hmm . grad e: or the , you know professor c: confidence or something like that . grad e: yeah , and the fact that i 'm , you know the fact maybe if i think it versus he thinks that might , you know , depending on how much you trust the two of us or whatever , grad f: yeah . grad a: uh great word in the english language is called `` about `` . grad e: you know grad a: if you study how people use that it 's also grad f: what 's the word ? grad a: `` about . `` it 's about professor c: about . grad a: clever . professor c: oh , that in that use of `` about `` , yeah . grad f: oh , oh , oh , as a hedge . grad e: yeah . professor c: and i think and i think y if you want us to spend a pleasant six or seven hours you could get george started on that . grad e: he wrote a paper about thirty - five years ago on that one . grad b: i r i read that paper , professor c: yeah . grad b: the hedges paper ? i read some of that paper actually . grad e: yeah . professor c: yeah . grad e: would you believe that that paper lead directly to the development of anti - lock brakes ? grad f: what ? professor c: no . grad e: ask me about it later i 'll tell you how . when we 're not on tape . grad f: i 'd love to know . grad b: oh , man . grad f: so , and and i think , uh , someone had raised like sarcasm as a complication at some point . professor c: there 's all that stuff . yeah , let 's i i do n't i think grad f: and we just wo n't deal with sarcastic people . professor c: yeah , i mean grad e: i do n't really know what like we we do n't have to care too much about the speaker attitude , right ? like there 's not so many different hhh , { comment } i do n't know , m grad f: certainly not as some well , they 're intonational markers i think for the most part . grad e: yeah . grad f: i do n't know too much about the like grammatical grad e: i just mean there 's lots of different attitudes that that the speaker could have and that we can clearly identify , and so on , and so forth . grad f: yeah . grad e: but like what are the distinctions among those that we actually care about for our current purposes ? professor c: right . right , so , uh , this this raises the question of what are our current purposes . grad f: mm - hmm . professor c: right ? grad e: oh , shoot . grad f: oh , yeah , do we have any ? grad e: here it is three - fifteen already . grad a: mmm . yeah . professor c: uh , so , um , i i do n't know the answer but but , um , it does seem that , you know , this is this is coming along . i think it 's it 's converging . it 's as far as i can tell there 's this one major thing we have to do which is the mental the whole s mental space thing . and then there 's some other minor things . grad f: mm - hmm . professor c: um , and we 're going to have to s sort of bound the complexity . i mean , if we get everything that anybody ever thought about you know , w we 'll go nuts . grad e: yeah . professor c: so we had started with the idea that the actual , uh , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and were n't trying to d you know , there 's all sorts of god knows , irony , and stuff like which you is n't probably of much use in dealing with a tourist guide . grad e: yeah . professor c: yeah ? grad e: yeah . professor c: uh . grad f: m mockery . professor c: right . whatever . so y uh , no end of things th that that , you know , we do n't deal with . grad a: but it professor c: and grad a: i is n't that part easy though professor c: go ahead . grad a: because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to sort of negate whatever the content of that is in terms of irony grad e: yeah . professor c: n no . grad f: mmm . grad a: or professor c: no . grad e: right . grad f: maybe . professor c: no . grad f: yeah , in model theory cuz the semantics is always like `` speaker believes not - p `` , you know ? professor c: right . grad f: like `` the speaker says p and believes not - p `` . grad e: we have a theoretical model of sarcasm now . grad f: but professor c: right . grad e: yeah , right , i mean . professor c: no , no . grad f: right , right , but , professor c: anyway , so so , um , i guess uh , let me make a proposal on how to proceed on that , which is that , um , it was keith 's , uh , sort of job over the summer to come up with this set of constructions . uh , and my suggestion to keith is that you , over the next couple weeks , n grad e: mmm . professor c: do n't try to do them in detail or formally but just try to describe which ones you think we ought to have . grad e: ok . professor c: uh , and then when robert gets back we 'll look at the set of them . grad e: ok . professor c: just just sort of , you know , define your space . grad e: yeah , ok . professor c: and , um , so th these are this is a set of things that i think we ought to deal with . grad e: yeah . professor c: and then we 'll we 'll we 'll go back over it and w people will will give feedback on it . grad e: ok . professor c: and then then we 'll have a at least initial spec of of what we 're actually trying to do . grad e: yeah . professor c: and that 'll also be useful for anybody who 's trying to write a parser . grad e: mm - hmm . professor c: knowing uh grad e: in case there 's any around . grad f: if we knew anybody like that . professor c: right , `` who might want `` et cetera . so , uh grad e: ok . professor c: so a and we get this this , uh , portals fixed and then we have an idea of the sort of initial range . and then of course nancy you 're gon na have to , uh , do your set of but you have to do that anyway . grad f: for the same , yeah , data . yeah , mm - hmm . professor c: so so we 're gon na get the w we 're basically dealing with two domains , the tourist domain and the and the child language learning . grad b: mmm . professor c: and we 'll see what we need for those two . and then my proposal would be to , um , not totally cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . grad e: mm - hmm . professor c: and then as a kind of separate thread , think about the more general things and and all that . grad e: mm - hmm . mm - hmm . grad a: well , i also think the detailed discussion will hit you know , bring us to problems that are of a general nature and maybe even professor c: uh , without doubt . yeah . grad f: yeah . grad a: even suggest some solutions . professor c: but what i want to do is is is to to constrain the things that we really feel responsible for . grad a: yeah . mmm . professor c: so that that we say these are the things we 're really gon na try do by the end of the summer grad e: mm - hmm . professor c: and other things we 'll put on a list of of research problems or something , because you can easily get to the point where nothing gets done because every time you start to do something you say , `` oh , yeah , but what about this case ? `` grad e: mm - hmm . professor c: this is this is called being a linguist . grad a: mmm . grad e: yeah . professor c: and , uh , grad e: basically . grad f: or me . professor c: huh ? grad f: or me . anyways grad b: there 's that quote in jurafsky and martin where where it goes where some guy goes , `` every time i fire a linguist the performance of the recognizer goes up . `` professor c: right . grad f: yeah . grad e: exactly . professor c: right . but anyway . so , is is that does that make sense as a , uh a general way to proceed ? grad f: sure , yeah . grad e: yeah , yeah , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it . professor c: exactly right . grad a: mmm . grad e: got it . grad a: mmm . grad e: ok . grad a: we have a little bit of news , uh , just minor stuff . the one big grad b: ooo , can i ask a grad e: you ran out of power . grad a: huh ? grad b: can i ask a quick question about this side ? grad a: yeah . grad f: yes . grad b: is this , uh was it intentional to leave off things like `` inherits `` and grad f: oops . um , grad e: no . grad f: not really just on the constructions , right ? grad b: yeah , like constructions can inherit from other things , grad f: um , grad b: am i right ? grad f: yeah . grad b: yeah . grad f: i did n't want to think too much about that for for now . grad b: ok . professor c: yeah . grad f: so , uh , maybe it was subconsciously intentional . professor c: yeah , uh yeah . grad e: um , yeah , there should be i i wanted to s find out someday if there was gon na be some way of dealing with , uh , if this is the right term , multiple inheritance , professor c: mm - hmm . grad e: where one construction is inheriting from , uh from both parents , grad f: uh - huh . yep . grad e: uh , or different ones , or three or four different ones . professor c: yeah . so let me grad e: cuz the problem is that then you have to grad f: yeah . grad e: which of you know , which are how they 're getting bound together . grad f: refer to them . professor c: yeah , right , right , right . yeah , yeah , yeah . grad f: yeah , and and there are certainly cases like that . even with just semantic schemas we have some examples . professor c: right . grad f: so , and we 've been talking a little bit about that anyway . professor c: yeah . so what i would like to do is separate that problem out . grad f: inherits . professor c: so um , grad e: ok . professor c: my argument is there 's nothing you can do with that that you ca n't do by just having more constructions . grad e: yeah , yes . professor c: it 's uglier and it d does n't have the deep linguistic insights and stuff . grad e: that 's right . professor c: uh , grad e: but whatever . professor c: right . grad e: yeah , no , no , no no . grad f: uh , those are over rated . grad e: no , by all means , professor c: and so i what i 'd like to do is is in the short run focus on getting it right . grad e: right . uh , sure . professor c: and when we think we have it right then saying , `` aha ! , grad e: yeah . professor c: can we make it more elegant ? `` grad e: yeah , that 's professor c: can can we , uh what are the generalizations , and stuff ? grad e: yeah . connect the dots . yeah . professor c: but rather than try to guess a inheritance structure and all that sort of stuff before we know what we 're doing . grad e: yep . yeah . professor c: so i would say in the short run we 're not gon na b grad e: yeah . professor c: first of all , we 're not doing them yet at all . and and it could be that half way through we say , `` aha ! , we we now see how we want to clean it up . `` grad e: mm - hmm . professor c: uh , and inheritance is only one i mean , that 's one way to organize it but there are others . and it may or may not be the best way . grad e: yeah . grad a: mmm . professor c: i 'm sorry , you had news . grad a: oh , just small stuff . um , thanks to eva on our web site we can now , if you want to run javabayes , uh , you could see get download these classes . and then it will enable you she modified the gui so it has now a m a m a button menu item for saving it into the embedded javabayes format . grad d: mm - hmm . grad b: mmm . grad a: so that 's wonderful . professor c: great . grad a: and , um and she , a you tested it out . do you want to say something about that , that it works , right ? with the grad d: i was just checking like , when we wan na , um , get the posterior probability of , like , variables . you know how you asked whether we can , like , just observe all the variables like in the same list ? you ca n't . grad a: uh - huh . grad d: you have to make separate queries every time . grad a: ok , that 's that 's a bit unfortunate grad d: so yeah . grad a: but for the time being it 's it 's it 's fine to do it grad d: you just have to have a long list of , you know , all the variables . grad a: yeah . but uh grad d: basically . grad f: uh , all the things you want to query , you just have to like ask for separately . grad d: yeah , yeah . grad a: well that 's probably maybe in the long term that 's good news because it forces us to think a little bit more carefully how how we want to get an out output . um , but that 's a different discussion for a different time . and , um , i do n't know . we 're really running late , so i had , uh , an idea yesterday but , uh , i do n't know whether we should even start discussing . professor c: w what yeah , sure , tell us what it is . grad a: um , the construal bit that , um , has been pointed to but has n't been , um , made precise by any means , um , may w may work as follows . i thought that we would , uh that the following thing would be in incredibly nice and i have no clue whether it will work at all or nothing . so that 's just a tangent , a couple of mental disclaimers here . um , imagine you you write a bayes - net , um grad f: bayes ? grad a: bayes - net , grad f: ok . grad a: um , completely from scratch every time you do construal . so you have nothing . just a white piece of paper . professor c: mmm , right . grad a: you consult consult your ontology which will tell you a bunch of stuff , and parts , and properties , uh - uh - uh grad f: grout out the things that that you need . professor c: right . grad a: then y you 'd simply write , uh , these into onto your your white piece of paper . and you will get a lot of notes and stuff out of there . you wo n't get you wo n't really get any c p t 's , therefore we need everything that that configures to what the situation is , ie , the context dependent stuff . so you get whatever comes from discourse but also filtered . uh , so only the ontology relevant stuff from the discourse plus the situation and the user model . grad f: mm - hmm . grad a: and that fills in your cpt 's with which you can then query , um , the the net that you just wrote and find out how thing x is construed as an utterance u . and the embedded javabayes works exactly like that , that once you we have , you know , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the the nice thing about this idea is that you do n't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the the initial notes . but it 's in that respect it 's completely scalable . because it does n't have any prior , um , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work at all , that 'd be kind of funky . professor c: um , it sounds to me like you want p r grad a: p r ms - uh , prm i mean , since you can unfold a prm into a straightforward bayes - net professor c: beca - because it b because no , no , you ca n't . see the the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it . grad a: then you can . mm - hmm , yeah . no , i was m using it generic . so , uh , probabilistic , whatever , relational models . whatever you write it . in professor c: well , no , but it matters a lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case . grad a: and then then instantiate them . that 's ma maybe the the way the only way it works . professor c: yeah , and that 's grad a:  professor c: yeah , that 's the only way it could work . i we have a our local expert on p r uh , but my guess is that they 're not currently good enough to do that . but we 'll we 'll have to see . grad a: but , uh , professor c: uh yes . this is that 's that would be a good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , uh grad a: except there 's no no theorem prover involved . grad f: best explanation . professor c: no , there is n't a theorem prover but there but but the , um , the cove the the p r ms are like rules of inference and you 're you 're coupling a bunch of them together . grad a: mm - hmm , yeah . professor c: and then ins instead of proving you 're trying to , you know , compute the most likely . uh tricky . but you yeah , it 's a good it 's a it 's a good thing to put in your thesis proposal . grad a: what 's it ? professor c: so are you gon na write something for us before you go ? grad a: yes . um . professor c: oh , you have something . grad a: in the process thereof , or whatever . professor c: ok . so , what 's what when are we gon na meet again ? grad f: when are you leaving ? grad a: fri - uh , grad f: thursday , friday ? grad a: thursday 's my last day here . grad d: fri professor c: yeah . grad f: ok . grad a: so i would suggest as soon as possible . do you mean by we , the whole ben gang ? professor c: n no , i did n't mean y just the two of us . we obviously we can we can do this . but the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal and get , uh , another session on feedback on that ? or grad a: we can do it th - thursday again . yeah . grad e: fine with me . should we do the one pm time for thursday since we were on that before or ? grad a: sure . grad e: ok . professor c: alright . grad d: hmm . grad a: thursday at one ? i can also maybe then sort of run through the , uh the talk i have to give at eml which highlights all of our work . professor c: ok . grad a: and we can make some last minute changes on that . professor c: ok . grad b: you can just give him the abstract that we wrote for the paper . professor c: that - that 'll tell him exactly what 's going on . yeah , that alright . grad f: can we do can we do one - thirty ? grad a: no . grad f: oh , you already told me no . grad a: but we can do four . grad f: one , ok , it 's fine . i can do one . it 's fine . it 's fine . grad a: one or four . i do n't care . grad e: to me this is equal . i do n't care . grad a: if it 's equal for all ? what should we do ? grad f: yeah , it 's fine . grad a: four ? grad f: fine . yeah no , no , no , uh , i do n't care . it 's fine . grad a: it 's equal to all of us , so you can decide one or four . grad b: the pressure 's on you nancy . grad a: liz actually said she likes four because it forces the meeting recorder people to cut , you know the discussions short . grad f: ok . ok , four . grad e: well , if you insist , then . grad f: ok ? ok . i am .","output":"mental spaces can be tackled with mechanisms that can also deal with context issues ( time , space etc . ) : creating a base space and rules of interaction with other interconnected spaces . however , the complexity of these mechanisms has to be bound as well : it is necessary to define the range of constructions to be studied ."},{"instruction":"what is the description of the domains in the mental spaces ?","input":"grad b: what things to talk about . grad f: i 'm what ? really ? oh , that 's horrible ! disincentive ! grad a: ok , we 're recording . grad f: hello ? grad b: check check check check . grad d: uh , yeah . grad f: hello ? which am i ? professor c: oh right . grad b: alright . good . grad f: channel fi ok . ok . are you doing something ? ok , then i guess i 'm doing something . so , um , so basically the result of m much thinking since the last time we met , um , but not as much writing , um , is a sheet that i have a lot of , like , thoughts and justification of comments on but i 'll just pass out as is right now . so , um , here . if you could pass this around ? and there 's two things . and so one on one side is on one side is a sort of the revised sort of updated semantic specification . grad d: um the wait . grad f: and the other side is , um , sort of a revised construction formalism . grad e: this is just one sheet , right ? grad d: ah ! just one sheet . grad f: it 's just one sheet . grad d: ok . grad f: it 's just a nothing else . grad d: front , back . grad f: um , enough to go around ? ok . and in some ways it 's it 's it 's very similar to there are very few changes in some ways from what we 've , um , uh , b done before but i do n't think everyone here has seen all of this . so , uh , i 'm not sure where to begin . um , as usual the disclaimers are there are all these things are it 's only slightly more stable than it was before . grad e: mm - hmm . grad f: and , um , after a little bit more discussion and especially like keith and i i have more linguistic things to settle in the next few days , um , it 'll probably change again some more . grad e: yeah . grad f: um , maybe i will let 's start b let 's start on number two actually on the notation , um , because that 's , i 'm thinking , possibly a little more familiar to , um to people . ok , so the top block is just sort of a sort of abstract nota it 's sort of like , um , listings of the kinds of things that we can have . and certain things that have , um , changed , have changed back to this . there there 's been a little bit of , um , going back and forth . but basically obviously all constructions have some kind of name . i forgot to include that you could have a type included in this line . professor c: what i was gon na right . grad f: so something like , um well , there 's an example the textual example at the end has clausal construction . so , um , just to show it does n't have to be beautiful it could be , you know , simple old text as well . um , there are a couple of uh , these three have various ways of doing certain things . so i 'll just try to go through them . so they could all have a type at the beginning . um , and then they say the key word construction professor c: oh , i see . grad f: and they have some name . professor c: so so the current syntax is if it s if there 's a type it 's before construct grad f: yeah , right . professor c: ok , that 's fine . grad f: ok , and then it has a block that is constituents . and as usual i guess all the constructions her all the examples here have only , um , tsk { comment } one type of constituent , that is a constructional constituent . i think that 's actually gon na turn out to m be certainly the most common kind . but in general instead of the word `` construct `` , th here you might have `` meaning `` or `` form `` as well . ok ? so if there 's some element that does n't that is n't yet constructional in the sense that it maps form and meaning . ok , um , the main change with the constructs which each of which has , um , the key word `` construct `` and then some name , and then some type specification , is that it 's it 's pro it 's often sometimes the case in the first case here that you know what kind of construction it is . so for example whatever i have here is gon na be a form of the word `` throw `` , or it 's gon na be a form of the word , you know , i do n't know , `` happy `` , or something like that . or , you know , some it 'll be a specific word or maybe you 'll have the type . you 'll say `` i need a p uh spatial relation phrase here `` or `` i need a directional specifier here `` . so - uh you could have a j a actual type here . um , or you could just say in the second case that you only know the meaning type . so a very common example of this is that , you know , in directed motion , the first person to do something should be an agent of some kind , often a human . right ? so if i you know , the um , uh , run down the street then i i i run down the street , it 's typed , uh , `` i `` , meaning category is what 's there . the the new kind is this one that is sort of a pair and , um , sort of skipping fonts and whatever . the idea is that sometimes there are , um , general constructions that you know , that you 're going to need . it 's it 's the equivalent of a noun phrase or a prepositional phrase , or something like that there . grad e: mm - hmm . grad f: and usually it has formal um , considerations that will go along with it . professor c: mm - hmm . grad f: and then uh , you might know something much more specific depending on what construction you 're talking about , about what meaning what specific meaning you want . so the example again at the bottom , which is directed motion , you might need a nominal expression to take the place of , you know , um , `` the big th `` , you you know , `` the big the tall dark man `` , you know , `` walked into the room `` . grad e: mm - hmm . grad f: but because of the nature of this particular construction you know not just that it 's nominal of some kind but in particular , that it 's some kind of animate nominal , and which will apply just as well to like , you know , a per you know , a simple proper noun or to some complicated expression . um , so i do n't know if the syntax will hold but something that gives you a way to do both constructional and meaning types . so . ok , then i do n't think the , { comment } um at least yeah . { comment } none of these examples have anything different for formal constraints ? but you can refer to any of the , um , sort of available elements and scope , right ? which here are the constructs , { comment } to say something about the relation . and i think i if you not if you compare like the top block and the textual block , um , we dropped like the little f subscript . the f subscripts refer to the `` form `` piece of the construct . professor c: good . grad f: and i think that , um , in general it 'll be unambiguous . like if you were giving a formal constraint then you 're referring to the formal pole of that . so so by saying if i just said `` name one `` then that means name one formal and we 're talking about formal struc { comment } which which makes sense . uh , there are certain times when we 'll have an exception to that , in which case you could just indicate `` here i mean the meaningful for some reason `` . right ? or actually it 's more often that , only to handle this one special case of , you know , `` george and jerry walk into the room in that order `` . grad e: mm - hmm . grad f: so we have a few funny things where something in the meaning might refer to something in the form . but but s we 're not gon na really worry about that for right now and there are way we can be more specific if we have to later on . ok , and so in terms of the the relations , you know , as usual they 're before and ends . i should have put an example in of something that is n't an interval relation but in form you might also have a value binding . you know , you could say that , um , you know , `` name - one dot `` , t you know , `` number equals `` , you know , a plural or something like that . grad e: mm - hmm . grad f: there are certain things that are attribute - value , similar to the bindings below but i mean they 're just us usually they 're going to be value value fillers , right ? ok , and then again semantic constraints here are just are just bindings . there was talk of changing the name of that . and johno and i i you you and i can like fight about that if you like ? but about changing it to `` semantic n effects `` , which i thought was a little bit too order - biased grad b: well th grad f: and `` semantic bindings `` , which i thought might be too restrictive in case we do n't have only bindings . and so it was an issue whether constraints um , there were some linguists who reacted against `` constraints `` , saying , `` oh , if it 's not used for matching , then it should n't be called a constraint `` . but i think we want to be uncommitted about whether it 's used for matching or not . right ? cuz there are i think we thought of some situations where it would be useful to use whatever the c bindings are , for actual , you know , sort of like modified constraining purposes . professor c: well , you definitely want to de - couple the formalism from the parsing strategy . so that whether or not it 's used for matching or only for verification , i grad e: yeah . grad f: yeah , yeah . it 's used should n't matter , right ? mm - hmm . professor c: s for sure . i mean , i do n't know what , uh , term we want to use grad f: mm - hmm . professor c: but we do n't want to grad f: yeah , uh , there was one time when when hans explained why `` constraints `` was a misleading word for him . professor c: yep . grad f: and i think the reason that he gave was similar to the reason why johno thought it was a misleading term , which was just an interesting coincidence . um , but , uh and so i was like , `` ok , well both of you do n't like it ? professor c: it 's g it 's gone . grad f: fine , we can change it `` . but i i i 'm starting to like it again . grad b: but grad f: so that that 's why { comment } that 's why i 'll stick with it . grad a: well , you know what ? grad f: so grad a: if you have an `` if - then `` phrase , do you know what the `` then `` phrase is called ? professor c: th grad f: what ? con - uh , a consequent ? grad a: yeah . grad f: yeah , but it 's not an `` if - then `` . grad a: no , but professor c: i know . anyway , so the other the other strategy you guys could consider is when you do n't know what word to put , you could put no word , grad f: mm - hmm . professor c: just meaning . ok ? and the then let grad e: yeah . grad f: yeah , that 's true . grad b: so that 's why you put semantic constraints up top and meaning bindings down down here ? grad f: oh , oops ! no . that was just a mistake of cut and paste from when i was going with it . grad b: ok . professor c: ok . grad f: so , i 'm sorry . i did n't mean that one 's an in unintentional . grad b: so this should be semantic and grad f: sometimes i 'm intentionally inconsistent grad b:  grad f: cuz i 'm not sure yet . here , i actually it was just a mistake . grad b: th - so this definitely should be `` semantic constraints `` down at the bottom ? grad e: sure . grad f: yeah . grad b: ok . grad f: well , unless i go with `` meaning `` but i i mean , i kind of like `` meaning `` better than `` semantic `` grad b: or professor c: oh , whatever . grad f: but i think there 's vestiges of other people 's biases . professor c: or wh that - b grad f: like professor c: right . minor min problem grad f: minor point . professor c: ok . grad e: extremely . grad f: ok , um , so i think the middle block does n't really give you any more information , ex than the top block . and the bottom block similarly only just illus you know , all it does is illustrate that you can drop the subscripts and and that you can drop the , um uh , that you can give dual types . oh , one thing i should mention is about `` designates `` . i think i 'm actually inconsistent across these as well . so , um , strike out the m subscript on the middle block . professor c: mm - hmm . grad f: so basically now , um , this is actually this little change actually goes along with a big linguistic change , which is that `` designates `` is n't only something for the semantics to worry about now . professor c: good . grad f: so we want s `` designates `` to actually know one of the constituents which acts like a head in some respects but is sort of , um , really important for say composition later on . so for instance , if some other construction says , you know , `` are you of type is this part of type whatever `` , um , the `` designates `` tells you which sort of part is the meaning part . ok , so if you have like `` the big red ball `` , you know , you wan na know if there 's an object or a noun . well , ball is going to be the designated sort of element of that kind of phrase . grad e: mmm . grad f: um , there is a slight complication here which is that when we talk about form it 's useful sometimes to talk about , um to talk about there also being a designated object and we think that that 'll be the same one , right ? so the ball is the head of the phrase , `` the r the `` , um , `` big red ball `` , and the entity denoted by the word `` ball `` is sort of the semantic head in some ways of of this sort of , um , in interesting larger element . professor c: a a and the yeah . and there 's uh there 's ca some cases where the grammar depends on some form property of the head . and and this enables you to get that , if i understand you right . grad e: yeah . grad f: mm - hmm . grad e: yeah . grad f: right , right . grad e: that 's the idea . professor c: yeah yeah . grad e: yeah . grad f: and , uh , you might be able to say things like if the head has to go last in a head - final language , you can refer to the head as a p the , you know the formal head as opposed to the rest of the form having to be at the end of that decision . professor c: right . grad f: so that 's a useful thing so that you can get some internal structural constraints in . professor c: ok , so that all looks good . let me oh , w oh . i do n't know . were you finished ? grad f: um , there was a list of things that is n't included but you you can you can ask a question . that might @ @ it . professor c: ok . so , i if i understand this the aside from , uh , construed and all that sort of stuff , the the differences are mainly that , we 've gone to the possibility of having form - meaning pairs for a type grad f: mm - hmm . professor c: or actually gone back to , grad f: right . professor c: if we go back far enough grad f: well , except for their construction meaning , so it 's not clear that , uh well , right now it 's a c uh contr construction type and meaning type . so i do n't know what a form type is . professor c: oh , i see . yeah , yeah , yeah . i 'm sorry , you 're right . grad f: yeah . professor c: a construction type . uh , that 's fine . but it , um grad f: right . a well , and a previous , um , you know , version of the notation certainly allowed you to single out the meaning bit by it . so you could say `` construct of type whatever designates something `` . professor c: yeah . grad f: but that was mostly for reference purposes , just to refer to the meaning pole . i do n't think that it was often used to give an extra meaning const type constraint on the meaning , which is really what we want most of the time i think . professor c: mm - hmm . grad f: um , i i do n't know if we 'll ever have a case where we actually h if there is a form category constraint , you could imagine having a triple there that says , you know that 's kind of weird . professor c: no , no , no , i do n't think so . i think that you 'll you 'll do fine . grad e: i professor c: in fact , these are , um , as long as as mark is n't around , these are form constraints . so a nominal expression is uh , the fact that it 's animate , is semantic . the fact that it 's n uh , a nominal expression i would say on most people 's notion of of f you know , higher form types , this i this is one . grad f: mm - hmm . grad e: yeah . grad f: right , right . professor c: and i think that 's just fine . grad e: yeah , yeah . grad f: which is fine , yeah . professor c: yeah . grad e: it 's that now , um , i 'm mentioned this , i i do n't know if i ever explained this but the point of , um , i mentioned in the last meeting , { comment } the point of having something called `` nominal expression `` is , um , because it seems like having the verb subcategorize for , you know , like say taking as its object just some expression which , um , designates an object or designates a thing , or whatever , um , that leads to some syntactic problems basically ? so you wan na , you know you sort of have this problem like `` ok , well , i 'll put the word `` , uh , let 's say , the word `` dog `` , you know . and that has to come right after the verb grad f: mm - hmm . grad e: cuz we know verb meets its object . and then we have a construction that says , oh , you can have `` the `` preceding a noun . and so you 'd have this sort of problem that the verb has to meet the designatum . professor c: right . grad e: and you could get , you know , `` the kicked dog `` or something like that , meaning `` kicked the dog `` . professor c: right . grad e: um , so you kind of have to let this phrase idea in there professor c: that i i have no problem with it at all . grad e: but it - it professor c: i think it 's fine . grad e: yeah . grad f: yeah . right , n s you may be you may not be like everyone else in in berkeley , grad e: yeah . yeah . grad f: but that 's ok . grad e: i mean , we we we sort of thought we were getting away with , uh with , a p grad f: uh , we do n't mind either , so grad e: i mean , this is not reverting to the x - bar theory of of phrase structure . professor c: right . grad e: but , uh , grad f: right . grad e: i just know that this is like , we did n't originally have in mind that , uh that verbs would subcategorize for a particular sort of form . grad f: mm - hmm . professor c: but they do . grad e: um , but they does . grad f: well , there 's an alternative to this grad e: at least in english . grad f: which is , um the question was did we want directed motion , professor c: yeah . grad f: which is an argument structure construction professor c: mm - hmm . grad e: yeah . grad f: did we want it to worry about , um , anything more than the fact that it , you know , has semantic you know , it 's sort of frame - based construction . so one option that , you know , keith had mentioned also was like , well if you have more abstract constructions such as subject , predicate , basically things like grammatical relations , grad e: mm - hmm . grad f: those could intersect with these in such a way that subject , predicate , or subject , predicate , subject , verb , ob you know , verb object would require that those things that f fill a subject and object are nom expressions . professor c: right . grad f: and that would be a little bit cleaner in some way . but you know , for now , i mean , professor c: yeah . but it y y it 's yeah , just moving it moving the c the cons the constraints around . grad f: uh , you know . m moving it to another place , right . grad e: yeah . professor c: ok , so that 's grad f: but there does basically , the point is there has to be that constraint somewhere , right ? professor c: right . grad f: so , yeah . professor c: and so that was the grad f: robert 's not happy now ? grad a: no ! grad f: oh , ok . professor c: ok , and sort of going with that is that the designatum also now is a pair . grad f: yes . professor c: instead of just the meaning . grad f: mm - hmm . professor c: and that aside from some terminology , that 's basically it . grad f: right . professor c: i just want to b i 'm i 'm asking . grad e: mm - hmm . grad f: yep . grad e: yeah . grad f: yeah , um , the un sort of the un - addressed questions in this , um , definitely would for instance be semantic constraints we talked about . professor c: yeah . grad f: here are just bindings but , right ? we might want to introduce mental spaces you know , there 's all these things that we do n't professor c: the whole the mental space thing is clearly not here . grad f: right ? so there 's going to be some extra you know , definitely other notation we 'll need for that which we skip for now . grad e: mm - hmm . professor c: by the way , i do want to get on that as soon as robert gets back . grad f: uh yeah . professor c: so , uh , the the mental space thing . grad f: ok . professor c: um , obviously , construal is a b is a b is a big component of that grad e: mm - hmm . professor c: so this probably not worth trying to do anything till he gets back . but sort of as soon as he gets back i think um , we ought to grad f: mm - hmm . mm - hmm . grad e: so what 's the what 's the time frame ? i forgot again when you 're going away for how long ? grad a: just , uh , as a sort of a mental bridge , i 'm not i 'm skipping fourth of july . so , uh , right afterwards i 'm back . grad e: ok . ok . grad f: what ? you 're missing like the premier american holiday ? what 's the point of spending a year here ? grad a: uh , i 've had it often enough . grad f: so , anyway . grad b: well he w he went to college here . grad f: oh , yeah , i forgot . oops . { comment } sorry . professor c: yeah . grad f: ok . professor c: and furthermore it 's well worth missing . grad f: not in california . grad e: yes . grad f: yeah , that 's true . i like i i like spending fourth of july in other countries , whenever i can . professor c: right . grad f: um professor c: ok , so that 's great . grad f: construal , ok , so oh , so there was one question that came out . i hate this thing . sorry . um , which is , so something like `` past `` which i you know , we think is a very simple uh , we 've often just stuck it in as a feature , professor c: right . right . grad f: you know , `` oh , this event takes place before speech time `` , { comment } ok , is what this means . um , it 's often thought of as it is also considered a mental space , professor c: right . grad f: you know , by , you know , lots of people around here . professor c: right . grad f: so there 's this issue of well sometimes there are really exotic explicit space builders that say `` in france , blah - blah - blah `` , grad e: mm - hmm . grad f: and you have to build up you ha you would imagine that would require you , you know , to be very specific about the machinery , whereas past is a very conventionalized one and we sort of know what it means but it we does n't do n't necessarily want to , you know , unload all the notation every time we see that it 's past tense . professor c: right . grad f: so , you know , we could think of our uh , just like x - schema `` walk `` refers to this complicated structure , past refers to , you know , a certain configuration of this thing with respect to it . professor c: i think that 's exactly right . grad f: so so we 're kind of like having our cake and eating it professor c: yeah . grad f: you know , having it both ways , right ? professor c: yeah . no , i think i think that i we 'll have to see how it works out when we do the details grad f: so , i i mm - hmm . professor c: but my intuition would be that that 's right . grad f: mm - hmm . yeah , ok . grad a: do you want to do the same for space ? grad f: wha - sorry ? grad a: space ? grad f: space ? grad a: here ? now ? grad f: oh , oh , oh , oh , instead of just time ? grad a: mm - hmm . grad f: yeah , yeah , yeah . same thing . so there are very conventionalized like deictic ones , right ? and then i think for other spaces that you introduce , you could just attach y whatever grad a: hmm . grad f: you could build up an appropriately uh , appropriate structure according to the l the sentence . professor c: yeah . grad a: hmm , well this this basically would involve everything you can imagine to fit under your c dot something grad e: n grad a: you know , where where it 's contextually dependent , grad f: yeah . right . grad a: `` what is now , what was past , grad f: mm - hmm . grad a: what is in the future , where is this , what is here , what is there , what is `` grad f: mm - hmm . yeah . so time and space . um , we 'll we 'll get that on the other side a little , like very minimally . there 's a sort of there 's a slot for setting time and setting place . professor c: good . grad f: and you know , you could imagine for both of those are absolute things you could say about the time and place , and then there are many in more interestingly , linguistically anyway , { comment } there are relative things that , you know , you relate the event in time and space to where you are now . if there 's something a lot more complicated like , or so hypothetical or whatever , then you have to do your job , grad e: mm - hmm . grad f: like or somebody 's job anyway . grad e: yeah . grad f: i 'm gon na point to at random . grad e: yeah . i mean , i 'm i 'm s curious about how much of the mental i mean , i 'm not sure that the formalism , sort of the grammatical side of things , { comment } is gon na have that much going on in terms of the mental space stuff . you know , um , basically all of these so - called space builders that are in the sentence are going to sort of i think of it as , sort of giving you the coordinates of , you know assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , um the construction that you actually get is just gon na sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to . grad f: mm - hmm . grad e: so `` in france , uh , watergate would n't have hurt nixon `` or something like that . um , well , you say , `` alright , i 'm supposed to add some structure to my model of this hypothetical past france universe `` or something like that . the information in the sentence tells you that much but it does n't tell you like exactly what it what the point of doing so is . so for example , depending on the linguistic con uh , context it could be like the question is for example , what does `` watergate `` refer to there ? does it , you know does it refer to , um if you just hear that sentence cold , the assumption is that when you say `` watergate `` you 're referring to `` a watergate - like scandal as we might imagine it happening in france `` . but in a different context , `` oh , you know , if nixon had apologized right away it would n't you know , watergate would n't have hurt him so badly in the us and in france it would n't have hurt him at all `` . now we 're s now that `` watergate `` we 're now talking about the real one , grad f: they 're real , right . grad e: and the `` would `` sort of it 's a sort of different dimension of hypothe - theticality , right ? we 're not saying what 's hypothetical about this world . grad f: i see right . grad e: in the first case , hypothetically we 're imagining that watergate happened in france . grad f: hmm . grad e: in the second case we 're imagining hypothetically that nixon had apologized right away grad f: mm - hmm . grad e: or something . right ? grad f: right . grad e: so a lot of this is n't happening at the grammatical level . professor c: correct . grad e: uh , um , and so grad f: mm - hmm . grad e: i do n't know where that sits then , grad a: hmm . grad e: sort of the idea of sorting out what the person meant . grad f: it seems like , um , the grammatical things such as the auxiliaries that you know introduce these conditionals , whatever , give you sort of the the most basi grad e: mm - hmm . grad f: th those we i think we can figure out what the possibilities are , right ? grad e: mm - hmm . grad f: there are sort of a relatively limited number . and then how they interact with some extra thing like `` in france `` or `` if such - and - such `` , that 's like there are certain ways that they c they can grad e: yeah . grad f: you know , one is a more specific version of the general pattern that the grammat grammar gives you . grad e: yeah . grad f: i think . but , you know , whatever , professor c: yeah , in the short run all we need is a enough mechanism on the form side to get things going . grad f: we we 're grad e: mm - hmm . yeah . professor c: uh , i uh , you you grad e: but the whole point of the whole point of what fauconnier and turner have to say about , uh , mental spaces , and blending , and all that stuff is that you do n't really get that much out of the sentence . you know , there 's not that much information contained in the sentence . it just says , `` here . add this structure to this space . `` and exactly what that means for the overall ongoing interpretation is quite open . an individual sentence could mean a hundred different things depending on , quote , `` what the space configuration is at the time of utterance `` . grad f: mm - hmm . mm - hmm . grad e: and so somebody 's gon na have to be doing a whole lot of work but not me , i think . professor c: well i think that 's right . oh , i yeah , i , uh , uh i think that 's not k i th i do n't think it 's completely right . i mean , in fact a sentence examples you gave in f did constrain the meaning b the form did constrain the meaning , grad e: yeah . professor c: and so , um , it is n't , uh grad e: sure , but like what what was the point of saying that sentence about nixon and france ? that is not there is nothing about that in the in the sentence really . grad f: that 's ok . we usually do n't know the point of the sentence at all . grad e: yeah . grad f: but we know what it 's trying to say . professor c: yeah . grad e: y yeah . grad f: we we know that it 's what predication it 's setting up . professor c: but but bottom line , i agree with you , grad e: yeah . grad f: that 's all . professor c: that that that we 're not expecting much out of the , uh f grad e: yeah . grad f: purely linguistic cues , right ? professor c: uh , the purely form cues , yeah . grad f: so . professor c: and , um i mean , you 're you 're the linguist grad f: mmm . professor c: but , uh , it seems to me that th these we we you know , we 've talked about maybe a half a dozen linguistics theses in the last few minutes or something . grad e: yeah , yeah . professor c: yeah , i mean grad e: yeah . oh , yeah . professor c: uh , i i mean , that that 's my feeling that that these are really hard uh , problems that decide exactly what what 's going on . grad e: mm - hmm . yeah . yeah . professor c: ok . grad f: ok , so , um , one other thing i just want to point out is there 's a lot of confusion about the terms like `` profile , designate , focus `` , et cetera , et cetera . professor c: uh , right , right , right . grad e: mm - hmm . grad f: um , for now i 'm gon na say like `` profile `` 's often used like two uses that come to mind immediately . one is in the traditional like semantic highlight of one element with respect to everything else . so `` hypotenuse `` , you profiled this guy against the background of the right t right triangle . grad e: mm - hmm . grad f: ok . and the second use , um , is in framenet . it 's slightly different . oh , i was asking hans about this . they use it to really mean , um , this in a frame th this is the profiles on the these are the ones that are required . so they have to be there or expressed in some way . which which i 'm not saying one and two are mutually exclusive but they 're they 're different meanings . professor c: right . grad e: mm - hmm . grad f: so the closest thing so i was thinking about how it relates to this notation . for us , um ok , so how is it professor c: does that is that really what they mean in in grad f: so `` designate `` framenet ? professor c: i did n't know that . grad f: framenet ? yeah , yeah . i i mean , i i was a little bit surprised about it too . professor c: yeah . grad f: i knew that i thought that that would be something like there 's another term that i 've heard for that thing professor c: right , ok . grad f: but they i mean uh , well , at least hans says they use it that way . and professor c: well , i 'll check . grad f: and may maybe he 's wrong . anyway , so i think the the `` designate `` that we have in terms of meaning is really the `` highlight this thing with respect to everything else `` . ok ? professor c: right . grad f: so this is what what it means . but the second one seems to be useful but we might not need a notation for it ? we do n't have a notation for it but we might want one . so for example we 've talked about if you 're talking about the lexical item `` walk `` , you know it 's an action . well , it also has this idea it carries along with it the idea of an actor or somebody 's gon na do the walking . or if you talk about an adjective `` red `` , it carries along the idea of the thing that has the property of having color red . so we used to use the notation `` with `` for this professor c: right . grad f: and i think that 's closest to their second one . so i d do n't yet know , i have no commitment , as to whether we need it . it might be it 's the kind of thing that w a parser might want to think about whether we require you know , these things are like it 's semantically part of it professor c: n no , no . well , uh , th critically they 're not required syntactically . often they 're pres presu presupposed and all that sort of stuff . grad f: right . right , right . yeah , um , definitely . so , um , `` in `` was a good example . if you walk `` in `` , like well , in what ? professor c: right , there 's grad f: you know , like you have to have the { comment } so so it 's only semantically is it it is still required , say , by simulation time though professor c: right . grad f: to have something . so it 's that i meant the idea of like that the semantic value is filled in by sim simulation . i do n't know if that 's something we need to spa to to like say ever as part of the requirement ? or the construction ? or not . we 'll we 'll again defer . professor c: or i mean , or or , uh so the grad f: have it construed , professor c: yeah , yeah . grad f: is that the idea ? just point at robert . whenever i 'm confused just point to him . professor c: right . it 's it 's his thesis , right ? grad f: you tell me . professor c: anyway , grad f: ok . professor c: right , yeah , w this is gon na be a b you 're right , this is a bit of in a mess and we still have emphasis as well , or stress , or whatever . grad f: ok , well we 'll get , uh uh , i we have thoughts about those as well . professor c: yeah . great . grad f: um , the i w i would just s some of this is just like my you know , by fiat . i 'm going to say , this is how we use these terms . i do n't - you know , there 's lots of different ways in the world that people use it . professor c: i that 's fine . grad e: yeah . grad f: i think that , um , the other terms that are related are like focus and stress . professor c: mm - hmm . grad f: so , s i think that the way i we would like to think , uh , i think is focus is something that comes up in , i mean , lots of basically this is the information structure . professor c: mm - hmm . grad f: ok , it 's like uh , it 's not it might be that there 's a syntactic , uh , device that you use to indicate focus or that there are things like , you know , i think keith was telling me , { comment } things toward the end of the sentence , post - verbal , tend to be the focused focused element , grad e: mmm . grad f: the new information . you know , if i `` i walked into the room `` , you tend to think that , whatever , `` into the room `` is sort of like the more focused kind of thing . grad e: mm - hmm . yeah . grad f: and when you , uh , uh , you have stress on something that might be , you know , a cue that the stressed element , or for instance , the negated element is kind of related to information structure . so that 's like the new the sort of like import or whatever of of this thing . uh , so so i think that 's kind of nice to keep `` focus `` being an information structure term . `` stress `` i th and then there are different kinds of focus that you can bring to it . so , um , like `` stress `` , th stress is kind of a pun on you might have like whatever , like , um , accent kind of stress . grad e: mm - hmm . grad f: and that 's just a uh , w we 'll want to distinguish stress as a form device . you know , like , oh , high volume or whatever . grad e: yeah . grad f: um , t uh , and distinguish that from it 's effect which is , `` oh , the kind of focus we have is we 're emphasizing this value often as opposed to other values `` , right ? so focus carries along a scope . like if you 're gon na focus on this thing and you wan na know it sort of evokes all the other possibilities that it was n't . grad e: mm - hmm . grad f: um , so my classic my now - classic example of saying , `` oh , he did go to the meeting ? `` , grad e: yeah . grad f: that was my way of saying as opposed to , you know , `` oh , he did n't g `` or `` there was a meeting ? `` grad e: yeah . grad f: i think that was the example that was caught on by the linguists immediately . grad e: yeah . grad f: and so , um , the like if you said he you know , there 's all these different things that if you put stress on a different part of it then you 're , c focusing , whatever , on , uh grad e: mm - hmm . grad f: `` he walked to the meeting `` as opposed to `` he ran `` , or `` he did walk to the meeting `` as opposed to `` he did n't walk `` . you know , grad e: mm - hmm . grad f: so we need to have a notation for that which , um , i think that 's still in progress . so , sort of i 'm still working it out . but it did one one implication it does f have for the other side , which we 'll get to in a minute is that i could n't think of a good way to say `` here are the possible things that you could focus on `` , cuz it seems like any entity in any sentence , you know , or any meaning component of anyth you know all the possible meanings you could have , any of them could be the subject of focus . professor c: mmm . grad f: but i think one the one thing you can schematize is the kind of focus , right ? so for instance , you could say it 's the the tense on this as opposed to , um , the the action . ok . or it 's uh , it 's an identity thing or a contrast with other things , or stress this value as opposed to other things . so , um , it 's it is kind of like a profile profile - background thing but i i ca n't think of like the limited set of possible meanings that you would that you would focu grad e: light up with focus , yeah . grad f: light highlight as opposed to other ones . so it has some certain complications for the , uh , uh later on . li - i mean , uh , the best thing i can come up with is that information has a list of focused elements . for instance , you oh , one other type that i forgot to mention is like query elements and that 's probably relevant for the like `` where is `` , you know , `` the castle `` kind of thing ? grad e: mm - hmm . grad f: because you might want to say that , um , location or cert certain wh words bring you know , sort of automatically focus in a , you know , `` i do n't know the identity of this thing `` kind of way on certain elements . so . ok . anyway . so that 's onl there are there are many more things that are uncl that are sort of like a little bit unstable about the notation but it 's most i think it 's this is , you know , the current current form . other things we did n't totally deal with , um , grad e: oh , there 's a bunch . grad f: well , we 've had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . grad e: yeah . grad f: you know , a a nominal expression . grad e: yeah . grad f: and , um , i mean , we should have put an example of this and we could do that later . grad e: yeah . grad f: but i think the not inherently like the general principles still work though , that , um , we can have constructions that have sort of constituent structure in that there is like , you know , for instance , one uh , you know , they they have constituents , right ? so you can like nest things when you need to , but they can also overlap in a sort of flatter way . so if you do n't have like a lot of grammar experience , then like this this might , you know , be a little o opaque . but , you know , we have the properties of dependency grammars and some properties of constituents constituent - based grammar . so that 's i think that 's sort of the main thing we wanted to aim for grad e: mm - hmm . grad f: and so far it 's worked out ok . professor c: good . grad f: so . ok . grad a: i can say two things about the f grad f: yes . grad a: maybe you want to forget stress . this my f grad f: as a word ? grad a: no , as as just do n't do n't think about it . grad f: as a what 's that ? grad a: if grad f: sorry . grad a: canonically speaking you can if you look at a a curve over sentence , you can find out where a certain stress is and say , `` hey , that 's my focus exponent . `` grad e: right . grad f: mm - hmm . grad a: it does n't tell you anything what the focus is . if it 's just that thing , grad f: mm - hmm . or the constituent that it falls in . grad a: a little bit more or the whole phrase . grad e: mm - hmm . grad a: um grad f: you mean t forget about stress , the form cue ? grad a: the form bit grad e: yeah . grad a: because , uh , as a form cue , um , not even trained experts can always well , they can tell you where the focus exponent is sometimes . grad f: ok . grad a: and that 's also mostly true for read speech . in in real speech , um , people may put stress . it 's so d context dependent on what was there before , phrase ba breaks , um , restarts . grad f: yeah . mm - hmm . grad a: it 's just , um it 's absurd . it 's complicated . grad f: ok , grad a: and all grad e: yeah , i mean , i i 'm sort of inclined to say let 's worry about specifying the information structure focus of the sentence grad f: i believe you , yeah . grad e: and then , grad f: mm - hmm . ways that you can get it come from th grad e: hhh , { comment } the phonology component can handle actually assigning an intonation contour to that . grad f: right . grad e: you know , i mean , later on we 'll worry about exactly how grad a: or or map from the contour to to what the focus exponent is . grad e: y yeah . exactly . grad f: mm - hmm . grad e: but figure out how the grad a: but , uh , if you do n't know what you 're what you 're focus is then you 're you 're hopeless - uh - ly lost anyways , grad e: yeah . grad f: right . that 's fine , yeah . mm - hmm . grad a: and the only way of figuring out what that is , is , um , by sort of generating all the possible alternatives to each focused element , decide which one in that context makes sense and which one does n't . grad f: mm - hmm . grad a: and then you 're left with a couple three . so , you know , again , that 's something that h humans can do , grad f: mm - hmm . grad a: um , but far outside the scope of of any anything . so . you know . it 's grad f: ok . well , uh , yeah , i would n't have assumed that it 's an easy problem in in absence of all the oth grad a: u u grad f: you need all the other information i guess . grad a: but it 's it 's what it uh , it 's pretty easy to put it in the formalism , though . i mean , because grad f: yeah . grad a: you can just say whatever stuff , `` i is the container being focused or the the entire whatever , both , and so forth . `` grad f: mm - hmm , mm - hmm . grad e: mm - hmm . grad f: yeah . exactly . so the sort of effect of it is something we want to be able to capture . professor c: yeah , so b b but i think the poi i 'm not sure i understand but here 's what i th think is going on . that if we do the constructions right when a particular construction matches , it the fact that it matches , does in fact specify the focus . grad f: w uh , i 'm not sure about that . professor c: ok . grad f: or it might limit it cert certainly constrains the possibilities of focus . professor c: uh k uh , at at the very least it constrai grad f: i think that 's that 's , th that 's certainly true . and depending on the construction it may or may not f specify the focus , right ? professor c: oh , uh , for sure , yes . there are constrai yeah , it 's not every but there are constructions , uh , where you t explicitly take into account those considerations grad f: yeah . mm - hmm . professor c: that you need to take into account in order to decide which what is being focused . grad f: mm - hmm . grad a: mm - hmm . so we talked about that a little bit this morning . `` john is on the bus , not nancy . `` grad f: mm - hmm . grad a: so that 's focuses on john . professor c: right . grad f: hmm . grad a: `` john is on the bus and not on the train . `` grad f: mm - hmm . grad a: `` john is on the bus `` versus `` john is on the train . `` professor c: right . grad f: right . grad a: and `` john is on the bus `` versus `` was `` , and e grad f: is on . `` john is on the bus `` . yeah . yeah . grad a: `` it 's the bu `` so e professor c: right . yeah , all all of those . grad a: all of these professor c: yeah . grad f: right . grad a: and will we have u is it all the same constructions ? just with a different foc focus constituent ? grad f: yeah , i would say that argument structure in terms of like the main like sort of , grad a: mm - hmm . grad f: i do n't know the fact that you can get it without any stress and you have some whatever is predicated anyway should be the same set of constructions . so that 's why i was talking about overlapping constructions . so , then you have a separate thing that picks out , you know , stress on something relative to everything else . professor c: yeah . so , the question is actually grad e: mm - hmm . professor c: oh , i 'm sorry , grad f: and it would professor c: go ahead , grad f: yeah , professor c: finish . grad f: and it w and that would have to uh it might be ambiguous as , uh , whether it picks up that element , or the phrase , or something like that . but it 's still is limited possibility . grad a: hmm . grad f: so that should , you know , interact with it should overlap with whatever other construction is there . grad a: yeah . professor c: s s the question is , do we have a way on the other page , uh , when we get to the s semantic side , of saying what the stressed element was , or stressed phrase , or something . grad f: mm - hmm . well , so that 's why i was saying how since i could n't think of an easy like limited way of doing it , um , all i can say is that information structure has a focused slot professor c: right . grad f: and i think that should be able to refer to professor c: so that 's down at the bottom here when we get over there . ok . grad f: yeah , and , infer and i do n't have i do n't have a great way or great examples professor c: i 'll - i 'll wait . ok . grad f: but i think that something like that is probably gon na be , uh , more more what we have to do . grad a: hmm . professor c: ok . grad f: but , um , grad a: so grad f: ok , that was one comment . and you had another one ? grad a: yeah , well the once you know what the focus is the everything else is background . how about `` topic - comment `` that 's the other side of information . grad f: how about what ? grad a: topic - comment . grad f: yeah , so that was the other thing . and so i did n't realize it before . it 's like , `` oh ! `` it was an epiphany that it you know , topic and focus are a contrast set . so topic is topic - focused seems to me like , um , background profile , ok , or a landmark trajector , or some something like that . there 's there 's definitely , um , that kind of thing going on . grad a: mmm . grad f: now i do n't know whether i n i do n't have as many great examples of like topic - indicating constructions on like focus , right ? um , topic it seems kind of you know , i think that might be an ongoing kind of thing . grad a: mm - hmm . grad e: japanese has this though . you know . grad f: topic marker ? grad a: yeah . grad e: yeah , that 's what `` wa `` is , uh , just to mark which thing is the topic . grad f: mm - hmm . grad e: it does n't always have to be the subject . grad f: mm - hmm . right . so again , information structure has a topic slot . and , you know , i stuck it in thinking that we might use it . grad a: mm - hmm . grad f: um , i think i stuck it in . professor c: yep , it 's there . grad f: um , and one thing that i did n't do consistently , um , is when we get there , is like indicate what kind of thing fits into every role . i think i have an idea of what it should be but th you know , so far we 've been getting away with like either a type constraint or , um , you know , whatever . i forg it 'll be a frame . you know , it 'll be it 'll be another predication or it 'll be , um , i do n't know , some value from from some something , some variable and scope or something like that , or a slot chain based on a variable and scope . ok , so well that 's should we flip over to the other side officially then ? grad a: mm - hmm , hmm . grad e: ok , side one . grad f: i keep , uh , like , pointing forward to it . yeah . now we 'll go back to s ok , so this does n't include something which mi mi may have some effect on on it , which is , um , the discourse situation context record , right ? so i did n't i i meant just like draw a line and like , you know , you also have , uh , some tracking of what was going on . professor c: right . grad f: and sort of this is a big scale comment before i , you know , look into the details of this . but for instance you could imagine instead of having i i changed the name of um it used to be `` entities `` . so you see it 's `` scenario `` , `` referent `` and `` discourse segment `` . and `` scenario `` is essentially what kind of what 's the basic predication , what event happened . and actually it 's just a list of various slots from which you would draw draw in order to paint your picture , a bunch of frames , bi and bindings , right ? um , and obviously there are other ones that are not included here , general cultural frames and general like , uh , other action f grad e: mm - hmm . grad f: you know , specific x - schema frames . ok , whatever . the middle thing used to be `` entities `` because you could imagine it should be like really a list where here was various information . and this is intended to be grammatically specifiable information about a referent uh , you know , about some entity that you were going to talk about . so `` harry walked into the room `` , `` harry `` and `` room `` , you know , the room th but they would be represented in this list somehow . and it could also have for instance , it has this category slot . um , it should be either category or in or instance . basically , it could be a pointer to ontology . so that everything you know about this could be could be drawn in . but the important things for grammatical purposes are for things like number , gender , um ki the ones i included here are slightly arbitrary but you could imagine that , um , you need to figure out wheth if it 's a group whether , um , some event is happening , linear time , linear spaces , like , you know , are are they doing something serially or is it like , um , uh i 'm i 'm not sure . because this partly came from , uh , talmy 's schema and i 'm not sure we 'll need all of these actually . but um , and then the `` status `` i used was like , again , in some languages , you know , like for instance in child language you might distinguish between different status . so , th the the big com and and finally `` discourse segment `` is about sort of speech - act - y information structure - y , like utterance - specific kinds of things . so the comment i was going to make about , um , changing entity the entity 's block to reference is that you can imagine your discourse like situation context , you have a set of entities that you 're sort of referring to . and you might that might be sort of a general , i do n't know , database of all the things in this discourse that you could refer to . and i changed to `` reference `` cuz i would say , for a particular utterance you have particular referring expressions in it . and those are the ones that you get information about that you stick in here . for instance , i know it 's going to be plural . i know it 's gon na be feminine or something like that . and and these could actually just point to , you know , the the id in my other list of enti active entities , right ? so , um , uh , th there 's there 's all this stuff about discourse status . we 've talked about . i almost listed `` discourse status `` as a slot where you could say it 's active . you know , there 's this , um , hierarchy uh there 's a schematization of , you know , things can be active or they can be , um , accessible , inaccessible . grad e: yeah . grad f: it was the one that , you know , keith , um , emailed to us once , to some of us , not all of us . and the thing is that that i noticed that that , um , list was sort of discourse dependent . it was like in this particular set , s you know , instance , it has been referred to recently or it has n't been , grad e: yeah . grad f: or this is something that 's like in my world knowledge but not active . professor c: this uh yeah , well there there seems to be context properties . grad f: so . professor c: yeah . grad f: yeah , they 're contex and for instance , i used to have a location thing there but actually that 's a property of the situation . and it 's again , time , you know at cert certain points things are located , you know , near or far from you professor c: well , uh , uh , this is recursive grad f: and professor c: cuz until we do the uh , mental space story , we 're not quite sure { comment } th - th grad f: yeah . professor c: which is fine . we 'll just we 'll j grad f: yeah , yeah . so some of these are , uh professor c: we just do n't know yet . grad f: right . so i so for now i thought , well maybe i 'll just have in this list the things that are relevant to this particular utterance , right ? everything else here is utterance - specific . um , and i left the slot , `` predications `` , open because you can have , um , things like `` the guy i know from school `` . grad e: mm - hmm . grad f: or , you know , like your referring expression might be constrained by certain like unbounded na amounts of prep you know , predications that you might make . and it 's unclear whether i mean , you could just have in your scenario , `` here are some extra few things that are true `` , right ? grad e: mm - hmm . grad f: and then you could just sort of not have this slot here . right ? you 're but but it 's used for identification purposes . professor c: right . grad e: yeah . grad f: so it 's it 's a little bit different from just saying `` all these things are true from my utterance `` . grad e: yeah . grad f: um . grad e: right , `` this guy i know from school came for dinner `` does not mean , um , `` there 's a guy , i know him from school , and he came over for dinner `` . that 's not the same effect . grad f: yeah , it 's a little bit it 's a little bit different . right ? so or maybe that 's like a restrictive , non - restrictive grad e: yeah . grad f: you know , it 's like it gets into that kind of thing for um , but maybe i 'm mixing , you know this is kind of like the final result after parsing the sentence . grad e: mm - hmm . grad f: so you might imagine that the information you pass to , you know in identifying a particular referent would be , `` oh , some `` you know , `` it 's a guy and it 's someone i know from school `` . grad e: yeah . grad f: so maybe that would , you know , be some intermediate structure that you would pass into the disc to the , whatever , construal engine or whatever , discourse context , to find you know , either create this reference , grad e: mm - hmm . grad f: in which case it 'd be created here , and you know , so so you could imagine that this might not so , uh , i 'm uncommitted to a couple of these things . grad a: but to make it m precise at least in my mind , uh , it 's not precise . grad f: um . grad a: so `` house `` is gender neuter ? in reality grad f: um , it could be in grad a: or in professor c: semantically . grad a: semantically . grad f: semantically , yeah . yeah . grad a: so grad f: so it uh , uh , a table . you know , a thing that c does n't have a gender . so . uh , it could be that i mean , maybe you 'd maybe not all these i mean , i wou i would say that i tried to keep slots here that were potentially relevant to most most things . grad a: no , just to make sure that we everybody that 's completely agreed that it it has nothing to do with , uh , form . grad f: yeah . ok , that is semantic as opposed to yeah . yeah . that 's right . um . grad a: then `` predications `` makes sense to to have it open for something like , uh , accessibility or not . grad f: s so again open to various things . grad a: yeah . grad f: right . ok , so . let 's see . so maybe having made that big sca sort of like large scale comment , should i just go through each of these slots uh , each of these blocks , um , a little bit ? grad e: sure . grad f: um , mostly the top one is sort of image schematic . and just a note , which was that , um s so when we actually ha so for instance , um , some of them seem more inherently static , ok , like a container or sort of support - ish . and others are a little bit seemingly inherently dynamic like `` source , path , goal `` is often thought of that way or `` force `` , or something like that . but in actual fact , i think that they 're intended to be sort of neutral with respect to that . and different x - schemas use them in a way that 's either static or dynamic . so `` path `` , you could just be talking about the path between this and this . grad e: mmm . grad f: and you know , `` container `` that you can go in and out . all of these things . and so , um , i think this came up when , uh , ben and i were working with the spaniards , um , the other day the `` spaniettes `` , as we called them um , to decide like how you want to split up , like , s image schematic contributions versus , like , x - schematic contributions . how do you link them up . and i think again , um , it 's gon na be something in the x - schema that tells you `` is this static or is this dynamic `` . so we definitely need that sort of aspectual type gives you some of that . um , that , you know , is it , uh , a state or is it a change of state , or is it a , um , action of some kind ? grad a: uh , i i i is there any meaning to when you have sort of parameters behind it and when you do n't ? grad f: uh . yeah . grad a: just means grad f: oh , oh ! you mean , in the slot ? grad a: mm - hmm . grad f: um , no , it 's like x - sc it 's it 's like i was thinking of type constraints but x - schema , well it obviously has to be an x - schema . `` agent `` , i mean , the the performer of the x - schema , that s depends on the x - schema . you know , and i in general it would probably be , you know grad e: so the difference is basically whether you thought it was obvious what the possible fillers were . grad f: yeah , basically . grad a: mm - hmm . grad e: ok . grad f: um , `` aspectual type `` probably is n't obvious but i should have so , i just neglected to stick something in . `` perspective `` , `` actor `` , `` undergoer `` , `` observer `` , um , grad b: mmm . grad f: i think we 've often used `` agent `` , `` patient `` , obser grad e: `` whee ! `` that 's that one , right ? grad f: yeah , exactly . exactly . um , and so one nice thing that , uh , we had talked about is this example { comment } of like , if you have a passive construction then one thing it does is ch you know definitely , it is one way to for you to , you know , specifically take the perspective of the undergoing kind of object . and so then we talked about , you know , whether well , does that specify topic as well ? well , maybe there are other things . you know , now that it 's subject is more like a topic . and now that , you know anyway . so . sorry . i 'm gon na trail off on that one cuz it 's not that f important right now . professor c: n now , for the moment we just need the ability to l l write it down if if somebody figured out what the rules were . grad f: um , to know how yeah . yeah . exactly . professor c: yeah . grad f: um , some of these other ones , let 's see . so , uh , one thing i 'm uncertain about is how polarity interacts . professor c: mm - hmm . grad f: so polarity , uh , is using for like action did not take place for instance . so by default it 'll be like `` true `` , i guess , you know , if you 're specifying events that did happen . you could imagine that you skip out this you know , leave off this polarity , you know , not do n't have it here . and then have it part of the speech - act in some way . professor c: mm - hmm . grad f: there 's some negation . but the reason why i left it in is cuz you might have a change of state , let 's say , where some state holds and then some state does n't hold , and you 're just talking , you know if you 're trying to have the nuts and bolts of simulation you need to know that , you know , whatever , the holder does n't and professor c: no , i th i think at this lev which is it should be where you have it . grad f: ok , it 's so it 's it 's it 's fine where it is . professor c: i mean , how you get it may may in will often involve the discourse grad f: so , ok . may come from a few places . professor c: but but by the time you 're simulating you sh y you should know that . grad f: right . right . grad e: so , i 'm still just really not clear on what i 'm looking at . the `` scenario `` box , like , what does that look like for an example ? like , not all of these things are gon na be here . grad f: yeah . professor c: correct . grad e: this is just basically says grad f: mm - hmm . it 's a grab bag of grad e: `` part of what i 'm going to hand you is a whole bunch of s uh , schemas , image , and x - schemas . here are some examples of the sorts of things you might have in there `` . grad f: so that 's exactly what it is . grad e: ok . grad f: and for a particular instance which i will , you know , make an example of something , is that you might have an instance of container and path , let 's say , as part of your , you know , `` into `` you know , definition . grad e: mm - hmm . mm - hmm . grad f: so you would eventually have instances filled in with various various values for all the different slots . grad e: mm - hmm . grad f: and they 're bound up in , you know , their bindings and and and values . professor c: w it c grad e: ok . do you have to say about the binding in your is there a slot in here for that tells you how the bindings are done ? professor c: no , no , no . i let 's see , i think we 're we 're not i do n't think we have it quite right yet . so , uh , what this is , grad e: ok . professor c: let 's suppose for the moment it 's complete . ok , uh , then this says that when an analysis is finished , the whole analysis is finished , { comment } you 'll have as a result , uh , some s resulting s semspec for that utterance in context , grad e: ok . mm - hmm . professor c: which is made up entirely of these things and , uh , bindings among them . and bindings to ontology items . grad e: mm - hmm . professor c: so that that the who that this is the tool kit under whi out of which you can make a semantic specification . grad e: mm - hmm . mm - hmm . professor c: so that 's a . but b , which is more relevant to your life , is this is also the tool kit that is used in the semantic side of constructions . grad e: ok . mm - hmm . professor c: so this is an that anything you have , in the party line , { comment } anything you have as the semantic side of constructions comes , from pieces of this ignoring li grad e: ok . professor c: i mean , in general , you ignore lots of it . grad e: right . professor c: but it 's got to be pieces of this along with constraints among them . grad e: ok . professor c: uh , so that the , you know , goal of the , uh uh , `` source , path , goal `` has to be the landmark of the conta you know , the interior of this container . grad e: mm - hmm . professor c: or whate whatever . grad e: yeah . professor c: so those constraints appear in constructions grad e: mm - hmm . professor c: but pretty much this is the full range of semantic structures available to you . grad e: ok . grad f: except for `` cause `` , that i forgot . but anyway , there 's som some kind of causal structure for composite events . grad e: yeah . professor c: ok , good . let 's let 's mark that . so we need a c grad f: uh , i mean , so it gets a little funny . these are all so far these structures , especially from `` path `` and on down , these are sort of relatively familiar , um , image schematic kind of slots . now with `` cause `` , uh , the fillers will actually be themselves frames . right ? professor c: right . grad e: mm - hmm . grad f: so you 'll say , `` event one causes event b professor c: and and and and this this this again may ge our , um and we and and , of course , worlds . grad f: uh , event two `` , and grad e: mm - hmm . grad f: yeah . so that 's , uh these are all implicitly one within , uh within one world . um , even though saying that place takes place , whatever . uh , if y if i said `` time `` is , you know , `` past `` , that would say `` set that this world `` , you know , `` somewhere , before the world that corresponds to our current speech time `` . grad e: mm - hmm . mm - hmm . yeah . grad f: so . but that that that 's sort of ok . the the within the event it 's st it 's still one world . um . yeah , so `` cause `` and other frames that could come in i mean , unfortunately you could bring in say for instance , um , uh , `` desire `` or something like that , grad e: mm - hmm . grad f: like `` want `` . and actually there is right now under `` discourse segments `` , um , `` attitude `` ? grad e: mm - hmm . grad f: `` volition `` ? could fill that . so there are a couple things where i like , `` oh , i 'm not sure if i wanted to have it there grad e: well that 's grad f: or `` basically there was a whole list of of possible speaker attitudes that like say talmy listed . and , like , well , i do n't you know , it was like `` hope , wish . desire `` , professor c: right . grad e: uh - huh . grad f: blah - blah - blah . and it 's like , well , i feel like if i wanted to have an extra meaning i do n't know if those are grammatically marked in the first place . so they 're more lexically marked , right ? grad e: mmm . grad f: at least in english . so if i wanted to i would stick in an extra frame in my meaning , saying , e so th it 'd be a hierarchical frame them , right ? you know , like `` naomi wants wants su a certain situation and that situation itself is a state of affairs `` . professor c: s right . so so , `` want `` itself can be i i i i i grad f: u can be just another frame that 's part of your professor c: well , and it i basically it 's an action . in in our s in our in our grad f: yeah . situation . { comment } right , right . professor c: in in our in our s terminology , `` want `` can be an action and `` what you want `` is a world . grad f: mm - hmm . grad b: hmm . professor c: so that 's i mean , it 's certainly one way to do it . grad f: mmm . professor c: yeah , there there are other things . grad e: mm - hmm . professor c: causal stuff we absolutely need . mental space we need . grad f: mm - hmm . professor c: the context we need . um , so anyway , keith so is this comfortable to you that , uh , once we have this defined , it is your tool kit for building the semantic part of constructions . grad e: mm - hmm . professor c: and then when we combine constructions semantically , the goal is going to be to fill out more and more of the bindings needed in order to come up with the final one . grad e: mm - hmm . professor c: and that 's the wh and and i mean , that according to the party line , that 's the whole story . grad e: yeah . mm - hmm . yeah . um . y right . that makes sense . so i mean , there 's this stuff in the off in the scenario , which just tells you how various what schemas you 're using and they 're how they 're bound together . and i guess that some of the discourse segment stuff is that where you would sa grad f: mm - hmm . grad e: i mean , that 's ok , that 's where the information structure is which sort of is a kind of profiling on different parts of , um , of this . grad f: right . exactly . grad e: i mean , what 's interesting is that the information structure stuff hmm . there 's almost i mean , we keep coming back to how focus is like this this , uh , trajector - landmark thing . grad f: yeah . grad e: so if i say , um , you know , `` in france it 's like this `` . you know , great , we 've learned something about france but the fact is that utterances of that sort are generally used to help you draw a conclusion also about some implicit contrast , like `` in france it 's like this `` . and therefore you 're supposed to say , `` boy , life sure `` grad f: right . grad e: you know , `` in france kids are allowed to drink at age three `` . and w you 're that 's not just a fact about france . you also conclude something about how boring it is here in the u s . right ? grad f: right , right . professor c: right . grad e: and so grad f: s so i would prefer not to worry about that for right now grad e: ok . grad f: and to think that there are , um , grad e: that comes in and , uh grad f: discourse level constructions in a sense , topic topic - focus constructions that would say , `` oh , when you focus something `` then grad e: mm - hmm . yeah . grad f: just done the same way just actually in the same way as the lower level . if you stressed , you know , `` john went to the `` , you know , `` the bar `` whatever , you 're focusing that grad e: mm - hmm . grad f: and a in a possible inference is `` in contrast to other things `` . grad e: yeah . grad f: so similarly for a whole sentence , you know , `` in france such - and - such happens `` . grad e: yeah . yeah , yeah . grad f: so the whole thing is sort of like again implicitly as opposed to other things that are possible . grad e: yeah . grad a: uh , just just , uh , look read uh even sem semi formal mats rooth . grad f: i mean yeah . grad a: if you have n't read it . it 's nice . grad f: uh - huh . grad a: and just pick any paper on alternative semantics . grad f: uh - huh . grad e: ok . grad a: so that 's his that 's the best way of talking about focus , is i think his way . grad e: ok , what was the name ? grad a: mats . mats . rooth . grad e: ok . grad a: i think two o 's , yes , th . grad e: ok . grad a: i never know how to pronounce his name because he 's sort of , professor c: s swede ? grad a: uh , he is dutch professor c: dutch ? grad a: and , um but very confused background i think . professor c: oh , dutch . grad e: yeah . professor c: uh - huh . grad a: so and , um , grad e: mats gould . grad a: and sadly enough he also just left the ims in stuttgart . so he 's not there anymore . grad e: hmm . grad a: but , um i do n't know where he is right now but alternative semantics is if you type that into an , uh , uh , browser or search engine you 'll get tons of stuff . grad e: ok . ok . ok , thanks . grad a: and what i 'm kind of confused about is is what the speaker and the hearer is is sort of doing there . grad f: so for a particular segment it 's really just a reference to some other entity again in the situation , right ? so for a particular segment the speaker might be you or might be me . grad a: yeah . grad f: um , hearer is a little bit harder . it could be like multiple people . i guess that that that that 's not very clear from here grad a: yeah , but you do n't we ultimately want to handle that analogously to the way we handle time and place , grad f: i mean , that 's not allowed here . grad a: because `` you `` , `` me `` , `` he `` , `` they `` , you know , `` these guys `` , all these expressions , nuh , are in in much the same way contextually dependent as `` here , `` and `` now , `` and `` there `` grad f: mm - hmm . professor c: now , this is this is assuming you 've already solved that . grad f: ye - yeah . professor c: so it 's it 's fred and mary , grad f: so th professor c: so the speaker would be fred and the grad a: ah ! grad f: right , so the constructions might of course will refer , using pronouns or whatever . grad a: mm - hmm . grad f: in which case they have to check to see , uh , who the , uh , speaker in here wa in order to resolve those . but when you actually say that `` he walked into `` , whatever , um , the `` he `` will refer to a particular you you will already have figured who `` he `` or `` you `` , mmm , or `` i `` , maybe is a bett better example , who `` i `` refers to . um , and then you 'd just be able to refer to harry , you know , in wherever that person whatever role that person was playing in the event . grad a: mmm . that 's up at the reference part . grad f: yeah , yeah . grad a: and down there in the speaker - hearer part ? grad f: s so , that 's i think that 's just n for instance , speaker is known from the situation , right ? you 're when you hear something you 're told who the speaker is i mean , you know who the speaker is . in fact , that 's kind of constraining how in some ways you know this before you get to the you fill in all the rest of it . i think . professor c: mmm . grad f: i mean , how else would you um grad a: you know , uh , uh , it 's the speaker may in english is allowed to say `` i . `` professor c: yeah . well , here grad a: uh , among the twenty - five percent most used words . grad f: yeah . right . grad a: but would n't the `` i `` then set up the the s s referent that happens to be the speaker this time grad f: mm - hmm . grad a: and not `` they , `` whoever they are . grad f: right , right . grad a: or `` you `` grad f: so grad a: much like the `` you `` could n grad f: s so ok , so i would say ref under referent should be something that corresponds to `` i `` . and maybe each referent should probably have a list of way whatever , the way it was referred to . so that 's `` i `` but , uh , uh , should we say it it refers to , what ? uh , if it were `` harry `` it would refer to like some ontology thing . if it were if it 's `` i `` it would refer to the current speaker , ok , which is given to be like , you know , whoever it is . grad a: well , not not always . i mean , so there 's `` and then he said , i w `` uh - huh . professor c: uh grad f: `` i `` within the current world . grad a: yeah . professor c: yeah . that 's right . so so again , this uh , this this is gon na to get us into the mental space stuff grad f: yeah , yeah , yeah , yeah . professor c: and t because you know , `` fred said that mary said `` , and whatever . grad e: mmm . grad f: mm - hmm . professor c: and and so we 're , uh gon na have to , um , chain those as well . grad a: mm - hmm . twhhh - whhh . but grad f: mm - hmm . so this entire thing is inside a world , professor c: right . right . grad f: not just like the top part . professor c: i i think , uh grad f: that 's grad a: mm - hmm . professor c: except s it 's it 's trickier than that because um , the reference for example so he where it gets really tricky is there 's some things , grad f: yeah . professor c: and this is where blends and all terribl so , some things which really are meant to be identified and some things which are n't . grad f: yeah . right . professor c: and again , all we need for the moment is some way to say that . grad f: right . so i thought of having like for each referent , having the list of of the things t with which it is identified . you know , which which , uh you know , you you you professor c: you could do that . grad f: for instance , um so , i guess , it sort of depends on if it is a referring exp if it 's identifiable already or it 's a new thing . grad e: mm - hmm . grad f: if it 's a new thing you 'd have to like create a structure or whatever . if it 's an old thing it could be referring to , um , usually w something in a situation , right ? or something in ontology . professor c: uh - huh . grad f: so , there 's a you know , whatever , it c it could point at one of these . professor c: i just had a i just had an an idea that would be very nice if it works . grad f: for what ? professor c: uh , uh , uh , i have n't told you what it is yet . grad f: if it works . professor c: this was my build - up . grad f: mm - hmm . mmm . professor c: an i an idea that would be nice i grad f: yeah . ok , we 're crossing our fingers . professor c: right . grad b: so we 're building a mental space , good . professor c: if it worked . yeah . grad f: ok . professor c: right , it was a space builder . um , we might be able to handle context in the same way that we handle mental spaces because , uh , you have somewhat the same things going on of , uh , things being accessible or not . grad f: mm - hmm . professor c: and so , i grad f: yep . professor c: it c it it , uh i think if we did it right we might be able to get at least a lot of the same structure . grad f: use the same { comment } yep . professor c: so that pulling something out of a discourse context is i think similar to other kinds of , uh , mental space phenomena . grad b: i see . grad f: mm - hmm . and and professor c: uh , i 've i 've i 've never seen anybody write that up but maybe they did . i do n't know . that may be all over the literature . grad f: yeah . grad e: there 's things like ther you know , there 's all kinds of stuff like , um , in i think i mentioned last time in czech if you have a a verb of saying then grad f: so so by default grad e: um , you know , you say something like or or i was thinking you can say something like , `` oh , i thought , uh , you are a republican `` or something like that . where as in english you would say , `` i thought you were `` . professor c: right . grad e: um , you know , sort of the past tense being copied onto the lower verb does n't happen there , so you have to say something about , you know , tense is determined relative to current blah - blah - blah . grad f: mm - hmm . grad e: same things happens with pronouns . grad f: mm - hmm . grad e: there 's languages where , um , if you have a verb of saying then , ehhh , where ok , so a situation like `` bob said he was going to the movies `` , where that lower subject is the same as the person who was saying or thinking , you 're actually required to have `` i `` there . grad f: mm - hmm . professor c: mm - hmm . grad e: um , and it 's sort of in an extended function professor c: so we would have it be in quotes in english . grad e: yeah . grad b: right . grad e: but it 's not perceived as a quotative construction . grad f: right . professor c: yeah . grad e: i mean , it 's been analyzed by the formalists as being a logophoric pronoun , um which means a pronoun which refers back to the person who is speaking or that sort of thing , right ? professor c: ok . grad f: oh , right . yeah , that makes sense . grad e: um , but uh , that happens to sound like the word for `` i `` but is actually semantically unrelated to it . grad f: oh , no ! professor c: oh , good , i love the formali grad e: um , grad f: really ? grad e: yeah . yeah . grad f: you 're kidding . grad e: there 's a whole book which basically operates on this assumption . uh , mary dalrymple , uh , this book , a ninety - three book on , uh on pronoun stuff . grad f: no , that 's horrible . ok . that 's horrible . { comment } ok . grad e: well , yeah . and then the same thing for asl where , you know , you 're signing and someone says something . and then , you know , so `` he say `` , and then you sort of do a role shift . and then you sign `` i , this , that , and the other `` . grad f: uh - huh . grad e: and you know , `` i did this `` . that 's also been analyzed as logophoric and having nothing to do with `` i `` . and the role shift thing is completely left out and so on . so , i mean , the point is that pronoun references , uh , you know , sort of ties in with all this mental space stuff and so on , and so forth . grad f: uh - huh . grad e: and so , yeah , i mean grad f: yeah . professor c: so that that d that does sound like it 's co consistent with what we 're saying , yeah . grad e: right . yeah . grad f: ok , so it 's kind of like the unspecified mental spaces just are occurring in context . and then when you embed them sometimes you have to pop up to the h you know , depending on the construction or the whatever , um , you you you 're scope is m might extend out to the the base one . grad e: mm - hmm . professor c: mm - hmm . grad e: yeah . grad f: it would be nice to actually use the same , um , mechanism since there are so many cases where you actually need it 'll be one or the other . grad e: yeah . grad f: it 's like , oh , actually , it 's the same same operation . professor c: oh , ok , so this this is worth some thought . grad f: so . grad e: it 's like it 's like what 's happening that , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ? grad f: yeah , yeah . grad e: so that 's that 's how fauconnier would talk about it . and it happens diff under different circumstances in different languages . grad f: mm - hmm . grad e: and so , grad f: mm - hmm . grad e: um , things like pronoun reference and tense which we 're thinking of as being these discourse - y things actually are relative to a bayes space which can change . grad f: mm - hmm , grad e: and we need all the same machinery . grad f: right . grad a: mm - hmm . grad f: robert . professor c: well , but , uh , this is very good actually grad e: schade . professor c: cuz it it it to the extent that it works , it y grad f: ties it all into it . professor c: it it ties together several of of these things . grad f: yeah . yep . grad a: mm - hmm . mm - hmm . and i 'm sure gon na read the transcript of this one . so . but the , uh , but it 's too bad that we do n't have a camera . you know , all the pointing is gon na be lost . grad e: yeah . grad f: oh , yeah . grad b: well every time nancy giggles it means it means that it 's your job . grad f: yeah , that 's why i said `` point to robert `` , when i did it . grad a: uh . yeah . mmm , is n't i mean , i 'm i was sort of dubious why why he even introduces this sort of reality , you know , as your basic mental space and then builds up grad e: mm - hmm . grad a: d does n't start with some because it 's so obvi it should be so obvious , at least it is to me , { comment } that whenever i say something i could preface that with `` i think . `` nuh ? grad e: yeah . grad a: so there should be no categorical difference between your base and all the others that ensue . grad e: yeah . professor c: no , but there 's there 's a gricean thing going on there , that when you say `` i think `` you 're actually hedging . grad e: yeah , i mean grad f: mmm . it 's like i do n't totally think professor c: right . grad e: yeah . y grad f: i mostly think , uh grad a: yeah , it 's absolutely . grad e: yeah , it 's an it 's an evidential . it 's sort of semi - grammaticalized . people have talked about it this way . and you know , you can do sort of special things . you can , th put just the phrase `` i think `` as a parenthetical in the middle of a sentence and so on , and so forth . grad a: yeah . grad e: so grad f: actually one of the child language researchers who works with t tomasello studied a bunch of these constructions and it was like it 's not using any kind of interesting embedded ways just to mark , you know , uncertainty or something like that . grad e: yeah . grad f: so . grad a: yeah , but about linguistic hedges , i mean , those those tend to be , um , funky anyways because they blur professor c: so we do n't have that in here either do we ? grad e: yeah . grad f: hedges ? professor c: yeah , yeah . grad f: hhh , { comment } i there used to be a slot for speaker , um , it was something like factivity . i could n't really remember what it meant grad e: yeah . grad f: so i took it out . grad e: um . grad f: but it 's something grad e: well we were just talking about this sort of evidentiality and stuff like that , right ? grad f: we we were talking about sarcasm too , right ? oh , oh . grad e: i mean , grad f: oh , yeah , yeah , right . grad e: that 's what i think is , um , sort of telling you what percent reality you should give this professor c: so we probably should . grad f: yeah . grad a: mm - hmm . grad e: or the , you know professor c: confidence or something like that . grad e: yeah , and the fact that i 'm , you know the fact maybe if i think it versus he thinks that might , you know , depending on how much you trust the two of us or whatever , grad f: yeah . grad a: uh great word in the english language is called `` about `` . grad e: you know grad a: if you study how people use that it 's also grad f: what 's the word ? grad a: `` about . `` it 's about professor c: about . grad a: clever . professor c: oh , that in that use of `` about `` , yeah . grad f: oh , oh , oh , as a hedge . grad e: yeah . professor c: and i think and i think y if you want us to spend a pleasant six or seven hours you could get george started on that . grad e: he wrote a paper about thirty - five years ago on that one . grad b: i r i read that paper , professor c: yeah . grad b: the hedges paper ? i read some of that paper actually . grad e: yeah . professor c: yeah . grad e: would you believe that that paper lead directly to the development of anti - lock brakes ? grad f: what ? professor c: no . grad e: ask me about it later i 'll tell you how . when we 're not on tape . grad f: i 'd love to know . grad b: oh , man . grad f: so , and and i think , uh , someone had raised like sarcasm as a complication at some point . professor c: there 's all that stuff . yeah , let 's i i do n't i think grad f: and we just wo n't deal with sarcastic people . professor c: yeah , i mean grad e: i do n't really know what like we we do n't have to care too much about the speaker attitude , right ? like there 's not so many different hhh , { comment } i do n't know , m grad f: certainly not as some well , they 're intonational markers i think for the most part . grad e: yeah . grad f: i do n't know too much about the like grammatical grad e: i just mean there 's lots of different attitudes that that the speaker could have and that we can clearly identify , and so on , and so forth . grad f: yeah . grad e: but like what are the distinctions among those that we actually care about for our current purposes ? professor c: right . right , so , uh , this this raises the question of what are our current purposes . grad f: mm - hmm . professor c: right ? grad e: oh , shoot . grad f: oh , yeah , do we have any ? grad e: here it is three - fifteen already . grad a: mmm . yeah . professor c: uh , so , um , i i do n't know the answer but but , um , it does seem that , you know , this is this is coming along . i think it 's it 's converging . it 's as far as i can tell there 's this one major thing we have to do which is the mental the whole s mental space thing . and then there 's some other minor things . grad f: mm - hmm . professor c: um , and we 're going to have to s sort of bound the complexity . i mean , if we get everything that anybody ever thought about you know , w we 'll go nuts . grad e: yeah . professor c: so we had started with the idea that the actual , uh , constraint was related to this tourist domain and the kinds of interactions that might occur in the tourist domain , assuming that people were being helpful and were n't trying to d you know , there 's all sorts of god knows , irony , and stuff like which you is n't probably of much use in dealing with a tourist guide . grad e: yeah . professor c: yeah ? grad e: yeah . professor c: uh . grad f: m mockery . professor c: right . whatever . so y uh , no end of things th that that , you know , we do n't deal with . grad a: but it professor c: and grad a: i is n't that part easy though professor c: go ahead . grad a: because in terms of the s simspec , it would just mean you put one more set of brack brackets around it , and then just tell it to sort of negate whatever the content of that is in terms of irony grad e: yeah . professor c: n no . grad f: mmm . grad a: or professor c: no . grad e: right . grad f: maybe . professor c: no . grad f: yeah , in model theory cuz the semantics is always like `` speaker believes not - p `` , you know ? professor c: right . grad f: like `` the speaker says p and believes not - p `` . grad e: we have a theoretical model of sarcasm now . grad f: but professor c: right . grad e: yeah , right , i mean . professor c: no , no . grad f: right , right , but , professor c: anyway , so so , um , i guess uh , let me make a proposal on how to proceed on that , which is that , um , it was keith 's , uh , sort of job over the summer to come up with this set of constructions . uh , and my suggestion to keith is that you , over the next couple weeks , n grad e: mmm . professor c: do n't try to do them in detail or formally but just try to describe which ones you think we ought to have . grad e: ok . professor c: uh , and then when robert gets back we 'll look at the set of them . grad e: ok . professor c: just just sort of , you know , define your space . grad e: yeah , ok . professor c: and , um , so th these are this is a set of things that i think we ought to deal with . grad e: yeah . professor c: and then we 'll we 'll we 'll go back over it and w people will will give feedback on it . grad e: ok . professor c: and then then we 'll have a at least initial spec of of what we 're actually trying to do . grad e: yeah . professor c: and that 'll also be useful for anybody who 's trying to write a parser . grad e: mm - hmm . professor c: knowing uh grad e: in case there 's any around . grad f: if we knew anybody like that . professor c: right , `` who might want `` et cetera . so , uh grad e: ok . professor c: so a and we get this this , uh , portals fixed and then we have an idea of the sort of initial range . and then of course nancy you 're gon na have to , uh , do your set of but you have to do that anyway . grad f: for the same , yeah , data . yeah , mm - hmm . professor c: so so we 're gon na get the w we 're basically dealing with two domains , the tourist domain and the and the child language learning . grad b: mmm . professor c: and we 'll see what we need for those two . and then my proposal would be to , um , not totally cut off more general discussion but to focus really detailed work on the subset of things that we 've we really want to get done . grad e: mm - hmm . professor c: and then as a kind of separate thread , think about the more general things and and all that . grad e: mm - hmm . mm - hmm . grad a: well , i also think the detailed discussion will hit you know , bring us to problems that are of a general nature and maybe even professor c: uh , without doubt . yeah . grad f: yeah . grad a: even suggest some solutions . professor c: but what i want to do is is is to to constrain the things that we really feel responsible for . grad a: yeah . mmm . professor c: so that that we say these are the things we 're really gon na try do by the end of the summer grad e: mm - hmm . professor c: and other things we 'll put on a list of of research problems or something , because you can easily get to the point where nothing gets done because every time you start to do something you say , `` oh , yeah , but what about this case ? `` grad e: mm - hmm . professor c: this is this is called being a linguist . grad a: mmm . grad e: yeah . professor c: and , uh , grad e: basically . grad f: or me . professor c: huh ? grad f: or me . anyways grad b: there 's that quote in jurafsky and martin where where it goes where some guy goes , `` every time i fire a linguist the performance of the recognizer goes up . `` professor c: right . grad f: yeah . grad e: exactly . professor c: right . but anyway . so , is is that does that make sense as a , uh a general way to proceed ? grad f: sure , yeah . grad e: yeah , yeah , we 'll start with that , just figuring out what needs to be done then actually the next step is to start trying to do it . professor c: exactly right . grad a: mmm . grad e: got it . grad a: mmm . grad e: ok . grad a: we have a little bit of news , uh , just minor stuff . the one big grad b: ooo , can i ask a grad e: you ran out of power . grad a: huh ? grad b: can i ask a quick question about this side ? grad a: yeah . grad f: yes . grad b: is this , uh was it intentional to leave off things like `` inherits `` and grad f: oops . um , grad e: no . grad f: not really just on the constructions , right ? grad b: yeah , like constructions can inherit from other things , grad f: um , grad b: am i right ? grad f: yeah . grad b: yeah . grad f: i did n't want to think too much about that for for now . grad b: ok . professor c: yeah . grad f: so , uh , maybe it was subconsciously intentional . professor c: yeah , uh yeah . grad e: um , yeah , there should be i i wanted to s find out someday if there was gon na be some way of dealing with , uh , if this is the right term , multiple inheritance , professor c: mm - hmm . grad e: where one construction is inheriting from , uh from both parents , grad f: uh - huh . yep . grad e: uh , or different ones , or three or four different ones . professor c: yeah . so let me grad e: cuz the problem is that then you have to grad f: yeah . grad e: which of you know , which are how they 're getting bound together . grad f: refer to them . professor c: yeah , right , right , right . yeah , yeah , yeah . grad f: yeah , and and there are certainly cases like that . even with just semantic schemas we have some examples . professor c: right . grad f: so , and we 've been talking a little bit about that anyway . professor c: yeah . so what i would like to do is separate that problem out . grad f: inherits . professor c: so um , grad e: ok . professor c: my argument is there 's nothing you can do with that that you ca n't do by just having more constructions . grad e: yeah , yes . professor c: it 's uglier and it d does n't have the deep linguistic insights and stuff . grad e: that 's right . professor c: uh , grad e: but whatever . professor c: right . grad e: yeah , no , no , no no . grad f: uh , those are over rated . grad e: no , by all means , professor c: and so i what i 'd like to do is is in the short run focus on getting it right . grad e: right . uh , sure . professor c: and when we think we have it right then saying , `` aha ! , grad e: yeah . professor c: can we make it more elegant ? `` grad e: yeah , that 's professor c: can can we , uh what are the generalizations , and stuff ? grad e: yeah . connect the dots . yeah . professor c: but rather than try to guess a inheritance structure and all that sort of stuff before we know what we 're doing . grad e: yep . yeah . professor c: so i would say in the short run we 're not gon na b grad e: yeah . professor c: first of all , we 're not doing them yet at all . and and it could be that half way through we say , `` aha ! , we we now see how we want to clean it up . `` grad e: mm - hmm . professor c: uh , and inheritance is only one i mean , that 's one way to organize it but there are others . and it may or may not be the best way . grad e: yeah . grad a: mmm . professor c: i 'm sorry , you had news . grad a: oh , just small stuff . um , thanks to eva on our web site we can now , if you want to run javabayes , uh , you could see get download these classes . and then it will enable you she modified the gui so it has now a m a m a button menu item for saving it into the embedded javabayes format . grad d: mm - hmm . grad b: mmm . grad a: so that 's wonderful . professor c: great . grad a: and , um and she , a you tested it out . do you want to say something about that , that it works , right ? with the grad d: i was just checking like , when we wan na , um , get the posterior probability of , like , variables . you know how you asked whether we can , like , just observe all the variables like in the same list ? you ca n't . grad a: uh - huh . grad d: you have to make separate queries every time . grad a: ok , that 's that 's a bit unfortunate grad d: so yeah . grad a: but for the time being it 's it 's it 's fine to do it grad d: you just have to have a long list of , you know , all the variables . grad a: yeah . but uh grad d: basically . grad f: uh , all the things you want to query , you just have to like ask for separately . grad d: yeah , yeah . grad a: well that 's probably maybe in the long term that 's good news because it forces us to think a little bit more carefully how how we want to get an out output . um , but that 's a different discussion for a different time . and , um , i do n't know . we 're really running late , so i had , uh , an idea yesterday but , uh , i do n't know whether we should even start discussing . professor c: w what yeah , sure , tell us what it is . grad a: um , the construal bit that , um , has been pointed to but has n't been , um , made precise by any means , um , may w may work as follows . i thought that we would , uh that the following thing would be in incredibly nice and i have no clue whether it will work at all or nothing . so that 's just a tangent , a couple of mental disclaimers here . um , imagine you you write a bayes - net , um grad f: bayes ? grad a: bayes - net , grad f: ok . grad a: um , completely from scratch every time you do construal . so you have nothing . just a white piece of paper . professor c: mmm , right . grad a: you consult consult your ontology which will tell you a bunch of stuff , and parts , and properties , uh - uh - uh grad f: grout out the things that that you need . professor c: right . grad a: then y you 'd simply write , uh , these into onto your your white piece of paper . and you will get a lot of notes and stuff out of there . you wo n't get you wo n't really get any c p t 's , therefore we need everything that that configures to what the situation is , ie , the context dependent stuff . so you get whatever comes from discourse but also filtered . uh , so only the ontology relevant stuff from the discourse plus the situation and the user model . grad f: mm - hmm . grad a: and that fills in your cpt 's with which you can then query , um , the the net that you just wrote and find out how thing x is construed as an utterance u . and the embedded javabayes works exactly like that , that once you we have , you know , precise format in which to write it , so we write it down . you query it . you get the result , and you throw it away . and the the nice thing about this idea is that you do n't ever have to sit down and think about it or write about it . you may have some general rules as to how things can be can be construed as what , so that will allow you to craft the the the initial notes . but it 's in that respect it 's completely scalable . because it does n't have any prior , um , configuration . it 's just you need an ontology of the domain and you need the context dependent modules . and if this can be made to work at all , that 'd be kind of funky . professor c: um , it sounds to me like you want p r grad a: p r ms - uh , prm i mean , since you can unfold a prm into a straightforward bayes - net professor c: beca - because it b because no , no , you ca n't . see the the critical thing about the prm is it gives these relations in general form . so once you have instantiated the prm with the instances and ther then you can then you can unfold it . grad a: then you can . mm - hmm , yeah . no , i was m using it generic . so , uh , probabilistic , whatever , relational models . whatever you write it . in professor c: well , no , but it matters a lot because you what you want are these generalized rules about the way things relate , th that you then instantiate in each case . grad a: and then then instantiate them . that 's ma maybe the the way the only way it works . professor c: yeah , and that 's grad a:  professor c: yeah , that 's the only way it could work . i we have a our local expert on p r uh , but my guess is that they 're not currently good enough to do that . but we 'll we 'll have to see . grad a: but , uh , professor c: uh yes . this is that 's that would be a good thing to try . it 's related to the hobbs abduction story in that you th you throw everything into a pot and you try to come up with the , uh grad a: except there 's no no theorem prover involved . grad f: best explanation . professor c: no , there is n't a theorem prover but there but but the , um , the cove the the p r ms are like rules of inference and you 're you 're coupling a bunch of them together . grad a: mm - hmm , yeah . professor c: and then ins instead of proving you 're trying to , you know , compute the most likely . uh tricky . but you yeah , it 's a good it 's a it 's a good thing to put in your thesis proposal . grad a: what 's it ? professor c: so are you gon na write something for us before you go ? grad a: yes . um . professor c: oh , you have something . grad a: in the process thereof , or whatever . professor c: ok . so , what 's what when are we gon na meet again ? grad f: when are you leaving ? grad a: fri - uh , grad f: thursday , friday ? grad a: thursday 's my last day here . grad d: fri professor c: yeah . grad f: ok . grad a: so i would suggest as soon as possible . do you mean by we , the whole ben gang ? professor c: n no , i did n't mean y just the two of us . we obviously we can we can do this . but the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal and get , uh , another session on feedback on that ? or grad a: we can do it th - thursday again . yeah . grad e: fine with me . should we do the one pm time for thursday since we were on that before or ? grad a: sure . grad e: ok . professor c: alright . grad d: hmm . grad a: thursday at one ? i can also maybe then sort of run through the , uh the talk i have to give at eml which highlights all of our work . professor c: ok . grad a: and we can make some last minute changes on that . professor c: ok . grad b: you can just give him the abstract that we wrote for the paper . professor c: that - that 'll tell him exactly what 's going on . yeah , that alright . grad f: can we do can we do one - thirty ? grad a: no . grad f: oh , you already told me no . grad a: but we can do four . grad f: one , ok , it 's fine . i can do one . it 's fine . it 's fine . grad a: one or four . i do n't care . grad e: to me this is equal . i do n't care . grad a: if it 's equal for all ? what should we do ? grad f: yeah , it 's fine . grad a: four ? grad f: fine . yeah no , no , no , uh , i do n't care . it 's fine . grad a: it 's equal to all of us , so you can decide one or four . grad b: the pressure 's on you nancy . grad a: liz actually said she likes four because it forces the meeting recorder people to cut , you know the discussions short . grad f: ok . ok , four . grad e: well , if you insist , then . grad f: ok ? ok . i am .","output":"given the domains currently used ( tourist , child language learning ) , some features , like speaker attitude , are not of equal importance at this stage . on the other hand , it was decided for the inheritance between constructions to be left out for now , as the notation can be rendered more elegant later on ."},{"instruction":"summarize the meeting","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"the participants went over the results of the most recent experiments , discussing future directions to take . adding in more languages was still decreasing model performance . the best network consisted of the timit and noise . the team thought that they should try to reduce their dependence on noise in the data . the professor outlined how they could continue their experimentation ."},{"instruction":"summarize the discussion about the results from the experiments","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"last run of experiments showed that adding more languages was still severely harming model performance . they noted that normalization of any kind has a good effect on the model , whereas msg does nothing ."},{"instruction":"what did the professor think about the results ?","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"the professor noted that the results were better than he expected and that the msg did nothing . he also noted that adding french and spanish to the multilingual english model hurt the model ."},{"instruction":"what did phd a think about the results ?","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"phd a thought that most of the nets are not that good , except for the multi english . msg was not bringing as much information as he thought it would . he explained that even when the features were not normalized , the neural network would perform at 90 % , as it would with normalization ."},{"instruction":"summarize the discussion on future directions","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"the team discussed testing a multi-band approach that is more resistance to noise . the professor thought that it many not be a bad idea to put together several mlp 's to improve performance . the team also thought that there might be problems with the pronunciation models ."},{"instruction":"what did the professor think about msg ?","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"the professor generally liked msg because of its different temporal properties . nonetheless , he recognized that it might not be practical to explore it further due to time constraints . at this point , he thought that there were no clear solutions to the challenges they were facing , but there was still plenty to do ."},{"instruction":"what did the team think about their progress ?","input":"professor d: ok . phd a: mike . mike - one ? phd b: ah . professor d: we 're on ? yes , please . i mean , we 're testing noise robustness but let 's not get silly . ok , so , uh , you 've got some , uh , xerox things to pass out ? phd a: yeah , professor d: that are phd a: um . professor d: yeah . phd a: yeah . yeah , i 'm sorry for the table , but as it grows in size , uh , it . professor d: uh , so for th the last column we use our imagination . ok . phd b: ah , yeah . professor d: ah . phd a: uh , yeah . phd b: uh , do you want @ @ . professor d: this one 's nice , though . this has nice big font . phd a: yeah . grad c: let 's see . yeah . chop ! professor d: yeah . phd a: so professor d: when you get older you have these different perspectives . i mean , lowering the word hour rate is fine , but having big font ! phd a: next time we will put colors or something . professor d: that 's what 's phd a: uh . professor d: yeah . it 's mostly big font . ok . phd a: ok , s so there is kind of summary of what has been done professor d: uh go ahead . phd a: it 's this . summary of experiments since , well , since last week professor d: oh . ok . phd a: and also since the we 've started to run work on this . um . so since last week we 've started to fill the column with um uh features w with nets trained on plp with on - line normalization but with delta also , because the column was not completely professor d: mm - hmm . mm - hmm . phd a: well , it 's still not completely filled , professor d:  phd a: but we have more results to compare with network using without plp and finally , hhh , { comment } um ehhh { comment } pl - uh delta seems very important . uh i do n't know . if you take um , let 's say , anyway aurora - two - b , so , the next t the second , uh , part of the table , professor d: mm - hmm . phd a: uh when we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . professor d: a and again all of these numbers are with a hundred percent being , uh , the baseline performance , phd a: yeah , on the baseline , yeah . so professor d: but with a mel cepstra system going straight into the htk ? phd a: yeah . yeah . so now we see that the gap between the different training set is much uh uh much smaller professor d: yes . phd a: um grad c: it 's out of the way . phd a: but , actually , um , for english training on timit is still better than the other languages . and mmm , yeah . and f also for italian , actually . if you take the second set of experiment for italian , so , the mismatched condition , professor d: mm - hmm . phd a: um when we use the training on timit so , it 's multi - english , we have a ninety - one number , professor d: mm - hmm . phd a: and training with other languages is a little bit worse . professor d: um oh , i see . down near the bottom of this sheet . phd a: so , professor d: uh , { comment } yes . phd a: yeah . professor d: ok . phd a: and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 's we have one hundred and seventy - two , professor d: yes . phd a: and one hundred and four when we use delta . professor d: yeah . phd a: uh . even if the contexts used is quite the same , professor d: mm - hmm . phd a: because without delta we use seventeenths seventeen frames . uh . yeah , um , so the second point is that we have no single cross - language experiments , uh , that we did not have last week . uh , so this is training the net on french only , or on english only , and testing on italian . professor d: mm - hmm . phd a: and training the net on french only and spanish only and testing on , uh ti - digits . professor d: mm - hmm . phd a: and , fff { comment } um , yeah . what we see is that these nets are not as good , except for the multi - english , which is always one of the best . yeah , then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh from { comment } uh english digits , and from italian digits . so this is the another line another set of lines in the table . uh , @ @ with spine professor d: ah , yes . mm - hmm . phd a: and uh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uh the experiment training the net with , uh plp , but with delta . but professor d: mm - hmm . phd a: um this this net performed quite well . well , it 's it 's better than the net using french , spanish , and english only . uh . so , uh , yeah . we have also started feature combination experiments . uh many experiments using features and net outputs together . and this is the results are on the other document . uh , we can discuss this after , perhaps well , just , @ @ . yeah , so basically there are four four kind of systems . the first one , yeah , is combining , um , two feature streams , uh using and each feature stream has its own mpl . so it 's the kind of similar to the tandem that was proposed for the first . the multi - stream tandem for the first proposal . the second is using features and klt transformed mlp outputs . and the third one is to u use a single klt trans transform features as well as mlp outputs . um , yeah . mmm . you know you can you can comment these results , phd b: yes , i can s i would like to say that , for example , um , mmm , if we does n't use the delta - delta , uh we have an improve when we use s some combination . but when phd a: yeah , we ju just to be clear , the numbers here are uh recognition accuracy . phd b: w yeah , this yeah , this number recognition acc phd a: so it 's not the again we switch to another phd b: yes , and the baseline the baseline have i is eighty - two . professor d: baseline is eighty - two . phd b: yeah phd a: so it 's experiment only on the italian mismatched for the moment for this . professor d: uh , this is italian mismatched . phd a: um . phd b: yeah , by the moment . phd a: mm - hmm . professor d: ok . phd b: and first in the experiment - one i i do i i use different mlp , professor d: mm - hmm . phd b: and is obviously that the multi - english mlp is the better . um . for the ne rest of experiment i use multi - english , only multi - english . and i try to combine different type of feature , but the result is that the msg - three feature does n't work for the italian database because never help to increase the accuracy . phd a: yeah , eh , actually , if w we look at the table , the huge table , um , we see that for ti - digits msg perform as well as the plp , professor d: mm - hmm . phd a: but this is not the case for italian what where the error rate is c is almost uh twice the error rate of plp . professor d: mm - hmm . phd a: so , um uh , well , i do n't think this is a bug but this this is something in probably in the msg um process that uh i do n't know what exactly . perhaps the fact that the the there 's no low - pass filter , well , or no pre - emp pre - emphasis filter and that there is some dc offset in the italian , or , well , something simple like that . but that we need to sort out if want to uh get improvement by combining plp and msg professor d: mm - hmm . phd a: because for the moment msg do does n't bring much information . professor d: mm - hmm . phd a: and as carmen said , if we combine the two , we have the result , basically , of plp . professor d: i um , the uh , baseline system when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , phd b: yeah . professor d: and the training is italian digits ? phd b: yeah . professor d: so the `` mismatch `` just refers to the noise and and , uh microphone and so forth , phd a: yeah . phd b: yeah . professor d: right ? so , um did we have so would that then correspond to the first line here of where the training is is the uh italian digits ? phd b: the train the training of the htk ? professor d: the phd b: yes . ah yes ! professor d: yes . phd b: this h yes . th - yes . professor d: yes . training of the net , phd b: yeah . professor d: yeah . so , um so what that says is that in a matched condition , we end up with a fair amount worse putting in the uh plp . now w would do we have a number , i suppose for the matched i i do n't mean matched , but uh use of italian training in italian digits for plp only ? phd b: uh yes ? phd a: uh yeah , so this is basically this is in the table . uh so the number is fifty - two , phd b: another table . phd a: uh professor d: fifty - two percent . phd a: fift - so no , it 's it 's the phd b: no . professor d: no , fifty - two percent of eighty - two ? phd a: of of of uh eighteen phd b: eighty . phd a: of eighteen . phd b: eighty . phd a: so it 's it 's error rate , basically . phd b: it 's plus six . phd a: it 's er error rate ratio . so professor d: oh this is accuracy ! phd a: uh , so we have nine nine let 's say ninety percent . phd b: yeah . professor d: oy ! { comment } ok . ninety . phd a: yeah . um { comment } which is uh { comment } what we have also if use plp and msg together , professor d: yeah . phd a: eighty - nine point seven . professor d: ok , so even just plp , uh , it is not , in the matched condition um i wonder if it 's a difference between plp and mel cepstra , or whether it 's that the net half , for some reason , is not helping . phd a: uh . p - plp and mel cepstra give the same same results . professor d: same result pretty much ? phd a: well , we have these results . i do n't know . it 's not do you have this result with plp alone , { comment } j fee feeding htk ? professor d: so , s phd a: that that 's what you mean ? phd b: yeah , phd a: just plp at the input of htk . phd b: yeah yeah yeah yeah , at the first and the yeah . phd a: yeah . so , plp professor d: eighty - eight point six . phd a: yeah . professor d: um , so adding msg phd a: um professor d: um well , but that 's yeah , that 's without the neural net , phd a: yeah , that 's without the neural net professor d: right ? phd a: and that 's the result basically that ogi has also with the mfcc with on - line normalization . professor d: but she had said eighty - two . phd a: this is the w well , but this is without on - line normalization . professor d: right ? oh , this the eighty - two . phd a: yeah . phd b:  phd a: eighty - two is the it 's the aurora baseline , so mfcc . then we can use well , ogi , they use mfcc th the baseline mfcc plus on - line normalization professor d: oh , i 'm sorry , i k i keep getting confused because this is accuracy . phd a: yeah , sorry . yeah . phd b: yeah . professor d: ok . alright . phd a: yeah . professor d: alright . so this is i was thinking all this was worse . ok so this is all better phd b: yes , better . professor d: because eighty - nine is bigger than eighty - two . phd a: mm - hmm . phd b: yeah . professor d: ok . i 'm i 'm all better now . ok , go ahead . phd a: so what happ what happens is that when we apply on - line normalization we jump to almost ninety percent . professor d: yeah . mm - hmm . phd a: uh , when we apply a neural network , is the same . we j jump to ninety percent . phd b: nnn , we do n't know exactly . professor d: yeah . phd a: and and um whatever the normalization , actually . if we use n neural network , even if the features are not correctly normalized , we jump to ninety percent . so professor d: so we go from eighty - si eighty - eight point six to to ninety , or something . phd a: well , ninety no , i i mean ninety it 's around eighty - nine , ninety , eighty - eight . professor d: eighty - nine . phd a: well , there are minor minor differences . phd b: yeah . professor d: and then adding the msg does nothing , basically . phd a: no . professor d: yeah . ok . phd a: uh for italian , yeah . professor d: for this case , right ? phd a: um . professor d: alright . so , um so actually , the answer for experiments with one is that adding msg , if you uh does not help in that case . phd a: mm - hmm . professor d: um phd a: but w yeah . professor d: the other ones , we 'd have to look at it , but and the multi - english , does uh so if we think of this in error rates , we start off with , uh eighteen percent error rate , roughly . phd a: mm - hmm . professor d: um and we uh almost , uh cut that in half by um putting in the on - line normalization and the neural net . phd a: yeah professor d: and the msg does n't however particularly affect things . phd a: no . professor d: and we cut off , i guess about twenty - five percent of the error . uh no , not quite that , is it . uh , two point six out of eighteen . about , um sixteen percent or something of the error , um , if we use multi - english instead of the matching condition . phd a: mm - hmm . yeah . professor d: not matching condition , but uh , the uh , italian training . phd a: mm - hmm . phd b: yeah . professor d: ok . phd a: mmm . phd b: we select these these these tasks because it 's the more difficult . professor d: yes , good . ok ? so then you 're assuming multi - english is closer to the kind of thing that you could use since you 're not gon na have matching , uh , data for the uh for the new for the other languages and so forth . um , one qu thing is that , uh i think i asked you this before , but i wan na double check . when you say `` me `` in these other tests , that 's the multi - english , phd a: that 's it 's a part it 's professor d: but it is not all of the multi - english , right ? it is some piece of part of it . phd a: or , one million frames . professor d: and the multi - english is how much ? phd b: you have here the information . phd a: it 's one million and a half . yeah . professor d: oh , so you used almost all you used two thirds of it , phd a: yeah . professor d: you think . so , it it 's still it hurts you seems to hurt you a fair amount to add in this french and spanish . phd a: mmm . phd b: yeah . professor d: i wonder why yeah . uh . grad c: well stephane was saying that they were n't hand - labeled , phd a: yeah , it 's phd b: yeah . phd a: yeah . grad c: the french and the spanish . phd b: the spanish . maybe for that . professor d: hmm . phd a: mmm . professor d: it 's still ok . alright , go ahead . and then then phd b: um . mmm , with the experiment type - two , i first i tried to to combine , nnn , some feature from the mlp and other feature another feature . professor d: mm - hmm . phd b: and we s we can first the feature are without delta and delta - delta , and we can see that in the situation , uh , the msg - three , the same help nothing . professor d: mm - hmm . phd b: and then i do the same but with the delta and delta - delta plp delta and delta - delta . and they all p but they all put off the mlp is it without delta and delta - delta . and we have a l little bit less result than the the the baseline plp with delta and delta - delta . professor d: mm - hmm . phd b: maybe if when we have the new the new neural network trained with plp delta and delta - delta , maybe the final result must be better . i do n't know . phd a: actually , just to be some more phd b: uh phd a: do this number , this eighty - seven point one number , has to be compared with the professor d: yes , yeah , i mean it ca n't be compared with the other phd a: which number ? professor d: cuz this is , uh with multi - english , uh , training . phd b: mm - hmm . professor d: so you have to compare it with the one over that you 've got in a box , which is that , uh the eighty - four point six . phd b: mm - hmm . professor d: right ? phd a: uh . professor d: so phd a: yeah , but i mean in this case for the eighty - seven point one we used mlp outputs for the plp net professor d: yeah . phd a: and straight features with delta - delta . and straight features with delta - delta gives you what 's on the first sheet . phd b: mm - hmm . professor d: yeah . not t not phd a: it 's eight eighty - eight point six . professor d: tr no . no . no . phd b: yes . professor d: not trained with multi - english . phd a: uh , yeah , but th this is the second configuration . phd b: no , but they they feature @ @ without phd a: so we use feature out uh , net outputs together with features . so yeah , this is not perhaps not clear here but in this table , the first column is for mlp and the second for the features . professor d: eh . { comment } oh , i see . ah . so you 're saying w so asking the question , `` what what has adding the mlp done to improve over the , phd a: so , just yeah so , actually it it it decreased the the accuracy . professor d: uh phd b: yeah . professor d: yes . phd a: because we have eighty - eight point six . professor d: uh - huh . phd a: and even the mlp alone what gives the mlp alone ? multi - english plp . oh no , it gives eighty - three point six . so we have our eighty - three point six and now eighty - eighty point six , phd b: but phd a: that gives eighty - seven point one . professor d: mm - hmm . eighty - s i thought it was eighty oh , ok , eighty - three point six and eighty eighty - eight point six . phd a: eighty - three point six . eighty professor d: ok . phd a: is th is that right ? yeah ? phd b: yeah . but i do n't know but maybe if we have the neural network trained with the plp delta and delta - delta , maybe tha this can help . phd a: perhaps , yeah . professor d: well , that 's that 's one thing , but see the other thing is that , um , i mean it 's good to take the difficult case , but let 's let 's consider what that means . what what we 're saying is that one o one of the things that i mean my interpretation of your your s original suggestion is something like this , as motivation . when we train on data that is in one sense or another , similar to the testing data , then we get a win by having discriminant training . phd a: mm - hmm . professor d: when we train on something that 's quite different , we have a potential to have some problems . phd a: mm - hmm . professor d: and , um , if we get something that helps us when it 's somewhat similar , and does n't hurt us too much when it when it 's quite different , that 's maybe not so bad . phd a: yeah . mmm . professor d: so the question is , if you took the same combination , and you tried it out on , uh on say digits , phd a: on ti - digits ? ok . professor d: you know , d was that experiment done ? phd a: no , not yet . professor d: yeah , ok . uh , then does that , eh you know maybe with similar noise conditions and so forth , { comment } does it does it then look much better ? phd a: mm - hmm . professor d: and so what is the range over these different kinds of uh of tests ? so , an anyway . ok , go ahead . phd a: yeah . phd b: and , with this type of configuration which i do on experiment using the new neural net with name broad klatt s twenty - seven , uh , d i have found more or less the same result . professor d: mm - hmm . phd a: so , it 's slightly better , phd b: little bit better ? phd a: yeah . professor d: slightly better . phd a: yeah . phd b: slightly bet better . yes , is better . professor d: and and you know again maybe if you use the , uh , delta there , uh , you would bring it up to where it was , uh you know at least about the same for a difficult case . phd b: yeah , maybe . maybe . maybe . phd a: yeah . phd b: oh , yeah . phd a: yeah . well , so perhaps let 's let 's jump at the last experiment . phd b: oh , yeah . professor d: so . phd a: it 's either less information from the neural network if we use only the silence output . phd b: i professor d: mm - hmm . phd a: it 's again better . so it 's eighty - nine point point one . phd b: yeah , professor d: mm - hmm . phd b: and we have only forty forty feature phd a: so . phd b: because in this situation we have one hundred and three feature . professor d: yeah . phd b: yeah . and then w with the first configuration , i f i am found that work , uh , does n't work professor d: yeah . phd b: uh , well , work , but is better , the second configuration . because i for the del engli - plp delta and delta - delta , here i have eighty - five point three accuracy , and with the second configuration i have eighty - seven point one . professor d: um , by the way , there is a another , uh , suggestion that would apply , uh , to the second configuration , um , which , uh , was made , uh , by , uh , hari . and that was that , um , if you have uh feed two streams into htk , um , and you , uh , change the , uh variances if you scale the variances associated with , uh these streams um , you can effectively scale the streams . right ? so , um , you know , without changing the scripts for htk , which is the rule here , uh , you can still change the variances phd a: mm - hmm . professor d: which would effectively change the scale of these these , uh , two streams that come in . phd a: uh , { comment } yeah . professor d: and , um , so , um , if you do that , for instance it may be the case that , um , the mlp should not be considered as strongly , for instance . phd a: mmm . professor d: and , um , so this is just setting them to be , excuse me , of equal equal weight . maybe it should n't be equal weight . phd b: maybe . professor d: right ? you know , i i 'm sorry to say that gives more experiments if we wanted to look at that , but but , uh , um , you know on the other hand it 's just experiments at the level of the htk recognition . phd a: mmm . professor d: it 's not even the htk , phd a: yeah . professor d: uh , uh phd b: yeah . yeah . professor d: well , i guess you have to do the htk training also . phd b: so this is what we decided to do . professor d: uh , do you ? let me think . maybe you do n't . uh . yeah , you have to change the no , you can just do it in as once you 've done the training grad c: and then you can vary it . yeah . professor d: yeah , the training is just coming up with the variances so i guess you could you could just scale them all . phd a: scale professor d: variances . phd a: yeah . but is it i th i mean the htk models are diagonal covariances , so i d is it professor d: that 's uh , exactly the point , i think , that if you change um , change what they are phd a: hmm . mm - hmm . professor d: it 's diagonal covariance matrices , but you say what those variances are . phd a: mm - hmm . professor d: so , that you know , it 's diagonal , but the diagonal means th that then you 're gon na it 's gon na it 's gon na internally multiply it and and uh , uh , i it im uh implicitly exponentiated to get probabilities , and so it 's it 's gon na it 's it 's going to affect the range of things if you change the change the variances of some of the features . phd a: mmm . mmm . phd b: do ? professor d: so , i it 's precisely given that model you can very simply affect , uh , the s the strength that you apply the features . that was that was , uh , hari 's suggestion . phd a: yeah . yeah . professor d: so , um phd b: yeah . professor d: yeah . so . so it could just be that h treating them equally , tea treating two streams equally is just just not the right thing to do . of course it 's potentially opening a can of worms because , you know , maybe it should be a different number for for each kind of test set , or something , phd a: mm - hmm . professor d: but ok . phd a: yeah . professor d: so i guess the other thing is to take you know if one were to take , uh , you know , a couple of the most successful of these , phd a: yeah , and test across everything . professor d: and uh yeah , try all these different tests . phd a: mmm . phd b: yeah . phd a: yeah . professor d: alright . uh . phd a: so , the next point , yeah , we 've had some discussion with steve and shawn , um , about their um , uh , articulatory stuff , um . so we 'll perhaps start something next week . professor d: mm - hmm . phd a: um , discussion with hynek , sunil and pratibha for trying to plug in their our our networks with their within their block diagram , uh , where to plug in the the network , uh , after the the feature , before as um a as a plugin or as a anoth another path , discussion about multi - band and traps , um , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . well , basically , it would be a trap system . basically , this is a trap system kind of trap system , i mean , but where the neural network are replaced by lda . hmm . um , yeah , and about multi - band , uh , i started multi - band mlp trainings , um mmh { comment } actually , i w i w hhh { comment } prefer to do exactly what i did when i was in belgium . so i take exactly the same configurations , seven bands with nine frames of context , and we just train on timit , and on the large database , so , with spine and everything . and , mmm , i 'm starting to train also , networks with larger contexts . so , this would would be something between traps and multi - band because we still have quite large bands , and but with a lot of context also . so um yeah , we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . so . now we can test these two networks on with with delta and large networks . well , test them also on finnish phd b: mmm . phd a: and see which one is the the the best . uh , well , the next part of the document is , well , basically , a kind of summary of what everything that has been done . so . we have seventy - nine m l ps trained on one , two , three , four , uh , three , four , five , six , seven ten on ten different databases . professor d: mm - hmm . phd a: uh , the number of frames is bad also , so we have one million and a half for some , three million for other , and six million for the last one . uh , yeah ! { comment } as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . um . yeah , the other are just viterbi - aligned . so these seventy - nine mlp differ on different things . first , um with respect to the on - line normalization , there are that use bad on - line normalization , and other good on - line normalization . um . with respect to the features , with respect to the use of delta or no , uh with respect to the hidden layer size and to the targets . uh , but of course we do n't have all the combination of these different parameters um . s what 's this ? we only have two hundred eighty six different tests and no not two thousand . professor d: ugh ! i was impressed boy , two thousand . phd a: yeah . phd b: ah , yes . professor d: ok . phd b: i say this morning that @ @ thought it was the professor d: alright , now i 'm just slightly impressed , ok . phd a: um . yeah , basically the observation is what we discussed already . the msg problem , um , the fact that the mlp trained on target task decreased the error rate . but when the m - mlp is trained on the um is not trained on the target task , it increased the error rate compared to using straight features . except if the features are bad uh , actually except if the features are not correctly on - line normalized . in this case the tandem is still better even if it 's trained on not on the target digits . professor d: yeah . so it sounds like yeah , the net corrects some of the problems with some poor normalization . phd a: yeah . professor d: but if you can do good normalization it 's it 's uh ok . phd a: yeah . phd b: yeah . phd a: uh , so the fourth point is , yeah , the timit plus noise seems to be the training set that gives better the best network . professor d: so so - let me bef before you go on to the possible issues . phd a: mm - hmm . professor d: so , on the msg uh problem um , i think that in in the um , in the short time solution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , phd a: mm - hmm . professor d: uh , much as i said with jrasta , even though i really like jrasta and i really like msg , phd a: mm - hmm . professor d: i think it 's kind of in category that it 's , it it may be complicated . phd a: yeah . professor d: and uh it might be if someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rush uh for results . phd a: mm - hmm . professor d: but in the short term , unless you have some some s strong idea of what 's wrong , phd a: i do n't know at all but i 've perhaps i have the feeling that it 's something that 's quite quite simple or just like nnn , no high - pass filter professor d: yeah , probably . phd a: or mmm . yeah . my but i do n't know . professor d: there 's supposed to well msg is supposed to have a an on - line normalization though , right ? phd a: it 's there is , yeah , an agc - kind of agc . yeah . yeah . yeah . professor d: yeah , but also there 's an on - line norm besides the agc , there 's an on - line normalization that 's supposed to be uh , yeah , phd a: mmm . professor d: taking out means and variances and so forth . so . phd a: yeah . professor d: in fac in fact the on - line normalization that we 're using came from the msg design , phd a: um . professor d: so it 's phd a: yeah , but yeah . but this was the bad on - line normalization . actually . uh . are your results are still with the bad the bad phd b: maybe , may no ? with the better phd a: with the o - oln - two ? phd b: no ? phd a: ah yeah , you have you have oln - two , phd b: oh ! yeah , yeah , yeah ! with `` two `` , with `` on - line - two `` . phd a: yeah . phd b: yeah , yeah , professor d: `` on - line - two `` is good . phd a: so it 's , is the good yeah . phd b: yeah . yep , it 's a good . professor d: `` two `` is good ? phd a: and professor d: no , `` two `` is bad . phd a: yeah . phd b: well , actually , it 's good with the ch with the good . professor d: ok . yeah . so yeah , i i agree . it 's probably something simple uh , i if if uh someone , you know , uh , wants to play with it for a little bit . i mean , you 're gon na do what you 're gon na do phd a: mmm . professor d: but but my my guess would be that it 's something that is a simple thing that could take a while to find . phd a: but yeah . mmm . i see , yeah . professor d: yeah . phd a: and professor d: uh . { comment } and the other the results uh , observations two and three , um , is phd a: mmm . professor d: uh yeah , that 's pretty much what we 've seen . that 's that what we were concerned about is that if it 's not on the target task if it 's on the target task then it it it helps to have the mlp transforming it . phd a: mmm . professor d: if it uh if it 's not on the target task , then , depending on how different it is , uh you can get uh , a reduction in performance . phd a: mmm . professor d: and the question is now how to how to get one and not the other ? or how to how to ameliorate the the problems . phd a: mmm . professor d: um , because it it certainly does is nice to have in there , when it when there is something like the training data . phd a: mm - hmm . um . yeah . so , the the reason yeah , the reason is that the perhaps the target the the task dependency the language dependency , and the noise dependency professor d: so that 's what you say th there . i see . phd a: well , the e e but this is still not clear because , um , i i i do n't think we have enough result to talk about the the language dependency . well , the timit network is still the best but there is also an the other difference , the fact that it 's it 's hand - labeled . professor d: hey ! um , just you can just sit here . uh , i d i do n't think we want to mess with the microphones but it 's uh just uh , have a seat . um . s summary of the first uh , uh forty - five minutes is that some stuff work and works , and some stuff does n't ok , phd a: we still have uh this one of these perhaps ? phd b: yeah . phd a: mm - hmm . professor d: yeah , i guess we can do a little better than that but i think if you if you start off with the other one , actually , that sort of has it in words and then th that has it the associated results . phd b: um . professor d: ok . so you 're saying that um , um , although from what we see , yes there 's what you would expect in terms of a language dependency and a noise dependency . that is , uh , when the neural net is trained on one of those and tested on something different , we do n't do as well as in the target thing . but you 're saying that uh , it is although that general thing is observable so far , there 's something you 're not completely convinced about . and and what is that ? i mean , you say `` not clear yet `` . what what do you mean ? phd a: uh , mmm , uh , { comment } i mean , that the the fact that s well , for for ti - digits the timit net is the best , which is the english net . professor d: mm - hmm . phd a: but the other are slightly worse . but you have two two effects , the effect of changing language and the effect of training on something that 's viterbi - aligned instead of hand hand - labeled . phd b: yeah . phd a: so . um . yeah . professor d: do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? phd a: mmm . i do n't i do n't know . did - did you look at the spanish alignments carmen ? phd b: mmm , no . professor d: might be interesting to look at it . because , i mean , that is just looking but um , um it 's not clear to me you necessarily would do so badly from a viterbi alignment . it depends how good the recognizer is phd a: mm - hmm . professor d: that 's that the the engine is that 's doing the alignment . phd a: yeah . but yeah . but , perhaps it 's not really the the alignment that 's bad but the just the ph phoneme string that 's used for the alignment professor d: aha ! phd a: mmm . phd b: yeah . professor d: the pronunciation models and so forth phd a: i mean for we it 's single pronunciation , uh professor d: aha . phd a: french french s uh , phoneme strings were corrected manually professor d: i see . phd a: so we asked people to listen to the um the sentence and we gave the phoneme string and they kind of correct them . but still , there there might be errors just in the in in the ph string of phonemes . mmm . um . yeah , so this is not really the viterbi alignment , in fact , yeah . um , the third the third uh issue is the noise dependency perhaps but , well , this is not clear yet because all our nets are trained on the same noises and professor d: i thought some of the nets were trained with spine and so forth . so it and that has other noise . phd a: yeah . so yeah . but yeah . results are only coming for for this net . mmm . professor d: ok , yeah , just do n't just need more more results there with that @ @ . phd a: yeah . um . so . uh , from these results we have some questions with answers . what should be the network input ? um , plp work as well as mfcc , i mean . um . but it seems impor important to use the delta . uh , with respect to the network size , there 's one experiment that 's still running and we should have the result today , comparing network with five hundred and one thousand units . so , nnn , still no answer actually . professor d: hm - hmm . phd a: uh , the training set , well , some kind of answer . we can , we can tell which training set gives the best result , but we do n't know exactly why . uh , so . professor d: uh . right , i mean the multi - english so far is is the best . phd a: yeah . professor d: `` multi - multi - english `` just means `` timit `` , phd a: yeah . professor d: right ? phd b: yeah . professor d: so uh that 's yeah . so . and and when you add other things in to to broaden it , it gets worse uh typically . phd a: mmm . mm - hmm . professor d: yeah . phd a: then uh some questions without answers . professor d: ok . phd a: uh , training set , um , professor d: uh - huh . phd a: uh , training targets professor d: i like that . the training set is both questions , with answers and without answers . phd a: it 's yeah . yeah . professor d: it 's sort of , yes it 's mul it 's multi - uh - purpose . phd a: yeah . professor d: ok . phd a: uh , training s right . so yeah , the training targets actually , the two of the main issues perhaps are still the language dependency and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . professor d: mm - hmm . phd a: and labeling s labeling seems important uh , because of timit results . professor d: mm - hmm . phd a: uh . for moment you use we use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression so uh , train to have neural networks that um , um , uh , professor d: mm - hmm . phd a: does a regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features in other features that are not noisy . but continuous features . not uh uh , hard targets . professor d: mm - hmm . mm - hmm . phd a: uh professor d: yeah , that seems like a good thing to do , probably , not uh again a short - term sort of thing . phd a: yeah . professor d: i mean one of the things about that is that um it 's e u the ri i guess the major risk you have there of being is being dependent on very dependent on the kind of noise and and so forth . phd a: yeah . f but , yeah . professor d: uh . but it 's another thing to try . phd a: so , this is w w i wa wa this is one thing , this this could be could help could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches , like , well , the kleinschmidt approach . so the d the idea of putting all the noise that we can find inside a database . i think kleinschmidt was using more than fifty different noises to train his network , phd b: yeah . professor d: mm - hmm . phd a: and so this is one approach and the other is multi - band uh , that i think is more robust to the noisy changes . professor d: mm - hmm . mm - hmm . phd a: so perhaps , i think something like multi - band trained on a lot of noises with uh , features - based targets could could could help . professor d: yeah , if you i i it 's interesting thought maybe if you just trained up i mean w yeah , one one fantasy would be you have something like articulatory targets and you have um some reasonable database , um but then which is um copied over many times with a range of different noises , phd a: mm - hmm . professor d: and uh if cuz what you 're trying to do is come up with a a core , reasonable feature set which is then gon na be used uh , by the the uh hmm system . phd a: mm - hmm . professor d: so . yeah , ok . phd a: so , um , yeah . the future work is , well , try to connect to the to make to plug in the system to the ogi system . um , there are still open questions there , where to put the mlp basically . professor d: mm - hmm . phd a: um . professor d: and i guess , you know , the the the real open question , i mean , e u there 's lots of open questions , but one of the core quote { comment } `` open questions `` for that is um , um , if we take the uh you know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . um , how well do they do over a range of these different tests , not just the italian ? phd a: mmm , professor d: um . and y phd a: yeah , yeah . professor d: y right ? and then um then see , again , how we know that there 's a mis there 's a uh a a loss in performance when the neural net is trained on conditions that are different than than , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? phd b: mm - hmm . professor d: that 's that that seems like the the the real question . and if you know that so if you just take plp with uh , the double - deltas . assume that 's the p the feature . look at these different ways of combining it . and uh , take let 's say , just take uh multi - english cause that works pretty well for the training . phd a: mm - hmm . professor d: and just look take that case and then look over all the different things . how does that how does that compare between the phd a: so all the all the test sets you mean , yeah . phd b: yeah . professor d: all the different test sets , phd a: and professor d: and for and for the couple different ways that you have of of of combining them . phd a: yeah . professor d: um . how well do they stand up , over the phd a: mmm . and perhaps doing this for cha changing the variance of the streams and so on getting different scaling phd b: mm - hmm . professor d: that 's another possibility if you have time , yeah . yeah . phd a: um . yeah , so thi this sh would be more working on the mlp as an additional path instead of an insert to the to their diagram . professor d:  phd a: cuz yeah . perhaps the insert idea is kind of strange because nnn , they they make lda and then we will again add a network does discriminate anal nnn , that discriminates , professor d: yeah . it 's a little strange phd a: or ? mmm ? professor d: but on the other hand they did it before . phd a: mmm . and and and professor d: um the phd a: yeah . and because also perhaps we know that the when we have very good features the mlp does n't help . so . i do n't know . professor d: um , the other thing , though , is that um so . uh , we we wan na get their path running here , right ? if so , we can add this other stuff . phd a: um . professor d: as an additional path right ? phd a: yeah , the the way we want to do professor d: cuz they 're doing lda rasta . phd a: the d what ? professor d: they 're doing lda rasta , phd a: yeah , the way we want to do it perhaps is to just to get the vad labels and the final features . professor d: yeah ? phd a: so they will send us the well , provide us with the feature files , professor d: i see . i see . phd a: and with vad uh , binary labels so that we can uh , get our mlp features and filter them with the vad and then combine them with their f feature stream . so . professor d: i see . so we so . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . phd a: uh . you mean oh , yeah ! just re re retraining r retraining the htk ? professor d: yeah just th w i i just to make sure that we have we understand properly what things are , our very first thing to do is to is to double check that we get the exact same results as them on htk . phd a: oh yeah . yeah , ok . mmm . phd b: yeah . professor d: uh , i mean , i do n't know that we need to r phd a: yeah . professor d: um do we need to retrain i mean we can just take the re their training files also . but . but , uh just for the testing , jus just make sure that we get the same results so we can duplicate it before we add in another phd a: mmm . ok . professor d: cuz otherwise , you know , we wo n't know what things mean . phd a: oh , yeah . ok . and um . yeah , so fff , lograsta , i do n't know if we want to we can try networks with lograsta filtered features . professor d: maybe . phd a: mmm . i 'm sorry ? yeah . well yeah . but professor d: oh ! you know , the other thing is when you say comb i 'm i 'm sorry , i 'm interrupting . { comment } that u um , uh , when you 're talking about combining multiple features , um suppose we said , `` ok , we 've got these different features and so forth , but plp seems pretty good . `` if we take the approach that mike did and have phd a: mm - hmm . professor d: i mean , one of the situations we have is we have these different conditions . we have different languages , we have different different noises , um if we have some drastically different conditions and we just train up different m l ps with them . phd a:  professor d: and put put them together . what what what mike found , for the reverberation case at least , i mean i mean , who knows if it 'll work for these other ones . that you did have nice interpolative effects . that is , that yes , if you knew what the reverberation condition was gon na be and you trained for that , then you got the best results . but if you had , say , a heavily - reverberation ca heavy - reverberation case and a no - reverberation case , uh , and then you fed the thing , uh something that was a modest amount of reverberation then you 'd get some result in between the two . so it was sort of behaved reasonably . is tha that a fair yeah . phd a: yeah . so you you think it 's perhaps better to have several m l yeah but professor d: it works better if what ? phd a: yea professor d: i see . well , see , i oc you were doing some something that was so maybe the analogy is n't quite right . you were doing something that was in way a little better behaved . you had reverb for a single variable which was re uh , uh , reverberation . here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s f for this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount of of uh training data from a couple different conditions , and then uh in yeah , that and the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic , sort of all over the map . a bunch of different dimensions . and so , i 'm just concerned that we do n't really have um , the data to train up i mean one of the things that we were seeing is that when we added in we still do n't have a good explanation for this , but we are seeing that we 're adding in uh , a fe few different databases and uh the performance is getting worse and uh , when we just take one of those databases that 's a pretty good one , it actually is is is is is better . and uh that says to me , yes , that , you know , there might be some problems with the pronunciation models that some of the databases we 're adding in or something like that . but one way or another we do n't have uh , seemingly , the ability to represent , in the neural net of the size that we have , um , all of the variability that we 're gon na be covering . so that i 'm i 'm i 'm hoping that um , this is another take on the efficiency argument you 're making , which is i 'm hoping that with moderate size neural nets , uh , that uh if we if they look at more constrained conditions they they 'll have enough parameters to really represent them . mm - hmm . mm - hmm . mm - hmm . yeah . phd a: so doing both is is not is not right , you mean , or ? yeah . professor d: yeah . i i just sort of have a feeling phd a: but yeah . mm - hmm . professor d: yeah . i mean i i e the um i think it 's true that the ogi folk found that using lda rasta , which is a kind of lograsta , it 's just that they have the i mean it 's done in the log domain , as i recall , and it 's it uh it 's just that they d it 's trained up , right ? that that um benefitted from on - line normalization . so they did at least in their case , it did seem to be somewhat complimentary . so will it be in our case , where we 're using the neural net ? i mean they they were not not using the neural net . uh i do n't know . ok , so the other things you have here are uh , trying to improve results from a single yeah . make stuff better . ok . uh . yeah . and cpu memory issues . yeah . we 've been sort of ignoring that , have n't we ? phd a: yeah , so i do n't know . professor d: but phd a: but we have to address the problem of cpu and memory we professor d: yeah , but i li well , i think my impression you you folks have been looking at this more than me . but my impression was that uh , there was a a a a strict constraint on the delay , phd b: yeah . professor d: but beyond that it was kind of that uh using less memory was better , and using less cpu was better . something like that , phd a: yeah , but professor d: right ? phd a: yeah . so , yeah , but we 've i do n't know . we have to get some reference point to where we well , what 's a reasonable number ? perhaps be because if it 's if it 's too large or large or @ @ professor d: um , well i do n't think we 're um completely off the wall . i mean i think that if we if we have uh , i mean the ultimate fall back that we could do if we find uh i mean we may find that we we 're not really gon na worry about the m l you know , if the mlp ultimately , after all is said and done , does n't really help then we wo n't have it in . phd a: mmm . professor d: if the mlp does , we find , help us enough in some conditions , uh , we might even have more than one mlp . we could simply say that is uh , done on the uh , server . phd a: mmm . professor d: and it 's uh we do the other manipulations that we 're doing before that . so , i i i think i think that 's that 's ok . phd a: and yeah . professor d: so i think the key thing was um , this plug into ogi . um , what what are they what are they gon na be working do we know what they 're gon na be working on while we take their features , phd a: they 're they 're starting to wor work on some kind of multi - band . professor d: and ? phd a: so . um this that was pratibha . sunil , what was he doing , do you remember ? phd b: sunil ? phd a: yeah . he was doing something new or ? phd b: i i do n't re i did n't remember . maybe he 's working with neural network . phd a: i do n't think so . trying to tune wha networks ? phd b: yeah , i think so . phd a: i think they were also mainly , well , working a little bit of new things , like networks and multi - band , but mainly trying to tune their their system as it is now to just trying to get the best from this this architecture . phd b: yeah . phd a:  professor d: ok . so i guess the way it would work is that you 'd get there 'd be some point where you say , `` ok , this is their version - one `` or whatever , and we get these vad labels and features and so forth for all these test sets from them , phd a: mm - hmm . professor d: and then um , uh , that 's what we work with . we have a certain level we try to improve it with this other path and then um , uh , when it gets to be uh , january some point uh , we say , `` ok we we have shown that we can improve this , in this way . so now uh um what 's your newest version ? `` and then maybe they 'll have something that 's better and then we we 'd combine it . this is always hard . i mean i i i used to work with uh folks who were trying to improve a good uh , hmm system with uh with a neural net system and uh , it was a common problem that you 'd oh , and this actually , this is true not just for neural nets but just for in general if people were working with uh , rescoring uh , n - best lists or lattices that come came from uh , a mainstream recognizer . uh , you get something from the the other site at one point and you work really hard on making it better with rescoring . but they 're working really hard , too . so by the time you have uh , improved their score , they have also improved their score phd a: mmm . professor d: and now there is n't any difference , phd a: yeah . professor d: because the other phd b: yeah . professor d: so , um , i guess at some point we 'll have to phd a: so it 's professor d: uh { comment } uh , i i do n't know . i think we 're we 're integrated a little more tightly than happens in a lot of those cases . i think at the moment they they say that they have a better thing we can we e e phd a: mmm . professor d: what takes all the time here is that th we 're trying so many things , presumably uh , in a in a day we could turn around uh , taking a new set of things from them and and rescoring it , phd a: mmm . yeah . yeah , perhaps we could . professor d: right ? so . yeah . well , ok . no , this is i think this is good . i think that the most wide open thing is the issues about the uh , you know , different trainings . you know , da training targets and noises and so forth . phd a: mmm . so we we can for we c we can forget combining multiple features and mlg perhaps , professor d: that 's sort of wide open . phd a: or focus more on the targets and on the training data and ? professor d: yeah , i think for right now um , i th i i really liked msg . and i think that , you know , one of the things i liked about it is has such different temporal properties . and um , i think that there is ultimately a really good uh , potential for , you know , bringing in things with different temporal properties . um , but um , uh , we only have limited time and there 's a lot of other things we have to look at . phd a: mmm . professor d: and it seems like much more core questions are issues about the training set and the training targets , and fitting in uh what we 're doing with what they 're doing , and , you know , with limited time . yeah . i think we have to start cutting down . phd a: mmm . professor d: so uh i think so , yeah . and then , you know , once we um , having gone through this process and trying many different things , i would imagine that certain things uh , come up that you are curious about uh , that you 'd not getting to and so when the dust settles from the evaluation uh , i think that would time to go back and take whatever intrigued you most , you know , got you most interested uh and uh and and work with it , you know , for the next round . uh , as you can tell from these numbers uh , nothing that any of us is gon na do is actually gon na completely solve the problem . phd a: mmm . professor d: so . so , { comment } there 'll still be plenty to do . barry , you 've been pretty quiet . grad c: just listening . professor d: well i figured that , but that what what what were you involved in in this primarily ? grad c: um , helping out uh , preparing well , they 've been kind of running all the experiments and stuff and i 've been uh , uh w doing some work on the on the preparing all all the data for them to to um , train and to test on . um yeah . right now , i 'm i 'm focusing mainly on this final project i 'm working on in jordan 's class . professor d: ah ! grad c: yeah . professor d: i see . right . what 's what 's that ? grad c: um , i 'm trying to um so there was a paper in icslp about um this this multi - band um , belief - net structure . { comment } this guy did professor d: mm - hmm . grad c: uh basically it was two h m ms with with a with a dependency arrow between the two h m professor d: uh - huh . grad c: and so i wan na try try coupling them instead of t having an arrow that that flows from one sub - band to another sub - band . i wan na try having the arrows go both ways . and um , i 'm just gon na see if if that that better models um , uh asynchrony in any way or um yeah . professor d: oh ! ok . well , that sounds interesting . grad c: yeah . professor d: ok . alright . anything to you wanted to no . ok . silent partner in the in the meeting . oh , we got a laugh out of him , that 's good . ok , everyone h must contribute to the our our sound sound files here . ok , so speaking of which , if we do n't have anything else that we need you happy with where we are ? phd a: mmm . professor d: know know wher know where we 're going ? uh phd a: i think so , yeah . professor d: yeah , yeah . you you happy ? phd b:  professor d: you 're happy . ok everyone should be happy . ok . you do n't have to be happy . you 're almost done . yeah , yeah . ok . grad e: al - actually i should mention so if { comment } um , about the linux machine `` swede . `` professor d: yeah . grad e: so it looks like the um , neural net tools are installed there . phd a: mmm . grad e: and um dan ellis { comment } i believe knows something about using that machine so phd a: mmm . grad e: if people are interested in in getting jobs running on that maybe i could help with that . phd a: yeah , but i do n't know if we really need now a lot of machines . well . we could start computing another huge table but yeah , we professor d: well . yeah , i think we want a different table , at least phd a: yeah , sure . professor d: right ? i mean there 's there 's some different things that we 're trying to get at now . phd a: but professor d: but phd a: yeah . mmm . professor d: so . yeah , as far as you can tell , you 're actually ok on c - on cpu uh , for training and so on ? yeah . phd a: ah yeah . i think so . well , more is always better , but mmm , i do n't think we have to train a lot of networks , now that we know we just select what works fine professor d: ok . ok . phd a: and try to improve this phd b: yeah . to work professor d: and we 're ok on and we 're ok on disk ? phd a: and it 's ok , yeah . well sometimes we have some problems . phd b: some problems with the professor d: but they 're correctable , uh problems . phd a: yeah , restarting the script basically phd b: you know . phd a: and professor d: yes . yeah , i 'm familiar with that one , ok . alright , so uh , { comment } since uh , we did n't ha get a channel on for you , { comment } you do n't have to read any digits but the rest of us will . uh , is it on ? well . we did n't uh i think i wo n't touch anything cuz i 'm afraid of making the driver crash which it seems to do , pretty easily . ok , thanks . ok , so we 'll uh i 'll start off the uh um connect the phd a: my battery is low . professor d: well , let 's hope it works . maybe you should go first and see so that you 're ok . phd b: batteries ? grad c: yeah , your battery 's going down too . professor d: transcript uh two grad c: carmen 's battery is d going down too . professor d: oh , ok . yeah . why do n't you go next then . ok . guess we 're done . ok , uh so . just finished digits . yeah , so . uh well , it 's good . i think i guess we can turn off our microphones now . grad c: just pull the batteries out .","output":"the professor asked if the team was happy with their progress . the team thought that they were okay . the professor was insistent that everyone be happy since they were pretty much done ."},{"instruction":"summarize the meeting","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"the meeting began with the team catching up the professor , who had missed the previous meeting . then , the team moved onto talking about echo cancelling techniques . they were trying to get the voice of other people from the primary person 's microphone . then , the team discussed how they could improve the performance on the aurora task by playing around with the model . the team ended the meeting with various comments on different topics ."},{"instruction":"summarize the discussion on detecting important linguistic features","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"the team wanted to understand how they could combine different linguistic features to make a more robust recognition model . they were running experiments to figure out what the good features were . the team also entertained the possibility of clustering them , which would add to the robustness ."},{"instruction":"what did the professor think about clustering ?","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"the professor was not too excited about clustering . he thought that the team could identify the bands that were the most promising and weigh them more highly in the model . as it stood , the model was using all bands with equal strength ."},{"instruction":"what did the professor think about positional parameters ?","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"the professor recounted that the person who worked with positional parameters , mark randolph , is at motorola . he explained that his model consisted of many continuous variables and that heading in that direction would become a research project in and of itself ."},{"instruction":"summarize the discussion on improving the back recognizer for the aurora task","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"phd b was conducting an experiment to improve the backend performance of the aurora recognizer . the goal was recognizing the htk system by challenging the canonical paradigm ."},{"instruction":"how did phd b approach the back-end of the aurora recognizer ?","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"phd b focused on italian and experimented with the number of states for different words . phd b thought training for each case may improve performance by accounting for the difference in variance ."},{"instruction":"what did the professor think about improving the back recognizer for the aurora task ?","input":"professor a: am i on ? i guess so . radio two . hmm . radio two . grad e: hello ? professor a: wow . grad e: mm - hmm . hi ? phd b: blow into it , it works really well . grad f: channel b . professor a: people say the strangest things when their microphones are on . phd d: channel four . test . phd c: uh - oh . phd d: ok . phd c: radio four . grad e: hello ? professor a: so everybody everybody 's on ? phd d: today 's professor a: yeah . so y you guys had a a meeting with uh with hynek which i unfortunately had to miss . um and uh somebody phd c: mmm . professor a: eh e and uh i guess chuck you were n't there either , so the uh phd b: i was there . professor a: oh you were there ? phd b: with hynek ? professor a: yeah . phd b: yeah . professor a: so everybody knows what happened except me . ok . maybe somebody should tell me . phd c: oh yeah . alright . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . professor a: uh - huh . phd c: so . yeah . about the um , well the downsampling problem . professor a: yeah . phd c: uh and about the f the length of the filters and yeah . professor a: what was the w what was the downsampling problem again ? phd c: so we had professor a: i forget . phd c: so the fact that there there is no uh low - pass filtering before the downsampling . well . professor a: uh - huh . phd c: there is because there is lda filtering but that 's perhaps not uh the best w m professor a: depends what it 's frequency characteristic is , yeah . phd c: well . mm - hmm . professor a: so you could do a you could do a stricter one . phd d: system on professor a: maybe . yeah . phd c: yeah . so we discussed about this , about the um professor a: was there any conclusion about that ? phd c: uh `` try it `` . yeah . professor a: i see . phd c: i guess . professor a: yeah . so again this is th this is the downsampling uh of the uh the feature vector stream phd c: uh . professor a: and um yeah i guess the the uh lda filters they were doing do have um uh let 's see , so the the the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty fifty hertz . uh . um . phd c: yeah . mm - hmm . professor a: sorry at twenty - five hertz since they 're downsampling by two . so . does anybody know what the frequency characteristic is ? phd c: we do n't have yet professor a: oh ok . phd c: um so , yeah . professor a: ok . phd c: we should have a look first at , perhaps , the modulation spectrum . professor a: yeah . phd c: um . so there is this , there is the um length of the filters . um . so the i this idea of trying to find filters with shorter delays . um . we started to work with this . professor a: hmm - hmm . phd c: mmm . and the third point um was the um , yeah , the on - line normalization where , well , the recursion f recursion for the mean estimation is a filter with some kind of delay professor a: yeah . phd c: and that 's not taken into account right now . um . yeah . and there again , yeah . for this , the conclusion of hynek was , well , `` we can try it but `` professor a: uh - huh . phd c: um . professor a: try try what ? phd c: so try to um um take into account the delay of the recursion for the mean estimation . professor a: ok . phd c: mmm . and this we 've not uh worked on this yet . um , yeah . and so while discussing about these these lda filters , some i issues appeared , like well , the fact that if we look at the frequency response of these filters it 's uh , well , we do n't know really what 's the important part in the frequency response and there is the fact that in the very low frequency , these filters do n't do n't really remove a lot . compared to the to the uh standard rasta filter . uh and that 's probably a reason why , yeah , on - line normalization helps because it it , professor a: right . phd c: yeah , it removed this mean . um . yeah , but perhaps everything could should be could be in the filter , i mean , uh the the mean normalization and yeah . so . yeah . so basically that was that 's all we discussed about . we discussed about good things to do also uh well , generally good stuff to do for the research . professor a: mm - hmm . phd c: and this was this lda uh tuning perhaps and hynek proposed again to his uh traps , so . professor a: ok . phd c: yeah , professor a: i mean i g i guess the key thing for me is is figuring out how to better coordinate between the two sides phd c: um . professor a: cuz because um phd c: mm - hmm . professor a: uh i was talking with hynek about it later and the the sort of had the sense sort of that that neither group of people wanted to to bother the other group too much . and and i do n't think anybody is , you know , closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and and that and expected that they would do certain things and they were sor they did n't wan na bother you phd c: mm - hmm . professor a: and they were sort of waiting for you and and and uh we ended up with this thing where they they were filling up all of the possible latency themselves , and they just had had n't thought of that . so . uh . i mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue phd c: yeah . well , but . yeah . yeah . well professor a: in in uh the other phd c: yeah i do n't know what happened really , but professor a: yeah . phd c: i guess it 's it 's also so uh the time constraints . because , well , we discussed about that about this problem and they told us `` well , we will do all that 's possible to have enough space for a network `` but then , yeah , perhaps they were too short with the time and professor a: then they could n't . i see . phd c: uh yeah . but there was also problem perhaps a problem of communication . so , yeah . now we will try to professor a: just talk more . phd c: yeah , slikes and send mails . professor a: yeah . phd c: u s o o yeah . professor a: yeah . phd c: uh . ok . professor a: so there 's um alright . well maybe we should just uh i mean you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before right ? and this machines are busy and you 're busy phd c: yeah . professor a: and phd c: basically . professor a: yeah . ok . oh . phd c: um . professor a: let 's let 's , i mean , i think that as as we said before that one of the things that we 're imagining is that uh there there will be uh in the system we end up with there 'll be something to explicitly uh uh do something about noise phd c: mm - hmm . professor a: in addition to the uh other things that we 're talking about and that 's probably the best thing to do . and there was that one email that said that it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson 's approach or something and in addition to they 're doing some noise removal thing , right ? phd c: yeah , yeah . so yeah we 're will start to do this also . professor a: yeah . phd c: uh so carmen is just looking at the ericsson ericsson code . phd d: yeah . we modif professor a: mm - hmm . phd c: and phd d: yeah , i modified it well , modifying i studied barry 's sim code , more or less . to take @ @ the first step the spectral subtraction . and we have some the feature for italian database and we will try with this feature with the filter to find the result . professor a: mm - hmm . mm - hmm . phd d: but we have n't result until this moment . professor a: yeah , sure . phd d: but well , we are working in this also professor a: yeah . phd d: and maybe try another type of spectral subtraction , i do n't professor a: when you say you do n't have a result yet you mean it 's it 's just that it 's in process or that you it finished and it did n't get a good result ? phd d: no . no , no n we have n we have do the experiment only have the feature the feature but the experiment have phd c: yeah . phd d: we have not make the experiment professor a: oh . ok . phd d: and maybe will be good result or bad result , we do n't know . professor a: yeah . yeah . phd c: yeah . professor a: ok . so um i suggest actually now we we we sorta move on and and hear what 's what 's what 's happening in in other areas like what 's what 's happening with your investigations about echos and so on . grad f: oh um well um i have n't started writing the test yet , i 'm meeting with adam today professor a: mm - hmm . grad f: um and he 's going t show me the scripts he has for um running recognition on mee meeting recorder digits . professor a: mm - hmm . grad f: uh i also um have n't got the code yet , i have n't asked hynek for for the for his code yet . cuz i looked at uh avendano 's thesis and i do n't really understand what he 's doing yet but it it it sounded like um the channel normalization part um of his thesis um was done in a a bit of i do n't know what the word is , a a bit of a rough way um it sounded like he um he he it it was n't really fleshed out and maybe he did something that was interesting for the test situation but i i 'm not sure if it 's what i 'd wan na use so i have to i have to read it more , i do n't really understand what he 's doing yet . professor a: ok . yeah i have n't read it in a while so i 'm not gon na be too much help unless i read it again , phd d: it 's my phd c: oh yeah ? phd d: i know this is mine here . professor a: so . ok . um . the um so you , and then you 're also gon na be doing this echo cancelling between the the close mounted and the and the the the what we 're calling a cheating experiment uh of sorts between the distant grad f: uh i i 'm ho right . well or i 'm hoping i 'm hoping espen will do it . professor a: ah ! ok . grad f: um professor a: f um grad f: u professor a: delegate . that 's good . it 's good to delegate . grad f: i i think he 's at least planning to do it for the cl close - mike cross - talk and so maybe i can just take whatever setup he has and use it . professor a: great . great . yeah actually um he should uh i wonder who else is i think maybe it 's dan ellis is going to be doing uh a different cancellation . um . one of the things that people working in the meeting task wan na get at is they would like to have cleaner close - miked recordings . so uh this is especially true for the lapel but even for the close close - miked uh cases um we 'd like to be able to have um other sounds from other people and so forth removed from so when someone is n't speaking you 'd like the part where they 're not speaking to actually be so what they 're talking about doing is using ec uh echo cancellation - like techniques . it 's not really echo but uh just um uh taking the input from other mikes and using uh uh a uh an adaptive filtering approach to remove the effect of that uh other speech . so . um what was it , there was there was some some some point where eh uh eric or somebody was was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not it was recognizing my words , which were the background speech on the close close mike . grad f: hmm . phd b: oh the what we talked about yesterday ? professor a: yes . phd b: yeah that was actually my i was wearing the i was wearing the lapel and you were sitting next to me , professor a: oh you it was you i was yeah . phd b: and i only said one thing but you were talking and it was picking up all your words . professor a: yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e: ok . professor a: uh . grad e: um . { comment } so continuing to um extend phd b: what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a: but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b: yeah . professor a: uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful phd c: hmm . professor a: um for phd b: and their their targets are based on canonical mappings of phones to acoustic f features . professor a: right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e: oh yeah . professor a: there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b: what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a: and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the phd b: hmm ! professor a: and then tell them to talk naturally ? yeah , yeah . phd b: pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a: maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b: yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a: yeah . yeah , be cool and help science . phd b: and yeah . professor a: ok . phd b: hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a: do you mean eh but you i mean mar phd c: well he was the guy the guy that was using professor a: you mean when was was mark randolph there , or ? phd b: mark randolph . professor a: yeah he 's he 's he 's at motorola now . phd b: oh is he ? professor a: yeah . phd b: oh ok . professor a: yeah . phd b: yeah . phd c: is it the guy that was using the pattern of pressure on the tongue or ? phd b: i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c: what yeah . phd b: and trying to m you know do speech recognition based on them . phd c: mm - hmm . professor a: yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so phd b: hmm . professor a: i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b: mm - hmm . professor a: but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b: mm - hmm . professor a: and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b: could you cluster the just do some kind of clustering ? professor a: guess you could , yeah . phd b: bin them up into different categories and professor a: yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e: right . right . phd b: so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e: right . phd b: so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e: mm - hmm . phd b: i see . grad e: mm - hmm . professor a: yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh phd b: hmm . professor a: he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b: so he does n't have professor a: which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b: mm - hmm . professor a: and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b: so he does n't have to have truth marks or ho grad e: f right , and uh he does n't have to have hard labels . professor a: well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e: right . for the full band . professor a: um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e: right . professor a: is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b: mm - hmm . ok . professor a: then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b: i see . professor a: and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b: so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e: from uh canonical mappings { comment } um at first phd b: ok . professor a: yeah . grad e: and then it 's unclear um eh phd b: using timit ? or using grad e: using timit phd b: uh - huh . grad e: right , right . professor a: yeah . grad e: and then uh he does some fine tuning um for um special cases . yeah . professor a: yeah . i mean we ha we have a kind of iterative training because we do this embedded viterbi , uh so there is some something that 's suggested , based on the data but it 's it 's not i think it s does n't seem like it 's quite the same , cuz of this cuz then whatever that alignment is , it 's that for all all bands . phd b: mm - hmm . professor a: well no , that 's not quite right , we did actually do them separate tried to do them separately so that would be a little more like what he did . um . but it 's still not quite the same because then it 's it 's um setting targets based on where you would say the sound begins in a particular band . where he 's s this is not a labeling per se . might be closer i guess if we did a soft soft target uh uh embedded neural net training like we 've done a few times uh f the forward um do the forward calculations to get the gammas and train on those . mmm . uh what 's next ? phd b: i could say a little bit about w stuff i 've been playing with . professor a: oh . you 're playing ? phd b: i um huh ? professor a: you 're playing ? phd b: yes , i 'm playing . um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back - end recognizer for the aurora task and see how that affects things . and so i had this um i think i sent around last week a this plan i had for an experiment , this matrix where i would take the um the original um the original system . so there 's the original system trained on the mel cepstral features and then com and then uh optimize the b htk system and run that again . so look at the difference there and then uh do the same thing for the icsi - ogi front - end . professor a: what which test set was this ? phd b: this is that i looked at ? professor a: mm - hmm . phd b: uh i 'm looking at the italian right now . professor a: mm - hmm . phd b: so as far as i 've gotten is i 've uh been able to go through from beginning to end the um full htk system for the italian data and got the same results that um that uh stephane had . so um i started looking to and now i 'm i 'm sort of lookin at the point where i wan na know what should i change in the htk back - end in order to try to uh to improve it . so . one of the first things i thought of was the fact that they use the same number of states for all of the models professor a: mm - hmm . phd b: and so i went on - line and i uh found a pronunciation dictionary for italian digits professor a: mm - hmm . phd b: and just looked at , you know , the number of phones in each one of the digits . um you know , sort of the canonical way of setting up a an hmm system is that you use um three states per phone and um so then the the total number of states for a word would just be , you know , the number of phones times three . and so when i did that for the italian digits , i got a number of states , ranging on the low end from nine to the high end , eighteen . um . now you have to really add two to that because in htk there 's an initial null and a final null so when they use uh models that have eighteen states , there 're really sixteen states . they 've got those initial and final null states . and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits , the four and five which um , according to my , you know , sort of off the cuff calculation , should have eighteen states each . professor a: mm - hmm . phd b: and so they had sixteen . so that 's pretty close . um but for the most of the words are sh much shorter . so the majority of them wan na have nine states . and so theirs are s sort of twice as long . so my guess uh and then if you i i printed out a confusion matrix um uh for the well - matched case , and it turns out that the longest words are actually the ones that do the best . so my guess about what 's happening is that you know , if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have , you know , half as much training data for those models . because if you have a long word and you 're training it to eighteen states , uh you 've got you know , you 've got the same number of gaussians , you 've got ta train in each case , professor a: mm - hmm . phd b: but for the shorter words , you know , the total number of frames is actually half as many . professor a: mm - hmm . phd b: so it could be that , you know , for the short words there 's because you have so many states , you just do n't have enough data to train all those gaussians . so um i 'm going to try to um create more word - specific um uh prototype h m ms to start training from . professor a: yeah , i mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word , phd b: mm - hmm . professor a: but . phd b: yeah so i 'll i 'll , the next experiment i 'm gon na try is to just um you know create uh models that seem to be more w matched to my guess about how long they should be . professor a: mm - hmm . phd b: and as part of that um i wanted to see sort of how the um how these models were coming out , you know , what w when we train up uh th you know , the model for `` one `` , which wants to have nine states , you know , what is the uh what do the transition probabilities look like in the self - loops , { comment } look like in in those models ? and so i talked to andreas and he explained to me how you can calculate the expected duration of an hmm just by looking at the transition matrix professor a: mm - hmm . phd b: and so i wrote a little matlab script that calculates that and so i 'm gon na sort of print those out for each of the words to see what 's happening , you know , how these models are training up , professor a: mm - hmm . mm - hmm . phd b: you know , the long ones versus the short ones . i d i did quickly , i did the silence model and and um that 's coming out with about one point two seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the string of digits . professor a: wow . lots of silence . phd b: yeah , yeah . and so the s p model , which is what they put in between digits , i i have n't calculated that for that one yet , but um . so they basically their their model for a whole digit string is silence digit , sp , digit , sp blah - blah - blah and then silence at the end . and so . professor a: are the sp 's optional ? i mean skip them ? phd b: i have to look at that , but i 'm not sure that they are . now the one thing about the s p model is really it only has a single s emitting state to it . professor a: mm - hmm . phd b: so if it 's not optional , you know , it 's it 's not gon na hurt a whole lot professor a: i see . phd b: and it 's tied to the center state of the silence model so it 's not its own um it does n't require its own training data , professor a: mm - hmm . phd b: it just shares that state . professor a: mm - hmm . phd b: so it , i mean , it 's pretty good the way that they have it set up , but um i so i wan na play with that a little bit more . i 'm curious about looking at , you know how these models have trained and looking at the expected durations of the models and i wan na compare that in the the well - matched case f to the unmatched case , and see if you can get an idea of just from looking at the durations of these models , you know , what what 's happening . professor a: yeah , i mean , i think that uh , as much as you can , it 's good to d sort of not do anything really tricky . phd b: mm - hmm . professor a: not do anything that 's really finely tuned , but just sort of eh you know you t you i z phd b: yeah . professor a: the premise is kind of you have a a good person look at this for a few weeks and what do you come up with ? phd b: mm - hmm . mm - hmm . professor a: and uh phd b: and hynek , when i wa told him about this , he had an interesting point , and that was th um the the final models that they end up training up have i think probably something on the order of six gaussians per state . so they 're fairly , you know , hefty models . and hynek was saying that well , probably in a real application , you would n't have enough compute to handle models that are very big or complicated . so in fact what we may want are simpler models . professor a: could be . phd b: and compare how they perform to that . but you know , it depends on what the actual application is and it 's really hard to know what your limits are in terms of how many gaussians you can have . professor a: right . and that , i mean , at the moment that 's not the limitation , so . phd b: mm - hmm . professor a: i mean , i i i what i thought you were gon na say i but which i was thinking was um where did six come from ? probably came from the same place eighteen came from . you know , so . phd b: yeah . right . professor a: uh that 's another parameter , right ? that that maybe , you know , uh you really want three or nine or phd b: yeah , yeah . well one thing i mean , if i if if i start um reducing the number of states for some of these shorter models that 's gon na reduce the total number of gaussians . professor a: right . phd b: so in a sense it 'll be a simpler system . professor a: yeah . yeah . but i think right now again the idea is doing just very simple things phd b: yeah . professor a: how much better can you make it ? and um since they 're only simple things there 's nothing that you 're gon na do that is going to blow up the amount of computation phd b: mm - hmm . professor a: um so phd b: right . right . professor a: if you found that nine was better than six that would be o k , i think , actually . phd b: mm - hmm . professor a: does n't have to go down . phd b: yeah . i really was n't even gon na play with that part of the system yet , professor a: mm - hmm , ok . phd b: i was just gon na change the the t professor a: yeah , just work with the models , yeah . phd b: yeah , just look at the length of the models and just see what happens . professor a: yeah . phd b: so . professor a: cool . ok . so uh what 's uh i guess your plan for you you you guys ' plan for the next next week is just continue on these these same things we 've been talking about for aurora and phd c: yeah , i guess we can try to have some kind of new baseline for next week perhaps . with all these minor things modified . and then do other things , play with the spectral subtraction , and retry the msg and things like that . professor a: yeah . yeah . yeah we we have a big list . phd c: big list ? professor a: you have a big list of of things to do . so . well that 's good . i think that after all of this uh um confusion settles down in another some point a little later next year there will be some sort of standard and it 'll get out there and hopefully it 'll have some effect from something that that has uh been done by our group of people but uh e even if it does n't there 's there 's go there 'll be standards after that . so . phd b: does anybody know how to um run matlab sort of in batch mode like you c send it s a bunch of commands to run and it gives you the output . is it possible to do that ? grad e: i i think uh mike tried it phd b: yeah ? grad e: and he says it 's impossible so he went to octave . phd b: octave . grad e: octave is the um unix clone of of matlab which you can batch . phd b: ah ! ok . great . thanks . grad e: yeah . phd b: i was going crazy trying to do that . professor a: huh . grad e: yeah . phd c: what is octave so ? it 's a free software ? grad e: what 's that ? uh , octave ? phd c: yeah . grad e: yeah it 's it 's it 's free . i think we have it here { comment } r running somewhere . phd b: great ! grad e: yeah . phd c: and it does the same syntax and everything eh like matlab , or ? grad e: um { comment } i it 's a little behind , it 's the same syntax but it 's a little behind in that { comment } matlab went to these like um you can have cells and you can you can { comment } uh implement object - oriented type things with matlab . uh octave does n't do that yet , so i think you , octave is kinda like matlab um four point something or . phd b: if it 'll do like a lot of the basic matrix and vector stuff grad e: the basic stuff , right . phd b: that 's perfect . grad e: yeah . phd b: great ! professor a: ok , guess we 're done . grad e: ok . grad f: well , although by the way .","output":"the professor thought that the experiments were pretty simple , so computational power was not really a problem . he also thought that it would be okay to increase the states from six to nine ."}]