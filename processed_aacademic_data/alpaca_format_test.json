[{"instruction":"summarize the meeting","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"the meeting covered the issues with different kinds of mics , progress on the aurora project , effectiveness of spectral subtraction , adding parameter to spectral coefficient , and studying energy in the data , along with a short discussion on student housing . the team thought that the lda was doing well for the aurora project , where the team had made good progress . the linear normalization was not as good . for spectral subtraction , the team discussed recreating data with fft of combining the weiner filtering with the signal subspace . the team had not made much progress on using spectral coefficients for voice-unvoice . the current approach was to study the variance , so other ideas were suggested . the meeting ended with a short discussion on student housing and a graduate student 's interest in studying energy ."},{"instruction":"summarize the discussion about microphone issues","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"the professor pointed out that the lapel microphones were too close , so they were not good representative microphones . there was strong agreement that mics capture breath and other non-voice sounds since they were common ."},{"instruction":"what did phd f think about computational resources ?","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"phd f explained that he mistakenly had run his tasks on all the available compute instances . there was not enough computational resources going around . new computers were coming soon , but people would have to learn to share until then . it was important not to saturate computational resources . he also told the team how to properly queue tasks ."},{"instruction":"what did the professor say about the workshop ?","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"the professor recalled that at a workshop at hopkins or rutgers , twenty-five participants were running their tasks on twenty-five machines . things would have been better if they ran tasks on their own machine . he was adding to phd f 's remarks on students in the team doing a similar thing ."},{"instruction":"summarize the discussion about spectral subtraction","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"the team was doing spectral subtraction with both scaling and ggt bins . there were pros and cons to both approaches . the professor suggested a simple spectral subtraction followed by a kl transformation . he also suggested using jrastra 's technique which relied on adding some noise to get rid of noise . the team also suggested vts techniques ."},{"instruction":"what did the team say about the person in grenada ?","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"phd d brought up a vts technique to do voice-unvoice which was developed by jose carlos segura , who is a person from grenada . the professor did not know him , but the inspiration for the vts had come from cmu ."},{"instruction":"what did the professor think about the wiener filter ?","input":"professor c: uh , is it the twenty - fourth ? phd f: now we 're on . professor c: yeah . phd a: uh chuck , is the mike type wireless phd f: yes . phd a: wireless headset ? ok . phd f: yes . professor c: yeah . phd f: for you it is . professor c: yeah . we uh we abandoned the lapel because they sort of were not too not too hot , not too cold , they were you know , they were uh , far enough away that you got more background noise , uh , and uh and so forth phd a: uh - huh . professor c: but they were n't so close that they got quite the you know , the really good no , th phd a: ok . professor c: they i mean they did n't wait a minute . i 'm saying that wrong . they were not so far away that they were really good representative distant mikes , phd a: uh - huh . professor c: but on the other hand they were not so close that they got rid of all the interference . so it was no did n't seem to be a good point to them . on the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . phd a: yeah , yeah . professor c: there 's uh , some kinds of junk that you get with these things that you do n't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we there seemed to be very strong opinions for uh , getting rid of lapels . phd a: the mike number is professor c: so , phd f: uh , your mike number 's written on the back of that unit there . phd a: oh yeah . one . phd f: and then the channel number 's usually one less than that . phd a: oh , ok . ok . phd f: it - it 's one less than what 's written on the back of your phd a: ok . ok . phd f: yeah . so you should be zero , actually . phd a: hello ? yeah . phd f: for your uh , channel number . phd a: yep , yep . professor c: and you should do a lot of talking so we get a lot more of your pronunciations . no , they do n't do n't have a have any indian pronunciations . phd f: so what we usually do is um , we typically will have our meetings professor c: yeah . phd f: and then at the end of the meetings we 'll read the digits . everybody goes around and reads the digits on the the bottom of their forms . professor c: session r phd d: r - nineteen ? phd a: ok . professor c: r - nineteen . phd f: yeah . we 're this is session r - nineteen . professor c: if you say so . o k . do we have anything like an agenda ? what 's going on ? um . i guess um . so . one thing phd f: sunil 's here for the summer ? professor c: sunil 's here for the summer , right . um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . um . phd f: i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . professor c: mm - hmm . ok . why do n't you start with that ? that 's sort of phd f: ok . professor c: yeah ? phd f: we um so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and um , uh , we ordered uh , sun - blade - one - hundreds , and um , i 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running so the plan for using these is , uh , we 're running p - make and customs here and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , run things using p - make and customs . you do n't actually have to write p - make scripts and things like that . the simplest thing and i can send an email around or , maybe i should do an faq on the web site about it or something . um , professor c: how about an email that points to the faq , phd f: there 's a c professor c: you know what i 'm saying ? phd f: yeah , yeah . professor c: so that you can yeah . phd f: uh , there 's a command , uh , that you can use called `` run command `` . `` run dash command `` , `` run hyphen command `` . and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh and run it there and it 'll duplicate your environment . so you can try this as a simple test with uh , the l s command . so you can say `` run dash command l s `` , and , um , it 'll actually export that ls command to some machine in the institute , and um , do an ls on your current directory . so , substitute ls for whatever command you want to run , and um and that 's a simple way to get started using using this . and , so , soon , when we get all the new machines up , um , e then we 'll have lots more compute to use . now th one of the nice things is that uh , each machine that 's part of the p - make and customs network has attributes associated with it . uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like `` run command `` , you can specify those attributes for your program . for example if you only want your thing to run under linux , you can give it the linux attribute , and then it will find the fastest available linux machine and run it on that . so . you can control where your jobs go , to a certain extent , all the way down to an individual machine . each machine has an attribute which is the name of itself . so you can give that as an attribute and it 'll only run on that . if there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . so , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now andreas and i have been the main ones using it and we 're uh . the sri recognizer has all this p - make customs stuff built into it . professor c: so as i understand , you know , he 's using all the machines and you 're using all the machines , phd f: so . professor c: is the rough division of phd f: yeah . exactly . yeah , you know , i i sort of got started { comment } using the recognizer just recently and uh , uh i fired off a training job , and then i fired off a recognition job and i get this email about midnight from andreas saying , `` uh , are you running two trainings simultaneously s my m my jobs are not getting run . `` so i had to back off a little bit . but , soon as we get some more machines then uh then we 'll have more compute available . so , um , that 's just a quick update about what we 've got . so . grad g: um , i have i have a question about the uh , parallelization ? phd f: mm - hmm . grad g: so , um , let 's say i have like , a thousand little little jobs to do ? phd f: mm - hmm . grad g: um , how do i do it with `` run command `` ? i mean do phd f: you could write a script uh , which called run command on each sub - job grad g: uh - huh . a thousand times ? phd f: right ? but you probably wan na be careful with that grad g: ok . phd f: because um , you do n't wan na saturate the network . uh , so , um , you know , you should you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people grad g: oh , too much file transfer and stuff . phd f: well it 's not that so much as that , you know , e with if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . um , grad g: ok . phd f: so you should try to limit it to somet sometim some number around ten jobs at a time . um . so if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gon na use `` run command `` , uh , to only have ten of those going at a time . and uh , then , when one of those finished you 'd fire off another one . um , professor c: i remember i i forget whether it was when the rutgers or or hopkins workshop , i remember one of the workshops i was at there were everybody was real excited cuz they got twenty - five machines and there was some kind of p - make like thing that sit sent things out . phd f: mm - hmm . mm - hmm . professor c: so all twenty - five people were sending things to all twenty - five machines phd f: mm - hmm . yeah . professor c: and and things were a lot less efficient than if you 'd just use your own machine . phd f: yeah . yep . yeah , exactly . yeah , you have to be a little bit careful . professor c: as i recall , but . yeah . phd d: hmm . phd f: um , but uh , you can also if you have that level of parallelization um , and you do n't wan na have to worry about writing the logic in in a perl script to take care of that , you can use um , p - make grad g: just do p - make . phd f: and and you basically write a make file that uh , you know your final job depends on these one thousand things , grad g: s mm - hmm . phd f: and when you run p - make , uh , on your make file , you can give it the dash capital j and and then a number , grad g: mm - hmm . phd f: and that number represents how many uh , machines to use at once . and then it 'll make sure that it never goes above that . grad g: right . phd f: so , grad g: right . ok . phd f: i can get some documentation . phd d: so it it 's it 's not systematically queued . i mean all the jobs are running . if you launch twenty jobs , they are all running . alright . phd f: it depends . if you `` run command `` , that i mentioned before , is does n't know about other things that you might be running . phd d: uh - huh . phd f: so , it would be possible to run a hundred run jobs at once , phd d: right . phd f: and they would n't know about each other . but if you use p - make , then , it knows about all the jobs that it has to run phd d: mm - hmm . phd f: and it can control , uh , how many it runs simultaneously . professor c: so `` run command `` does n't use p - make , or ? phd f: it uses `` export `` underlyingly . but , if you i it 's meant to be run one job at a time ? so you could fire off a thousand of those , and it does n't know any one of those does n't know about the other ones that are running . professor c: so why would one use that rather than p - make ? phd f: well , if you have , um like , for example , uh if you did n't wan na write a p - make script and you just had a , uh an htk training job that you know is gon na take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say `` run command `` and your htk thing and it 'll find another machine , the fastest currently available machine and and run your job there . professor c: now , does it have the same sort of behavior as p - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it phd f: yes . yeah , there are um right . so some of the machines at the institute , um , have this attribute called `` no evict `` . and if you specify that , in in one of your attribute lines , then it 'll go to a machine which your job wo n't be evicted from . professor c: mm - hmm . phd f: but , the machines that do n't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and and they were at lunch , professor c: mm - hmm . phd f: they come back from lunch and they start typing on the console , then your machine will get evicted your job { comment } will get evicted from their machine and be restarted on another machine . automatically . so which can cause you to lose time , right ? if you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . so . if you do n't want your job to run on a machine where it could be evicted , then you give it the minus the attribute , you know , `` no evict `` , and it 'll pick a machine that it ca n't be evicted from . so . professor c: um , what what about i remember always used to be an issue , maybe it 's not anymore , that if you if something required if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? phd f: mm - hmm . professor c: and you were n't hitting any keys ? cuz you were , home ? phd f: yeah , i i 'm not sure how that works . professor c: yeah . phd f: uh , it seems like andreas did something for that . professor c: hmm . phd f: um . professor c: ok . we can ask him sometime . phd f: but yeah . i do n't know whether it monitors the keyboard or actually looks at the console tty , so maybe if you echoed something to the you know , dev dev console or something . professor c: you probably would n't ordinarily , though . yeah . right ? you probably would n't ordinarily . phd f: hmm ? professor c: i mean you sort of you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , `` screw this `` , phd f: yeah , yeah . professor c: and you know . phd f: yeah . yeah , so , um , professor c: yeah . phd f: yeah . i i can i 'm not sure about that one . professor c: yeah . phd f: but uh . professor c: ok . phd a: uh , i need a little orientation about this environment and uh scr s how to run some jobs here because i never d did anything so far with this x emissions phd f: ok . phd a: so , i think maybe i 'll ask you after the meeting . phd f: um . yeah . yeah , and and also uh , stephane 's a a really good resource for that if you ca n't find me . phd a: yeah , yeah , yeah . yep . ok , sure phd d: mmm . phd f: especially with regard to the aurora stuff . phd a: ok . phd f: he he knows that stuff better than i do . professor c: ok . well , why do n't we uh , uh , sunil since you 're have n't have n't been at one of these yet , why do n't yo you tell us what 's what 's up with you ? wh - what you 've been up to , hopefully . phd a: um . yeah . so , uh , shall i start from well i do n't know how may i how ok . uh , i think i 'll start from the post uh aurora submission maybe . professor c: yeah . phd a: uh , yeah , after the submission the what i 've been working on mainly was to take take other s submissions and then over their system , what they submitted , because we did n't have any speech enhancement system in in ours . so so i tried uh , and u first i tried just lda . and then i found that uh , i mean , if if i combine it with lda , it gives @ @ improvement over theirs . uh phd f: are y are you saying lda ? phd a: yeah . yeah . phd f: lda . ok . phd a: so , just just the lda filters . i just plug in i just take the cepstral coefficients coming from their system and then plug in lda on top of that . but the lda filter that i used was different from what we submitted in the proposal . phd f: mm - hmm . phd a: what i did was i took the lda filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow narrow band lda filter that we submitted uh , i got new filters . so that seems to be giving uh , improving over their uh , system . slightly . but , not very significantly . and uh , that was uh , showing any improvement over final by plugging in an lda . and uh , so then after after that i i added uh , on - line normalization also on top of that . and that there there also i n i found that i have to make some changes to their time constant that i used because th it has a a mean and variance update time constant and which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . but um , i did n't i did n't play with that time constant a lot , i just t g i just found that i have to reduce the value i mean , i have to increase the time constant , or reduce the value of the update value . that 's all i found so i have to . uh , yeah . and uh , uh , the other other thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of the i mean the w speech and nonspeech . and uh , i found that the baseline itself improves by twenty - two percent by just giving the wuh . professor c: uh , can you back up a second , i i i missed something , uh , i guess my mind wandered . ad - ad when you added the on - line normalization and so forth , uh , uh things got better again ? phd a: yeah . no . professor c: or is it ? phd a: no . no , things did n't get better with the same time constant that we used . professor c: did it not ? no , no . with a different time constant . phd a: with the different time constant i found that i mean , i did n't get an improvement over not using on - line normalization , professor c: oh . phd a: because i i found that i would have change the value of the update factor . professor c: no you did n't , ok . phd a: but i did n't play it with play play quite a bit to make it better than . professor c: yeah . phd a: so , it 's still not professor c: ok . phd a: i mean , the on - line normalization did n't give me any improvement . professor c: ok . phd a: and uh , so , professor c: ok . phd a: oh yeah so i just stopped there with the uh , speech enhancement . the the other thing what i tried was the adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the the second the new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use professor c: hmm . phd f: so people wo n't even have to worry about , uh , doing speech - nonspeech then . phd a: yeah that 's , that 's what the feeling is like . they 're going to give the endpoint information . phd f: mmm . professor c: g i guess the issue is that people do that anyway , phd f: i see . professor c: everybody does that , phd a: yeah . professor c: and they wanted to see , given that you 're doing that , what what are the best features that you should use . phd f: yeah , i see . phd a: so , professor c: i mean clearly they 're interact . so i do n't know that i entirely agree with it . phd f: yeah . professor c: but but it might be uh in some ways it might be better t to rather than giving the endpoints , to have a standard that everybody uses and then interacts with . phd f: mm - hmm . professor c: but , you know . it 's it 's still someth reasonable . phd f: so , are people supposed to assume that there is uh are are people not supposed to use any speech outside of those endpoints ? phd a: uh phd f: or can you then use speech outside of it for estimating background noise and things ? phd a: no . no . that i i yeah . yeah , yeah , exactly . i guess that is that is where the consensus is . like y you will you will you 'll be given the information about the beginning and the end of speech but the whole speech is available to you . phd f: ok . phd a: so . professor c: so it should make the spectral subtraction style things work even better , phd a: yeah . professor c: because you do n't have the mistakes in it . yeah ? phd a: yeah . so professor c: ok . phd a: so that that the baseline itself i mean , it improves by twenty - two percent . i found that in s one of the speechdat - car cases , that like , the spanish one improves by just fifty percent by just putting the endpoint . w phd f: wow . phd a: i mean you do n't need any further speech enhancement with fifty . so , uh , phd f: so the baseline itself improves by fifty percent . phd a: yeah , by fifty percent . professor c: yeah . phd f: wow . professor c: so it 's g it 's gon na be harder to beat that actually . phd f: yeah . phd a: yeah , so professor c: but but phd a: so that is when uh , the the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . and i think they have they have actually changed their qualification c criteria now . and uh , yeah , i guess after that , i just went home f i just had a vacation fo for four weeks . uh . professor c: ok . no , that 's that 's that 's a good good update . phd a: ye yeah , and i i came back and i started working on uh , some other speech enhancement algorithm . i mean , so i from the submission what i found that people have tried spectral subtraction and wiener filtering . these are the main uh , approaches where people have tried , professor c: yeah . phd a: so just to just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , i i 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . and professor c: mm - hmm . phd a: so , i 've been actually running some s so far i 've been trying it only on matlab . i have to to to test whether it works first or not professor c: yeah . phd a: and then i 'll p port it to c and i 'll update it with the repository once i find it it giving any some positive result . so , yeah . professor c: s so you s you so you said one thing i want to jump on for a second . so so now you 're you 're getting tuned into the repository thing that he has here phd a: yeah . professor c: and so we we 'll have a single place where the stuff is . phd a: yep . yeah . professor c: cool . um , so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , i guess ? phd d: mm - hmm . professor c: um , where you were also combining something both of you i guess were both combining something from the uh , french telecom system with the u uh phd d: right . professor c: i i do n't know whether it was system one or system two , or ? phd d: mm - hmm . it was system one . so professor c: ok . phd d: we the main thing that we did is just to take the spectral subtraction from the france telecom , which provide us some speech samples that are uh , with noise removed . professor c: so i let me let me just stop you there . so then , one distinction is that uh , you were taking the actual france telecom features and then applying something to phd a: uh , no there is a slight different . uh i mean , which are extracted at the handset because they had another back - end blind equalization professor c: yeah . phd a: yeah . professor c: yeah . but that 's what i mean . phd a: yeah . professor c: but u u sorry , phd a: yeah . professor c: yeah , i 'm not being i 'm not being clear . phd a: yeah . professor c: what i meant was you had something like cepstra or something , right ? phd a: yeah , yeah , yeah , yeah . professor c: and so one difference is that , i guess you were taking spectra . phd a: the speech . phd b: yeah . phd d: yeah . but i guess it 's the s exactly the same thing because on the heads uh , handset they just applied this wiener filter and then compute cepstral features , phd a: yeah , the cepstral f the difference is like there may be a slight difference in the way phd d: right ? or ? phd a: because they use exactly the baseline system for converting the cepstrum once you have the speech . i mean , if we are using our own code for th i mean that that could be the only difference . phd d: right . phd a: i mean , there is no other difference . phd d: mm - hmm . phd a: yeah . professor c: but you got some sort of different result . so i 'm trying to understand it . but uh , i th phd d: yeah , well i think we should uh , have a table with all the result because i do n't know i uh , i do n't exactly know what are your results ? but , phd a: ok . ok . phd d: mmm . yeah , but so we did this , and another difference i guess is that we just applied uh , proposal - one system after this without well , with our modification to reduce the delay of the the lda filters , phd a: uh - huh . phd d: and phd b: and the filter phd d: well there are slight modifications , but it was the full proposal - one . in your case , if you tried just putting lda , then maybe on - line normalization ? phd a: only lda . yeah . af - i after that i added on - line normalization , yeah . phd d: mm - hmm . so we just tried directly to to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . phd a: yeah , yeah . yeah . phd d: because if we keep the value that was submitted uh , it does n't help at all . you can remove on - line normalization , or put it , it does n't change anything . uh , uh , as long as you have the spectral subtraction . but , you can still find some kind of optimum somewhere , and we do n't know where exactly phd a: yeah . phd d: but , uh . phd a: yeah , i assume . professor c: so it sounds like you should look at some tables of results or something phd d: right . phd a: yeah . phd d: yeah . professor c: and see where i where the where they were different and what we can learn from it . phd d: mm - hmm . mm - hmm . phd a: without any change . ok . phd b: but it 's phd d: yeah . well , phd b: it 's the new . phd d: with with with changes , phd a: with phd b: the new . phd d: because we change it the system to have phd a: oh yeah , i mean the the new lda filters . phd b: the new . phd a: i mean ok . phd d: yeah . lda filters . there are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . phd a: mm - hmm . phd b: mm - hmm . phd d: w uh , it does n't seem to hurt on ti - digits , finally . phd a: ok . phd d: maybe because of other changes . phd a: ok . phd d: um , well there are some minor changes , yeah . phd a: mm - hmm . phd d: and , right now if we look at the results , it 's , um , always better than it seems always better than france telecom for mismatch and high - mismatch . and it 's still slightly worse for well - matched . phd b: but phd d: um , but this is not significant . but , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . even with very minor uh , even if it 's only slightly worse for well - matched . professor c: mm - hmm . phd d: and significantly better for hm . uh , but , well . i do n't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot hm , and mm , phd a: yeah . phd d: so , um , i guess what will happen i do n't know what will happen . but , the different contribution , i think , for the different test set will be more even . phd a: because the your improvement on hm and mm will also go down significantly in the spreadsheet so . but the the well - matched may still phd d: mm - hmm . phd a: i mean the well - matched may be the one which is least affected by adding the endpoint information . professor c: right . phd a: yeah . so the the mm phd d: mm - hmm . phd a: mm and hm are going to be v hugely affected by it . yeah . phd d: yeah , so um , yeah . phd a: yeah . but they d the everything i mean is like , but there that 's how they reduce why they reduce the qualification to twenty - five percent or some something on . phd d: mm - hmm . professor c: but are they changing the weighting ? phd a: uh , no , i guess they are going ahead with the same weighting . phd d: yeah . phd a: yeah . so there 's nothing on professor c: i do n't understand that . phd a: yeah . professor c: i guess i i have n't been part of the discussion , so , um , it seems to me that the well - matched condition is gon na be unusual , phd a: usual . professor c: in this case . unusual . phd a: uh - huh . professor c: because , um , you do n't actually have good matches ordinarily for what any @ @ particular person 's car is like , or phd a: mmm . professor c: uh , phd a: mmm . professor c: it seems like something like the middle one is is more natural . phd a: hmm . right . professor c: so i do n't know why the well - matched is uh phd d: mm - hmm . phd a: yeah , but actually the well well the well - matched um , uh , i mean the the well - matched condition is not like , uh , the one in ti - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . it 's like , this is not calibrated by snr or something . the well - matched has also some some mismatch in that which is other than the professor c: the well wa matched has mismatch ? phd a: has has also some slight mismatches , unlike the ti - digits where it 's like prefectly matched phd f: perfect to match . phd a: because it 's artificially added noise . professor c: yeah . phd a: but this is natural recording . professor c: yeah . so remind me of what well - matched meant ? phd a: the the well - matched is like professor c: you 've told me many times . phd a: the the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . phd d: yeah . well , so it means that if the database is large enough , it 's matched . phd a: it 's it 's phd d: because it phd a: ok , it 's professor c: yeah . phd d: in each set you have a range of conditions well professor c: right . so , i mean , yeah , unless they deliberately chose it to be different , which they did n't because they want it to be well - matched , it is pretty much you know , so it 's so it 's sort of saying if you phd f: it 's it 's not guaranteed though . phd a: yeah . professor c: uh , it 's not guaranteed . phd a: yeah . professor c: right . phd d: mm - hmm . phd a: yeah because the m the main major reason for the m professor c: right . phd a: the main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually . professor c: again , if you have enough if you have enough phd a: no yeah , yeah . yeah . professor c: so it 's sort of i i it 's sort of saying ok , so you much as you train your dictation machine for talking into your computer , um , you you have a car , and so you drive it around a bunch and and record noise conditions , or something , and then i do n't think that 's very realistic , i mean i th phd a: mm - hmm . professor c: i i you know , so i i i you know , i guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and and you would have something that was roughly similar and maybe that 's the argument , but i 'm not sure i buy it , so . phd a: yeah , yeah , yeah . professor c: uh , so what else is going on ? phd d: mmm . you yeah . we are playing we are also playing , trying to put other spectral subtraction mmm , in the code . um , it would be a very simple spectral subtraction , on the um , mel energies which i already tested but without the um frame dropping actually , and i think it 's important to have frame dropping if you use spectral subtraction . phd f: is it is spectral subtraction typically done on the after the mel , uh , scaling or is it done on the fft bins ? phd d: um , phd f: does it matter , or ? phd d: i d i do n't know . well , it 's both both uh , cases can i phd f: oh . phd d: yeah . so - some of the proposal , uh , we 're doing this on the bin on the fft bins , phd f: hmm . phd d: others on the um , mel energies . you can do both , but i can not tell you what 's which one might be better or i phd f: hmm . phd a: i guess if you want to reconstruct the speech , it may be a good idea to do it on fft bins . phd d: i do n't know . yeah , but phd f: mmm . phd a: but for speech recognition , it may not . i mean it may not be very different if you do it on mel warped or whether you do it on fft . so you 're going to do a linear weighting anyway after that . phd f: i see . phd a: well yeah ? phd f: hmm . phd a: so , it may not be really a big different . phd d: well , it gives something different , but i do n't know what are the , pros and cons of both . phd a: it i uh - huh . professor c: hmm . phd a: so professor c: ok . phd a: the other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement . phd d: yeah . phd b: mm - hmm . phd d: mm - hmm . phd a: i mean they just do the same thing again once more . professor c: mm - hmm . phd a: and so , there 's something that is good about doing it i mean , to cleaning it up once more . phd d: yeah , it might be . phd a: yeah , phd d: yeah . phd a: so we can phd d: so maybe in my implementation i should also try to inspire me from this kind of thing phd a: yeah . that 's what professor c: well , the other thing would be to combine what you 're doing . phd d: and yeah . professor c: i mean maybe one or one or the other of the things that you 're doing would benefit from the other happening first . phd a: that 's wh yeah . so , professor c: right , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around , phd d: yeah , mm - hmm . phd a: yeah . professor c: you know ? phd a: so i 've been thinking about combining the wiener filtering with signal subspace , phd d: mm - hmm . phd a: i mean just to see all some some such permutation combination to see whether it really helps or not . phd d: mm - hmm . mm - hmm . mm - hmm . yeah . yeah . professor c: how is it i i guess i 'm ignorant about this , how does i mean , since wiener filter also assumes that you 're that you 're adding together the two signals , how is how is that differ from signal subspace ? phd a: the signal subspace ? the professor c: yeah . phd a: the signal subspace approach has actually an in - built wiener filtering in it . professor c: oh , ok . phd a: yeah . it is like a kl transform followed by a wiener filter . is the signal is is a signal substrate . professor c: oh , oh , ok so the difference is the kl . phd a: so , the the different the c the the advantage of combining two things is mainly coming from the signal subspace approach does n't work very well if the snr is very bad . it 's it works very poorly with the poor snr conditions , and in colored noise . professor c: i see . so essentially you could do simple spectral subtraction , followed by a kl transform , followed by a phd a: wiener filtering . it 's a it 's a cascade of two s professor c: wiener filter . yeah , in general , you do n't that 's right you do n't wan na othorg orthogonalize if the things are noisy . actually . um , that was something that uh , herve and i were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . phd a: mm - hmm . ok . yeah . so . professor c: uh , so . phd a: so that that 's one reason maybe we could combine s some something to improve snr a little bit , first stage , professor c: yeah . phd a: and then do a something in the second stage which could take it further . phd d: what was your point about about colored noise there ? phd a: oh , the colored noise uh phd d: yeah . phd a: the colored noise the the v the signal subspace approach has i mean , it it actually depends on inverting the matrices . so it it ac the covariance matrix of the noise . so if if it is not positive definite , phd d: mm - hmm . phd a: i mean it has a it 's it does n't behave very well if it is not positive definite ak it works very well with white noise because we know for sure that it has a positive definite . professor c: so you should do spectral subtraction and then add noise . phd a: so the way they get around is like they do an inverse filtering , first of the colo colored noise professor c: yeah . phd a: and then make the noise white , professor c: yeah . phd a: and then finally when you reconstruct the speech back , you do this filtering again . phd d: yeah , right . professor c: i was only half kidding . i mean if you sort of you do the s spectral subtraction , that also gets rid phd a: yeah . phd d: yeah . phd a: yeah . professor c: and then you then then add a little bit l noise noise addition i mean , that sort of what j jrasta does , in a way . phd a: yeah . professor c: if you look at what jrasta doing essentially i i it 's equivalent to sort of adding a little adding a little noise , phd a: huh ? uh - huh . phd d: uh - huh . professor c: in order to get rid of the effects of noise . phd a: so . professor c: ok . phd d: yeah . uh , yeah . so there is this . and maybe we well we find some people so that uh , agree to maybe work with us , and they have implementation of vts techniques so it 's um , vector taylor series that are used to mmm , uh f to model the transformation between clean cepstra and noisy cepstra . so . well , if you take the standard model of channel plus noise , uh , it 's it 's a nonlinear eh uh , transformation in the cepstral domain . professor c: mm - hmm . yes . phd d: and uh , there is a way to approximate this using uh , first - order or second - order taylor series and it can be used for uh , getting rid of the noise and the channel effect . professor c: who is doing this ? phd d: uh w working in the cepstral domain ? so there is one guy in grenada , phd b: yeah , in grenada one of my friend . phd d: and another in uh , lucent that i met at icassp . professor c: who 's the guy in grenada ? phd d: uh , phd b: uh , jose carlos segura . professor c: i do n't know him . phd a: this vts has been proposed by cmu ? phd d: mm - hmm . phd a: is it is it the cmu ? yeah , yeah , ok . phd b: yeah , yeah , yeah . originally the idea was from cmu . phd a: from c . phd d: mm - hmm . yeah . professor c: uh - huh . phd d: well , it 's again a different thing that could be tried . um , professor c: uh - huh . phd d: mmm , yeah . professor c: yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with with these other things we have , phd d: mm - hmm . professor c: uh , looks like a worthy thing to to do here . phd d: uh , yeah . but , yeah . but for sure there 's required to that requires to re - check everything else , and re - optimize the other things professor c: oh yeah . phd d: and , for sure the on - line normalization may be the lda filter . um , professor c: well one of the seems like one of the things to go through next week when hari 's here , phd d: i professor c: cuz hari 'll have his own ideas too or i guess not next week , phd d: uh - huh . professor c: week and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . um . you know . so , i mean one way would he here are some alternate visions . i mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same different aspects of the same thing . another thing would be to have t to to pick two pol two plausible things , and and you know , have t sort of two working things for a while until we figure out what 's better , phd d: mm - hmm . professor c: and then , you know , uh , but , w um , uh , he 'll have some ideas on that too . phd a: the other thing is to , uh most of the speech enhancement techniques have reported results on small vocabulary tasks . but we we going to address this wall street journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . so , there are some i mean , i was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction does n't seems to be the thing to do for large vocabulary tasks . and it 's always people have shown improvement with wiener filtering and maybe subspace approach over spectral subtraction everywhere . but if we if we have to use simple spectral subtraction , we may have to do some optimization to make it work @ @ . professor c: so they 're making there somebody 's generating wall street journal with additive artificially added noise or something ? phd a: yeah , yeah . professor c: sort of a sort of like what they did with ti - digits , and ? phd a: yeah . yeah . professor c: yeah , ok . phd a: i m i guess guenter hirsch is in charge of that . guenter hirsch and ti . professor c: ok . phd a: maybe roger r roger , maybe in charge of . professor c: and then they 're they 're uh , uh , generating htk scripts to phd a: yeah . yeah , i do n't know . there are they have there is no i do n't know if they are converging on htk or are using some mississippi state , professor c: mis - mississippi state maybe , phd a: yeah . i 'm not sure about that . professor c: yeah . yeah , so that 'll be a little little task in itself . phd a: yeah . professor c: um , well we 've yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . but for n there 's been noisy speech this larv large vocabulary that we 've worked with in broadcast news . so we we did the broadcast news evaluation phd a: mm - hmm . professor c: and some of the focus conditions were noisy and and phd a: it had additive n professor c: but we but we did n't do spectral subtraction . we were doing our funny stuff , right ? we were doing multi multi uh , multi - stream and and so forth . phd a: yeah . professor c: but it , you know , we di stuff we did helped . i mean it , did something . phd a: ok . professor c: so . um , now we have this um , meeting data . you know , like the stuff we 're { comment } recording right now , phd a: yeah . yeah . professor c: and and uh , that we have uh , for the uh , the quote - unquote noisy data there is just noisy and reverberant actually . it 's the far field mike . and uh , we have uh , the digits that we do at the end of these things . and that 's what most o again , most of our work has been done with that , with with uh , connected digits . phd a: uh - huh . professor c: um , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using switchboard uh , switchboard recognizer , phd a: yeah . ok . professor c: uh , no training , from this , just just plain using the switchboard . phd a: oh . you just take the switchboard trained ? yeah , professor c: that 's that 's what we 're doing , phd a: yeah . professor c: yeah . now there are some adaptation though , phd a: ok . yeah . that 's cool . professor c: that that uh , andreas has been playing with , phd a: ok . professor c: but we 're hop uh , actually uh , dave and i were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . um , i mean , i guess no one had done yet done test one on the distant mike using uh , the sri recognizer and , uh , phd f: i do n't not that i know of . professor c: yeah , cuz everybody 's scared . phd a: yeah . professor c: you 'll see a little smoke coming up from the the cpu or something trying to trying to do it , phd f: that 's right professor c: but uh , yeah . but , you 're right that that that 's a real good point , that uh , we we do n't know yeah , uh , i mean , what if any of these ta i guess that 's why they 're pushing that in the uh in the evaluation . phd a: yeah . professor c: uh , but um , good . ok . anything else going on ? at you guys ' end , phd b: i do n't have good result , with the inc including the new parameters , professor c: or ? phd b: i do n't have good result . are similar or a little bit worse . phd a: with what what other new p new parameter ? grad g: you 're talking about your voicing ? professor c: yeah . phd b: yeah . professor c: so maybe you probably need to back up a bit phd a: yeah . phd b: mm - hmm . professor c: seeing as how sunil , phd b: i tried to include another new parameter to the traditional parameter , professor c: yeah . phd b: the coe the cepstrum coefficient , phd a: uh - huh . phd b: that , like , the auto - correlation , the r - zero and r - one over r - zero phd a: mm - hmm . mm - hmm . phd b: and another estimation of the var the variance of the difference for of the spec si uh , spectrum of the signal and and the spectrum of time after filt mel filter bank . phd a: i 'm so sorry . i did n't get it . phd b: nuh . well . anyway . the first you have the sp the spectrum of the signal , phd a: mm - hmm . phd b: and you have the on the other side you have the output of the mel filter bank . phd a: mm - hmm . phd b: you can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal . phd a: mmm . ok . phd b: i do the difference phd a: ok . phd b: i found a difference at the variance of this different phd a: uh - huh . phd b: because , suppose we we think that if the variance is high , maybe you have n uh , noise . phd a: yeah . phd b: and if the variance is small , maybe you have uh , speech . phd a: uh - huh . phd b: to to to the idea is to found another feature for discriminate between voice sound and unvoice sound . phd a: ok . phd b: and we try to use this new feature feature . and i did experiment i need to change to obtain this new feature i need to change the size the window size size . of the a of the analysis window size , to have more information . phd a: yeah . make it longer . phd b: uh , sixty - two point five milliseconds i think . phd a: ok . phd b: and i do i did two type of experiment to include this feature directly with the with the other feature and to train a neural network to select it voice - unvoice - silence silence phd a: unvoiced . well . phd b: and to to concat this new feature . but the result are n with the neural network i have more or less the same result . phd a: as using just the cepstrum , phd b: result . phd a: or ? phd b: yeah . phd a: ok . phd b: yeah . it 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly . phd a: uh , is it with ti - digits , or with ? phd b: and no , i work with eh , italian and spanish basically . phd a: ok . ok . phd b: and if i do n't y use the neural network , and use directly the feature the results are worse . phd a: uh - huh . phd b: but does n't help . professor c: i i i really wonder though . phd d: mm - hmm . professor c: i mean we 've had these discussions before , and and one of the things that struck me was that uh , about this line of thought that was particularly interesting to me was that we um whenever you condense things , uh , in an irreversible way , um , you throw away some information . and , that 's mostly viewed on as a good thing , in the way we use it , because we wan na suppress things that will cause variability for uh particular , uh , phonetic units . um , but , you 'll do throw something away . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . and um . so , when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voice voiced property whatever . `` so that that 's interesting . maybe that helps to drive the the thought process of coming up with the features . but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , phd b: to know professor c: and then use it , you know , in combination , or alone , or or whatever phd f: wi - with what targets ? phd a: voiced , unvoiced is like professor c: uh , no . phd a: oh . or anything . professor c: no the just the same same way we 're using i mean , the same way that we 're using the filter bank . phd f: phones . phd a: oh , ok . professor c: exact way the same way we 're using the filter bank . phd d: mm - hmm . professor c: i mean , the filter bank is good for all the reasons that we say it 's good . but it 's different . and , you know , maybe if it 's used in combination , it will get at something that we 're missing . and maybe , you know , using , orth you know , klt , or uh , um , adding probabilities , i mean , all th all the different ways that we 've been playing with , that we would let the essentially let the neural network determine what is it that 's useful , that we 're missing here . phd d: mm - hmm . mm - hmm . phd a: mm - hmm . phd d: yeah , but there is so much variability in the power spectrum . professor c: well , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination . phd d: mm - hmm . mmm . professor c: but i i i have to tell you , i ca n't remember the conference , but , uh , i think it 's about ten years ago , i remember going to one of the speech conferences and and uh , i saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the fft and the fft did slightly better . so i mean the i i it 's true there 's lots of variability , phd d: mm - hmm . professor c: but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . phd d: mm - hmm . professor c: so , um , uh , it - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in lda , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily not necessarily gon na be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . so , phd a: yeah , d professor c: part of what we 're discovering , is ways to combine things that are data driven than are not . phd a: yeah . professor c: uh , so anyway , it 's just a thought , that that if we if we had that maybe it 's just a baseline uh , which would show us `` well , what are we really getting out of the filters `` , or maybe i i probably not by itself , but in combination , uh , phd d: mm - hmm . professor c: you know , maybe there 's something to be gained from it , and let the but , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . but , maybe the neural net and the h m ms could figure it out quicker than you . phd b: maybe . professor c: so . phd b: yeah , professor c: it 's just a thought . phd b: i can i will try to do that . professor c: yeah . phd a: what one one um p one thing is like what before we started using this vad in this aurora , the th what we did was like , i i guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the hmm on that . professor c: mm - hmm . phd a: that is just a binary feature and that seems to be improving a lot on the speechdat - car where there is a lot of noise but not much on the ti - digits . so , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . that 's it . phd d: wait i i 'm sorry ? phd a: yeah , we actually added an additional binary feature to the cepstrum , just the baseline . phd d: yeah ? phd b: you did some experiment . phd a: yeah , yeah . well , in in the case of ti - digits it did n't actually give us anything , because there was n't any f anything to discriminate between speech , phd d: yeah . phd a: and it was very short . but italian was like very it was a huge improvement on italian . phd d: hmm . well mm - hmm . but anyway the question is even more , is within speech , can we get some features ? are we drop dropping information that can might be useful within speech , phd a: ok . phd d: i mean . to maybe to distinguish between voice sound and unvoiced sounds ? phd a: mm - hmm . yeah , yeah . yeah . professor c: and it 's particularly more relevant now since we 're gon na be given the endpoints . phd d: yeah . professor c: so . phd d: mm - hmm . phd a: yeah , yeah . professor c: uh . so . phd d: mmm . phd a: mmm . professor c: um . phd a: there was a paper in icassp this icassp over the uh extracting some higher - order uh , information from the cepstral coefficients and i forgot the name . some is some harmonics i do n't know , i can i can pull that paper out from icassp . it professor c: talking cumulants or something ? phd d: yeah . phd a: huh ? uh , i do n't know . professor c: cumulants or something . phd a: i do n't remember . professor c: but no . phd a: it wa it was taking the , um it was about finding the higher - order moments of yeah . professor c: yeah , phd a: and i 'm not sure about whether it is the higher - order moments , or professor c: cumulants , yeah . phd a: maybe higher - order cumulants professor c: oh . phd a: and yeah . it was it was professor c: or m e phd a: yeah . i mean , he was showing up uh some something on noisy speech , professor c: yeah . phd a: some improvement on the noisy speech . phd d: mm - hmm . phd a: some small vocabulary tasks . professor c: uh . phd a: so it was on plp derived cepstral coefficients . professor c: yeah , but again you could argue that th that 's exactly what the neural network does . phd a: mmm . professor c: so n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you phd a: trying to f to moments , yeah . yeah . professor c: yeah . so . i mean , it does n't do it very specifically , phd d: mm - hmm . professor c: and pretty you know . but . phd a: yep . professor c: uh , anything on your end you want to talk about ? uh . grad g: um , nothing i wan na really talk about . i can i can just uh , um , share a little bit sunil has n't has n't heard about uh , what i 've been doing . professor c: yeah . grad g: um , so , um , i told you i was i was i was getting prepared to take this qualifier exam . so basically that 's just , um , trying to propose um , uh , your next your your following years of of your phd work , trying trying to find a project to to define and and to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . so , um , the idea is you have all these these different events , for example voicing , nasality , r - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . um , and , um , these these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to larry saul 's work on , uh , graphical models to to detect these these , uh , acoustic events . and , um , so i i been i been thinking about that and some of the issues that i 've been running into are , um , exactly what what kind of acoustic events i need , what um , what acoustic events will provide a a good enough coverage to in order to do the later recognition steps . and , also , um , once i decide a set of acoustic events , um , h how do i how do i get labels ? training data for for these acoustic events . and , then later on down the line , i can start playing with the the models themselves , the the primary detectors . um , so , um , i kinda see like , after after building the primary detectors i see um , myself taking the outputs and feeding them in , sorta tandem style into into a um , gaussian mixtures hmm back - end , um , and doing recognition . um . so , that 's that 's just generally what i 've been looking at . phd a: yeah . grad g: um , professor c: by by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what carmen was looking at . grad g: yeah . professor c: so , phd d: mm - hmm . professor c: you know , um , if you if a multi - band approach was helpful as as i think it is , it seems to be helpful for determining voiced - unvoiced , grad g: mm - hmm . professor c: that one might be another thing . phd b: mm - hmm . grad g: yeah . yeah . um , were were you gon na say something ? phd f: mmm . grad g: oh . it looked ok , never mind . um , yeah . and so , this this past week um , i 've been uh , looking a little bit into uh , traps um , and doing doing traps on on these e events too , just , um , seeing seeing if that 's possible . uh , and um , other than that , uh , i was kicked out of i - house for living there for four years . professor c: oh no . so you live in a cardboard box in the street now grad g: yeah . professor c: or , no ? grad g: uh , well , s s som something like that . professor c: yeah . grad g: in albany , yeah . yeah . and uh . yep . that 's it . professor c: suni - i d ' you v did uh did you find a place ? phd a: uh , no professor c: is that out of the way ? phd a: not yet . uh , yesterday i called up a lady who ha who will have a vacant room from may thirtieth and she said she 's interviewing two more people . so . and she would get back to me on monday . so that 's that 's only thing i have and diane has a few more houses . she 's going to take some pictures and send me after i go back . so it 's that 's professor c: ok . phd f: oh . so you 're not down here permanently yet ? phd a: no . i 'm going back to ogi today . phd f: ah ! oh , ok . grad g: oh . professor c: ok . and then , you 're coming back uh phd a: uh , i i mean , i i p i plan to be here on thirty - first . professor c: thirty - first , phd a: yeah , well if there 's a house available or place to professor c: ok . grad g: thirty - first . professor c: well , i mean i i if if phd a: yeah , i hope . professor c: they 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for for for a while phd a: yeah . so , in that case , i 'm going to be here on thirty - first definitely . professor c: until you ok . grad e: you know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . i 've got a spare bedroom right now . phd a: oh . ok . thanks . that sure is nice of you . so , it may be he needs more than me . grad g: oh r oh . oh no , no . my my cardboard box is actually a nice spacious two bedroom apartment . professor c: so a two bedroom cardboard box . th - that 's great . phd a: yeah . yeah . yeah . professor c: thanks dave . grad g: yeah phd a: yeah . professor c: um , phd a: yeah . professor c: do y wan na say anything about you you actually been uh , last week you were doing this stuff with pierre , you were you were mentioning . is that that something worth talking about , or ? grad e: um , it 's well , um , it i do n't think it directly relates . um , well , so , i was helping a speech researcher named pierre divenyi and he 's int he wanted to um , look at um , how people respond to formant changes , i think . um . so he he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . and he wanted to look at um , how the energy is moving over time in that spectrum and compare that to the to the listener tests . and , um . so , i gave him a plp spectrum . and to um he he t wanted to track the peaks so he could look at how they 're moving . so i took the um , plp lpc coefficients and um , i found the roots . this was something that stephane suggested . i found the roots of the um , lpc polynomial to , um , track the peaks in the , um , plp lpc spectra . phd a: well there is aligned spectral pairs , is like the the is that the aligned s professor c: it 's a r root lpc , uh , of some sort . phd a: oh , no . phd d: mm - hmm . phd a: so you just professor c: yeah . phd a: instead of the log you took the root square , i mean cubic root or something . what di w i did n't get that . professor c: no , no . it 's it 's it 's taking the finding the roots of the lpc polynomial . phd a: polynomial . yeah . is that the line spectral professor c: so it 's like line spectral pairs . phd a: oh , it 's like line sp professor c: except i think what they call line spectral pairs they push it towards the unit circle , do n't they , phd a: yeah , yeah , yeah , yeah . professor c: to sort of ? but it but uh , you know . but what we 'd used to do w when i did synthesis at national semiconductor twenty years ago , the technique we were playing with initially was was taking the lpc polynomial and and uh , finding the roots . it was n't plp cuz hynek had n't invented it yet , but it was just lpc , and uh , we found the roots of the polynomial , and th when you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not . phd a: mmm . professor c: so it 's it 's it 's a little , phd d: hmm . professor c: uh formant tracking with it can be a little tricky cuz you get these funny values in in real speech , phd f: so you just you typically just get a few roots ? professor c: but . phd f: you know , two or three , professor c: well you get these complex pairs . phd f: something like that ? professor c: and it depends on the order that you 're doing , but . phd d: mm - hmm . grad e: right . so , um , if @ @ { comment } every root that 's since it 's a real signal , the lpc polynomial 's gon na have real coefficients . so i think that means that every root that is not a real root { comment } is gon na be a c complex pair , phd f: mm - hmm . grad e: um , of a complex value and its conjugate . um . so for each and if you look at that on the unit circle , um , one of these one of the members of the pair will be a positive frequency , one will be a negative frequency , i think . so i just so , um , f for the i 'm using an eighth - order polynomial and i 'll get three or four of these pairs professor c: yeah . phd a: hmm . grad e: which give me s which gives me three or four peak positions . professor c: this is from synthetic speech , or ? grad e: it 's right . yeah . professor c: yeah . so if it 's from synthetic speech then maybe it 'll be cleaner . i mean for real speech in real then what you end up having is , like i say , funny little things that are do n't exactly fit your notion of formants all that well . phd f: how did professor c: but but mostly they are . phd d: but professor c: mostly they do . phd d: yeah . grad e: mmm , professor c: and and what i mean in in what we were doing , which was not so much looking at things , it was ok phd d: i professor c: because it was just a question of quantization . uh , we were just you know , storing it was we were doing , uh , stored speech , uh , quantization . phd d: mm - hmm . professor c: but but uh , in your case um , you know phd d: actually you have peaks that are not at the formant 's positions , but they are lower in energy grad e: but there 's some of that , yes . phd d: and well they are much lower . phd f: if this is synthetic speech ca n't you just get the formants directly ? i mean h how is the speech created ? grad e: it was created from a synthesizer , and um phd f: was n't a formant synthesizer was it ? professor c: i bet it it might have may have been grad e: i d d this professor c: but maybe he did n't have control over it or something ? grad e: in in fact w we we could get , um , formant frequencies out of the synthesizer , as well . and , um , w one thing that the , um , lpc approach will hopefully give me in addition , um , is that i i might be able to find the b the bandwidths of these humps as well . um , stephane suggested looking at each complex pair as a like a se second - order iir filter . professor c: yeah . grad e: um , but i do n't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . except that you do n't have the psycho - acoustic modeling in that . professor c: yeah , so the actual so you 're not getting the actual formants per se . you 're getting the again , you 're getting sort of the , uh phd d: mm - hmm . professor c: you 're getting something that is is uh , af strongly affected by the plp model . and so it 's more psycho - acoustic . so it 's a little it 's it 's it 's sort of sort of a different thing . phd f: oh , i see . that 's sort of the point . professor c: but yeah . i ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are phd f: yeah . professor c: i mean , that 's somewhere in the synthesizer that was put in , as as what you grad e: mm - hmm . professor c: but but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um but . yeah . o k . so , uh , yeah , you 're going back today and then back in a week i guess , phd a: yeah . professor c: and . yeah . great ! well , welcome . phd a: thanks . phd f: i guess we should do digits quickly . professor c: oh yeah , digits . phd d: mmm . professor c: i almost forgot that . phd b: digits . professor c: i almost forgot our daily digits . phd f: you wan na go ahead ? professor c: sure . phd f: ok .","output":"the professor could not see the advantage in combining the wiener filter and the subspace . he later understood it would be a simple spectral subtraction , followed by a kl transform , followed by a wiener filter ."},{"instruction":"what were the topics talked about in the meeting ?","input":"professor e: alright . grad c: so are you professor e: so . grad c: are we going ? professor e: it is uh , must be february fifteenth . postdoc f: yeah . grad c: yu i think the date 's written in there , yep . and actually if everyone could cross out the r - nine next to `` session `` , and write mr eleven . professor e: yeah . yeah . we did n't have a front - end meeting today . grad c: and let 's remember also to make sure that one 's { comment } gets marked as unread , unused . professor e: ok . phd a: mr eleven . grad c: mr eleven . postdoc f: that sounds like a spy code . professor e: mmm . ok . so . grad c: there 's lots of clicking i 'm sure as i 'm trying to get this to work correctly . professor e: agenda . any agenda items today ? grad c: i wan na talk a little bit about getting how we 're gon na to get people to edit bleeps , parts of the meeting that they do n't want to include . what i 've done so far , and i wan na get some opinions on , how to how to finish it up . professor e: ok . postdoc f: i wan na ask about um , some aud audio monitoring on some of the um well some of the equipment . in particular , the well uh , that 's just what i wan na ask . professor e: ok audio monitoring , jane . postdoc f: ba - based on some of the tran uh i in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact in fact this one i 'm talking on is one of of the ones that showed up in one of the meetings , grad c: oh really . postdoc f: so i phd b: `` spikes `` , you mean like uh , instantaneous click type spikes , or ? postdoc f: mm - hmm . yeah . phd a: spikes ? grad c: clicks . postdoc f: yeah . professor e: hmm . postdoc f: yeah . phd b: huh . postdoc f: and i do n't know what the e electronics is but . grad c: yeah . postdoc f: yeah . grad c: well , i think it 's phd a: touching . grad c: uh , it it could be a number of things . phd a: yeah . grad c: it could be touching and fiddling , and the other thing is that it could the fact that it 's on a wired mike is suspicious . it might be a connector . postdoc f: oh , ok . well maybe then we do n't really have to talk about that as an phd b: you could try an experiment and say `` ok , i 'm about to test for spikes `` , postdoc f: i i take that off the agenda . phd b: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . grad c: yeah . right . phd b: `` come get me when you transcribe this and see if there 's spikes . `` postdoc f: oh that professor e: um . postdoc f: well , ok . phd b: no i 'm just professor e: i mean , were this a professional audio recording , what we would do { comment } what you would do is in testing it is , you would actually do all this wiggling and make sure that that that things are not giving that kind of performance . and if they are , then they ca n't be used . grad c: right . professor e: so . um . let 's see . i guess i would like to have a discussion about you know where we are on uh , recording , transcription you know , basically you know where we are on the corpus . postdoc f: good . professor e: and then um , the other thing which i would like to talk about which is a real meta - quest , i think , deal is , uh , agendas . so maybe i 'll i 'll start with that actually . uh , um . andreas brought up the fact that he would kinda like to know , if possible , what we were gon na be talking about because he 's sort of peripherally involved to this point , and if there 's gon na be a topic about discussion about something that he uh strongly cares about then he would come and and i think part of part of his motivation with this is that he 's trying to help us out , in the because of uh the fact that the meetings are are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing grad c: mmm . professor e: and and i 'm sure help out his own time . by not showing up if it 's a meeting that he 's he 's so , uh in order i 'd i think that this is a wish on his part . uh . it 's actually gon na be hard because it seems like a lot of times uh things come up that are unanticipated and and grad c: right . professor e: but um , we could try anyway , uh , do another try at coming up with the agenda uh , at some point before the meeting , uh , say the day before . grad c: well maybe it would be a good idea for one of us to like on wednesday , or tuesday send out a reminder for people to send in agenda items . phd a: yeah . professor e: ok . you you wan na volunteer to do that ? grad c: sure . professor e: ok . alright so we 'll send out agenda request . grad c: let me professor e: uh . phd b: that 'll be i think that 'll help grad c: i 'll put that on my spare brain or it will not get done . phd b: that 'll help a lot , actually . professor e: yeah , i have to tell you for the uh for the admin meeting that we have , lila does that um every time before an admin meeting . and uh , she ends up getting the agenda requests uh , uh ten minutes before the meeting . but but { comment } but . uh . { comment } but we can try . maybe it 'll work . phd b: mmm . grad c: yeah . maybe . weirder things have happened . professor e: yeah . postdoc f: i 'm wondering if he were to just , uh , specify particular topics , i mean . maybe we 'd be able to meet that request of his a little more . phd b: i would i would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him . grad c: well then professor e: yeah . actually it this this maybe brings up another topic which is um so we 're done with that topic . the other topic i was thinking of was the sta status on microphones and channels , and all that . grad c: yeah , actually i i was going to say we need to talk about that too . professor e: yeah . why why do n't we do that . grad c: ok . um , the new microphones , the two new ones are in . um . and they are being assembled as we speak , i hope . and i did n't bring my car today so i 'm gon na pick them up tomorrow . um , and then the other question i was thinking about is well , a couple things . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , phd a:  grad c: and get people 's opinions on on what they think of them . um , then the other question i had is maybe we should get another wireless . another wireless setup . i mean it 's expensive , but it does seem to be better than the wired . professor e: so how many channels do you get to have in a wireless setup ? grad c: um , well , i 'm pretty sure that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and apparently you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . professor e: so , um . grad c: and so , you know it 's still , it 's fifteen minus six . professor e: so let 's see we grad c: right ? so we could have up to nine . professor e: and right now we can have up to six . grad c: right . and we have five , we 're getting one more . professor e: yeah . grad c: and it 's um , about nine hundred dollars for the base station , and then eight hundred per channel . professor e: oh . so yeah so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . grad c: right . professor e: oh , we should do it . grad c: ok . ok , so i 'll look into how you daisy - chain them and and then just go ahead and order them . professor e: yeah . yeah . phd b: i do n't quite understand how that how that works , . if so we 're not increasing the number of channels . ok . grad c: no , we 're just replacing the wired the two wired that are still working , phd b: ok . i see . grad c: along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless . professor e: yeah . phd b: three wireds work , professor e: basically we found phd b: right ? grad c: i i guess three wireds work , yeah . phd b: yeah . yeah . professor e: yeah . but we 've had more problems with that . grad c: yep . professor e: and that sort of bypasses the whole the whole jimbox thing and all that . grad c: right . professor e: and so um , we we seem to have uh , a reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . grad c: right . professor e: that seems to be the key issue . grad c: everyone 's battery ok ? phd b: i checked them this morning , they should be . grad c: ok . professor e: yeah . um , that 's the only thing with them . but the quality seems really good and um i heard from uw that they 're they 're uh very close to getting their , uh setup purchased . they 're they 're they 're buying something that you can just sort of buy off the shelf . grad c: well we should talk to them about it because i know that sri is also in the process of looking at stuff , and so , you know , what we should try to keep everyone on the same page with that . professor e: yeah . phd b: sri , really ? grad c: yeah . phd b: oh . grad c: they got sa apparent well , maybe this needs to be bleeped out ? i have no clue . professor e: uh , i do n't know . grad c: i do n't know how much of it 's public . professor e: probably we should n't probably we should n't talk about funding stuff . grad c: right . professor e: yeah . but anyway there 's there 's there 's uh , uh other activities that are going on there and and uh and nist and uw . so . um . but but yeah i thin i think that at least the message we can tell other people is that our experience is is quite positive with the sony , grad c: right . professor e: uh , radio - mikes . now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering or something , right ? grad c: uh , no , we 're having the them do it . professor e: no ? grad c: so it 's so hand - soldering it , but i 'm not doing it . professor e: oh . grad c: so , they they charge professor e: ok . nothing against you and your hand - soldering grad c: right . professor e: but grad c: you 've never seen my hand - soldering . but uh , a as i said they 're coming in . professor e: uh , ok , so that 's being done professionally and grad c: i i mean professor e: yeah . grad c: yeah . i mean . professor e: yeah . grad c: as professionally as i guess you can get it done . professor e: well , it could if they do a lot of it , it 's grad c: i mean i it 's just their repair shop . right ? their maintenance people . professor e: well , we 'll see what it it 's like . grad c: yep . professor e: that tha that can be quite good . th - this yeah , ok . good . yeah . so let 's go with that . grad c: and , i mean we 'll see , tomorrow , you know , what it looks like . professor e: uh , yeah . so , um , uh , dave is n't here but he was going to start working on some things with the digits . uh , so he 'll be interested in what 's going on with that . i guess was the decision last time was that the the uh transcribers were going to be doing stuff with the digits as well ? has that started , or is that ? postdoc f: mm - hmm . yeah . uh , it would be to use his interface and i was going to meet with him today about that . grad c: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so i did the all that last week . so all the all the forms are now on the computer . and uh , then i have a bunch of scripts that we 'll read those and let the uh transcribers use different tools . and i just want to talk to jane about how we transition to using those . postdoc f: mm - hmm . so he has a nice set up that they it w it will be efficient for them to do that . professor e: ok . grad c: i i do n't think it 'll take too long . professor e: so anyway grad c: so , you know , just uh , a matter of a few days i suspect . professor e: so anyway i think we we have at least one uh , user for the digits once they get done , which will be dave . grad c: right . i 've already done five or six sets . postdoc f: ok . grad c: so if he wanted to , you know , just have a few to start with , he could . you know , and i also have a bunch of scripts that will , like , generate p - files and run recognition on them also . professor e: yeah , he might he might be asking right . ok . uh , is dave i do n't know if dave is on the list , if he 's invited to these meetings , uh if he knows . postdoc f: i do n't tend to get an invitation myself for them even . phd a: no , no . grad c: uh , we do n't have a active one but i 'll make sure he 's on the list . postdoc f: yeah . should we call him ? i mean is he d is he definitely not available today ? professor e: i do n't know . postdoc f: should i call his office and see ? phd a: he was in . grad c: i mean , he 's still taking classes , so uh , he may well have conflicts . professor e: uh , well i it 's uh phd a: yeah . professor e: yeah . phd a: yeah , he was in s postdoc f: he was n't there at cof professor e: yeah , so this might be a conflict for him . phd a: yeah . professor e: yeah . postdoc f: ok . professor e: ok . uh , so . grad c: yeah did n't he say his signal - processing class was like tuesdays and thursdays ? phd a: i think he has a class . yeah . phd b: yeah . he might have . grad c: oh well , whatever . grad d: you talking about david gelbart ? professor e: oh , ok . phd a: yeah . phd b: yeah . grad c: yeah . professor e: yeah . postdoc f: yes . grad d: yeah , i think he 's taking two twenty - five a which is now . phd b: yeah . grad d: so . professor e: yeah . postdoc f: ok . professor e: ok . so , that 's why we 're not seeing him . ok . uh , transcriptions , uh , beyond the digits , where we are , and so on . postdoc f: ok . professor e: and the and the recordings also , postdoc f: um professor e: just where we are . yeah . postdoc f: well , so um , should we we do n't wan wan na do the recording status first , or ? grad c: well , we have about thirty - two hours uh as of , i guess a week and a half ago , so we probably now have about thirty - five hours . professor e: and and that 's that 's uh how much of that is digits ? it 's uh that 's including digits , grad c: that 's including digits . professor e: right ? grad c: i have n't separated it out so i have no clue how much of that is digits . professor e: so yeah . so anyway there 's at least probably thirty hours , or something of there 's got to be more than thirty hour phd a: mmm . grad c: of of non - digits ? professor e: i it could n't of of non - digits . grad c: yeah , absolutely . i mean , the digits do n't take up that much time . professor e: yeah , yeah . ok . postdoc f: ok , and the transcribers h i , uh , do n't have the exact numbers , but i think it would come to about eleven hours that are finished uh , transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what i mean by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that uh , liz requested in terms of um , um in terms of having a s a systematic handling of numbers , and acronyms which i had n't been specific about . um , for example , i they 'll say uh `` ninety - two `` . and you know , so how you could grad c: nine two , postdoc f: e exactly . grad c: right . postdoc f: so if you just say `` nine two `` , the there are many s ways that could have been expressed . an - and i just had them i i mean , a certain number of them did put the words down , but now we have a convention which also involves having it followed by , um , a gloss th and things . phd b: you know , jane ? grad c: mm - hmm . phd b: um , one suggestion and you may already be doing this , but i 've noticed in the past that when i 've gone through transcriptions and you know in in order to build lexicons and things , if you um , just take all the transcriptions and separate them into words and then alphabetize them , { comment } a lot of times just scanning down that list you 'll find a lot of inconsistencies and mis grad c: misspelled . phd a: yeah . postdoc f: you 're talking about the type token frequency listings , and i use those too . y you mean just uh on each on each line there 's a one word right ? it 's one token from the from the corpus . phd b: mm - hmm . mm - hmm . postdoc f: yeah , those are e extremely efficient and i and i i agree that 's a very good use of it . phd b: oh so you already have that , ok . postdoc f: well that 's that 's a way that 's you know , the spell - check basically does that but but in addition yes , that 's that 's exactly the strategy i wan na do in terms of locating these things which are you know colloquial spoken forms which are n't in the lexicon . phd b: mm - hmm . cuz a lot of times they 'll appear next to each other , and uh , postdoc f: exactly . and then you ca then you can do a s phd a: yeah . phd b: i in alphabetized lists , they 'll appear next to each other and and so it makes it easier . postdoc f: absolutely . i agree . that 's a very good that 's a very good uh , suggestion . and that was that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . i did n't get to that point but so there are numbers , then there are acronyms , and then um , there 's a he she wants the uh , actually a an explicit marker of what type of comment this is , so i curly b inside the curly brackets i 'm gon na put either `` voc `` for vocalized , like cough or like laugh or whatever , `` nonvoc `` for door - slam , and `` gloss `` for things that have to do with if they said a s a spoken form with this m this pronunciation error . grad c: right . postdoc f: i already had that convention phd b: oh that 's great . postdoc f: but i i have n't been asking these people to do it systematically cuz i think it most ha most efficiently handled by uh by a a filter . that was what i was always planing on . so that , you know you get a whole long list exactly what you 're saying , you get a whole list of things that say `` curly bracket laugh curly bracket `` , phd b: mm - hmm . postdoc f: then y you know it 's it 's you you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in sort of a voc space , phd b: yeah . postdoc f: so man so many ways that error prone . phd b: right . right . postdoc f: so , um , um i 'm i 'm going to convert that via a filter , into these tagged uh , subcategorized comments , and same thing with you know , we see you get a subset when you do what you 're saying , phd b: mm - hmm . postdoc f: you end up with a s with uh , you 're collapsing across a frequency you just have the tokens phd b: mm - hmm . postdoc f: and you can um , have a filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , you know i mean , jus grad c: you do n't know what they could be . phd b: yeah . postdoc f: yeah now timit 's clear um and plp is clear but uh there are things that are not so well known , in or or have variant u u uses like the numbers you can say `` nine two `` or you can say `` ninety - two `` , grad c: so how are you doing the postdoc f: and uh i 'd handle the numbers individually . grad c: how are you doing the uh , acronyms so if i say pzm what would it appear on the transcript ? postdoc f: it would be separate the letters would be separated in space grad c: ok . postdoc f: and potentially they 'll have a curly bracket thing afterwards e but i 'm not sure if that 's necessary , clarifying what it is , grad c: mm - hmm . postdoc f: so gloss of whatever . grad c: right . postdoc f: i do n't know if that 's really necessary to do that . maybe it 's a nice thing to do because of it then indicating this is uh , a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's uh the you know , { comment } uh enumerated , or i grad c: mm - hmm . postdoc f: it 's not a good way of saying but it 's it 's the specific uh way of stating these these letters . grad c: right . so it sounds good . postdoc f: and so anyway , the clean those are those things and then channelized is to then um , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . phd a: yeah . grad c: right . postdoc f: and uh , thilo had a e e a breakthrough with this this last week in terms of getting the channel - based um uh s s speech - nonspeech segmentation um , up and running and i have n't i have n't been able to use that yet cuz i 'm working s re this is my top priority get the data clean , and channelized . phd a: i actually gave grad c: have you also been doing spot checks , jane ? postdoc f: oh yes . grad c: okay , good . postdoc f: well you see that 's part of the cleaning process . i spent um actually um i have a segment of ten minutes that was transcribed by two of our transcribers , grad c: oh good . good . postdoc f: and i went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas i i left them discretion at commas . grad c: right . postdoc f: uh and so because it 's not part of our st of our ne needed conventions . professor e: mm - hmm . postdoc f: and um , and so they 'll be a difference in commas , but it 's word - by - word the same , in in huge patches of the data . and i have t ten minute stretch where i can where i can show that . and and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . so um , the one i i the colloquial speech person picked up `` gobbledy - gook `` . phd b: hmm . postdoc f: and the other one did n't . and on this side , this one 's picking up things like `` neural nets `` and the one that 's good on the sp o on th the vocabulary on the uh colloquial did n't . grad c: right . phd b: when for the person who missed `` gobbledy - gook `` what did they put ? postdoc f: it was an interesting approximation , put in parentheses , cuz i have this convention that , i if they 're not sure what it was , they put it in parentheses . phd b: oh . postdoc f: so they tried to approximate it , but it was phd b: oh good . postdoc f: it was spelled gabbl phd b: sort of how it sounds . yeah . postdoc f: yes . more of an attempt to i mean apparently it was very clear to her that these the a this this was a sound these are the sounds , grad c: it was a technical term that she did n't recognize , phd b: yeah . postdoc f: but yeah . but she knew that she did n't know it . maybe it was a technical ter exactly . but she even though her technical perception is just really uh you know i 've i 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses grad c: right . postdoc f: then cuz `` neural nets `` and oh she has some things that are oh `` downsampled `` , she got that right . phd b: hmm . postdoc f: and some of these are rather uh unexpected . grad c: obscure , yeah . postdoc f: but ch ten solid uh m ch s chunk of ten solid minutes where they both coded the same data . professor e: and and again the main track that you 're working with is elev eleven hours ? postdoc f: and um professor e: is that right ? postdoc f: yes exactly . professor e: yeah , ok . postdoc f: and that 's part of this eleven hours . professor e: is that is that that including digits ? yeah . postdoc f: yes it is . professor e: so let 's say roughly ten hours or so of postdoc f: mm - hmm . professor e: i mean it 's probably more than that but but with of of non - digits . phd a: yeah . postdoc f: it 'd be more than that because i my recollection is the minutes that da digits do n't take more than half a minute . per person . professor e: oh , ok . postdoc f: but um the the total set that i gave them is twelve hours of tape , professor e: oh , i see . postdoc f: but they have n't gotten to the end of that yet . professor e: oh , i see . postdoc f: so they 're still working some of them are two of them are still working on completing that . yeah . phd b: boy , they 're moving right along . professor e: yeah . postdoc f: yeah . they are . mm - hmm . they 're very efficient . there 're some who have more hours that they devote to it than others . phd b: mm - hmm . professor e: mm - hmm . postdoc f: yeah . professor e: so what what what 's the deal with with your phd a: the channel u thing ? professor e: yeah . phd a: oh , it 's just uh , i ran the recognizer uh , the { comment } speech - nonspeech detector on different channels and , it 's just in uh in this new multi - channel format and output , and i just gave one one meeting to to liz who wanted to to try it for for the recognizer professor e: oh , i see . phd a: as uh , apparently the recognizer had problems with those long chunks of speech , which took too much memory or whatever , professor e: right . phd a: and so she she will try that i think professor e: yeah . phd a: and i 'm i 'm working on it . so , i hope grad c: is this anything different than the hmm system you were using before ? professor e: yeah . phd a: no . uh , i mmm , use some some different features but not not grad c: mm - hmm . phd a: the basic thing is this hmm base . grad c: so there 's still no no knowledge using different channels at the same time . phd a: there is some , uh as the energy is normalized across channels grad c: you know what i mean ? across all of them . phd a: yeah . grad c: ok . phd a: so . but basically that 's one of the main changes . grad c: mm - hmm . professor e: mm - hmm . what are some of the other features ? besides the energy ? you said you 're trying some different features , or something . phd a: oh i just uh mmm , i just use um our loudness - based things now as they before there were they were some in in the log domain and i i changed this to the to the professor e: cu - cube root ? phd a: yeah . to no , i changed this to the to the to the loudness thingy with the with the grad c: hmm . professor e: ah . phd a: how do you call it ? i 'm not sure . with the , uh professor e: fletcher munson ? no . phd a: i 'm not sure about the term . professor e: oh , ok . phd a: uh , i 'll look it up . and say it to you . professor e: yeah , alright . phd a: uh , ok , and yeah . that 's that 's basically the the the thing . yeah , and i and i tried t to normalize uh uh the features , there 's loudness and modified loudness , um , within one channel , professor e: ok . phd a: because they 're , yeah to to be able to distinguish between foreground and background speech . and it works quite well . but , not always . professor e: uh - huh . uh - huh . phd a: so . professor e: ok . grad c: good . professor e: um , let 's see . i think the uh were were you basically done with the transcription part ? so i guess the next thing is this uh bleep editing . grad c: right . so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they do n't want . so i 've written a bunch of tools that will generate web pages , uh with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's a form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , uh , some of the questions on this is what do we do about the privacy issue . and so i thought about this a little bit and i think the best way to do it is every participant will have a password , professor e: yeah . grad c: a single password . each person will have a single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password . professor e: i i ca n't help but wonder if this is maybe a little more elaborate than is needed . i mean if people have uh , i mean , for me i would actually want to have some pieces of paper that had the transcription and i would sort of flip through it . and then um if i thought it was ok , i 'd say `` it 's ok `` . grad c: mm - hmm . professor e: and , i uh i mean it depends how this really ends up working out , but i guess my thought was that the occasion of somebody wondering whether something was ok or not and needing to listen to it was gon na be extremely rare . grad c: right , i mean so th th th the fact that you could listen to it over the web is a minor thing that i had already done for other reasons . professor e: ok . grad c: and so that that 's a minor part of it , i just wanted some web interface so that people you did n't actually have to send everyone the text . so m what my intention to do is that as the transcripts become ready , um i would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just uh , tell them , `` here 's the web page `` , um , `` you need a password `` . so th th question number one is how do we distribute the passwords , and question number two is how else do we wan na provide this information if they want it . professor e: that 's i think what i was sort of saying is that if you just say `` here is a here is `` i mean this maybe it sounds paleolithic but but i just thought if you handed them some sheets of paper , that said , uh , `` here 's what was said in this transcription is it ok with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's ok `` . grad c: i think that um there are a subset of people who will want printouts that we can certainly provide . professor e: and then they 'd hand it back to you . grad c: but certainly i would n't want a printout . these are big , and i would much rather be ha be able to just sit and leaf through it . professor e: you find it easier to go through a large i mean how do you read books ? grad c: well i certainly read books by hand . but for something like this , i think it 's easier to do it on the web . professor e: really ? i mean , it grad c: cuz you 're gon na get , you know , if i i 'm i 'm in a bunch of meetings and i do n't wan na get a stack of these . i wan na just be able to go to go to the web site { comment } and visit it as i want . professor e: going to a web site is easy , but flipping through a hundred pounds a hundred pages of stuff is not easy on the web . grad c: well , i do n't think it 's that much harder than , paper . so . professor e: really ? postdoc f: i have one question . so are you thinking that um the person would have a transcript and go strictly from the transcript ? because i i do think that there 's a benefit to being able to hear the tone of voice and the professor e: so here 's the way i was imagining it , and maybe i 'm wrong , postdoc f: yeah . professor e: but the way i imagined it was that um , the largest set of people is gon na go `` oh yeah , i did n't say anything funny in that meeting just go ahead , where 's the where 's the release ? `` and then there 'll be a subset of people , right ? ok there 's i mean think of who it is we 've been recording mostly . phd a: yeah . professor e: ok there 'll be a subset of people , who um , will say uh `` well , yeah , i really would like to see that . `` and for them , the easiest way to flip through , if it 's a really large document , i mean unless you 're searching . searching , of course , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something or something like that , phd a: yeah . professor e: but see then we 're getting more elaborate with this thing . um if if uh you do n't have search mechanisms you just sort of have this really , really long document , i mean whenever i 've had a really , really long document that it was sitting on the web , i 've always ended up printing it out . i mean , so it 's it 's i mean , you you 're you 're not necessarily gon na be sitting at the desk all the time , you wan na figure you have a train ride , and there 's all these situations where where i i mean , this is how i was imagining it , anyway . and then i figured , that out of that group , there would be a subset who would go `` hmm you know i 'm really not sure about this section here , `` and then that group would need it s it seems like i if i 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that uh , now we have to worry about privacy , grad c: well , no fre for the most professor e: we have to worry about all these passwords , for different people grad c: for the most frequent case they just say `` it 's ok `` and then they 're done . and i think almost everyone would rather do that by email than any other method . professor e: mm - hmm . postdoc f: the other thing too is it seems like professor e: um , yeah , that 's true . postdoc f: go ahead . grad c: i mean , cuz you do n't have to visit the web page if you do n't want to . phd a: yeah . professor e: i guess yeah , i guess we do n't need their signature . i guess an email ok is alright . grad c: oh that was another thing i i had assumed that we did n't need their signature , that it that an email approval was sufficient . but i do n't actually know . phd b: are are people going to be allowed to bleep out sections of a meeting where they were n't speaking ? grad c: yes . if someone feels strongly enough about it , then i i i think they should be allowed to do that . postdoc f: i also mm - hmm . phd b: so that means other people are editing what you say ? professor e: uh i do n't know about that . grad c: yeah . phd b: i do n't know if i like that . grad c: well , the only other choice is that the person would say `` no , do n't distribute this meeting at all `` , and i would rather they were able to edit out other people then just say `` do n't distribute it at all `` . professor e: but th what they signed in the consent form , was something that said you can use my voice . grad c: well , but if if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient . professor e: right ? yeah . yeah , but that 's our decision then . right ? grad c: um , i do n't think so . i mean , because if i object to the conversation . professor e: i think it is . grad c: if i say `` we were having a conversation , and i consider that conversation private , `` and i consider that your side of it is enough for other people to infer , i wan na be able to bleep out your side . postdoc f: the i agree that the consent forms were uh , i cons agree with what adam 's saying , that um , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or did n't say them . professor e: i see . ok , well , if that 's what it said . postdoc f: and the other thing is from the standpoint of the l of the l i 'm not a law lawyer , but it strikes me that uh , we would n't want someone to say `` oh yes , i was a little concerned about it but it was too hard to access `` . so i think it 's kind of nice to have this facility to listen to it . now in terms of like editing it by hand , i mean i think it 's i some people would find that easier to specify the bleep part by having a document they edited . but but it seems to me that sometimes um , you know i if a person had a bad day , and they had a tone in their voice that they did n't really like , you know it 's nice it 's nice to be able to listen to it and be sure that that was ok . grad c: i mean i can certainly provide a printable version if people want it . um . professor e: um i mean it 's also a mixture of people , i mean some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not . grad c: yep . professor e: others would consider it this uh a a set of skills that they would have to gain . you know ? grad c: well i think most of the people in the meetings are the former . professor e: it depends on what meetings . postdoc f: that 's true . phd b: so far . grad c: so . professor e: in the meetings so far , yeah . grad c: yep . professor e: but we 're trying to expand this , right ? grad c: right . professor e: so i i i actually think that paper is the more universal thing . grad c: and that well , but if they want to print it out that 's alright . postdoc f: mm - hmm . yeah . grad c: i think everyone in the meeting can access the web . professor e: no , i think we have to be able to print it out . it 's not just if they want to print it out . i i think grad c: ok , so does that mean that i ca n't use email ? or what ? postdoc f: cuz you could send it through email you 're thinking . professor e: i i th grad c: well , i do n't think i professor e: well we there was this grad c: well i do n't think we can send the text through email because of the privacy issues . professor e: no . postdoc f: good . for security ? phd a: yeah . postdoc f: yeah , ok good . professor e: right . grad c: um . so giving them , you think a web site to say , `` if you wan na print it out here it is `` , is not sufficient ? postdoc f: good point . phd a: yeah . i professor e: certainly for everybody who 's been in the meetings so far it would be sufficient . grad c: yeah , i 'm just thinking for people that that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them . professor e: i 'm just wondering about postdoc f: you could mail it to them . phd a: yeah . postdoc f: get an a mailing address . grad c: equivalent . phd a: but postdoc f: but i think it 's easier to drop in the box . phd a: just put the button on on the web page which say `` please send me the the scripts `` . grad c: that 's right . postdoc f: oh that 's interesting . phd a: yeah . phd b: what um when you display it on the web page , what are what are you showing them ? utterances , or ? grad c: mm - hmm . phd b: and so can they bleep within an utterance ? grad c: no . whole utterances only . phd b: whole utterances . grad c: and that was just convenience for my sake , that it 's uh , uh it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way i can just delete an entire line out of a transcript file rather than have to do it by hand . professor e: there 's another aspect to this which maybe is part of why this is bothering me . um , i think you 're really trying very hard to make this as convenient as possible for people to do this . phd b: mmm . grad c: i mean that 's why i did the web form , because for me that would be my most convenient . professor e: i i i understand . phd b: i know where you 're going . professor e: i think that 's the bad idea . grad c: oh . professor e: see because you 're gon you 're uh really . you 're gon na end up with all these little patchy things , whereas really what we want to do is have the the the bias towards letting it go . because nob you know it there was a one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gon na get hurt . nobody 's being l libeled . you know , this is this we 're we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gon na end up encouraging a headache . that i think that 's i 'm sort of psyching myself out here , i i 'm trying to uh grad c: i guess i do n't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out . professor e: but i i think that 's well , it 's grad c: so . phd b: i think what morgan 's saying is the easier it is , the more is gon na be bleeped . professor e: but i and and it really depends on what kind of research you 're doing . i think some researchers who are gon na be working with this corpus years from now are really gon na be cursing the fact that there 's a bunch of stuff in there { comment } that 's missing from the dialogue . grad c: mm - hmm . professor e: you know , it depends on the kind of research they 're doing , phd a: yeah . professor e: but it might be , uh it might be really a a pain . and , you know where it 's really gon na hurt somebody , in some way the one who said it or someone who is being spoken about , { comment } we definitely want to allow the option of it being bleeped out . but i really think we wan na make it the rare incidence . and and uh , i am just a little worried about making it so easy for people to do , and so much fun ! that they 're gon na go through and bleep out stuff . postdoc f: so much fun . professor e: and they can bleep out stuff they do n't like too , right from somebody else , as you say , you know , so `` well i did n't like what he said . `` grad c: well i do n't see any way of avoiding that . i mean , we have to provi we have promised that we would provide them the transcript and that they can remove parts that they do n't like . so that the professor e: yeah . no , no , i i i do n't grad c: the only question is professor e: you - you 've talked me into that , but i i just think that we should make it harder to do . grad c: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , i just get email , it 's all formatted , it 's all ready to go and i can just insert it . professor e: so maybe you do n't give them access to the web interface unless they really need it . so so so postdoc f: well i guess yeah . professor e: i 'm sorry so so so maybe this is a s a way out of it . postdoc f: hmm . professor e: you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but i think the issue of privacy and ease and so forth should be that uh , they get access to this if they really need it . grad c: well phd b: so you 're saying the the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . professor e: right . phd b: and then if they do n't , you 're done . if they do , then he provides them access to the the web site . grad c: well , to some extent i have to do that anyway because as i said we have to distribute passwords . professor e: w w phd b: or a printed - out form . professor e: there 's there grad c: so , professor e: y but you do n't necessarily have to distribute passwords is what i 'm saying . grad c: well , but professor e: so phd b: only if they want it . grad c: what i 'm saying is that i ca n't just email them the password because that 's not secure . so they have to call me and ask . professor e: no , no , no . but you are n't necessarily giving them right . but we do n't even necessarily need to end up distributing passwords at all . phd a:  grad c: well , we do because of privacy . we ca n't just make it openly available on the web . professor e: no , no . you 're missing the point . postdoc f: mm - hmm . professor e: we 're we 're trying i we 're trying to make it less of an obvious just l l l l uh fall off a log , to do this . postdoc f: not everyone gets a password , unless they ask for it . professor e: right ? so th so what i would see , is that first you contact them and ask them if they would like to review it for to check for the postdoc f: yeah . professor e: not just for fun , ok ? but to to check this for uh things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . um and , uh , and we should think carefully actually we should review go through how that 's worded , ok ? then , if someone uh wants to review it , uh , and i know you do n't like this , but i 'm offering this as a suggestion , is that is that we then give them a print out . and then if they say that `` i have a potential problem with these things , `` then , you you say `` ok well you might wan na hear this in context to s think if you need that , `` you issue them a password , i in the grad c: but the the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . i would much prefer to have all be automatic , they visit the web site if they want to . obviously they do n't have to . professor e: i know you 'd prefer it , but the proble grad c: yeah . professor e: we have grad c: so i think you 're thinking people are going to arbitrarily start bleeping and i just do n't think that 's gon na happen . professor e: there 's a problem with it . postdoc f: i 'm also concerned about the spirit of the of the informed consent thing . cuz i think if they feel that uh , it 's i th i th you know , if it turns out that something gets published in this corpus that someone really should have eliminated and did n't detect , then it could have been because of their own negligence that they did n't pursue that next level and get the password and do that , um , but but they might be able to argue `` oh well it was cumbersome , and i was busy and it was gon na take me too much time to trace it down `` . so it could that the burden would come back onto us . so i 'm a little bit worried about uh , making it harder for them , from the legal standpoint . professor e: well you can go too far in that direction , and you need to find somewhere between i think , postdoc f: yeah . grad c: it seems to me that sending them email , saying `` if you have an o - ok reply to this email and say ok , professor e: because uh - huh . grad c: if you have a problem with it contact me and i 'll give you a password `` , seems like is a perfectly , reasonable compromise . and if they want a printout they can print it out themselves . postdoc f: or we could print it up for them , phd a: yeah . postdoc f: i mean we could offer that but but there 's uh , another aspect to that and that is that in the informed consent form , um , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . and and i ha professor e: yeah . postdoc f: i do n't know that there 's a chance of really skipping that stage . i mean i i thought that you were maybe i misinterpreted what you said but it 's professor e: having access to it does n't necessarily mean , that having it grad c: having it . postdoc f: giving it to them . grad c: well the in professor e: right ? it just means they have the right to have it . postdoc f: ok . grad c: the consent form is right in there if anyone wants to look at it , postdoc f: alright . fine . ok . fair enough . grad c: so . professor e: yeah . grad c: d you want me to grab one ? postdoc f: sh - sh well i could i 'm closer . grad c: yeah , but you 're wired postdoc f: i could grad c: are n't you ? postdoc f: yeah . that is true . professor e: um . yeah , i mean i do n't wan na fool them , postdoc f: i do n't know professor e: i just meant that e every ev any time you say anything to anyone there is in fact a a bias that is presented , postdoc f: oh yeah yeah oh i know . professor e: right ? grad c: `` if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` professor e: of and postdoc f: yeah that 's true . yeah . grad c: `` once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . professor e: yeah . grad c: there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . `` postdoc f: hmm . well that 's more open than i realized . grad c: well , i mean it the one question is definitely clear with anything as opposed to just what you said . professor e: i phd a: yeah . professor e: yeah , uh no that it tha postdoc f: tha - that 's true . that 's more severe , but the next one says the transcript will be around . professor e: that 's right . postdoc f: and it does n't { comment } really say we 'll send it to you , or wi it 'll be available for you on the web , or anything . phd b: i think it probably leaves it open how we get it to them . professor e: i i postdoc f: at least it more often . yeah . it means also we do n't have to g to give it to them . i mean like like morgan was saying they they grad c: they just have to make sure that it is available to them . postdoc f: it 's available to them if they ask for it . professor e: yeah , ok , so . wh um i think i have an idea that may be sat may satisfy both you and me in this which is , um , it 's a it we just go over carefully how these notes to people are worded . so i i just want it to be worded in such a way where it gives the strong impre it gives very , i mean nothing hidden , v very strongly the bias that we would really like to use all of these data . grad c: right . professor e: that that we really would rather it was n't a patchwork of things tossed out , postdoc f: good . professor e: that it would be better for , um , our , uh , field if that is the case . but if you really think something is gon na and i do n't think there 's anything in the legal aspects that that is hurt by our expressing that bias . postdoc f: great . great , great . professor e: and then then my concern about which postdoc f: yeah . i agree . professor e: you know you might be right , it may be it was just paranoia on my part , uh but people just see i 'm @ @ worried about this interface so much fun that people start bleeping stuff out { comment } just as just because they can . grad c: it 's just a check box next to the text , it 's not any fun at all . professor e: yeah . well i do n't know . i kind of had fun when you played me something that was bleeped out . you know . grad c: well , but they wo n't get that feedback . professor e: i grad c: all no because it does n't automatically bleep it at the time . professor e: oh they wo n't ? grad c: it just sends me professor e: oh good . so you have n't made it so much fun . grad c: right . professor e: oh good . grad c: it just sends me the time intervals . professor e: ok , grad c: and then at some point i 'll incorporate them all and put bleeps . i mean i do n't wan na have t ha do that yet until we actually release the data professor e: yeah . grad c: because um , then we have to have two copies of every meeting and we 're already short on disk space . professor e: yeah . grad c: so i i wan na i just keep the times until we actually wan na release the data and then we bleep it . professor e: ok . alright , so i think yeah so if we have if i again let 's you know , sort of circulate the the wording on each of these things and get it right , grad c: well since you seem to feel heart uh , strongest about it , would you like to do the first pass ? professor e: but but ok . uh , fair enough . turn about is fair play , postdoc f: al - also it ther there is this other question , the legal question that that adam 's raised , uh about whether we need a concrete signature , or email c i suffices or whatever professor e: sorry . grad c: yeah . postdoc f: and i do n't know how that works . i there 's something down there about `` if you agree to `` professor e: i 'm i 'm i 'm i thought i i thought about it with one of my background processes grad c: i do n't think so . professor e: and i uh it 's uh it 's uh , it 's fine to do the email . postdoc f: ah . fine . grad c: yeah because thi th they 're signing here that they 're agreeing to the paragraph which says `` you 'll be given an opportunity . `` professor e: ok . postdoc f: good . ok . professor e: yeah . grad c: and so i do n't think they need another signature . professor e: and well and furthermore i it 's now fairly routine in a lot of arrangements that i do with people on contracts and so forth that that uh if it 's if it 's that sort of thing where you 're you 're saying uh `` ok i agree , we want eighty hours of this person at such - and - such amount , and i agree that 's ok , `` uh if it 's a follow up to some other agreement where there was a signature it 's often done in email now grad c: right . professor e: so it 's it 's ok . postdoc f: great . professor e: um . grad c: so i guess i probably should at the minimum , think about how to present it in a printed form . i 'm not really sure what 's best with that . the problem is a lot of them are really short , postdoc f: well grad c: and so i do n't necessarily wan na do one per line . but i do n't know how else to do it . postdoc f: well i s i also have this i i think it 's nice you have it uh , viewab her { comment } hearable on the on the web for those who might wonder about um , the non nonverbal side , i mean i i agree that our bias should be as as expressed here , and but i i think it 's nice that a person could check . cuz sometimes you know you the words on a on the page , come out soun sounding different in terms of the social dynamics if they hear it . grad c: hmm . professor e: mm - hmm . mm - hmm . postdoc f: and i realize we should n't emphasize that people { comment } you know , should n't borrow trouble . what it comes down to but grad c: yeah i think actually my opinion probably is that the only time someone will need to listen to it is if the transcript is uh not good . you know , if if there are lots of mumbles and parentheses and things like that . postdoc f: oh , you know , or what if there was an error in the transcript that did n't get detected and there was a whole uh i segment a against some personal i th grad c: right . that was all mumbled ? phd a: yeah . grad c: i think microsoft is postdoc f: yeah exactly phd a: oh , grad c: sorry transcribers . postdoc f: or or even or even { comment } there was a a line you know about how `` hmm - mmm - mmm { comment } bill gates duh - duh - duh - duh . `` professor e: yeah . postdoc f: but but it was all the words were all visible , but they did n't end up i some there was a slip in the transcript . phd a: oh , god . grad c: they 're gon na hate this meeting . phd a: yeah . postdoc f: yeah that 's true . grad c: actually liz will like it . you know , but . professor e: liz will like it . we had a pretty strong disagreement going there . grad c: yep , yep , that 's right . professor e: yeah . postdoc f: yeah . so i do n't know . i mean , i i guess we 're assuming that the transcript is a close enough approximation and that that my double checking will be so close to absolutely perfect that it that nothing will slip by . grad c: mm - hmm . professor e: but it the some something might sometime , and they uh if if it 's something that they said , they might i i i mean , you might be very accurate in putting down what they actually said , postdoc f: mm - hmm . professor e: but , when they hear it , themselves , they may hear something different because they know what they meant . postdoc f: i do n't know how to notate that . phd b: sarcasm , postdoc f: yeah , that 's right . phd b: how do you how do you indicate sarcasm ? postdoc f: yeah that 's right . professor e: no , i 'm serious . so the so i the so we might we might get some feedback from people that such - and - such was , you know , not not really what i said . grad c: yeah . well that would be good to get , definitely . professor e: yeah , but , yeah , sure . grad c: just for corrections . professor e: yeah . grad c: so um , in terms of password distribution , i think phone is really the only way to do it , phone and in person . or mail , physical mail . postdoc f: yeah . or if for leave it on their voice mail . phd b: any sub - word level thing . grad c: any sub - wor yeah , ok . i mean you could do it with pgp or things like that but it 's too complex . postdoc f: you know i just realized something , which is of e th this question about the uh the possible mismatch of i mean i well , and actually also the lawyer saying that um , we should n't really have them have the people believing that they will be cleared by our checks . you know ? professor e: mm - hmm . postdoc f: i mean . so it 's like i in a way it 's it 's nice to have the responsibility still on them to listen to the tape and and hear the transcript , to have that be the professor e: well yeah , but you ca n't dep i mean , most people will not wan na take the time to do that , though . postdoc f: yeah , ok , fair enough . and they 're s they 're absorbing the responsibility themselves . professor e: and they they have to postdoc f: so it 's not it 's not um yeah , good . professor e: but i mean if you were at a meeting , and and you you do n't think , at least , that you said anything funny and the meeting was about , you know , some some funny thing about semantics or something , or uh grad c: you probably wo n't listen to it . professor e: yeah . postdoc f: it is true that tec that the content is technical , i and so i and we 're not having these discussions which professor e: yeah . postdoc f: i i mean , when i listen to these things , i do n't find things that are questionable , in other people 's speech or in my own . professor e: yeah . you would think it would be rare , postdoc f: just it should be very rare . professor e: i mean we 're not talking about the energy crisis or something , people have postdoc f: yeah . yeah , ok . grad c: how about them energy crises . professor e: yeah . i think we 're uh grad c: done ? professor e: kind of done . actually , i was gon na di - did you have anything n that 's going on , or grad d: not really . no . um , my project is going along but um , i 'm really just here to um fill the project uh the overall progress . i do n't really have anything specific to to talk about . professor e: yeah . that 's fine . i just did n't wan na go by you , if you had something . grad d: oh , ok . professor e: you do n't have anything to say . phd b: no . professor e: nah . grad c:  professor e: transcribers , he was rattling the b marbles in his brain back and forth just then this this grad c: shall we do digits ? professor e: oh yeah . grad c: um , oh by the way i did find a bunch grad d: it um grad c: uh , we should count out how many more digits to forms do we have back there ? phd b: there were quite a few . uh . grad c: that 's what i thought . i f i was going through them all and i found actually a lot filed in with them , that were blanks , that no one had actually read . phd b: mmm . grad c: and so we still have more than i thought we did . phd b: oh good . grad c: so , we have a few more digits before we 're done . phd b: you know having this headset reminds me of like working at burger king or something . grad c: oops . postdoc f: oh , did you do that ? phd a: burger king grad c: i 'd like a burger with that , phd b: no i never did . grad c: do you want fries with that ? professor e: wow . phd b: but i feel like i could now . grad c: and { pause }","output":"the group discussed recording equipment issues , including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use . speaker fe008 presented the current status on transcriptions , and explained procedures for cleaning up transcripts and ensuring they conform with set conventions . speaker mn014 briefly described his efforts to normalize loudness levels across speech channels to distinguish between foreground and background speech . finally , the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out ' any sections of speech they want excluded from the meeting recorder database ."},{"instruction":"what was said about the equipment ?","input":"professor e: alright . grad c: so are you professor e: so . grad c: are we going ? professor e: it is uh , must be february fifteenth . postdoc f: yeah . grad c: yu i think the date 's written in there , yep . and actually if everyone could cross out the r - nine next to `` session `` , and write mr eleven . professor e: yeah . yeah . we did n't have a front - end meeting today . grad c: and let 's remember also to make sure that one 's { comment } gets marked as unread , unused . professor e: ok . phd a: mr eleven . grad c: mr eleven . postdoc f: that sounds like a spy code . professor e: mmm . ok . so . grad c: there 's lots of clicking i 'm sure as i 'm trying to get this to work correctly . professor e: agenda . any agenda items today ? grad c: i wan na talk a little bit about getting how we 're gon na to get people to edit bleeps , parts of the meeting that they do n't want to include . what i 've done so far , and i wan na get some opinions on , how to how to finish it up . professor e: ok . postdoc f: i wan na ask about um , some aud audio monitoring on some of the um well some of the equipment . in particular , the well uh , that 's just what i wan na ask . professor e: ok audio monitoring , jane . postdoc f: ba - based on some of the tran uh i in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact in fact this one i 'm talking on is one of of the ones that showed up in one of the meetings , grad c: oh really . postdoc f: so i phd b: `` spikes `` , you mean like uh , instantaneous click type spikes , or ? postdoc f: mm - hmm . yeah . phd a: spikes ? grad c: clicks . postdoc f: yeah . professor e: hmm . postdoc f: yeah . phd b: huh . postdoc f: and i do n't know what the e electronics is but . grad c: yeah . postdoc f: yeah . grad c: well , i think it 's phd a: touching . grad c: uh , it it could be a number of things . phd a: yeah . grad c: it could be touching and fiddling , and the other thing is that it could the fact that it 's on a wired mike is suspicious . it might be a connector . postdoc f: oh , ok . well maybe then we do n't really have to talk about that as an phd b: you could try an experiment and say `` ok , i 'm about to test for spikes `` , postdoc f: i i take that off the agenda . phd b: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . grad c: yeah . right . phd b: `` come get me when you transcribe this and see if there 's spikes . `` postdoc f: oh that professor e: um . postdoc f: well , ok . phd b: no i 'm just professor e: i mean , were this a professional audio recording , what we would do { comment } what you would do is in testing it is , you would actually do all this wiggling and make sure that that that things are not giving that kind of performance . and if they are , then they ca n't be used . grad c: right . professor e: so . um . let 's see . i guess i would like to have a discussion about you know where we are on uh , recording , transcription you know , basically you know where we are on the corpus . postdoc f: good . professor e: and then um , the other thing which i would like to talk about which is a real meta - quest , i think , deal is , uh , agendas . so maybe i 'll i 'll start with that actually . uh , um . andreas brought up the fact that he would kinda like to know , if possible , what we were gon na be talking about because he 's sort of peripherally involved to this point , and if there 's gon na be a topic about discussion about something that he uh strongly cares about then he would come and and i think part of part of his motivation with this is that he 's trying to help us out , in the because of uh the fact that the meetings are are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing grad c: mmm . professor e: and and i 'm sure help out his own time . by not showing up if it 's a meeting that he 's he 's so , uh in order i 'd i think that this is a wish on his part . uh . it 's actually gon na be hard because it seems like a lot of times uh things come up that are unanticipated and and grad c: right . professor e: but um , we could try anyway , uh , do another try at coming up with the agenda uh , at some point before the meeting , uh , say the day before . grad c: well maybe it would be a good idea for one of us to like on wednesday , or tuesday send out a reminder for people to send in agenda items . phd a: yeah . professor e: ok . you you wan na volunteer to do that ? grad c: sure . professor e: ok . alright so we 'll send out agenda request . grad c: let me professor e: uh . phd b: that 'll be i think that 'll help grad c: i 'll put that on my spare brain or it will not get done . phd b: that 'll help a lot , actually . professor e: yeah , i have to tell you for the uh for the admin meeting that we have , lila does that um every time before an admin meeting . and uh , she ends up getting the agenda requests uh , uh ten minutes before the meeting . but but { comment } but . uh . { comment } but we can try . maybe it 'll work . phd b: mmm . grad c: yeah . maybe . weirder things have happened . professor e: yeah . postdoc f: i 'm wondering if he were to just , uh , specify particular topics , i mean . maybe we 'd be able to meet that request of his a little more . phd b: i would i would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him . grad c: well then professor e: yeah . actually it this this maybe brings up another topic which is um so we 're done with that topic . the other topic i was thinking of was the sta status on microphones and channels , and all that . grad c: yeah , actually i i was going to say we need to talk about that too . professor e: yeah . why why do n't we do that . grad c: ok . um , the new microphones , the two new ones are in . um . and they are being assembled as we speak , i hope . and i did n't bring my car today so i 'm gon na pick them up tomorrow . um , and then the other question i was thinking about is well , a couple things . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , phd a:  grad c: and get people 's opinions on on what they think of them . um , then the other question i had is maybe we should get another wireless . another wireless setup . i mean it 's expensive , but it does seem to be better than the wired . professor e: so how many channels do you get to have in a wireless setup ? grad c: um , well , i 'm pretty sure that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and apparently you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . professor e: so , um . grad c: and so , you know it 's still , it 's fifteen minus six . professor e: so let 's see we grad c: right ? so we could have up to nine . professor e: and right now we can have up to six . grad c: right . and we have five , we 're getting one more . professor e: yeah . grad c: and it 's um , about nine hundred dollars for the base station , and then eight hundred per channel . professor e: oh . so yeah so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . grad c: right . professor e: oh , we should do it . grad c: ok . ok , so i 'll look into how you daisy - chain them and and then just go ahead and order them . professor e: yeah . yeah . phd b: i do n't quite understand how that how that works , . if so we 're not increasing the number of channels . ok . grad c: no , we 're just replacing the wired the two wired that are still working , phd b: ok . i see . grad c: along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless . professor e: yeah . phd b: three wireds work , professor e: basically we found phd b: right ? grad c: i i guess three wireds work , yeah . phd b: yeah . yeah . professor e: yeah . but we 've had more problems with that . grad c: yep . professor e: and that sort of bypasses the whole the whole jimbox thing and all that . grad c: right . professor e: and so um , we we seem to have uh , a reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . grad c: right . professor e: that seems to be the key issue . grad c: everyone 's battery ok ? phd b: i checked them this morning , they should be . grad c: ok . professor e: yeah . um , that 's the only thing with them . but the quality seems really good and um i heard from uw that they 're they 're uh very close to getting their , uh setup purchased . they 're they 're they 're buying something that you can just sort of buy off the shelf . grad c: well we should talk to them about it because i know that sri is also in the process of looking at stuff , and so , you know , what we should try to keep everyone on the same page with that . professor e: yeah . phd b: sri , really ? grad c: yeah . phd b: oh . grad c: they got sa apparent well , maybe this needs to be bleeped out ? i have no clue . professor e: uh , i do n't know . grad c: i do n't know how much of it 's public . professor e: probably we should n't probably we should n't talk about funding stuff . grad c: right . professor e: yeah . but anyway there 's there 's there 's uh , uh other activities that are going on there and and uh and nist and uw . so . um . but but yeah i thin i think that at least the message we can tell other people is that our experience is is quite positive with the sony , grad c: right . professor e: uh , radio - mikes . now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering or something , right ? grad c: uh , no , we 're having the them do it . professor e: no ? grad c: so it 's so hand - soldering it , but i 'm not doing it . professor e: oh . grad c: so , they they charge professor e: ok . nothing against you and your hand - soldering grad c: right . professor e: but grad c: you 've never seen my hand - soldering . but uh , a as i said they 're coming in . professor e: uh , ok , so that 's being done professionally and grad c: i i mean professor e: yeah . grad c: yeah . i mean . professor e: yeah . grad c: as professionally as i guess you can get it done . professor e: well , it could if they do a lot of it , it 's grad c: i mean i it 's just their repair shop . right ? their maintenance people . professor e: well , we 'll see what it it 's like . grad c: yep . professor e: that tha that can be quite good . th - this yeah , ok . good . yeah . so let 's go with that . grad c: and , i mean we 'll see , tomorrow , you know , what it looks like . professor e: uh , yeah . so , um , uh , dave is n't here but he was going to start working on some things with the digits . uh , so he 'll be interested in what 's going on with that . i guess was the decision last time was that the the uh transcribers were going to be doing stuff with the digits as well ? has that started , or is that ? postdoc f: mm - hmm . yeah . uh , it would be to use his interface and i was going to meet with him today about that . grad c: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so i did the all that last week . so all the all the forms are now on the computer . and uh , then i have a bunch of scripts that we 'll read those and let the uh transcribers use different tools . and i just want to talk to jane about how we transition to using those . postdoc f: mm - hmm . so he has a nice set up that they it w it will be efficient for them to do that . professor e: ok . grad c: i i do n't think it 'll take too long . professor e: so anyway grad c: so , you know , just uh , a matter of a few days i suspect . professor e: so anyway i think we we have at least one uh , user for the digits once they get done , which will be dave . grad c: right . i 've already done five or six sets . postdoc f: ok . grad c: so if he wanted to , you know , just have a few to start with , he could . you know , and i also have a bunch of scripts that will , like , generate p - files and run recognition on them also . professor e: yeah , he might he might be asking right . ok . uh , is dave i do n't know if dave is on the list , if he 's invited to these meetings , uh if he knows . postdoc f: i do n't tend to get an invitation myself for them even . phd a: no , no . grad c: uh , we do n't have a active one but i 'll make sure he 's on the list . postdoc f: yeah . should we call him ? i mean is he d is he definitely not available today ? professor e: i do n't know . postdoc f: should i call his office and see ? phd a: he was in . grad c: i mean , he 's still taking classes , so uh , he may well have conflicts . professor e: uh , well i it 's uh phd a: yeah . professor e: yeah . phd a: yeah , he was in s postdoc f: he was n't there at cof professor e: yeah , so this might be a conflict for him . phd a: yeah . professor e: yeah . postdoc f: ok . professor e: ok . uh , so . grad c: yeah did n't he say his signal - processing class was like tuesdays and thursdays ? phd a: i think he has a class . yeah . phd b: yeah . he might have . grad c: oh well , whatever . grad d: you talking about david gelbart ? professor e: oh , ok . phd a: yeah . phd b: yeah . grad c: yeah . professor e: yeah . postdoc f: yes . grad d: yeah , i think he 's taking two twenty - five a which is now . phd b: yeah . grad d: so . professor e: yeah . postdoc f: ok . professor e: ok . so , that 's why we 're not seeing him . ok . uh , transcriptions , uh , beyond the digits , where we are , and so on . postdoc f: ok . professor e: and the and the recordings also , postdoc f: um professor e: just where we are . yeah . postdoc f: well , so um , should we we do n't wan wan na do the recording status first , or ? grad c: well , we have about thirty - two hours uh as of , i guess a week and a half ago , so we probably now have about thirty - five hours . professor e: and and that 's that 's uh how much of that is digits ? it 's uh that 's including digits , grad c: that 's including digits . professor e: right ? grad c: i have n't separated it out so i have no clue how much of that is digits . professor e: so yeah . so anyway there 's at least probably thirty hours , or something of there 's got to be more than thirty hour phd a: mmm . grad c: of of non - digits ? professor e: i it could n't of of non - digits . grad c: yeah , absolutely . i mean , the digits do n't take up that much time . professor e: yeah , yeah . ok . postdoc f: ok , and the transcribers h i , uh , do n't have the exact numbers , but i think it would come to about eleven hours that are finished uh , transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what i mean by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that uh , liz requested in terms of um , um in terms of having a s a systematic handling of numbers , and acronyms which i had n't been specific about . um , for example , i they 'll say uh `` ninety - two `` . and you know , so how you could grad c: nine two , postdoc f: e exactly . grad c: right . postdoc f: so if you just say `` nine two `` , the there are many s ways that could have been expressed . an - and i just had them i i mean , a certain number of them did put the words down , but now we have a convention which also involves having it followed by , um , a gloss th and things . phd b: you know , jane ? grad c: mm - hmm . phd b: um , one suggestion and you may already be doing this , but i 've noticed in the past that when i 've gone through transcriptions and you know in in order to build lexicons and things , if you um , just take all the transcriptions and separate them into words and then alphabetize them , { comment } a lot of times just scanning down that list you 'll find a lot of inconsistencies and mis grad c: misspelled . phd a: yeah . postdoc f: you 're talking about the type token frequency listings , and i use those too . y you mean just uh on each on each line there 's a one word right ? it 's one token from the from the corpus . phd b: mm - hmm . mm - hmm . postdoc f: yeah , those are e extremely efficient and i and i i agree that 's a very good use of it . phd b: oh so you already have that , ok . postdoc f: well that 's that 's a way that 's you know , the spell - check basically does that but but in addition yes , that 's that 's exactly the strategy i wan na do in terms of locating these things which are you know colloquial spoken forms which are n't in the lexicon . phd b: mm - hmm . cuz a lot of times they 'll appear next to each other , and uh , postdoc f: exactly . and then you ca then you can do a s phd a: yeah . phd b: i in alphabetized lists , they 'll appear next to each other and and so it makes it easier . postdoc f: absolutely . i agree . that 's a very good that 's a very good uh , suggestion . and that was that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . i did n't get to that point but so there are numbers , then there are acronyms , and then um , there 's a he she wants the uh , actually a an explicit marker of what type of comment this is , so i curly b inside the curly brackets i 'm gon na put either `` voc `` for vocalized , like cough or like laugh or whatever , `` nonvoc `` for door - slam , and `` gloss `` for things that have to do with if they said a s a spoken form with this m this pronunciation error . grad c: right . postdoc f: i already had that convention phd b: oh that 's great . postdoc f: but i i have n't been asking these people to do it systematically cuz i think it most ha most efficiently handled by uh by a a filter . that was what i was always planing on . so that , you know you get a whole long list exactly what you 're saying , you get a whole list of things that say `` curly bracket laugh curly bracket `` , phd b: mm - hmm . postdoc f: then y you know it 's it 's you you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in sort of a voc space , phd b: yeah . postdoc f: so man so many ways that error prone . phd b: right . right . postdoc f: so , um , um i 'm i 'm going to convert that via a filter , into these tagged uh , subcategorized comments , and same thing with you know , we see you get a subset when you do what you 're saying , phd b: mm - hmm . postdoc f: you end up with a s with uh , you 're collapsing across a frequency you just have the tokens phd b: mm - hmm . postdoc f: and you can um , have a filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , you know i mean , jus grad c: you do n't know what they could be . phd b: yeah . postdoc f: yeah now timit 's clear um and plp is clear but uh there are things that are not so well known , in or or have variant u u uses like the numbers you can say `` nine two `` or you can say `` ninety - two `` , grad c: so how are you doing the postdoc f: and uh i 'd handle the numbers individually . grad c: how are you doing the uh , acronyms so if i say pzm what would it appear on the transcript ? postdoc f: it would be separate the letters would be separated in space grad c: ok . postdoc f: and potentially they 'll have a curly bracket thing afterwards e but i 'm not sure if that 's necessary , clarifying what it is , grad c: mm - hmm . postdoc f: so gloss of whatever . grad c: right . postdoc f: i do n't know if that 's really necessary to do that . maybe it 's a nice thing to do because of it then indicating this is uh , a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's uh the you know , { comment } uh enumerated , or i grad c: mm - hmm . postdoc f: it 's not a good way of saying but it 's it 's the specific uh way of stating these these letters . grad c: right . so it sounds good . postdoc f: and so anyway , the clean those are those things and then channelized is to then um , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . phd a: yeah . grad c: right . postdoc f: and uh , thilo had a e e a breakthrough with this this last week in terms of getting the channel - based um uh s s speech - nonspeech segmentation um , up and running and i have n't i have n't been able to use that yet cuz i 'm working s re this is my top priority get the data clean , and channelized . phd a: i actually gave grad c: have you also been doing spot checks , jane ? postdoc f: oh yes . grad c: okay , good . postdoc f: well you see that 's part of the cleaning process . i spent um actually um i have a segment of ten minutes that was transcribed by two of our transcribers , grad c: oh good . good . postdoc f: and i went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas i i left them discretion at commas . grad c: right . postdoc f: uh and so because it 's not part of our st of our ne needed conventions . professor e: mm - hmm . postdoc f: and um , and so they 'll be a difference in commas , but it 's word - by - word the same , in in huge patches of the data . and i have t ten minute stretch where i can where i can show that . and and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . so um , the one i i the colloquial speech person picked up `` gobbledy - gook `` . phd b: hmm . postdoc f: and the other one did n't . and on this side , this one 's picking up things like `` neural nets `` and the one that 's good on the sp o on th the vocabulary on the uh colloquial did n't . grad c: right . phd b: when for the person who missed `` gobbledy - gook `` what did they put ? postdoc f: it was an interesting approximation , put in parentheses , cuz i have this convention that , i if they 're not sure what it was , they put it in parentheses . phd b: oh . postdoc f: so they tried to approximate it , but it was phd b: oh good . postdoc f: it was spelled gabbl phd b: sort of how it sounds . yeah . postdoc f: yes . more of an attempt to i mean apparently it was very clear to her that these the a this this was a sound these are the sounds , grad c: it was a technical term that she did n't recognize , phd b: yeah . postdoc f: but yeah . but she knew that she did n't know it . maybe it was a technical ter exactly . but she even though her technical perception is just really uh you know i 've i 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses grad c: right . postdoc f: then cuz `` neural nets `` and oh she has some things that are oh `` downsampled `` , she got that right . phd b: hmm . postdoc f: and some of these are rather uh unexpected . grad c: obscure , yeah . postdoc f: but ch ten solid uh m ch s chunk of ten solid minutes where they both coded the same data . professor e: and and again the main track that you 're working with is elev eleven hours ? postdoc f: and um professor e: is that right ? postdoc f: yes exactly . professor e: yeah , ok . postdoc f: and that 's part of this eleven hours . professor e: is that is that that including digits ? yeah . postdoc f: yes it is . professor e: so let 's say roughly ten hours or so of postdoc f: mm - hmm . professor e: i mean it 's probably more than that but but with of of non - digits . phd a: yeah . postdoc f: it 'd be more than that because i my recollection is the minutes that da digits do n't take more than half a minute . per person . professor e: oh , ok . postdoc f: but um the the total set that i gave them is twelve hours of tape , professor e: oh , i see . postdoc f: but they have n't gotten to the end of that yet . professor e: oh , i see . postdoc f: so they 're still working some of them are two of them are still working on completing that . yeah . phd b: boy , they 're moving right along . professor e: yeah . postdoc f: yeah . they are . mm - hmm . they 're very efficient . there 're some who have more hours that they devote to it than others . phd b: mm - hmm . professor e: mm - hmm . postdoc f: yeah . professor e: so what what what 's the deal with with your phd a: the channel u thing ? professor e: yeah . phd a: oh , it 's just uh , i ran the recognizer uh , the { comment } speech - nonspeech detector on different channels and , it 's just in uh in this new multi - channel format and output , and i just gave one one meeting to to liz who wanted to to try it for for the recognizer professor e: oh , i see . phd a: as uh , apparently the recognizer had problems with those long chunks of speech , which took too much memory or whatever , professor e: right . phd a: and so she she will try that i think professor e: yeah . phd a: and i 'm i 'm working on it . so , i hope grad c: is this anything different than the hmm system you were using before ? professor e: yeah . phd a: no . uh , i mmm , use some some different features but not not grad c: mm - hmm . phd a: the basic thing is this hmm base . grad c: so there 's still no no knowledge using different channels at the same time . phd a: there is some , uh as the energy is normalized across channels grad c: you know what i mean ? across all of them . phd a: yeah . grad c: ok . phd a: so . but basically that 's one of the main changes . grad c: mm - hmm . professor e: mm - hmm . what are some of the other features ? besides the energy ? you said you 're trying some different features , or something . phd a: oh i just uh mmm , i just use um our loudness - based things now as they before there were they were some in in the log domain and i i changed this to the to the professor e: cu - cube root ? phd a: yeah . to no , i changed this to the to the to the loudness thingy with the with the grad c: hmm . professor e: ah . phd a: how do you call it ? i 'm not sure . with the , uh professor e: fletcher munson ? no . phd a: i 'm not sure about the term . professor e: oh , ok . phd a: uh , i 'll look it up . and say it to you . professor e: yeah , alright . phd a: uh , ok , and yeah . that 's that 's basically the the the thing . yeah , and i and i tried t to normalize uh uh the features , there 's loudness and modified loudness , um , within one channel , professor e: ok . phd a: because they 're , yeah to to be able to distinguish between foreground and background speech . and it works quite well . but , not always . professor e: uh - huh . uh - huh . phd a: so . professor e: ok . grad c: good . professor e: um , let 's see . i think the uh were were you basically done with the transcription part ? so i guess the next thing is this uh bleep editing . grad c: right . so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they do n't want . so i 've written a bunch of tools that will generate web pages , uh with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's a form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , uh , some of the questions on this is what do we do about the privacy issue . and so i thought about this a little bit and i think the best way to do it is every participant will have a password , professor e: yeah . grad c: a single password . each person will have a single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password . professor e: i i ca n't help but wonder if this is maybe a little more elaborate than is needed . i mean if people have uh , i mean , for me i would actually want to have some pieces of paper that had the transcription and i would sort of flip through it . and then um if i thought it was ok , i 'd say `` it 's ok `` . grad c: mm - hmm . professor e: and , i uh i mean it depends how this really ends up working out , but i guess my thought was that the occasion of somebody wondering whether something was ok or not and needing to listen to it was gon na be extremely rare . grad c: right , i mean so th th th the fact that you could listen to it over the web is a minor thing that i had already done for other reasons . professor e: ok . grad c: and so that that 's a minor part of it , i just wanted some web interface so that people you did n't actually have to send everyone the text . so m what my intention to do is that as the transcripts become ready , um i would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just uh , tell them , `` here 's the web page `` , um , `` you need a password `` . so th th question number one is how do we distribute the passwords , and question number two is how else do we wan na provide this information if they want it . professor e: that 's i think what i was sort of saying is that if you just say `` here is a here is `` i mean this maybe it sounds paleolithic but but i just thought if you handed them some sheets of paper , that said , uh , `` here 's what was said in this transcription is it ok with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's ok `` . grad c: i think that um there are a subset of people who will want printouts that we can certainly provide . professor e: and then they 'd hand it back to you . grad c: but certainly i would n't want a printout . these are big , and i would much rather be ha be able to just sit and leaf through it . professor e: you find it easier to go through a large i mean how do you read books ? grad c: well i certainly read books by hand . but for something like this , i think it 's easier to do it on the web . professor e: really ? i mean , it grad c: cuz you 're gon na get , you know , if i i 'm i 'm in a bunch of meetings and i do n't wan na get a stack of these . i wan na just be able to go to go to the web site { comment } and visit it as i want . professor e: going to a web site is easy , but flipping through a hundred pounds a hundred pages of stuff is not easy on the web . grad c: well , i do n't think it 's that much harder than , paper . so . professor e: really ? postdoc f: i have one question . so are you thinking that um the person would have a transcript and go strictly from the transcript ? because i i do think that there 's a benefit to being able to hear the tone of voice and the professor e: so here 's the way i was imagining it , and maybe i 'm wrong , postdoc f: yeah . professor e: but the way i imagined it was that um , the largest set of people is gon na go `` oh yeah , i did n't say anything funny in that meeting just go ahead , where 's the where 's the release ? `` and then there 'll be a subset of people , right ? ok there 's i mean think of who it is we 've been recording mostly . phd a: yeah . professor e: ok there 'll be a subset of people , who um , will say uh `` well , yeah , i really would like to see that . `` and for them , the easiest way to flip through , if it 's a really large document , i mean unless you 're searching . searching , of course , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something or something like that , phd a: yeah . professor e: but see then we 're getting more elaborate with this thing . um if if uh you do n't have search mechanisms you just sort of have this really , really long document , i mean whenever i 've had a really , really long document that it was sitting on the web , i 've always ended up printing it out . i mean , so it 's it 's i mean , you you 're you 're not necessarily gon na be sitting at the desk all the time , you wan na figure you have a train ride , and there 's all these situations where where i i mean , this is how i was imagining it , anyway . and then i figured , that out of that group , there would be a subset who would go `` hmm you know i 'm really not sure about this section here , `` and then that group would need it s it seems like i if i 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that uh , now we have to worry about privacy , grad c: well , no fre for the most professor e: we have to worry about all these passwords , for different people grad c: for the most frequent case they just say `` it 's ok `` and then they 're done . and i think almost everyone would rather do that by email than any other method . professor e: mm - hmm . postdoc f: the other thing too is it seems like professor e: um , yeah , that 's true . postdoc f: go ahead . grad c: i mean , cuz you do n't have to visit the web page if you do n't want to . phd a: yeah . professor e: i guess yeah , i guess we do n't need their signature . i guess an email ok is alright . grad c: oh that was another thing i i had assumed that we did n't need their signature , that it that an email approval was sufficient . but i do n't actually know . phd b: are are people going to be allowed to bleep out sections of a meeting where they were n't speaking ? grad c: yes . if someone feels strongly enough about it , then i i i think they should be allowed to do that . postdoc f: i also mm - hmm . phd b: so that means other people are editing what you say ? professor e: uh i do n't know about that . grad c: yeah . phd b: i do n't know if i like that . grad c: well , the only other choice is that the person would say `` no , do n't distribute this meeting at all `` , and i would rather they were able to edit out other people then just say `` do n't distribute it at all `` . professor e: but th what they signed in the consent form , was something that said you can use my voice . grad c: well , but if if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient . professor e: right ? yeah . yeah , but that 's our decision then . right ? grad c: um , i do n't think so . i mean , because if i object to the conversation . professor e: i think it is . grad c: if i say `` we were having a conversation , and i consider that conversation private , `` and i consider that your side of it is enough for other people to infer , i wan na be able to bleep out your side . postdoc f: the i agree that the consent forms were uh , i cons agree with what adam 's saying , that um , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or did n't say them . professor e: i see . ok , well , if that 's what it said . postdoc f: and the other thing is from the standpoint of the l of the l i 'm not a law lawyer , but it strikes me that uh , we would n't want someone to say `` oh yes , i was a little concerned about it but it was too hard to access `` . so i think it 's kind of nice to have this facility to listen to it . now in terms of like editing it by hand , i mean i think it 's i some people would find that easier to specify the bleep part by having a document they edited . but but it seems to me that sometimes um , you know i if a person had a bad day , and they had a tone in their voice that they did n't really like , you know it 's nice it 's nice to be able to listen to it and be sure that that was ok . grad c: i mean i can certainly provide a printable version if people want it . um . professor e: um i mean it 's also a mixture of people , i mean some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not . grad c: yep . professor e: others would consider it this uh a a set of skills that they would have to gain . you know ? grad c: well i think most of the people in the meetings are the former . professor e: it depends on what meetings . postdoc f: that 's true . phd b: so far . grad c: so . professor e: in the meetings so far , yeah . grad c: yep . professor e: but we 're trying to expand this , right ? grad c: right . professor e: so i i i actually think that paper is the more universal thing . grad c: and that well , but if they want to print it out that 's alright . postdoc f: mm - hmm . yeah . grad c: i think everyone in the meeting can access the web . professor e: no , i think we have to be able to print it out . it 's not just if they want to print it out . i i think grad c: ok , so does that mean that i ca n't use email ? or what ? postdoc f: cuz you could send it through email you 're thinking . professor e: i i th grad c: well , i do n't think i professor e: well we there was this grad c: well i do n't think we can send the text through email because of the privacy issues . professor e: no . postdoc f: good . for security ? phd a: yeah . postdoc f: yeah , ok good . professor e: right . grad c: um . so giving them , you think a web site to say , `` if you wan na print it out here it is `` , is not sufficient ? postdoc f: good point . phd a: yeah . i professor e: certainly for everybody who 's been in the meetings so far it would be sufficient . grad c: yeah , i 'm just thinking for people that that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them . professor e: i 'm just wondering about postdoc f: you could mail it to them . phd a: yeah . postdoc f: get an a mailing address . grad c: equivalent . phd a: but postdoc f: but i think it 's easier to drop in the box . phd a: just put the button on on the web page which say `` please send me the the scripts `` . grad c: that 's right . postdoc f: oh that 's interesting . phd a: yeah . phd b: what um when you display it on the web page , what are what are you showing them ? utterances , or ? grad c: mm - hmm . phd b: and so can they bleep within an utterance ? grad c: no . whole utterances only . phd b: whole utterances . grad c: and that was just convenience for my sake , that it 's uh , uh it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way i can just delete an entire line out of a transcript file rather than have to do it by hand . professor e: there 's another aspect to this which maybe is part of why this is bothering me . um , i think you 're really trying very hard to make this as convenient as possible for people to do this . phd b: mmm . grad c: i mean that 's why i did the web form , because for me that would be my most convenient . professor e: i i i understand . phd b: i know where you 're going . professor e: i think that 's the bad idea . grad c: oh . professor e: see because you 're gon you 're uh really . you 're gon na end up with all these little patchy things , whereas really what we want to do is have the the the bias towards letting it go . because nob you know it there was a one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gon na get hurt . nobody 's being l libeled . you know , this is this we 're we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gon na end up encouraging a headache . that i think that 's i 'm sort of psyching myself out here , i i 'm trying to uh grad c: i guess i do n't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out . professor e: but i i think that 's well , it 's grad c: so . phd b: i think what morgan 's saying is the easier it is , the more is gon na be bleeped . professor e: but i and and it really depends on what kind of research you 're doing . i think some researchers who are gon na be working with this corpus years from now are really gon na be cursing the fact that there 's a bunch of stuff in there { comment } that 's missing from the dialogue . grad c: mm - hmm . professor e: you know , it depends on the kind of research they 're doing , phd a: yeah . professor e: but it might be , uh it might be really a a pain . and , you know where it 's really gon na hurt somebody , in some way the one who said it or someone who is being spoken about , { comment } we definitely want to allow the option of it being bleeped out . but i really think we wan na make it the rare incidence . and and uh , i am just a little worried about making it so easy for people to do , and so much fun ! that they 're gon na go through and bleep out stuff . postdoc f: so much fun . professor e: and they can bleep out stuff they do n't like too , right from somebody else , as you say , you know , so `` well i did n't like what he said . `` grad c: well i do n't see any way of avoiding that . i mean , we have to provi we have promised that we would provide them the transcript and that they can remove parts that they do n't like . so that the professor e: yeah . no , no , i i i do n't grad c: the only question is professor e: you - you 've talked me into that , but i i just think that we should make it harder to do . grad c: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , i just get email , it 's all formatted , it 's all ready to go and i can just insert it . professor e: so maybe you do n't give them access to the web interface unless they really need it . so so so postdoc f: well i guess yeah . professor e: i 'm sorry so so so maybe this is a s a way out of it . postdoc f: hmm . professor e: you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but i think the issue of privacy and ease and so forth should be that uh , they get access to this if they really need it . grad c: well phd b: so you 're saying the the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . professor e: right . phd b: and then if they do n't , you 're done . if they do , then he provides them access to the the web site . grad c: well , to some extent i have to do that anyway because as i said we have to distribute passwords . professor e: w w phd b: or a printed - out form . professor e: there 's there grad c: so , professor e: y but you do n't necessarily have to distribute passwords is what i 'm saying . grad c: well , but professor e: so phd b: only if they want it . grad c: what i 'm saying is that i ca n't just email them the password because that 's not secure . so they have to call me and ask . professor e: no , no , no . but you are n't necessarily giving them right . but we do n't even necessarily need to end up distributing passwords at all . phd a:  grad c: well , we do because of privacy . we ca n't just make it openly available on the web . professor e: no , no . you 're missing the point . postdoc f: mm - hmm . professor e: we 're we 're trying i we 're trying to make it less of an obvious just l l l l uh fall off a log , to do this . postdoc f: not everyone gets a password , unless they ask for it . professor e: right ? so th so what i would see , is that first you contact them and ask them if they would like to review it for to check for the postdoc f: yeah . professor e: not just for fun , ok ? but to to check this for uh things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . um and , uh , and we should think carefully actually we should review go through how that 's worded , ok ? then , if someone uh wants to review it , uh , and i know you do n't like this , but i 'm offering this as a suggestion , is that is that we then give them a print out . and then if they say that `` i have a potential problem with these things , `` then , you you say `` ok well you might wan na hear this in context to s think if you need that , `` you issue them a password , i in the grad c: but the the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . i would much prefer to have all be automatic , they visit the web site if they want to . obviously they do n't have to . professor e: i know you 'd prefer it , but the proble grad c: yeah . professor e: we have grad c: so i think you 're thinking people are going to arbitrarily start bleeping and i just do n't think that 's gon na happen . professor e: there 's a problem with it . postdoc f: i 'm also concerned about the spirit of the of the informed consent thing . cuz i think if they feel that uh , it 's i th i th you know , if it turns out that something gets published in this corpus that someone really should have eliminated and did n't detect , then it could have been because of their own negligence that they did n't pursue that next level and get the password and do that , um , but but they might be able to argue `` oh well it was cumbersome , and i was busy and it was gon na take me too much time to trace it down `` . so it could that the burden would come back onto us . so i 'm a little bit worried about uh , making it harder for them , from the legal standpoint . professor e: well you can go too far in that direction , and you need to find somewhere between i think , postdoc f: yeah . grad c: it seems to me that sending them email , saying `` if you have an o - ok reply to this email and say ok , professor e: because uh - huh . grad c: if you have a problem with it contact me and i 'll give you a password `` , seems like is a perfectly , reasonable compromise . and if they want a printout they can print it out themselves . postdoc f: or we could print it up for them , phd a: yeah . postdoc f: i mean we could offer that but but there 's uh , another aspect to that and that is that in the informed consent form , um , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . and and i ha professor e: yeah . postdoc f: i do n't know that there 's a chance of really skipping that stage . i mean i i thought that you were maybe i misinterpreted what you said but it 's professor e: having access to it does n't necessarily mean , that having it grad c: having it . postdoc f: giving it to them . grad c: well the in professor e: right ? it just means they have the right to have it . postdoc f: ok . grad c: the consent form is right in there if anyone wants to look at it , postdoc f: alright . fine . ok . fair enough . grad c: so . professor e: yeah . grad c: d you want me to grab one ? postdoc f: sh - sh well i could i 'm closer . grad c: yeah , but you 're wired postdoc f: i could grad c: are n't you ? postdoc f: yeah . that is true . professor e: um . yeah , i mean i do n't wan na fool them , postdoc f: i do n't know professor e: i just meant that e every ev any time you say anything to anyone there is in fact a a bias that is presented , postdoc f: oh yeah yeah oh i know . professor e: right ? grad c: `` if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` professor e: of and postdoc f: yeah that 's true . yeah . grad c: `` once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . professor e: yeah . grad c: there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . `` postdoc f: hmm . well that 's more open than i realized . grad c: well , i mean it the one question is definitely clear with anything as opposed to just what you said . professor e: i phd a: yeah . professor e: yeah , uh no that it tha postdoc f: tha - that 's true . that 's more severe , but the next one says the transcript will be around . professor e: that 's right . postdoc f: and it does n't { comment } really say we 'll send it to you , or wi it 'll be available for you on the web , or anything . phd b: i think it probably leaves it open how we get it to them . professor e: i i postdoc f: at least it more often . yeah . it means also we do n't have to g to give it to them . i mean like like morgan was saying they they grad c: they just have to make sure that it is available to them . postdoc f: it 's available to them if they ask for it . professor e: yeah , ok , so . wh um i think i have an idea that may be sat may satisfy both you and me in this which is , um , it 's a it we just go over carefully how these notes to people are worded . so i i just want it to be worded in such a way where it gives the strong impre it gives very , i mean nothing hidden , v very strongly the bias that we would really like to use all of these data . grad c: right . professor e: that that we really would rather it was n't a patchwork of things tossed out , postdoc f: good . professor e: that it would be better for , um , our , uh , field if that is the case . but if you really think something is gon na and i do n't think there 's anything in the legal aspects that that is hurt by our expressing that bias . postdoc f: great . great , great . professor e: and then then my concern about which postdoc f: yeah . i agree . professor e: you know you might be right , it may be it was just paranoia on my part , uh but people just see i 'm @ @ worried about this interface so much fun that people start bleeping stuff out { comment } just as just because they can . grad c: it 's just a check box next to the text , it 's not any fun at all . professor e: yeah . well i do n't know . i kind of had fun when you played me something that was bleeped out . you know . grad c: well , but they wo n't get that feedback . professor e: i grad c: all no because it does n't automatically bleep it at the time . professor e: oh they wo n't ? grad c: it just sends me professor e: oh good . so you have n't made it so much fun . grad c: right . professor e: oh good . grad c: it just sends me the time intervals . professor e: ok , grad c: and then at some point i 'll incorporate them all and put bleeps . i mean i do n't wan na have t ha do that yet until we actually release the data professor e: yeah . grad c: because um , then we have to have two copies of every meeting and we 're already short on disk space . professor e: yeah . grad c: so i i wan na i just keep the times until we actually wan na release the data and then we bleep it . professor e: ok . alright , so i think yeah so if we have if i again let 's you know , sort of circulate the the wording on each of these things and get it right , grad c: well since you seem to feel heart uh , strongest about it , would you like to do the first pass ? professor e: but but ok . uh , fair enough . turn about is fair play , postdoc f: al - also it ther there is this other question , the legal question that that adam 's raised , uh about whether we need a concrete signature , or email c i suffices or whatever professor e: sorry . grad c: yeah . postdoc f: and i do n't know how that works . i there 's something down there about `` if you agree to `` professor e: i 'm i 'm i 'm i thought i i thought about it with one of my background processes grad c: i do n't think so . professor e: and i uh it 's uh it 's uh , it 's fine to do the email . postdoc f: ah . fine . grad c: yeah because thi th they 're signing here that they 're agreeing to the paragraph which says `` you 'll be given an opportunity . `` professor e: ok . postdoc f: good . ok . professor e: yeah . grad c: and so i do n't think they need another signature . professor e: and well and furthermore i it 's now fairly routine in a lot of arrangements that i do with people on contracts and so forth that that uh if it 's if it 's that sort of thing where you 're you 're saying uh `` ok i agree , we want eighty hours of this person at such - and - such amount , and i agree that 's ok , `` uh if it 's a follow up to some other agreement where there was a signature it 's often done in email now grad c: right . professor e: so it 's it 's ok . postdoc f: great . professor e: um . grad c: so i guess i probably should at the minimum , think about how to present it in a printed form . i 'm not really sure what 's best with that . the problem is a lot of them are really short , postdoc f: well grad c: and so i do n't necessarily wan na do one per line . but i do n't know how else to do it . postdoc f: well i s i also have this i i think it 's nice you have it uh , viewab her { comment } hearable on the on the web for those who might wonder about um , the non nonverbal side , i mean i i agree that our bias should be as as expressed here , and but i i think it 's nice that a person could check . cuz sometimes you know you the words on a on the page , come out soun sounding different in terms of the social dynamics if they hear it . grad c: hmm . professor e: mm - hmm . mm - hmm . postdoc f: and i realize we should n't emphasize that people { comment } you know , should n't borrow trouble . what it comes down to but grad c: yeah i think actually my opinion probably is that the only time someone will need to listen to it is if the transcript is uh not good . you know , if if there are lots of mumbles and parentheses and things like that . postdoc f: oh , you know , or what if there was an error in the transcript that did n't get detected and there was a whole uh i segment a against some personal i th grad c: right . that was all mumbled ? phd a: yeah . grad c: i think microsoft is postdoc f: yeah exactly phd a: oh , grad c: sorry transcribers . postdoc f: or or even or even { comment } there was a a line you know about how `` hmm - mmm - mmm { comment } bill gates duh - duh - duh - duh . `` professor e: yeah . postdoc f: but but it was all the words were all visible , but they did n't end up i some there was a slip in the transcript . phd a: oh , god . grad c: they 're gon na hate this meeting . phd a: yeah . postdoc f: yeah that 's true . grad c: actually liz will like it . you know , but . professor e: liz will like it . we had a pretty strong disagreement going there . grad c: yep , yep , that 's right . professor e: yeah . postdoc f: yeah . so i do n't know . i mean , i i guess we 're assuming that the transcript is a close enough approximation and that that my double checking will be so close to absolutely perfect that it that nothing will slip by . grad c: mm - hmm . professor e: but it the some something might sometime , and they uh if if it 's something that they said , they might i i i mean , you might be very accurate in putting down what they actually said , postdoc f: mm - hmm . professor e: but , when they hear it , themselves , they may hear something different because they know what they meant . postdoc f: i do n't know how to notate that . phd b: sarcasm , postdoc f: yeah , that 's right . phd b: how do you how do you indicate sarcasm ? postdoc f: yeah that 's right . professor e: no , i 'm serious . so the so i the so we might we might get some feedback from people that such - and - such was , you know , not not really what i said . grad c: yeah . well that would be good to get , definitely . professor e: yeah , but , yeah , sure . grad c: just for corrections . professor e: yeah . grad c: so um , in terms of password distribution , i think phone is really the only way to do it , phone and in person . or mail , physical mail . postdoc f: yeah . or if for leave it on their voice mail . phd b: any sub - word level thing . grad c: any sub - wor yeah , ok . i mean you could do it with pgp or things like that but it 's too complex . postdoc f: you know i just realized something , which is of e th this question about the uh the possible mismatch of i mean i well , and actually also the lawyer saying that um , we should n't really have them have the people believing that they will be cleared by our checks . you know ? professor e: mm - hmm . postdoc f: i mean . so it 's like i in a way it 's it 's nice to have the responsibility still on them to listen to the tape and and hear the transcript , to have that be the professor e: well yeah , but you ca n't dep i mean , most people will not wan na take the time to do that , though . postdoc f: yeah , ok , fair enough . and they 're s they 're absorbing the responsibility themselves . professor e: and they they have to postdoc f: so it 's not it 's not um yeah , good . professor e: but i mean if you were at a meeting , and and you you do n't think , at least , that you said anything funny and the meeting was about , you know , some some funny thing about semantics or something , or uh grad c: you probably wo n't listen to it . professor e: yeah . postdoc f: it is true that tec that the content is technical , i and so i and we 're not having these discussions which professor e: yeah . postdoc f: i i mean , when i listen to these things , i do n't find things that are questionable , in other people 's speech or in my own . professor e: yeah . you would think it would be rare , postdoc f: just it should be very rare . professor e: i mean we 're not talking about the energy crisis or something , people have postdoc f: yeah . yeah , ok . grad c: how about them energy crises . professor e: yeah . i think we 're uh grad c: done ? professor e: kind of done . actually , i was gon na di - did you have anything n that 's going on , or grad d: not really . no . um , my project is going along but um , i 'm really just here to um fill the project uh the overall progress . i do n't really have anything specific to to talk about . professor e: yeah . that 's fine . i just did n't wan na go by you , if you had something . grad d: oh , ok . professor e: you do n't have anything to say . phd b: no . professor e: nah . grad c:  professor e: transcribers , he was rattling the b marbles in his brain back and forth just then this this grad c: shall we do digits ? professor e: oh yeah . grad c: um , oh by the way i did find a bunch grad d: it um grad c: uh , we should count out how many more digits to forms do we have back there ? phd b: there were quite a few . uh . grad c: that 's what i thought . i f i was going through them all and i found actually a lot filed in with them , that were blanks , that no one had actually read . phd b: mmm . grad c: and so we still have more than i thought we did . phd b: oh good . grad c: so , we have a few more digits before we 're done . phd b: you know having this headset reminds me of like working at burger king or something . grad c: oops . postdoc f: oh , did you do that ? phd a: burger king grad c: i 'd like a burger with that , phd b: no i never did . grad c: do you want fries with that ? professor e: wow . phd b: but i feel like i could now . grad c: and { pause }","output":"the group discussed recording equipment issues , including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use ."},{"instruction":"what did the team say about recording conventions ?","input":"professor e: alright . grad c: so are you professor e: so . grad c: are we going ? professor e: it is uh , must be february fifteenth . postdoc f: yeah . grad c: yu i think the date 's written in there , yep . and actually if everyone could cross out the r - nine next to `` session `` , and write mr eleven . professor e: yeah . yeah . we did n't have a front - end meeting today . grad c: and let 's remember also to make sure that one 's { comment } gets marked as unread , unused . professor e: ok . phd a: mr eleven . grad c: mr eleven . postdoc f: that sounds like a spy code . professor e: mmm . ok . so . grad c: there 's lots of clicking i 'm sure as i 'm trying to get this to work correctly . professor e: agenda . any agenda items today ? grad c: i wan na talk a little bit about getting how we 're gon na to get people to edit bleeps , parts of the meeting that they do n't want to include . what i 've done so far , and i wan na get some opinions on , how to how to finish it up . professor e: ok . postdoc f: i wan na ask about um , some aud audio monitoring on some of the um well some of the equipment . in particular , the well uh , that 's just what i wan na ask . professor e: ok audio monitoring , jane . postdoc f: ba - based on some of the tran uh i in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact in fact this one i 'm talking on is one of of the ones that showed up in one of the meetings , grad c: oh really . postdoc f: so i phd b: `` spikes `` , you mean like uh , instantaneous click type spikes , or ? postdoc f: mm - hmm . yeah . phd a: spikes ? grad c: clicks . postdoc f: yeah . professor e: hmm . postdoc f: yeah . phd b: huh . postdoc f: and i do n't know what the e electronics is but . grad c: yeah . postdoc f: yeah . grad c: well , i think it 's phd a: touching . grad c: uh , it it could be a number of things . phd a: yeah . grad c: it could be touching and fiddling , and the other thing is that it could the fact that it 's on a wired mike is suspicious . it might be a connector . postdoc f: oh , ok . well maybe then we do n't really have to talk about that as an phd b: you could try an experiment and say `` ok , i 'm about to test for spikes `` , postdoc f: i i take that off the agenda . phd b: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . grad c: yeah . right . phd b: `` come get me when you transcribe this and see if there 's spikes . `` postdoc f: oh that professor e: um . postdoc f: well , ok . phd b: no i 'm just professor e: i mean , were this a professional audio recording , what we would do { comment } what you would do is in testing it is , you would actually do all this wiggling and make sure that that that things are not giving that kind of performance . and if they are , then they ca n't be used . grad c: right . professor e: so . um . let 's see . i guess i would like to have a discussion about you know where we are on uh , recording , transcription you know , basically you know where we are on the corpus . postdoc f: good . professor e: and then um , the other thing which i would like to talk about which is a real meta - quest , i think , deal is , uh , agendas . so maybe i 'll i 'll start with that actually . uh , um . andreas brought up the fact that he would kinda like to know , if possible , what we were gon na be talking about because he 's sort of peripherally involved to this point , and if there 's gon na be a topic about discussion about something that he uh strongly cares about then he would come and and i think part of part of his motivation with this is that he 's trying to help us out , in the because of uh the fact that the meetings are are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing grad c: mmm . professor e: and and i 'm sure help out his own time . by not showing up if it 's a meeting that he 's he 's so , uh in order i 'd i think that this is a wish on his part . uh . it 's actually gon na be hard because it seems like a lot of times uh things come up that are unanticipated and and grad c: right . professor e: but um , we could try anyway , uh , do another try at coming up with the agenda uh , at some point before the meeting , uh , say the day before . grad c: well maybe it would be a good idea for one of us to like on wednesday , or tuesday send out a reminder for people to send in agenda items . phd a: yeah . professor e: ok . you you wan na volunteer to do that ? grad c: sure . professor e: ok . alright so we 'll send out agenda request . grad c: let me professor e: uh . phd b: that 'll be i think that 'll help grad c: i 'll put that on my spare brain or it will not get done . phd b: that 'll help a lot , actually . professor e: yeah , i have to tell you for the uh for the admin meeting that we have , lila does that um every time before an admin meeting . and uh , she ends up getting the agenda requests uh , uh ten minutes before the meeting . but but { comment } but . uh . { comment } but we can try . maybe it 'll work . phd b: mmm . grad c: yeah . maybe . weirder things have happened . professor e: yeah . postdoc f: i 'm wondering if he were to just , uh , specify particular topics , i mean . maybe we 'd be able to meet that request of his a little more . phd b: i would i would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him . grad c: well then professor e: yeah . actually it this this maybe brings up another topic which is um so we 're done with that topic . the other topic i was thinking of was the sta status on microphones and channels , and all that . grad c: yeah , actually i i was going to say we need to talk about that too . professor e: yeah . why why do n't we do that . grad c: ok . um , the new microphones , the two new ones are in . um . and they are being assembled as we speak , i hope . and i did n't bring my car today so i 'm gon na pick them up tomorrow . um , and then the other question i was thinking about is well , a couple things . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , phd a:  grad c: and get people 's opinions on on what they think of them . um , then the other question i had is maybe we should get another wireless . another wireless setup . i mean it 's expensive , but it does seem to be better than the wired . professor e: so how many channels do you get to have in a wireless setup ? grad c: um , well , i 'm pretty sure that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and apparently you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . professor e: so , um . grad c: and so , you know it 's still , it 's fifteen minus six . professor e: so let 's see we grad c: right ? so we could have up to nine . professor e: and right now we can have up to six . grad c: right . and we have five , we 're getting one more . professor e: yeah . grad c: and it 's um , about nine hundred dollars for the base station , and then eight hundred per channel . professor e: oh . so yeah so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . grad c: right . professor e: oh , we should do it . grad c: ok . ok , so i 'll look into how you daisy - chain them and and then just go ahead and order them . professor e: yeah . yeah . phd b: i do n't quite understand how that how that works , . if so we 're not increasing the number of channels . ok . grad c: no , we 're just replacing the wired the two wired that are still working , phd b: ok . i see . grad c: along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless . professor e: yeah . phd b: three wireds work , professor e: basically we found phd b: right ? grad c: i i guess three wireds work , yeah . phd b: yeah . yeah . professor e: yeah . but we 've had more problems with that . grad c: yep . professor e: and that sort of bypasses the whole the whole jimbox thing and all that . grad c: right . professor e: and so um , we we seem to have uh , a reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . grad c: right . professor e: that seems to be the key issue . grad c: everyone 's battery ok ? phd b: i checked them this morning , they should be . grad c: ok . professor e: yeah . um , that 's the only thing with them . but the quality seems really good and um i heard from uw that they 're they 're uh very close to getting their , uh setup purchased . they 're they 're they 're buying something that you can just sort of buy off the shelf . grad c: well we should talk to them about it because i know that sri is also in the process of looking at stuff , and so , you know , what we should try to keep everyone on the same page with that . professor e: yeah . phd b: sri , really ? grad c: yeah . phd b: oh . grad c: they got sa apparent well , maybe this needs to be bleeped out ? i have no clue . professor e: uh , i do n't know . grad c: i do n't know how much of it 's public . professor e: probably we should n't probably we should n't talk about funding stuff . grad c: right . professor e: yeah . but anyway there 's there 's there 's uh , uh other activities that are going on there and and uh and nist and uw . so . um . but but yeah i thin i think that at least the message we can tell other people is that our experience is is quite positive with the sony , grad c: right . professor e: uh , radio - mikes . now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering or something , right ? grad c: uh , no , we 're having the them do it . professor e: no ? grad c: so it 's so hand - soldering it , but i 'm not doing it . professor e: oh . grad c: so , they they charge professor e: ok . nothing against you and your hand - soldering grad c: right . professor e: but grad c: you 've never seen my hand - soldering . but uh , a as i said they 're coming in . professor e: uh , ok , so that 's being done professionally and grad c: i i mean professor e: yeah . grad c: yeah . i mean . professor e: yeah . grad c: as professionally as i guess you can get it done . professor e: well , it could if they do a lot of it , it 's grad c: i mean i it 's just their repair shop . right ? their maintenance people . professor e: well , we 'll see what it it 's like . grad c: yep . professor e: that tha that can be quite good . th - this yeah , ok . good . yeah . so let 's go with that . grad c: and , i mean we 'll see , tomorrow , you know , what it looks like . professor e: uh , yeah . so , um , uh , dave is n't here but he was going to start working on some things with the digits . uh , so he 'll be interested in what 's going on with that . i guess was the decision last time was that the the uh transcribers were going to be doing stuff with the digits as well ? has that started , or is that ? postdoc f: mm - hmm . yeah . uh , it would be to use his interface and i was going to meet with him today about that . grad c: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so i did the all that last week . so all the all the forms are now on the computer . and uh , then i have a bunch of scripts that we 'll read those and let the uh transcribers use different tools . and i just want to talk to jane about how we transition to using those . postdoc f: mm - hmm . so he has a nice set up that they it w it will be efficient for them to do that . professor e: ok . grad c: i i do n't think it 'll take too long . professor e: so anyway grad c: so , you know , just uh , a matter of a few days i suspect . professor e: so anyway i think we we have at least one uh , user for the digits once they get done , which will be dave . grad c: right . i 've already done five or six sets . postdoc f: ok . grad c: so if he wanted to , you know , just have a few to start with , he could . you know , and i also have a bunch of scripts that will , like , generate p - files and run recognition on them also . professor e: yeah , he might he might be asking right . ok . uh , is dave i do n't know if dave is on the list , if he 's invited to these meetings , uh if he knows . postdoc f: i do n't tend to get an invitation myself for them even . phd a: no , no . grad c: uh , we do n't have a active one but i 'll make sure he 's on the list . postdoc f: yeah . should we call him ? i mean is he d is he definitely not available today ? professor e: i do n't know . postdoc f: should i call his office and see ? phd a: he was in . grad c: i mean , he 's still taking classes , so uh , he may well have conflicts . professor e: uh , well i it 's uh phd a: yeah . professor e: yeah . phd a: yeah , he was in s postdoc f: he was n't there at cof professor e: yeah , so this might be a conflict for him . phd a: yeah . professor e: yeah . postdoc f: ok . professor e: ok . uh , so . grad c: yeah did n't he say his signal - processing class was like tuesdays and thursdays ? phd a: i think he has a class . yeah . phd b: yeah . he might have . grad c: oh well , whatever . grad d: you talking about david gelbart ? professor e: oh , ok . phd a: yeah . phd b: yeah . grad c: yeah . professor e: yeah . postdoc f: yes . grad d: yeah , i think he 's taking two twenty - five a which is now . phd b: yeah . grad d: so . professor e: yeah . postdoc f: ok . professor e: ok . so , that 's why we 're not seeing him . ok . uh , transcriptions , uh , beyond the digits , where we are , and so on . postdoc f: ok . professor e: and the and the recordings also , postdoc f: um professor e: just where we are . yeah . postdoc f: well , so um , should we we do n't wan wan na do the recording status first , or ? grad c: well , we have about thirty - two hours uh as of , i guess a week and a half ago , so we probably now have about thirty - five hours . professor e: and and that 's that 's uh how much of that is digits ? it 's uh that 's including digits , grad c: that 's including digits . professor e: right ? grad c: i have n't separated it out so i have no clue how much of that is digits . professor e: so yeah . so anyway there 's at least probably thirty hours , or something of there 's got to be more than thirty hour phd a: mmm . grad c: of of non - digits ? professor e: i it could n't of of non - digits . grad c: yeah , absolutely . i mean , the digits do n't take up that much time . professor e: yeah , yeah . ok . postdoc f: ok , and the transcribers h i , uh , do n't have the exact numbers , but i think it would come to about eleven hours that are finished uh , transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what i mean by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that uh , liz requested in terms of um , um in terms of having a s a systematic handling of numbers , and acronyms which i had n't been specific about . um , for example , i they 'll say uh `` ninety - two `` . and you know , so how you could grad c: nine two , postdoc f: e exactly . grad c: right . postdoc f: so if you just say `` nine two `` , the there are many s ways that could have been expressed . an - and i just had them i i mean , a certain number of them did put the words down , but now we have a convention which also involves having it followed by , um , a gloss th and things . phd b: you know , jane ? grad c: mm - hmm . phd b: um , one suggestion and you may already be doing this , but i 've noticed in the past that when i 've gone through transcriptions and you know in in order to build lexicons and things , if you um , just take all the transcriptions and separate them into words and then alphabetize them , { comment } a lot of times just scanning down that list you 'll find a lot of inconsistencies and mis grad c: misspelled . phd a: yeah . postdoc f: you 're talking about the type token frequency listings , and i use those too . y you mean just uh on each on each line there 's a one word right ? it 's one token from the from the corpus . phd b: mm - hmm . mm - hmm . postdoc f: yeah , those are e extremely efficient and i and i i agree that 's a very good use of it . phd b: oh so you already have that , ok . postdoc f: well that 's that 's a way that 's you know , the spell - check basically does that but but in addition yes , that 's that 's exactly the strategy i wan na do in terms of locating these things which are you know colloquial spoken forms which are n't in the lexicon . phd b: mm - hmm . cuz a lot of times they 'll appear next to each other , and uh , postdoc f: exactly . and then you ca then you can do a s phd a: yeah . phd b: i in alphabetized lists , they 'll appear next to each other and and so it makes it easier . postdoc f: absolutely . i agree . that 's a very good that 's a very good uh , suggestion . and that was that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . i did n't get to that point but so there are numbers , then there are acronyms , and then um , there 's a he she wants the uh , actually a an explicit marker of what type of comment this is , so i curly b inside the curly brackets i 'm gon na put either `` voc `` for vocalized , like cough or like laugh or whatever , `` nonvoc `` for door - slam , and `` gloss `` for things that have to do with if they said a s a spoken form with this m this pronunciation error . grad c: right . postdoc f: i already had that convention phd b: oh that 's great . postdoc f: but i i have n't been asking these people to do it systematically cuz i think it most ha most efficiently handled by uh by a a filter . that was what i was always planing on . so that , you know you get a whole long list exactly what you 're saying , you get a whole list of things that say `` curly bracket laugh curly bracket `` , phd b: mm - hmm . postdoc f: then y you know it 's it 's you you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in sort of a voc space , phd b: yeah . postdoc f: so man so many ways that error prone . phd b: right . right . postdoc f: so , um , um i 'm i 'm going to convert that via a filter , into these tagged uh , subcategorized comments , and same thing with you know , we see you get a subset when you do what you 're saying , phd b: mm - hmm . postdoc f: you end up with a s with uh , you 're collapsing across a frequency you just have the tokens phd b: mm - hmm . postdoc f: and you can um , have a filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , you know i mean , jus grad c: you do n't know what they could be . phd b: yeah . postdoc f: yeah now timit 's clear um and plp is clear but uh there are things that are not so well known , in or or have variant u u uses like the numbers you can say `` nine two `` or you can say `` ninety - two `` , grad c: so how are you doing the postdoc f: and uh i 'd handle the numbers individually . grad c: how are you doing the uh , acronyms so if i say pzm what would it appear on the transcript ? postdoc f: it would be separate the letters would be separated in space grad c: ok . postdoc f: and potentially they 'll have a curly bracket thing afterwards e but i 'm not sure if that 's necessary , clarifying what it is , grad c: mm - hmm . postdoc f: so gloss of whatever . grad c: right . postdoc f: i do n't know if that 's really necessary to do that . maybe it 's a nice thing to do because of it then indicating this is uh , a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's uh the you know , { comment } uh enumerated , or i grad c: mm - hmm . postdoc f: it 's not a good way of saying but it 's it 's the specific uh way of stating these these letters . grad c: right . so it sounds good . postdoc f: and so anyway , the clean those are those things and then channelized is to then um , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . phd a: yeah . grad c: right . postdoc f: and uh , thilo had a e e a breakthrough with this this last week in terms of getting the channel - based um uh s s speech - nonspeech segmentation um , up and running and i have n't i have n't been able to use that yet cuz i 'm working s re this is my top priority get the data clean , and channelized . phd a: i actually gave grad c: have you also been doing spot checks , jane ? postdoc f: oh yes . grad c: okay , good . postdoc f: well you see that 's part of the cleaning process . i spent um actually um i have a segment of ten minutes that was transcribed by two of our transcribers , grad c: oh good . good . postdoc f: and i went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas i i left them discretion at commas . grad c: right . postdoc f: uh and so because it 's not part of our st of our ne needed conventions . professor e: mm - hmm . postdoc f: and um , and so they 'll be a difference in commas , but it 's word - by - word the same , in in huge patches of the data . and i have t ten minute stretch where i can where i can show that . and and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . so um , the one i i the colloquial speech person picked up `` gobbledy - gook `` . phd b: hmm . postdoc f: and the other one did n't . and on this side , this one 's picking up things like `` neural nets `` and the one that 's good on the sp o on th the vocabulary on the uh colloquial did n't . grad c: right . phd b: when for the person who missed `` gobbledy - gook `` what did they put ? postdoc f: it was an interesting approximation , put in parentheses , cuz i have this convention that , i if they 're not sure what it was , they put it in parentheses . phd b: oh . postdoc f: so they tried to approximate it , but it was phd b: oh good . postdoc f: it was spelled gabbl phd b: sort of how it sounds . yeah . postdoc f: yes . more of an attempt to i mean apparently it was very clear to her that these the a this this was a sound these are the sounds , grad c: it was a technical term that she did n't recognize , phd b: yeah . postdoc f: but yeah . but she knew that she did n't know it . maybe it was a technical ter exactly . but she even though her technical perception is just really uh you know i 've i 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses grad c: right . postdoc f: then cuz `` neural nets `` and oh she has some things that are oh `` downsampled `` , she got that right . phd b: hmm . postdoc f: and some of these are rather uh unexpected . grad c: obscure , yeah . postdoc f: but ch ten solid uh m ch s chunk of ten solid minutes where they both coded the same data . professor e: and and again the main track that you 're working with is elev eleven hours ? postdoc f: and um professor e: is that right ? postdoc f: yes exactly . professor e: yeah , ok . postdoc f: and that 's part of this eleven hours . professor e: is that is that that including digits ? yeah . postdoc f: yes it is . professor e: so let 's say roughly ten hours or so of postdoc f: mm - hmm . professor e: i mean it 's probably more than that but but with of of non - digits . phd a: yeah . postdoc f: it 'd be more than that because i my recollection is the minutes that da digits do n't take more than half a minute . per person . professor e: oh , ok . postdoc f: but um the the total set that i gave them is twelve hours of tape , professor e: oh , i see . postdoc f: but they have n't gotten to the end of that yet . professor e: oh , i see . postdoc f: so they 're still working some of them are two of them are still working on completing that . yeah . phd b: boy , they 're moving right along . professor e: yeah . postdoc f: yeah . they are . mm - hmm . they 're very efficient . there 're some who have more hours that they devote to it than others . phd b: mm - hmm . professor e: mm - hmm . postdoc f: yeah . professor e: so what what what 's the deal with with your phd a: the channel u thing ? professor e: yeah . phd a: oh , it 's just uh , i ran the recognizer uh , the { comment } speech - nonspeech detector on different channels and , it 's just in uh in this new multi - channel format and output , and i just gave one one meeting to to liz who wanted to to try it for for the recognizer professor e: oh , i see . phd a: as uh , apparently the recognizer had problems with those long chunks of speech , which took too much memory or whatever , professor e: right . phd a: and so she she will try that i think professor e: yeah . phd a: and i 'm i 'm working on it . so , i hope grad c: is this anything different than the hmm system you were using before ? professor e: yeah . phd a: no . uh , i mmm , use some some different features but not not grad c: mm - hmm . phd a: the basic thing is this hmm base . grad c: so there 's still no no knowledge using different channels at the same time . phd a: there is some , uh as the energy is normalized across channels grad c: you know what i mean ? across all of them . phd a: yeah . grad c: ok . phd a: so . but basically that 's one of the main changes . grad c: mm - hmm . professor e: mm - hmm . what are some of the other features ? besides the energy ? you said you 're trying some different features , or something . phd a: oh i just uh mmm , i just use um our loudness - based things now as they before there were they were some in in the log domain and i i changed this to the to the professor e: cu - cube root ? phd a: yeah . to no , i changed this to the to the to the loudness thingy with the with the grad c: hmm . professor e: ah . phd a: how do you call it ? i 'm not sure . with the , uh professor e: fletcher munson ? no . phd a: i 'm not sure about the term . professor e: oh , ok . phd a: uh , i 'll look it up . and say it to you . professor e: yeah , alright . phd a: uh , ok , and yeah . that 's that 's basically the the the thing . yeah , and i and i tried t to normalize uh uh the features , there 's loudness and modified loudness , um , within one channel , professor e: ok . phd a: because they 're , yeah to to be able to distinguish between foreground and background speech . and it works quite well . but , not always . professor e: uh - huh . uh - huh . phd a: so . professor e: ok . grad c: good . professor e: um , let 's see . i think the uh were were you basically done with the transcription part ? so i guess the next thing is this uh bleep editing . grad c: right . so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they do n't want . so i 've written a bunch of tools that will generate web pages , uh with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's a form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , uh , some of the questions on this is what do we do about the privacy issue . and so i thought about this a little bit and i think the best way to do it is every participant will have a password , professor e: yeah . grad c: a single password . each person will have a single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password . professor e: i i ca n't help but wonder if this is maybe a little more elaborate than is needed . i mean if people have uh , i mean , for me i would actually want to have some pieces of paper that had the transcription and i would sort of flip through it . and then um if i thought it was ok , i 'd say `` it 's ok `` . grad c: mm - hmm . professor e: and , i uh i mean it depends how this really ends up working out , but i guess my thought was that the occasion of somebody wondering whether something was ok or not and needing to listen to it was gon na be extremely rare . grad c: right , i mean so th th th the fact that you could listen to it over the web is a minor thing that i had already done for other reasons . professor e: ok . grad c: and so that that 's a minor part of it , i just wanted some web interface so that people you did n't actually have to send everyone the text . so m what my intention to do is that as the transcripts become ready , um i would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just uh , tell them , `` here 's the web page `` , um , `` you need a password `` . so th th question number one is how do we distribute the passwords , and question number two is how else do we wan na provide this information if they want it . professor e: that 's i think what i was sort of saying is that if you just say `` here is a here is `` i mean this maybe it sounds paleolithic but but i just thought if you handed them some sheets of paper , that said , uh , `` here 's what was said in this transcription is it ok with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's ok `` . grad c: i think that um there are a subset of people who will want printouts that we can certainly provide . professor e: and then they 'd hand it back to you . grad c: but certainly i would n't want a printout . these are big , and i would much rather be ha be able to just sit and leaf through it . professor e: you find it easier to go through a large i mean how do you read books ? grad c: well i certainly read books by hand . but for something like this , i think it 's easier to do it on the web . professor e: really ? i mean , it grad c: cuz you 're gon na get , you know , if i i 'm i 'm in a bunch of meetings and i do n't wan na get a stack of these . i wan na just be able to go to go to the web site { comment } and visit it as i want . professor e: going to a web site is easy , but flipping through a hundred pounds a hundred pages of stuff is not easy on the web . grad c: well , i do n't think it 's that much harder than , paper . so . professor e: really ? postdoc f: i have one question . so are you thinking that um the person would have a transcript and go strictly from the transcript ? because i i do think that there 's a benefit to being able to hear the tone of voice and the professor e: so here 's the way i was imagining it , and maybe i 'm wrong , postdoc f: yeah . professor e: but the way i imagined it was that um , the largest set of people is gon na go `` oh yeah , i did n't say anything funny in that meeting just go ahead , where 's the where 's the release ? `` and then there 'll be a subset of people , right ? ok there 's i mean think of who it is we 've been recording mostly . phd a: yeah . professor e: ok there 'll be a subset of people , who um , will say uh `` well , yeah , i really would like to see that . `` and for them , the easiest way to flip through , if it 's a really large document , i mean unless you 're searching . searching , of course , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something or something like that , phd a: yeah . professor e: but see then we 're getting more elaborate with this thing . um if if uh you do n't have search mechanisms you just sort of have this really , really long document , i mean whenever i 've had a really , really long document that it was sitting on the web , i 've always ended up printing it out . i mean , so it 's it 's i mean , you you 're you 're not necessarily gon na be sitting at the desk all the time , you wan na figure you have a train ride , and there 's all these situations where where i i mean , this is how i was imagining it , anyway . and then i figured , that out of that group , there would be a subset who would go `` hmm you know i 'm really not sure about this section here , `` and then that group would need it s it seems like i if i 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that uh , now we have to worry about privacy , grad c: well , no fre for the most professor e: we have to worry about all these passwords , for different people grad c: for the most frequent case they just say `` it 's ok `` and then they 're done . and i think almost everyone would rather do that by email than any other method . professor e: mm - hmm . postdoc f: the other thing too is it seems like professor e: um , yeah , that 's true . postdoc f: go ahead . grad c: i mean , cuz you do n't have to visit the web page if you do n't want to . phd a: yeah . professor e: i guess yeah , i guess we do n't need their signature . i guess an email ok is alright . grad c: oh that was another thing i i had assumed that we did n't need their signature , that it that an email approval was sufficient . but i do n't actually know . phd b: are are people going to be allowed to bleep out sections of a meeting where they were n't speaking ? grad c: yes . if someone feels strongly enough about it , then i i i think they should be allowed to do that . postdoc f: i also mm - hmm . phd b: so that means other people are editing what you say ? professor e: uh i do n't know about that . grad c: yeah . phd b: i do n't know if i like that . grad c: well , the only other choice is that the person would say `` no , do n't distribute this meeting at all `` , and i would rather they were able to edit out other people then just say `` do n't distribute it at all `` . professor e: but th what they signed in the consent form , was something that said you can use my voice . grad c: well , but if if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient . professor e: right ? yeah . yeah , but that 's our decision then . right ? grad c: um , i do n't think so . i mean , because if i object to the conversation . professor e: i think it is . grad c: if i say `` we were having a conversation , and i consider that conversation private , `` and i consider that your side of it is enough for other people to infer , i wan na be able to bleep out your side . postdoc f: the i agree that the consent forms were uh , i cons agree with what adam 's saying , that um , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or did n't say them . professor e: i see . ok , well , if that 's what it said . postdoc f: and the other thing is from the standpoint of the l of the l i 'm not a law lawyer , but it strikes me that uh , we would n't want someone to say `` oh yes , i was a little concerned about it but it was too hard to access `` . so i think it 's kind of nice to have this facility to listen to it . now in terms of like editing it by hand , i mean i think it 's i some people would find that easier to specify the bleep part by having a document they edited . but but it seems to me that sometimes um , you know i if a person had a bad day , and they had a tone in their voice that they did n't really like , you know it 's nice it 's nice to be able to listen to it and be sure that that was ok . grad c: i mean i can certainly provide a printable version if people want it . um . professor e: um i mean it 's also a mixture of people , i mean some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not . grad c: yep . professor e: others would consider it this uh a a set of skills that they would have to gain . you know ? grad c: well i think most of the people in the meetings are the former . professor e: it depends on what meetings . postdoc f: that 's true . phd b: so far . grad c: so . professor e: in the meetings so far , yeah . grad c: yep . professor e: but we 're trying to expand this , right ? grad c: right . professor e: so i i i actually think that paper is the more universal thing . grad c: and that well , but if they want to print it out that 's alright . postdoc f: mm - hmm . yeah . grad c: i think everyone in the meeting can access the web . professor e: no , i think we have to be able to print it out . it 's not just if they want to print it out . i i think grad c: ok , so does that mean that i ca n't use email ? or what ? postdoc f: cuz you could send it through email you 're thinking . professor e: i i th grad c: well , i do n't think i professor e: well we there was this grad c: well i do n't think we can send the text through email because of the privacy issues . professor e: no . postdoc f: good . for security ? phd a: yeah . postdoc f: yeah , ok good . professor e: right . grad c: um . so giving them , you think a web site to say , `` if you wan na print it out here it is `` , is not sufficient ? postdoc f: good point . phd a: yeah . i professor e: certainly for everybody who 's been in the meetings so far it would be sufficient . grad c: yeah , i 'm just thinking for people that that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them . professor e: i 'm just wondering about postdoc f: you could mail it to them . phd a: yeah . postdoc f: get an a mailing address . grad c: equivalent . phd a: but postdoc f: but i think it 's easier to drop in the box . phd a: just put the button on on the web page which say `` please send me the the scripts `` . grad c: that 's right . postdoc f: oh that 's interesting . phd a: yeah . phd b: what um when you display it on the web page , what are what are you showing them ? utterances , or ? grad c: mm - hmm . phd b: and so can they bleep within an utterance ? grad c: no . whole utterances only . phd b: whole utterances . grad c: and that was just convenience for my sake , that it 's uh , uh it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way i can just delete an entire line out of a transcript file rather than have to do it by hand . professor e: there 's another aspect to this which maybe is part of why this is bothering me . um , i think you 're really trying very hard to make this as convenient as possible for people to do this . phd b: mmm . grad c: i mean that 's why i did the web form , because for me that would be my most convenient . professor e: i i i understand . phd b: i know where you 're going . professor e: i think that 's the bad idea . grad c: oh . professor e: see because you 're gon you 're uh really . you 're gon na end up with all these little patchy things , whereas really what we want to do is have the the the bias towards letting it go . because nob you know it there was a one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gon na get hurt . nobody 's being l libeled . you know , this is this we 're we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gon na end up encouraging a headache . that i think that 's i 'm sort of psyching myself out here , i i 'm trying to uh grad c: i guess i do n't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out . professor e: but i i think that 's well , it 's grad c: so . phd b: i think what morgan 's saying is the easier it is , the more is gon na be bleeped . professor e: but i and and it really depends on what kind of research you 're doing . i think some researchers who are gon na be working with this corpus years from now are really gon na be cursing the fact that there 's a bunch of stuff in there { comment } that 's missing from the dialogue . grad c: mm - hmm . professor e: you know , it depends on the kind of research they 're doing , phd a: yeah . professor e: but it might be , uh it might be really a a pain . and , you know where it 's really gon na hurt somebody , in some way the one who said it or someone who is being spoken about , { comment } we definitely want to allow the option of it being bleeped out . but i really think we wan na make it the rare incidence . and and uh , i am just a little worried about making it so easy for people to do , and so much fun ! that they 're gon na go through and bleep out stuff . postdoc f: so much fun . professor e: and they can bleep out stuff they do n't like too , right from somebody else , as you say , you know , so `` well i did n't like what he said . `` grad c: well i do n't see any way of avoiding that . i mean , we have to provi we have promised that we would provide them the transcript and that they can remove parts that they do n't like . so that the professor e: yeah . no , no , i i i do n't grad c: the only question is professor e: you - you 've talked me into that , but i i just think that we should make it harder to do . grad c: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , i just get email , it 's all formatted , it 's all ready to go and i can just insert it . professor e: so maybe you do n't give them access to the web interface unless they really need it . so so so postdoc f: well i guess yeah . professor e: i 'm sorry so so so maybe this is a s a way out of it . postdoc f: hmm . professor e: you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but i think the issue of privacy and ease and so forth should be that uh , they get access to this if they really need it . grad c: well phd b: so you 're saying the the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . professor e: right . phd b: and then if they do n't , you 're done . if they do , then he provides them access to the the web site . grad c: well , to some extent i have to do that anyway because as i said we have to distribute passwords . professor e: w w phd b: or a printed - out form . professor e: there 's there grad c: so , professor e: y but you do n't necessarily have to distribute passwords is what i 'm saying . grad c: well , but professor e: so phd b: only if they want it . grad c: what i 'm saying is that i ca n't just email them the password because that 's not secure . so they have to call me and ask . professor e: no , no , no . but you are n't necessarily giving them right . but we do n't even necessarily need to end up distributing passwords at all . phd a:  grad c: well , we do because of privacy . we ca n't just make it openly available on the web . professor e: no , no . you 're missing the point . postdoc f: mm - hmm . professor e: we 're we 're trying i we 're trying to make it less of an obvious just l l l l uh fall off a log , to do this . postdoc f: not everyone gets a password , unless they ask for it . professor e: right ? so th so what i would see , is that first you contact them and ask them if they would like to review it for to check for the postdoc f: yeah . professor e: not just for fun , ok ? but to to check this for uh things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . um and , uh , and we should think carefully actually we should review go through how that 's worded , ok ? then , if someone uh wants to review it , uh , and i know you do n't like this , but i 'm offering this as a suggestion , is that is that we then give them a print out . and then if they say that `` i have a potential problem with these things , `` then , you you say `` ok well you might wan na hear this in context to s think if you need that , `` you issue them a password , i in the grad c: but the the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . i would much prefer to have all be automatic , they visit the web site if they want to . obviously they do n't have to . professor e: i know you 'd prefer it , but the proble grad c: yeah . professor e: we have grad c: so i think you 're thinking people are going to arbitrarily start bleeping and i just do n't think that 's gon na happen . professor e: there 's a problem with it . postdoc f: i 'm also concerned about the spirit of the of the informed consent thing . cuz i think if they feel that uh , it 's i th i th you know , if it turns out that something gets published in this corpus that someone really should have eliminated and did n't detect , then it could have been because of their own negligence that they did n't pursue that next level and get the password and do that , um , but but they might be able to argue `` oh well it was cumbersome , and i was busy and it was gon na take me too much time to trace it down `` . so it could that the burden would come back onto us . so i 'm a little bit worried about uh , making it harder for them , from the legal standpoint . professor e: well you can go too far in that direction , and you need to find somewhere between i think , postdoc f: yeah . grad c: it seems to me that sending them email , saying `` if you have an o - ok reply to this email and say ok , professor e: because uh - huh . grad c: if you have a problem with it contact me and i 'll give you a password `` , seems like is a perfectly , reasonable compromise . and if they want a printout they can print it out themselves . postdoc f: or we could print it up for them , phd a: yeah . postdoc f: i mean we could offer that but but there 's uh , another aspect to that and that is that in the informed consent form , um , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . and and i ha professor e: yeah . postdoc f: i do n't know that there 's a chance of really skipping that stage . i mean i i thought that you were maybe i misinterpreted what you said but it 's professor e: having access to it does n't necessarily mean , that having it grad c: having it . postdoc f: giving it to them . grad c: well the in professor e: right ? it just means they have the right to have it . postdoc f: ok . grad c: the consent form is right in there if anyone wants to look at it , postdoc f: alright . fine . ok . fair enough . grad c: so . professor e: yeah . grad c: d you want me to grab one ? postdoc f: sh - sh well i could i 'm closer . grad c: yeah , but you 're wired postdoc f: i could grad c: are n't you ? postdoc f: yeah . that is true . professor e: um . yeah , i mean i do n't wan na fool them , postdoc f: i do n't know professor e: i just meant that e every ev any time you say anything to anyone there is in fact a a bias that is presented , postdoc f: oh yeah yeah oh i know . professor e: right ? grad c: `` if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` professor e: of and postdoc f: yeah that 's true . yeah . grad c: `` once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . professor e: yeah . grad c: there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . `` postdoc f: hmm . well that 's more open than i realized . grad c: well , i mean it the one question is definitely clear with anything as opposed to just what you said . professor e: i phd a: yeah . professor e: yeah , uh no that it tha postdoc f: tha - that 's true . that 's more severe , but the next one says the transcript will be around . professor e: that 's right . postdoc f: and it does n't { comment } really say we 'll send it to you , or wi it 'll be available for you on the web , or anything . phd b: i think it probably leaves it open how we get it to them . professor e: i i postdoc f: at least it more often . yeah . it means also we do n't have to g to give it to them . i mean like like morgan was saying they they grad c: they just have to make sure that it is available to them . postdoc f: it 's available to them if they ask for it . professor e: yeah , ok , so . wh um i think i have an idea that may be sat may satisfy both you and me in this which is , um , it 's a it we just go over carefully how these notes to people are worded . so i i just want it to be worded in such a way where it gives the strong impre it gives very , i mean nothing hidden , v very strongly the bias that we would really like to use all of these data . grad c: right . professor e: that that we really would rather it was n't a patchwork of things tossed out , postdoc f: good . professor e: that it would be better for , um , our , uh , field if that is the case . but if you really think something is gon na and i do n't think there 's anything in the legal aspects that that is hurt by our expressing that bias . postdoc f: great . great , great . professor e: and then then my concern about which postdoc f: yeah . i agree . professor e: you know you might be right , it may be it was just paranoia on my part , uh but people just see i 'm @ @ worried about this interface so much fun that people start bleeping stuff out { comment } just as just because they can . grad c: it 's just a check box next to the text , it 's not any fun at all . professor e: yeah . well i do n't know . i kind of had fun when you played me something that was bleeped out . you know . grad c: well , but they wo n't get that feedback . professor e: i grad c: all no because it does n't automatically bleep it at the time . professor e: oh they wo n't ? grad c: it just sends me professor e: oh good . so you have n't made it so much fun . grad c: right . professor e: oh good . grad c: it just sends me the time intervals . professor e: ok , grad c: and then at some point i 'll incorporate them all and put bleeps . i mean i do n't wan na have t ha do that yet until we actually release the data professor e: yeah . grad c: because um , then we have to have two copies of every meeting and we 're already short on disk space . professor e: yeah . grad c: so i i wan na i just keep the times until we actually wan na release the data and then we bleep it . professor e: ok . alright , so i think yeah so if we have if i again let 's you know , sort of circulate the the wording on each of these things and get it right , grad c: well since you seem to feel heart uh , strongest about it , would you like to do the first pass ? professor e: but but ok . uh , fair enough . turn about is fair play , postdoc f: al - also it ther there is this other question , the legal question that that adam 's raised , uh about whether we need a concrete signature , or email c i suffices or whatever professor e: sorry . grad c: yeah . postdoc f: and i do n't know how that works . i there 's something down there about `` if you agree to `` professor e: i 'm i 'm i 'm i thought i i thought about it with one of my background processes grad c: i do n't think so . professor e: and i uh it 's uh it 's uh , it 's fine to do the email . postdoc f: ah . fine . grad c: yeah because thi th they 're signing here that they 're agreeing to the paragraph which says `` you 'll be given an opportunity . `` professor e: ok . postdoc f: good . ok . professor e: yeah . grad c: and so i do n't think they need another signature . professor e: and well and furthermore i it 's now fairly routine in a lot of arrangements that i do with people on contracts and so forth that that uh if it 's if it 's that sort of thing where you 're you 're saying uh `` ok i agree , we want eighty hours of this person at such - and - such amount , and i agree that 's ok , `` uh if it 's a follow up to some other agreement where there was a signature it 's often done in email now grad c: right . professor e: so it 's it 's ok . postdoc f: great . professor e: um . grad c: so i guess i probably should at the minimum , think about how to present it in a printed form . i 'm not really sure what 's best with that . the problem is a lot of them are really short , postdoc f: well grad c: and so i do n't necessarily wan na do one per line . but i do n't know how else to do it . postdoc f: well i s i also have this i i think it 's nice you have it uh , viewab her { comment } hearable on the on the web for those who might wonder about um , the non nonverbal side , i mean i i agree that our bias should be as as expressed here , and but i i think it 's nice that a person could check . cuz sometimes you know you the words on a on the page , come out soun sounding different in terms of the social dynamics if they hear it . grad c: hmm . professor e: mm - hmm . mm - hmm . postdoc f: and i realize we should n't emphasize that people { comment } you know , should n't borrow trouble . what it comes down to but grad c: yeah i think actually my opinion probably is that the only time someone will need to listen to it is if the transcript is uh not good . you know , if if there are lots of mumbles and parentheses and things like that . postdoc f: oh , you know , or what if there was an error in the transcript that did n't get detected and there was a whole uh i segment a against some personal i th grad c: right . that was all mumbled ? phd a: yeah . grad c: i think microsoft is postdoc f: yeah exactly phd a: oh , grad c: sorry transcribers . postdoc f: or or even or even { comment } there was a a line you know about how `` hmm - mmm - mmm { comment } bill gates duh - duh - duh - duh . `` professor e: yeah . postdoc f: but but it was all the words were all visible , but they did n't end up i some there was a slip in the transcript . phd a: oh , god . grad c: they 're gon na hate this meeting . phd a: yeah . postdoc f: yeah that 's true . grad c: actually liz will like it . you know , but . professor e: liz will like it . we had a pretty strong disagreement going there . grad c: yep , yep , that 's right . professor e: yeah . postdoc f: yeah . so i do n't know . i mean , i i guess we 're assuming that the transcript is a close enough approximation and that that my double checking will be so close to absolutely perfect that it that nothing will slip by . grad c: mm - hmm . professor e: but it the some something might sometime , and they uh if if it 's something that they said , they might i i i mean , you might be very accurate in putting down what they actually said , postdoc f: mm - hmm . professor e: but , when they hear it , themselves , they may hear something different because they know what they meant . postdoc f: i do n't know how to notate that . phd b: sarcasm , postdoc f: yeah , that 's right . phd b: how do you how do you indicate sarcasm ? postdoc f: yeah that 's right . professor e: no , i 'm serious . so the so i the so we might we might get some feedback from people that such - and - such was , you know , not not really what i said . grad c: yeah . well that would be good to get , definitely . professor e: yeah , but , yeah , sure . grad c: just for corrections . professor e: yeah . grad c: so um , in terms of password distribution , i think phone is really the only way to do it , phone and in person . or mail , physical mail . postdoc f: yeah . or if for leave it on their voice mail . phd b: any sub - word level thing . grad c: any sub - wor yeah , ok . i mean you could do it with pgp or things like that but it 's too complex . postdoc f: you know i just realized something , which is of e th this question about the uh the possible mismatch of i mean i well , and actually also the lawyer saying that um , we should n't really have them have the people believing that they will be cleared by our checks . you know ? professor e: mm - hmm . postdoc f: i mean . so it 's like i in a way it 's it 's nice to have the responsibility still on them to listen to the tape and and hear the transcript , to have that be the professor e: well yeah , but you ca n't dep i mean , most people will not wan na take the time to do that , though . postdoc f: yeah , ok , fair enough . and they 're s they 're absorbing the responsibility themselves . professor e: and they they have to postdoc f: so it 's not it 's not um yeah , good . professor e: but i mean if you were at a meeting , and and you you do n't think , at least , that you said anything funny and the meeting was about , you know , some some funny thing about semantics or something , or uh grad c: you probably wo n't listen to it . professor e: yeah . postdoc f: it is true that tec that the content is technical , i and so i and we 're not having these discussions which professor e: yeah . postdoc f: i i mean , when i listen to these things , i do n't find things that are questionable , in other people 's speech or in my own . professor e: yeah . you would think it would be rare , postdoc f: just it should be very rare . professor e: i mean we 're not talking about the energy crisis or something , people have postdoc f: yeah . yeah , ok . grad c: how about them energy crises . professor e: yeah . i think we 're uh grad c: done ? professor e: kind of done . actually , i was gon na di - did you have anything n that 's going on , or grad d: not really . no . um , my project is going along but um , i 'm really just here to um fill the project uh the overall progress . i do n't really have anything specific to to talk about . professor e: yeah . that 's fine . i just did n't wan na go by you , if you had something . grad d: oh , ok . professor e: you do n't have anything to say . phd b: no . professor e: nah . grad c:  professor e: transcribers , he was rattling the b marbles in his brain back and forth just then this this grad c: shall we do digits ? professor e: oh yeah . grad c: um , oh by the way i did find a bunch grad d: it um grad c: uh , we should count out how many more digits to forms do we have back there ? phd b: there were quite a few . uh . grad c: that 's what i thought . i f i was going through them all and i found actually a lot filed in with them , that were blanks , that no one had actually read . phd b: mmm . grad c: and so we still have more than i thought we did . phd b: oh good . grad c: so , we have a few more digits before we 're done . phd b: you know having this headset reminds me of like working at burger king or something . grad c: oops . postdoc f: oh , did you do that ? phd a: burger king grad c: i 'd like a burger with that , phd b: no i never did . grad c: do you want fries with that ? professor e: wow . phd b: but i feel like i could now . grad c: and { pause }","output":"efforts will be made to ensure that recording conventions are consistent across icsi , the university of washington , and sri ."},{"instruction":"what \u2019 s the current state of transcriptions ?","input":"professor e: alright . grad c: so are you professor e: so . grad c: are we going ? professor e: it is uh , must be february fifteenth . postdoc f: yeah . grad c: yu i think the date 's written in there , yep . and actually if everyone could cross out the r - nine next to `` session `` , and write mr eleven . professor e: yeah . yeah . we did n't have a front - end meeting today . grad c: and let 's remember also to make sure that one 's { comment } gets marked as unread , unused . professor e: ok . phd a: mr eleven . grad c: mr eleven . postdoc f: that sounds like a spy code . professor e: mmm . ok . so . grad c: there 's lots of clicking i 'm sure as i 'm trying to get this to work correctly . professor e: agenda . any agenda items today ? grad c: i wan na talk a little bit about getting how we 're gon na to get people to edit bleeps , parts of the meeting that they do n't want to include . what i 've done so far , and i wan na get some opinions on , how to how to finish it up . professor e: ok . postdoc f: i wan na ask about um , some aud audio monitoring on some of the um well some of the equipment . in particular , the well uh , that 's just what i wan na ask . professor e: ok audio monitoring , jane . postdoc f: ba - based on some of the tran uh i in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact in fact this one i 'm talking on is one of of the ones that showed up in one of the meetings , grad c: oh really . postdoc f: so i phd b: `` spikes `` , you mean like uh , instantaneous click type spikes , or ? postdoc f: mm - hmm . yeah . phd a: spikes ? grad c: clicks . postdoc f: yeah . professor e: hmm . postdoc f: yeah . phd b: huh . postdoc f: and i do n't know what the e electronics is but . grad c: yeah . postdoc f: yeah . grad c: well , i think it 's phd a: touching . grad c: uh , it it could be a number of things . phd a: yeah . grad c: it could be touching and fiddling , and the other thing is that it could the fact that it 's on a wired mike is suspicious . it might be a connector . postdoc f: oh , ok . well maybe then we do n't really have to talk about that as an phd b: you could try an experiment and say `` ok , i 'm about to test for spikes `` , postdoc f: i i take that off the agenda . phd b: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . grad c: yeah . right . phd b: `` come get me when you transcribe this and see if there 's spikes . `` postdoc f: oh that professor e: um . postdoc f: well , ok . phd b: no i 'm just professor e: i mean , were this a professional audio recording , what we would do { comment } what you would do is in testing it is , you would actually do all this wiggling and make sure that that that things are not giving that kind of performance . and if they are , then they ca n't be used . grad c: right . professor e: so . um . let 's see . i guess i would like to have a discussion about you know where we are on uh , recording , transcription you know , basically you know where we are on the corpus . postdoc f: good . professor e: and then um , the other thing which i would like to talk about which is a real meta - quest , i think , deal is , uh , agendas . so maybe i 'll i 'll start with that actually . uh , um . andreas brought up the fact that he would kinda like to know , if possible , what we were gon na be talking about because he 's sort of peripherally involved to this point , and if there 's gon na be a topic about discussion about something that he uh strongly cares about then he would come and and i think part of part of his motivation with this is that he 's trying to help us out , in the because of uh the fact that the meetings are are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing grad c: mmm . professor e: and and i 'm sure help out his own time . by not showing up if it 's a meeting that he 's he 's so , uh in order i 'd i think that this is a wish on his part . uh . it 's actually gon na be hard because it seems like a lot of times uh things come up that are unanticipated and and grad c: right . professor e: but um , we could try anyway , uh , do another try at coming up with the agenda uh , at some point before the meeting , uh , say the day before . grad c: well maybe it would be a good idea for one of us to like on wednesday , or tuesday send out a reminder for people to send in agenda items . phd a: yeah . professor e: ok . you you wan na volunteer to do that ? grad c: sure . professor e: ok . alright so we 'll send out agenda request . grad c: let me professor e: uh . phd b: that 'll be i think that 'll help grad c: i 'll put that on my spare brain or it will not get done . phd b: that 'll help a lot , actually . professor e: yeah , i have to tell you for the uh for the admin meeting that we have , lila does that um every time before an admin meeting . and uh , she ends up getting the agenda requests uh , uh ten minutes before the meeting . but but { comment } but . uh . { comment } but we can try . maybe it 'll work . phd b: mmm . grad c: yeah . maybe . weirder things have happened . professor e: yeah . postdoc f: i 'm wondering if he were to just , uh , specify particular topics , i mean . maybe we 'd be able to meet that request of his a little more . phd b: i would i would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him . grad c: well then professor e: yeah . actually it this this maybe brings up another topic which is um so we 're done with that topic . the other topic i was thinking of was the sta status on microphones and channels , and all that . grad c: yeah , actually i i was going to say we need to talk about that too . professor e: yeah . why why do n't we do that . grad c: ok . um , the new microphones , the two new ones are in . um . and they are being assembled as we speak , i hope . and i did n't bring my car today so i 'm gon na pick them up tomorrow . um , and then the other question i was thinking about is well , a couple things . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , phd a:  grad c: and get people 's opinions on on what they think of them . um , then the other question i had is maybe we should get another wireless . another wireless setup . i mean it 's expensive , but it does seem to be better than the wired . professor e: so how many channels do you get to have in a wireless setup ? grad c: um , well , i 'm pretty sure that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and apparently you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . professor e: so , um . grad c: and so , you know it 's still , it 's fifteen minus six . professor e: so let 's see we grad c: right ? so we could have up to nine . professor e: and right now we can have up to six . grad c: right . and we have five , we 're getting one more . professor e: yeah . grad c: and it 's um , about nine hundred dollars for the base station , and then eight hundred per channel . professor e: oh . so yeah so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . grad c: right . professor e: oh , we should do it . grad c: ok . ok , so i 'll look into how you daisy - chain them and and then just go ahead and order them . professor e: yeah . yeah . phd b: i do n't quite understand how that how that works , . if so we 're not increasing the number of channels . ok . grad c: no , we 're just replacing the wired the two wired that are still working , phd b: ok . i see . grad c: along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless . professor e: yeah . phd b: three wireds work , professor e: basically we found phd b: right ? grad c: i i guess three wireds work , yeah . phd b: yeah . yeah . professor e: yeah . but we 've had more problems with that . grad c: yep . professor e: and that sort of bypasses the whole the whole jimbox thing and all that . grad c: right . professor e: and so um , we we seem to have uh , a reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . grad c: right . professor e: that seems to be the key issue . grad c: everyone 's battery ok ? phd b: i checked them this morning , they should be . grad c: ok . professor e: yeah . um , that 's the only thing with them . but the quality seems really good and um i heard from uw that they 're they 're uh very close to getting their , uh setup purchased . they 're they 're they 're buying something that you can just sort of buy off the shelf . grad c: well we should talk to them about it because i know that sri is also in the process of looking at stuff , and so , you know , what we should try to keep everyone on the same page with that . professor e: yeah . phd b: sri , really ? grad c: yeah . phd b: oh . grad c: they got sa apparent well , maybe this needs to be bleeped out ? i have no clue . professor e: uh , i do n't know . grad c: i do n't know how much of it 's public . professor e: probably we should n't probably we should n't talk about funding stuff . grad c: right . professor e: yeah . but anyway there 's there 's there 's uh , uh other activities that are going on there and and uh and nist and uw . so . um . but but yeah i thin i think that at least the message we can tell other people is that our experience is is quite positive with the sony , grad c: right . professor e: uh , radio - mikes . now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering or something , right ? grad c: uh , no , we 're having the them do it . professor e: no ? grad c: so it 's so hand - soldering it , but i 'm not doing it . professor e: oh . grad c: so , they they charge professor e: ok . nothing against you and your hand - soldering grad c: right . professor e: but grad c: you 've never seen my hand - soldering . but uh , a as i said they 're coming in . professor e: uh , ok , so that 's being done professionally and grad c: i i mean professor e: yeah . grad c: yeah . i mean . professor e: yeah . grad c: as professionally as i guess you can get it done . professor e: well , it could if they do a lot of it , it 's grad c: i mean i it 's just their repair shop . right ? their maintenance people . professor e: well , we 'll see what it it 's like . grad c: yep . professor e: that tha that can be quite good . th - this yeah , ok . good . yeah . so let 's go with that . grad c: and , i mean we 'll see , tomorrow , you know , what it looks like . professor e: uh , yeah . so , um , uh , dave is n't here but he was going to start working on some things with the digits . uh , so he 'll be interested in what 's going on with that . i guess was the decision last time was that the the uh transcribers were going to be doing stuff with the digits as well ? has that started , or is that ? postdoc f: mm - hmm . yeah . uh , it would be to use his interface and i was going to meet with him today about that . grad c: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so i did the all that last week . so all the all the forms are now on the computer . and uh , then i have a bunch of scripts that we 'll read those and let the uh transcribers use different tools . and i just want to talk to jane about how we transition to using those . postdoc f: mm - hmm . so he has a nice set up that they it w it will be efficient for them to do that . professor e: ok . grad c: i i do n't think it 'll take too long . professor e: so anyway grad c: so , you know , just uh , a matter of a few days i suspect . professor e: so anyway i think we we have at least one uh , user for the digits once they get done , which will be dave . grad c: right . i 've already done five or six sets . postdoc f: ok . grad c: so if he wanted to , you know , just have a few to start with , he could . you know , and i also have a bunch of scripts that will , like , generate p - files and run recognition on them also . professor e: yeah , he might he might be asking right . ok . uh , is dave i do n't know if dave is on the list , if he 's invited to these meetings , uh if he knows . postdoc f: i do n't tend to get an invitation myself for them even . phd a: no , no . grad c: uh , we do n't have a active one but i 'll make sure he 's on the list . postdoc f: yeah . should we call him ? i mean is he d is he definitely not available today ? professor e: i do n't know . postdoc f: should i call his office and see ? phd a: he was in . grad c: i mean , he 's still taking classes , so uh , he may well have conflicts . professor e: uh , well i it 's uh phd a: yeah . professor e: yeah . phd a: yeah , he was in s postdoc f: he was n't there at cof professor e: yeah , so this might be a conflict for him . phd a: yeah . professor e: yeah . postdoc f: ok . professor e: ok . uh , so . grad c: yeah did n't he say his signal - processing class was like tuesdays and thursdays ? phd a: i think he has a class . yeah . phd b: yeah . he might have . grad c: oh well , whatever . grad d: you talking about david gelbart ? professor e: oh , ok . phd a: yeah . phd b: yeah . grad c: yeah . professor e: yeah . postdoc f: yes . grad d: yeah , i think he 's taking two twenty - five a which is now . phd b: yeah . grad d: so . professor e: yeah . postdoc f: ok . professor e: ok . so , that 's why we 're not seeing him . ok . uh , transcriptions , uh , beyond the digits , where we are , and so on . postdoc f: ok . professor e: and the and the recordings also , postdoc f: um professor e: just where we are . yeah . postdoc f: well , so um , should we we do n't wan wan na do the recording status first , or ? grad c: well , we have about thirty - two hours uh as of , i guess a week and a half ago , so we probably now have about thirty - five hours . professor e: and and that 's that 's uh how much of that is digits ? it 's uh that 's including digits , grad c: that 's including digits . professor e: right ? grad c: i have n't separated it out so i have no clue how much of that is digits . professor e: so yeah . so anyway there 's at least probably thirty hours , or something of there 's got to be more than thirty hour phd a: mmm . grad c: of of non - digits ? professor e: i it could n't of of non - digits . grad c: yeah , absolutely . i mean , the digits do n't take up that much time . professor e: yeah , yeah . ok . postdoc f: ok , and the transcribers h i , uh , do n't have the exact numbers , but i think it would come to about eleven hours that are finished uh , transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what i mean by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that uh , liz requested in terms of um , um in terms of having a s a systematic handling of numbers , and acronyms which i had n't been specific about . um , for example , i they 'll say uh `` ninety - two `` . and you know , so how you could grad c: nine two , postdoc f: e exactly . grad c: right . postdoc f: so if you just say `` nine two `` , the there are many s ways that could have been expressed . an - and i just had them i i mean , a certain number of them did put the words down , but now we have a convention which also involves having it followed by , um , a gloss th and things . phd b: you know , jane ? grad c: mm - hmm . phd b: um , one suggestion and you may already be doing this , but i 've noticed in the past that when i 've gone through transcriptions and you know in in order to build lexicons and things , if you um , just take all the transcriptions and separate them into words and then alphabetize them , { comment } a lot of times just scanning down that list you 'll find a lot of inconsistencies and mis grad c: misspelled . phd a: yeah . postdoc f: you 're talking about the type token frequency listings , and i use those too . y you mean just uh on each on each line there 's a one word right ? it 's one token from the from the corpus . phd b: mm - hmm . mm - hmm . postdoc f: yeah , those are e extremely efficient and i and i i agree that 's a very good use of it . phd b: oh so you already have that , ok . postdoc f: well that 's that 's a way that 's you know , the spell - check basically does that but but in addition yes , that 's that 's exactly the strategy i wan na do in terms of locating these things which are you know colloquial spoken forms which are n't in the lexicon . phd b: mm - hmm . cuz a lot of times they 'll appear next to each other , and uh , postdoc f: exactly . and then you ca then you can do a s phd a: yeah . phd b: i in alphabetized lists , they 'll appear next to each other and and so it makes it easier . postdoc f: absolutely . i agree . that 's a very good that 's a very good uh , suggestion . and that was that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . i did n't get to that point but so there are numbers , then there are acronyms , and then um , there 's a he she wants the uh , actually a an explicit marker of what type of comment this is , so i curly b inside the curly brackets i 'm gon na put either `` voc `` for vocalized , like cough or like laugh or whatever , `` nonvoc `` for door - slam , and `` gloss `` for things that have to do with if they said a s a spoken form with this m this pronunciation error . grad c: right . postdoc f: i already had that convention phd b: oh that 's great . postdoc f: but i i have n't been asking these people to do it systematically cuz i think it most ha most efficiently handled by uh by a a filter . that was what i was always planing on . so that , you know you get a whole long list exactly what you 're saying , you get a whole list of things that say `` curly bracket laugh curly bracket `` , phd b: mm - hmm . postdoc f: then y you know it 's it 's you you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in sort of a voc space , phd b: yeah . postdoc f: so man so many ways that error prone . phd b: right . right . postdoc f: so , um , um i 'm i 'm going to convert that via a filter , into these tagged uh , subcategorized comments , and same thing with you know , we see you get a subset when you do what you 're saying , phd b: mm - hmm . postdoc f: you end up with a s with uh , you 're collapsing across a frequency you just have the tokens phd b: mm - hmm . postdoc f: and you can um , have a filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , you know i mean , jus grad c: you do n't know what they could be . phd b: yeah . postdoc f: yeah now timit 's clear um and plp is clear but uh there are things that are not so well known , in or or have variant u u uses like the numbers you can say `` nine two `` or you can say `` ninety - two `` , grad c: so how are you doing the postdoc f: and uh i 'd handle the numbers individually . grad c: how are you doing the uh , acronyms so if i say pzm what would it appear on the transcript ? postdoc f: it would be separate the letters would be separated in space grad c: ok . postdoc f: and potentially they 'll have a curly bracket thing afterwards e but i 'm not sure if that 's necessary , clarifying what it is , grad c: mm - hmm . postdoc f: so gloss of whatever . grad c: right . postdoc f: i do n't know if that 's really necessary to do that . maybe it 's a nice thing to do because of it then indicating this is uh , a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's uh the you know , { comment } uh enumerated , or i grad c: mm - hmm . postdoc f: it 's not a good way of saying but it 's it 's the specific uh way of stating these these letters . grad c: right . so it sounds good . postdoc f: and so anyway , the clean those are those things and then channelized is to then um , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . phd a: yeah . grad c: right . postdoc f: and uh , thilo had a e e a breakthrough with this this last week in terms of getting the channel - based um uh s s speech - nonspeech segmentation um , up and running and i have n't i have n't been able to use that yet cuz i 'm working s re this is my top priority get the data clean , and channelized . phd a: i actually gave grad c: have you also been doing spot checks , jane ? postdoc f: oh yes . grad c: okay , good . postdoc f: well you see that 's part of the cleaning process . i spent um actually um i have a segment of ten minutes that was transcribed by two of our transcribers , grad c: oh good . good . postdoc f: and i went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas i i left them discretion at commas . grad c: right . postdoc f: uh and so because it 's not part of our st of our ne needed conventions . professor e: mm - hmm . postdoc f: and um , and so they 'll be a difference in commas , but it 's word - by - word the same , in in huge patches of the data . and i have t ten minute stretch where i can where i can show that . and and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . so um , the one i i the colloquial speech person picked up `` gobbledy - gook `` . phd b: hmm . postdoc f: and the other one did n't . and on this side , this one 's picking up things like `` neural nets `` and the one that 's good on the sp o on th the vocabulary on the uh colloquial did n't . grad c: right . phd b: when for the person who missed `` gobbledy - gook `` what did they put ? postdoc f: it was an interesting approximation , put in parentheses , cuz i have this convention that , i if they 're not sure what it was , they put it in parentheses . phd b: oh . postdoc f: so they tried to approximate it , but it was phd b: oh good . postdoc f: it was spelled gabbl phd b: sort of how it sounds . yeah . postdoc f: yes . more of an attempt to i mean apparently it was very clear to her that these the a this this was a sound these are the sounds , grad c: it was a technical term that she did n't recognize , phd b: yeah . postdoc f: but yeah . but she knew that she did n't know it . maybe it was a technical ter exactly . but she even though her technical perception is just really uh you know i 've i 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses grad c: right . postdoc f: then cuz `` neural nets `` and oh she has some things that are oh `` downsampled `` , she got that right . phd b: hmm . postdoc f: and some of these are rather uh unexpected . grad c: obscure , yeah . postdoc f: but ch ten solid uh m ch s chunk of ten solid minutes where they both coded the same data . professor e: and and again the main track that you 're working with is elev eleven hours ? postdoc f: and um professor e: is that right ? postdoc f: yes exactly . professor e: yeah , ok . postdoc f: and that 's part of this eleven hours . professor e: is that is that that including digits ? yeah . postdoc f: yes it is . professor e: so let 's say roughly ten hours or so of postdoc f: mm - hmm . professor e: i mean it 's probably more than that but but with of of non - digits . phd a: yeah . postdoc f: it 'd be more than that because i my recollection is the minutes that da digits do n't take more than half a minute . per person . professor e: oh , ok . postdoc f: but um the the total set that i gave them is twelve hours of tape , professor e: oh , i see . postdoc f: but they have n't gotten to the end of that yet . professor e: oh , i see . postdoc f: so they 're still working some of them are two of them are still working on completing that . yeah . phd b: boy , they 're moving right along . professor e: yeah . postdoc f: yeah . they are . mm - hmm . they 're very efficient . there 're some who have more hours that they devote to it than others . phd b: mm - hmm . professor e: mm - hmm . postdoc f: yeah . professor e: so what what what 's the deal with with your phd a: the channel u thing ? professor e: yeah . phd a: oh , it 's just uh , i ran the recognizer uh , the { comment } speech - nonspeech detector on different channels and , it 's just in uh in this new multi - channel format and output , and i just gave one one meeting to to liz who wanted to to try it for for the recognizer professor e: oh , i see . phd a: as uh , apparently the recognizer had problems with those long chunks of speech , which took too much memory or whatever , professor e: right . phd a: and so she she will try that i think professor e: yeah . phd a: and i 'm i 'm working on it . so , i hope grad c: is this anything different than the hmm system you were using before ? professor e: yeah . phd a: no . uh , i mmm , use some some different features but not not grad c: mm - hmm . phd a: the basic thing is this hmm base . grad c: so there 's still no no knowledge using different channels at the same time . phd a: there is some , uh as the energy is normalized across channels grad c: you know what i mean ? across all of them . phd a: yeah . grad c: ok . phd a: so . but basically that 's one of the main changes . grad c: mm - hmm . professor e: mm - hmm . what are some of the other features ? besides the energy ? you said you 're trying some different features , or something . phd a: oh i just uh mmm , i just use um our loudness - based things now as they before there were they were some in in the log domain and i i changed this to the to the professor e: cu - cube root ? phd a: yeah . to no , i changed this to the to the to the loudness thingy with the with the grad c: hmm . professor e: ah . phd a: how do you call it ? i 'm not sure . with the , uh professor e: fletcher munson ? no . phd a: i 'm not sure about the term . professor e: oh , ok . phd a: uh , i 'll look it up . and say it to you . professor e: yeah , alright . phd a: uh , ok , and yeah . that 's that 's basically the the the thing . yeah , and i and i tried t to normalize uh uh the features , there 's loudness and modified loudness , um , within one channel , professor e: ok . phd a: because they 're , yeah to to be able to distinguish between foreground and background speech . and it works quite well . but , not always . professor e: uh - huh . uh - huh . phd a: so . professor e: ok . grad c: good . professor e: um , let 's see . i think the uh were were you basically done with the transcription part ? so i guess the next thing is this uh bleep editing . grad c: right . so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they do n't want . so i 've written a bunch of tools that will generate web pages , uh with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's a form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , uh , some of the questions on this is what do we do about the privacy issue . and so i thought about this a little bit and i think the best way to do it is every participant will have a password , professor e: yeah . grad c: a single password . each person will have a single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password . professor e: i i ca n't help but wonder if this is maybe a little more elaborate than is needed . i mean if people have uh , i mean , for me i would actually want to have some pieces of paper that had the transcription and i would sort of flip through it . and then um if i thought it was ok , i 'd say `` it 's ok `` . grad c: mm - hmm . professor e: and , i uh i mean it depends how this really ends up working out , but i guess my thought was that the occasion of somebody wondering whether something was ok or not and needing to listen to it was gon na be extremely rare . grad c: right , i mean so th th th the fact that you could listen to it over the web is a minor thing that i had already done for other reasons . professor e: ok . grad c: and so that that 's a minor part of it , i just wanted some web interface so that people you did n't actually have to send everyone the text . so m what my intention to do is that as the transcripts become ready , um i would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just uh , tell them , `` here 's the web page `` , um , `` you need a password `` . so th th question number one is how do we distribute the passwords , and question number two is how else do we wan na provide this information if they want it . professor e: that 's i think what i was sort of saying is that if you just say `` here is a here is `` i mean this maybe it sounds paleolithic but but i just thought if you handed them some sheets of paper , that said , uh , `` here 's what was said in this transcription is it ok with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's ok `` . grad c: i think that um there are a subset of people who will want printouts that we can certainly provide . professor e: and then they 'd hand it back to you . grad c: but certainly i would n't want a printout . these are big , and i would much rather be ha be able to just sit and leaf through it . professor e: you find it easier to go through a large i mean how do you read books ? grad c: well i certainly read books by hand . but for something like this , i think it 's easier to do it on the web . professor e: really ? i mean , it grad c: cuz you 're gon na get , you know , if i i 'm i 'm in a bunch of meetings and i do n't wan na get a stack of these . i wan na just be able to go to go to the web site { comment } and visit it as i want . professor e: going to a web site is easy , but flipping through a hundred pounds a hundred pages of stuff is not easy on the web . grad c: well , i do n't think it 's that much harder than , paper . so . professor e: really ? postdoc f: i have one question . so are you thinking that um the person would have a transcript and go strictly from the transcript ? because i i do think that there 's a benefit to being able to hear the tone of voice and the professor e: so here 's the way i was imagining it , and maybe i 'm wrong , postdoc f: yeah . professor e: but the way i imagined it was that um , the largest set of people is gon na go `` oh yeah , i did n't say anything funny in that meeting just go ahead , where 's the where 's the release ? `` and then there 'll be a subset of people , right ? ok there 's i mean think of who it is we 've been recording mostly . phd a: yeah . professor e: ok there 'll be a subset of people , who um , will say uh `` well , yeah , i really would like to see that . `` and for them , the easiest way to flip through , if it 's a really large document , i mean unless you 're searching . searching , of course , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something or something like that , phd a: yeah . professor e: but see then we 're getting more elaborate with this thing . um if if uh you do n't have search mechanisms you just sort of have this really , really long document , i mean whenever i 've had a really , really long document that it was sitting on the web , i 've always ended up printing it out . i mean , so it 's it 's i mean , you you 're you 're not necessarily gon na be sitting at the desk all the time , you wan na figure you have a train ride , and there 's all these situations where where i i mean , this is how i was imagining it , anyway . and then i figured , that out of that group , there would be a subset who would go `` hmm you know i 'm really not sure about this section here , `` and then that group would need it s it seems like i if i 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that uh , now we have to worry about privacy , grad c: well , no fre for the most professor e: we have to worry about all these passwords , for different people grad c: for the most frequent case they just say `` it 's ok `` and then they 're done . and i think almost everyone would rather do that by email than any other method . professor e: mm - hmm . postdoc f: the other thing too is it seems like professor e: um , yeah , that 's true . postdoc f: go ahead . grad c: i mean , cuz you do n't have to visit the web page if you do n't want to . phd a: yeah . professor e: i guess yeah , i guess we do n't need their signature . i guess an email ok is alright . grad c: oh that was another thing i i had assumed that we did n't need their signature , that it that an email approval was sufficient . but i do n't actually know . phd b: are are people going to be allowed to bleep out sections of a meeting where they were n't speaking ? grad c: yes . if someone feels strongly enough about it , then i i i think they should be allowed to do that . postdoc f: i also mm - hmm . phd b: so that means other people are editing what you say ? professor e: uh i do n't know about that . grad c: yeah . phd b: i do n't know if i like that . grad c: well , the only other choice is that the person would say `` no , do n't distribute this meeting at all `` , and i would rather they were able to edit out other people then just say `` do n't distribute it at all `` . professor e: but th what they signed in the consent form , was something that said you can use my voice . grad c: well , but if if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient . professor e: right ? yeah . yeah , but that 's our decision then . right ? grad c: um , i do n't think so . i mean , because if i object to the conversation . professor e: i think it is . grad c: if i say `` we were having a conversation , and i consider that conversation private , `` and i consider that your side of it is enough for other people to infer , i wan na be able to bleep out your side . postdoc f: the i agree that the consent forms were uh , i cons agree with what adam 's saying , that um , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or did n't say them . professor e: i see . ok , well , if that 's what it said . postdoc f: and the other thing is from the standpoint of the l of the l i 'm not a law lawyer , but it strikes me that uh , we would n't want someone to say `` oh yes , i was a little concerned about it but it was too hard to access `` . so i think it 's kind of nice to have this facility to listen to it . now in terms of like editing it by hand , i mean i think it 's i some people would find that easier to specify the bleep part by having a document they edited . but but it seems to me that sometimes um , you know i if a person had a bad day , and they had a tone in their voice that they did n't really like , you know it 's nice it 's nice to be able to listen to it and be sure that that was ok . grad c: i mean i can certainly provide a printable version if people want it . um . professor e: um i mean it 's also a mixture of people , i mean some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not . grad c: yep . professor e: others would consider it this uh a a set of skills that they would have to gain . you know ? grad c: well i think most of the people in the meetings are the former . professor e: it depends on what meetings . postdoc f: that 's true . phd b: so far . grad c: so . professor e: in the meetings so far , yeah . grad c: yep . professor e: but we 're trying to expand this , right ? grad c: right . professor e: so i i i actually think that paper is the more universal thing . grad c: and that well , but if they want to print it out that 's alright . postdoc f: mm - hmm . yeah . grad c: i think everyone in the meeting can access the web . professor e: no , i think we have to be able to print it out . it 's not just if they want to print it out . i i think grad c: ok , so does that mean that i ca n't use email ? or what ? postdoc f: cuz you could send it through email you 're thinking . professor e: i i th grad c: well , i do n't think i professor e: well we there was this grad c: well i do n't think we can send the text through email because of the privacy issues . professor e: no . postdoc f: good . for security ? phd a: yeah . postdoc f: yeah , ok good . professor e: right . grad c: um . so giving them , you think a web site to say , `` if you wan na print it out here it is `` , is not sufficient ? postdoc f: good point . phd a: yeah . i professor e: certainly for everybody who 's been in the meetings so far it would be sufficient . grad c: yeah , i 'm just thinking for people that that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them . professor e: i 'm just wondering about postdoc f: you could mail it to them . phd a: yeah . postdoc f: get an a mailing address . grad c: equivalent . phd a: but postdoc f: but i think it 's easier to drop in the box . phd a: just put the button on on the web page which say `` please send me the the scripts `` . grad c: that 's right . postdoc f: oh that 's interesting . phd a: yeah . phd b: what um when you display it on the web page , what are what are you showing them ? utterances , or ? grad c: mm - hmm . phd b: and so can they bleep within an utterance ? grad c: no . whole utterances only . phd b: whole utterances . grad c: and that was just convenience for my sake , that it 's uh , uh it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way i can just delete an entire line out of a transcript file rather than have to do it by hand . professor e: there 's another aspect to this which maybe is part of why this is bothering me . um , i think you 're really trying very hard to make this as convenient as possible for people to do this . phd b: mmm . grad c: i mean that 's why i did the web form , because for me that would be my most convenient . professor e: i i i understand . phd b: i know where you 're going . professor e: i think that 's the bad idea . grad c: oh . professor e: see because you 're gon you 're uh really . you 're gon na end up with all these little patchy things , whereas really what we want to do is have the the the bias towards letting it go . because nob you know it there was a one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gon na get hurt . nobody 's being l libeled . you know , this is this we 're we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gon na end up encouraging a headache . that i think that 's i 'm sort of psyching myself out here , i i 'm trying to uh grad c: i guess i do n't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out . professor e: but i i think that 's well , it 's grad c: so . phd b: i think what morgan 's saying is the easier it is , the more is gon na be bleeped . professor e: but i and and it really depends on what kind of research you 're doing . i think some researchers who are gon na be working with this corpus years from now are really gon na be cursing the fact that there 's a bunch of stuff in there { comment } that 's missing from the dialogue . grad c: mm - hmm . professor e: you know , it depends on the kind of research they 're doing , phd a: yeah . professor e: but it might be , uh it might be really a a pain . and , you know where it 's really gon na hurt somebody , in some way the one who said it or someone who is being spoken about , { comment } we definitely want to allow the option of it being bleeped out . but i really think we wan na make it the rare incidence . and and uh , i am just a little worried about making it so easy for people to do , and so much fun ! that they 're gon na go through and bleep out stuff . postdoc f: so much fun . professor e: and they can bleep out stuff they do n't like too , right from somebody else , as you say , you know , so `` well i did n't like what he said . `` grad c: well i do n't see any way of avoiding that . i mean , we have to provi we have promised that we would provide them the transcript and that they can remove parts that they do n't like . so that the professor e: yeah . no , no , i i i do n't grad c: the only question is professor e: you - you 've talked me into that , but i i just think that we should make it harder to do . grad c: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , i just get email , it 's all formatted , it 's all ready to go and i can just insert it . professor e: so maybe you do n't give them access to the web interface unless they really need it . so so so postdoc f: well i guess yeah . professor e: i 'm sorry so so so maybe this is a s a way out of it . postdoc f: hmm . professor e: you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but i think the issue of privacy and ease and so forth should be that uh , they get access to this if they really need it . grad c: well phd b: so you 're saying the the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . professor e: right . phd b: and then if they do n't , you 're done . if they do , then he provides them access to the the web site . grad c: well , to some extent i have to do that anyway because as i said we have to distribute passwords . professor e: w w phd b: or a printed - out form . professor e: there 's there grad c: so , professor e: y but you do n't necessarily have to distribute passwords is what i 'm saying . grad c: well , but professor e: so phd b: only if they want it . grad c: what i 'm saying is that i ca n't just email them the password because that 's not secure . so they have to call me and ask . professor e: no , no , no . but you are n't necessarily giving them right . but we do n't even necessarily need to end up distributing passwords at all . phd a:  grad c: well , we do because of privacy . we ca n't just make it openly available on the web . professor e: no , no . you 're missing the point . postdoc f: mm - hmm . professor e: we 're we 're trying i we 're trying to make it less of an obvious just l l l l uh fall off a log , to do this . postdoc f: not everyone gets a password , unless they ask for it . professor e: right ? so th so what i would see , is that first you contact them and ask them if they would like to review it for to check for the postdoc f: yeah . professor e: not just for fun , ok ? but to to check this for uh things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . um and , uh , and we should think carefully actually we should review go through how that 's worded , ok ? then , if someone uh wants to review it , uh , and i know you do n't like this , but i 'm offering this as a suggestion , is that is that we then give them a print out . and then if they say that `` i have a potential problem with these things , `` then , you you say `` ok well you might wan na hear this in context to s think if you need that , `` you issue them a password , i in the grad c: but the the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . i would much prefer to have all be automatic , they visit the web site if they want to . obviously they do n't have to . professor e: i know you 'd prefer it , but the proble grad c: yeah . professor e: we have grad c: so i think you 're thinking people are going to arbitrarily start bleeping and i just do n't think that 's gon na happen . professor e: there 's a problem with it . postdoc f: i 'm also concerned about the spirit of the of the informed consent thing . cuz i think if they feel that uh , it 's i th i th you know , if it turns out that something gets published in this corpus that someone really should have eliminated and did n't detect , then it could have been because of their own negligence that they did n't pursue that next level and get the password and do that , um , but but they might be able to argue `` oh well it was cumbersome , and i was busy and it was gon na take me too much time to trace it down `` . so it could that the burden would come back onto us . so i 'm a little bit worried about uh , making it harder for them , from the legal standpoint . professor e: well you can go too far in that direction , and you need to find somewhere between i think , postdoc f: yeah . grad c: it seems to me that sending them email , saying `` if you have an o - ok reply to this email and say ok , professor e: because uh - huh . grad c: if you have a problem with it contact me and i 'll give you a password `` , seems like is a perfectly , reasonable compromise . and if they want a printout they can print it out themselves . postdoc f: or we could print it up for them , phd a: yeah . postdoc f: i mean we could offer that but but there 's uh , another aspect to that and that is that in the informed consent form , um , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . and and i ha professor e: yeah . postdoc f: i do n't know that there 's a chance of really skipping that stage . i mean i i thought that you were maybe i misinterpreted what you said but it 's professor e: having access to it does n't necessarily mean , that having it grad c: having it . postdoc f: giving it to them . grad c: well the in professor e: right ? it just means they have the right to have it . postdoc f: ok . grad c: the consent form is right in there if anyone wants to look at it , postdoc f: alright . fine . ok . fair enough . grad c: so . professor e: yeah . grad c: d you want me to grab one ? postdoc f: sh - sh well i could i 'm closer . grad c: yeah , but you 're wired postdoc f: i could grad c: are n't you ? postdoc f: yeah . that is true . professor e: um . yeah , i mean i do n't wan na fool them , postdoc f: i do n't know professor e: i just meant that e every ev any time you say anything to anyone there is in fact a a bias that is presented , postdoc f: oh yeah yeah oh i know . professor e: right ? grad c: `` if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` professor e: of and postdoc f: yeah that 's true . yeah . grad c: `` once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . professor e: yeah . grad c: there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . `` postdoc f: hmm . well that 's more open than i realized . grad c: well , i mean it the one question is definitely clear with anything as opposed to just what you said . professor e: i phd a: yeah . professor e: yeah , uh no that it tha postdoc f: tha - that 's true . that 's more severe , but the next one says the transcript will be around . professor e: that 's right . postdoc f: and it does n't { comment } really say we 'll send it to you , or wi it 'll be available for you on the web , or anything . phd b: i think it probably leaves it open how we get it to them . professor e: i i postdoc f: at least it more often . yeah . it means also we do n't have to g to give it to them . i mean like like morgan was saying they they grad c: they just have to make sure that it is available to them . postdoc f: it 's available to them if they ask for it . professor e: yeah , ok , so . wh um i think i have an idea that may be sat may satisfy both you and me in this which is , um , it 's a it we just go over carefully how these notes to people are worded . so i i just want it to be worded in such a way where it gives the strong impre it gives very , i mean nothing hidden , v very strongly the bias that we would really like to use all of these data . grad c: right . professor e: that that we really would rather it was n't a patchwork of things tossed out , postdoc f: good . professor e: that it would be better for , um , our , uh , field if that is the case . but if you really think something is gon na and i do n't think there 's anything in the legal aspects that that is hurt by our expressing that bias . postdoc f: great . great , great . professor e: and then then my concern about which postdoc f: yeah . i agree . professor e: you know you might be right , it may be it was just paranoia on my part , uh but people just see i 'm @ @ worried about this interface so much fun that people start bleeping stuff out { comment } just as just because they can . grad c: it 's just a check box next to the text , it 's not any fun at all . professor e: yeah . well i do n't know . i kind of had fun when you played me something that was bleeped out . you know . grad c: well , but they wo n't get that feedback . professor e: i grad c: all no because it does n't automatically bleep it at the time . professor e: oh they wo n't ? grad c: it just sends me professor e: oh good . so you have n't made it so much fun . grad c: right . professor e: oh good . grad c: it just sends me the time intervals . professor e: ok , grad c: and then at some point i 'll incorporate them all and put bleeps . i mean i do n't wan na have t ha do that yet until we actually release the data professor e: yeah . grad c: because um , then we have to have two copies of every meeting and we 're already short on disk space . professor e: yeah . grad c: so i i wan na i just keep the times until we actually wan na release the data and then we bleep it . professor e: ok . alright , so i think yeah so if we have if i again let 's you know , sort of circulate the the wording on each of these things and get it right , grad c: well since you seem to feel heart uh , strongest about it , would you like to do the first pass ? professor e: but but ok . uh , fair enough . turn about is fair play , postdoc f: al - also it ther there is this other question , the legal question that that adam 's raised , uh about whether we need a concrete signature , or email c i suffices or whatever professor e: sorry . grad c: yeah . postdoc f: and i do n't know how that works . i there 's something down there about `` if you agree to `` professor e: i 'm i 'm i 'm i thought i i thought about it with one of my background processes grad c: i do n't think so . professor e: and i uh it 's uh it 's uh , it 's fine to do the email . postdoc f: ah . fine . grad c: yeah because thi th they 're signing here that they 're agreeing to the paragraph which says `` you 'll be given an opportunity . `` professor e: ok . postdoc f: good . ok . professor e: yeah . grad c: and so i do n't think they need another signature . professor e: and well and furthermore i it 's now fairly routine in a lot of arrangements that i do with people on contracts and so forth that that uh if it 's if it 's that sort of thing where you 're you 're saying uh `` ok i agree , we want eighty hours of this person at such - and - such amount , and i agree that 's ok , `` uh if it 's a follow up to some other agreement where there was a signature it 's often done in email now grad c: right . professor e: so it 's it 's ok . postdoc f: great . professor e: um . grad c: so i guess i probably should at the minimum , think about how to present it in a printed form . i 'm not really sure what 's best with that . the problem is a lot of them are really short , postdoc f: well grad c: and so i do n't necessarily wan na do one per line . but i do n't know how else to do it . postdoc f: well i s i also have this i i think it 's nice you have it uh , viewab her { comment } hearable on the on the web for those who might wonder about um , the non nonverbal side , i mean i i agree that our bias should be as as expressed here , and but i i think it 's nice that a person could check . cuz sometimes you know you the words on a on the page , come out soun sounding different in terms of the social dynamics if they hear it . grad c: hmm . professor e: mm - hmm . mm - hmm . postdoc f: and i realize we should n't emphasize that people { comment } you know , should n't borrow trouble . what it comes down to but grad c: yeah i think actually my opinion probably is that the only time someone will need to listen to it is if the transcript is uh not good . you know , if if there are lots of mumbles and parentheses and things like that . postdoc f: oh , you know , or what if there was an error in the transcript that did n't get detected and there was a whole uh i segment a against some personal i th grad c: right . that was all mumbled ? phd a: yeah . grad c: i think microsoft is postdoc f: yeah exactly phd a: oh , grad c: sorry transcribers . postdoc f: or or even or even { comment } there was a a line you know about how `` hmm - mmm - mmm { comment } bill gates duh - duh - duh - duh . `` professor e: yeah . postdoc f: but but it was all the words were all visible , but they did n't end up i some there was a slip in the transcript . phd a: oh , god . grad c: they 're gon na hate this meeting . phd a: yeah . postdoc f: yeah that 's true . grad c: actually liz will like it . you know , but . professor e: liz will like it . we had a pretty strong disagreement going there . grad c: yep , yep , that 's right . professor e: yeah . postdoc f: yeah . so i do n't know . i mean , i i guess we 're assuming that the transcript is a close enough approximation and that that my double checking will be so close to absolutely perfect that it that nothing will slip by . grad c: mm - hmm . professor e: but it the some something might sometime , and they uh if if it 's something that they said , they might i i i mean , you might be very accurate in putting down what they actually said , postdoc f: mm - hmm . professor e: but , when they hear it , themselves , they may hear something different because they know what they meant . postdoc f: i do n't know how to notate that . phd b: sarcasm , postdoc f: yeah , that 's right . phd b: how do you how do you indicate sarcasm ? postdoc f: yeah that 's right . professor e: no , i 'm serious . so the so i the so we might we might get some feedback from people that such - and - such was , you know , not not really what i said . grad c: yeah . well that would be good to get , definitely . professor e: yeah , but , yeah , sure . grad c: just for corrections . professor e: yeah . grad c: so um , in terms of password distribution , i think phone is really the only way to do it , phone and in person . or mail , physical mail . postdoc f: yeah . or if for leave it on their voice mail . phd b: any sub - word level thing . grad c: any sub - wor yeah , ok . i mean you could do it with pgp or things like that but it 's too complex . postdoc f: you know i just realized something , which is of e th this question about the uh the possible mismatch of i mean i well , and actually also the lawyer saying that um , we should n't really have them have the people believing that they will be cleared by our checks . you know ? professor e: mm - hmm . postdoc f: i mean . so it 's like i in a way it 's it 's nice to have the responsibility still on them to listen to the tape and and hear the transcript , to have that be the professor e: well yeah , but you ca n't dep i mean , most people will not wan na take the time to do that , though . postdoc f: yeah , ok , fair enough . and they 're s they 're absorbing the responsibility themselves . professor e: and they they have to postdoc f: so it 's not it 's not um yeah , good . professor e: but i mean if you were at a meeting , and and you you do n't think , at least , that you said anything funny and the meeting was about , you know , some some funny thing about semantics or something , or uh grad c: you probably wo n't listen to it . professor e: yeah . postdoc f: it is true that tec that the content is technical , i and so i and we 're not having these discussions which professor e: yeah . postdoc f: i i mean , when i listen to these things , i do n't find things that are questionable , in other people 's speech or in my own . professor e: yeah . you would think it would be rare , postdoc f: just it should be very rare . professor e: i mean we 're not talking about the energy crisis or something , people have postdoc f: yeah . yeah , ok . grad c: how about them energy crises . professor e: yeah . i think we 're uh grad c: done ? professor e: kind of done . actually , i was gon na di - did you have anything n that 's going on , or grad d: not really . no . um , my project is going along but um , i 'm really just here to um fill the project uh the overall progress . i do n't really have anything specific to to talk about . professor e: yeah . that 's fine . i just did n't wan na go by you , if you had something . grad d: oh , ok . professor e: you do n't have anything to say . phd b: no . professor e: nah . grad c:  professor e: transcribers , he was rattling the b marbles in his brain back and forth just then this this grad c: shall we do digits ? professor e: oh yeah . grad c: um , oh by the way i did find a bunch grad d: it um grad c: uh , we should count out how many more digits to forms do we have back there ? phd b: there were quite a few . uh . grad c: that 's what i thought . i f i was going through them all and i found actually a lot filed in with them , that were blanks , that no one had actually read . phd b: mmm . grad c: and so we still have more than i thought we did . phd b: oh good . grad c: so , we have a few more digits before we 're done . phd b: you know having this headset reminds me of like working at burger king or something . grad c: oops . postdoc f: oh , did you do that ? phd a: burger king grad c: i 'd like a burger with that , phd b: no i never did . grad c: do you want fries with that ? professor e: wow . phd b: but i feel like i could now . grad c: and { pause }","output":"approximately 32-35 hours of meeting data have been recorded , roughly 30 hours of which comprise non-digits recordings . the transcribers have begun performing digit extraction ( see abstract for bmr013 ) and should be finished within a few days . approximately 11 hours of speech have been transcribed ."},{"instruction":"what was needed for the transcripts ?","input":"professor e: alright . grad c: so are you professor e: so . grad c: are we going ? professor e: it is uh , must be february fifteenth . postdoc f: yeah . grad c: yu i think the date 's written in there , yep . and actually if everyone could cross out the r - nine next to `` session `` , and write mr eleven . professor e: yeah . yeah . we did n't have a front - end meeting today . grad c: and let 's remember also to make sure that one 's { comment } gets marked as unread , unused . professor e: ok . phd a: mr eleven . grad c: mr eleven . postdoc f: that sounds like a spy code . professor e: mmm . ok . so . grad c: there 's lots of clicking i 'm sure as i 'm trying to get this to work correctly . professor e: agenda . any agenda items today ? grad c: i wan na talk a little bit about getting how we 're gon na to get people to edit bleeps , parts of the meeting that they do n't want to include . what i 've done so far , and i wan na get some opinions on , how to how to finish it up . professor e: ok . postdoc f: i wan na ask about um , some aud audio monitoring on some of the um well some of the equipment . in particular , the well uh , that 's just what i wan na ask . professor e: ok audio monitoring , jane . postdoc f: ba - based on some of the tran uh i in listening to some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact in fact this one i 'm talking on is one of of the ones that showed up in one of the meetings , grad c: oh really . postdoc f: so i phd b: `` spikes `` , you mean like uh , instantaneous click type spikes , or ? postdoc f: mm - hmm . yeah . phd a: spikes ? grad c: clicks . postdoc f: yeah . professor e: hmm . postdoc f: yeah . phd b: huh . postdoc f: and i do n't know what the e electronics is but . grad c: yeah . postdoc f: yeah . grad c: well , i think it 's phd a: touching . grad c: uh , it it could be a number of things . phd a: yeah . grad c: it could be touching and fiddling , and the other thing is that it could the fact that it 's on a wired mike is suspicious . it might be a connector . postdoc f: oh , ok . well maybe then we do n't really have to talk about that as an phd b: you could try an experiment and say `` ok , i 'm about to test for spikes `` , postdoc f: i i take that off the agenda . phd b: and then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you . grad c: yeah . right . phd b: `` come get me when you transcribe this and see if there 's spikes . `` postdoc f: oh that professor e: um . postdoc f: well , ok . phd b: no i 'm just professor e: i mean , were this a professional audio recording , what we would do { comment } what you would do is in testing it is , you would actually do all this wiggling and make sure that that that things are not giving that kind of performance . and if they are , then they ca n't be used . grad c: right . professor e: so . um . let 's see . i guess i would like to have a discussion about you know where we are on uh , recording , transcription you know , basically you know where we are on the corpus . postdoc f: good . professor e: and then um , the other thing which i would like to talk about which is a real meta - quest , i think , deal is , uh , agendas . so maybe i 'll i 'll start with that actually . uh , um . andreas brought up the fact that he would kinda like to know , if possible , what we were gon na be talking about because he 's sort of peripherally involved to this point , and if there 's gon na be a topic about discussion about something that he uh strongly cares about then he would come and and i think part of part of his motivation with this is that he 's trying to help us out , in the because of uh the fact that the meetings are are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing grad c: mmm . professor e: and and i 'm sure help out his own time . by not showing up if it 's a meeting that he 's he 's so , uh in order i 'd i think that this is a wish on his part . uh . it 's actually gon na be hard because it seems like a lot of times uh things come up that are unanticipated and and grad c: right . professor e: but um , we could try anyway , uh , do another try at coming up with the agenda uh , at some point before the meeting , uh , say the day before . grad c: well maybe it would be a good idea for one of us to like on wednesday , or tuesday send out a reminder for people to send in agenda items . phd a: yeah . professor e: ok . you you wan na volunteer to do that ? grad c: sure . professor e: ok . alright so we 'll send out agenda request . grad c: let me professor e: uh . phd b: that 'll be i think that 'll help grad c: i 'll put that on my spare brain or it will not get done . phd b: that 'll help a lot , actually . professor e: yeah , i have to tell you for the uh for the admin meeting that we have , lila does that um every time before an admin meeting . and uh , she ends up getting the agenda requests uh , uh ten minutes before the meeting . but but { comment } but . uh . { comment } but we can try . maybe it 'll work . phd b: mmm . grad c: yeah . maybe . weirder things have happened . professor e: yeah . postdoc f: i 'm wondering if he were to just , uh , specify particular topics , i mean . maybe we 'd be able to meet that request of his a little more . phd b: i would i would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him . grad c: well then professor e: yeah . actually it this this maybe brings up another topic which is um so we 're done with that topic . the other topic i was thinking of was the sta status on microphones and channels , and all that . grad c: yeah , actually i i was going to say we need to talk about that too . professor e: yeah . why why do n't we do that . grad c: ok . um , the new microphones , the two new ones are in . um . and they are being assembled as we speak , i hope . and i did n't bring my car today so i 'm gon na pick them up tomorrow . um , and then the other question i was thinking about is well , a couple things . first of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . so we 'll have to evaluate that when they come in , phd a:  grad c: and get people 's opinions on on what they think of them . um , then the other question i had is maybe we should get another wireless . another wireless setup . i mean it 's expensive , but it does seem to be better than the wired . professor e: so how many channels do you get to have in a wireless setup ? grad c: um , well , i 'm pretty sure that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . so we currently have one base station with six wireless mike , possibility of six wireless receivers , and apparently you can chain those together . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . professor e: so , um . grad c: and so , you know it 's still , it 's fifteen minus six . professor e: so let 's see we grad c: right ? so we could have up to nine . professor e: and right now we can have up to six . grad c: right . and we have five , we 're getting one more . professor e: yeah . grad c: and it 's um , about nine hundred dollars for the base station , and then eight hundred per channel . professor e: oh . so yeah so the only beyond the mike the cost of the mikes the only thing is the base station that 's nine hundred dollars . grad c: right . professor e: oh , we should do it . grad c: ok . ok , so i 'll look into how you daisy - chain them and and then just go ahead and order them . professor e: yeah . yeah . phd b: i do n't quite understand how that how that works , . if so we 're not increasing the number of channels . ok . grad c: no , we 're just replacing the wired the two wired that are still working , phd b: ok . i see . grad c: along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless . professor e: yeah . phd b: three wireds work , professor e: basically we found phd b: right ? grad c: i i guess three wireds work , yeah . phd b: yeah . yeah . professor e: yeah . but we 've had more problems with that . grad c: yep . professor e: and that sort of bypasses the whole the whole jimbox thing and all that . grad c: right . professor e: and so um , we we seem to have uh , a reliable way of getting the data in , which is through the ra sony radio mikes , as long as we 're conscious about the batteries . grad c: right . professor e: that seems to be the key issue . grad c: everyone 's battery ok ? phd b: i checked them this morning , they should be . grad c: ok . professor e: yeah . um , that 's the only thing with them . but the quality seems really good and um i heard from uw that they 're they 're uh very close to getting their , uh setup purchased . they 're they 're they 're buying something that you can just sort of buy off the shelf . grad c: well we should talk to them about it because i know that sri is also in the process of looking at stuff , and so , you know , what we should try to keep everyone on the same page with that . professor e: yeah . phd b: sri , really ? grad c: yeah . phd b: oh . grad c: they got sa apparent well , maybe this needs to be bleeped out ? i have no clue . professor e: uh , i do n't know . grad c: i do n't know how much of it 's public . professor e: probably we should n't probably we should n't talk about funding stuff . grad c: right . professor e: yeah . but anyway there 's there 's there 's uh , uh other activities that are going on there and and uh and nist and uw . so . um . but but yeah i thin i think that at least the message we can tell other people is that our experience is is quite positive with the sony , grad c: right . professor e: uh , radio - mikes . now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering or something , right ? grad c: uh , no , we 're having the them do it . professor e: no ? grad c: so it 's so hand - soldering it , but i 'm not doing it . professor e: oh . grad c: so , they they charge professor e: ok . nothing against you and your hand - soldering grad c: right . professor e: but grad c: you 've never seen my hand - soldering . but uh , a as i said they 're coming in . professor e: uh , ok , so that 's being done professionally and grad c: i i mean professor e: yeah . grad c: yeah . i mean . professor e: yeah . grad c: as professionally as i guess you can get it done . professor e: well , it could if they do a lot of it , it 's grad c: i mean i it 's just their repair shop . right ? their maintenance people . professor e: well , we 'll see what it it 's like . grad c: yep . professor e: that tha that can be quite good . th - this yeah , ok . good . yeah . so let 's go with that . grad c: and , i mean we 'll see , tomorrow , you know , what it looks like . professor e: uh , yeah . so , um , uh , dave is n't here but he was going to start working on some things with the digits . uh , so he 'll be interested in what 's going on with that . i guess was the decision last time was that the the uh transcribers were going to be doing stuff with the digits as well ? has that started , or is that ? postdoc f: mm - hmm . yeah . uh , it would be to use his interface and i was going to meet with him today about that . grad c: right , so , the decision was that jane did not want the transcribers to be doing any of the paperwork . so i did the all that last week . so all the all the forms are now on the computer . and uh , then i have a bunch of scripts that we 'll read those and let the uh transcribers use different tools . and i just want to talk to jane about how we transition to using those . postdoc f: mm - hmm . so he has a nice set up that they it w it will be efficient for them to do that . professor e: ok . grad c: i i do n't think it 'll take too long . professor e: so anyway grad c: so , you know , just uh , a matter of a few days i suspect . professor e: so anyway i think we we have at least one uh , user for the digits once they get done , which will be dave . grad c: right . i 've already done five or six sets . postdoc f: ok . grad c: so if he wanted to , you know , just have a few to start with , he could . you know , and i also have a bunch of scripts that will , like , generate p - files and run recognition on them also . professor e: yeah , he might he might be asking right . ok . uh , is dave i do n't know if dave is on the list , if he 's invited to these meetings , uh if he knows . postdoc f: i do n't tend to get an invitation myself for them even . phd a: no , no . grad c: uh , we do n't have a active one but i 'll make sure he 's on the list . postdoc f: yeah . should we call him ? i mean is he d is he definitely not available today ? professor e: i do n't know . postdoc f: should i call his office and see ? phd a: he was in . grad c: i mean , he 's still taking classes , so uh , he may well have conflicts . professor e: uh , well i it 's uh phd a: yeah . professor e: yeah . phd a: yeah , he was in s postdoc f: he was n't there at cof professor e: yeah , so this might be a conflict for him . phd a: yeah . professor e: yeah . postdoc f: ok . professor e: ok . uh , so . grad c: yeah did n't he say his signal - processing class was like tuesdays and thursdays ? phd a: i think he has a class . yeah . phd b: yeah . he might have . grad c: oh well , whatever . grad d: you talking about david gelbart ? professor e: oh , ok . phd a: yeah . phd b: yeah . grad c: yeah . professor e: yeah . postdoc f: yes . grad d: yeah , i think he 's taking two twenty - five a which is now . phd b: yeah . grad d: so . professor e: yeah . postdoc f: ok . professor e: ok . so , that 's why we 're not seeing him . ok . uh , transcriptions , uh , beyond the digits , where we are , and so on . postdoc f: ok . professor e: and the and the recordings also , postdoc f: um professor e: just where we are . yeah . postdoc f: well , so um , should we we do n't wan wan na do the recording status first , or ? grad c: well , we have about thirty - two hours uh as of , i guess a week and a half ago , so we probably now have about thirty - five hours . professor e: and and that 's that 's uh how much of that is digits ? it 's uh that 's including digits , grad c: that 's including digits . professor e: right ? grad c: i have n't separated it out so i have no clue how much of that is digits . professor e: so yeah . so anyway there 's at least probably thirty hours , or something of there 's got to be more than thirty hour phd a: mmm . grad c: of of non - digits ? professor e: i it could n't of of non - digits . grad c: yeah , absolutely . i mean , the digits do n't take up that much time . professor e: yeah , yeah . ok . postdoc f: ok , and the transcribers h i , uh , do n't have the exact numbers , but i think it would come to about eleven hours that are finished uh , transcribing from them right now . the next step is to that i 'm working on is to insure that the data are clean first , and then channelized . what i mean by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that uh , liz requested in terms of um , um in terms of having a s a systematic handling of numbers , and acronyms which i had n't been specific about . um , for example , i they 'll say uh `` ninety - two `` . and you know , so how you could grad c: nine two , postdoc f: e exactly . grad c: right . postdoc f: so if you just say `` nine two `` , the there are many s ways that could have been expressed . an - and i just had them i i mean , a certain number of them did put the words down , but now we have a convention which also involves having it followed by , um , a gloss th and things . phd b: you know , jane ? grad c: mm - hmm . phd b: um , one suggestion and you may already be doing this , but i 've noticed in the past that when i 've gone through transcriptions and you know in in order to build lexicons and things , if you um , just take all the transcriptions and separate them into words and then alphabetize them , { comment } a lot of times just scanning down that list you 'll find a lot of inconsistencies and mis grad c: misspelled . phd a: yeah . postdoc f: you 're talking about the type token frequency listings , and i use those too . y you mean just uh on each on each line there 's a one word right ? it 's one token from the from the corpus . phd b: mm - hmm . mm - hmm . postdoc f: yeah , those are e extremely efficient and i and i i agree that 's a very good use of it . phd b: oh so you already have that , ok . postdoc f: well that 's that 's a way that 's you know , the spell - check basically does that but but in addition yes , that 's that 's exactly the strategy i wan na do in terms of locating these things which are you know colloquial spoken forms which are n't in the lexicon . phd b: mm - hmm . cuz a lot of times they 'll appear next to each other , and uh , postdoc f: exactly . and then you ca then you can do a s phd a: yeah . phd b: i in alphabetized lists , they 'll appear next to each other and and so it makes it easier . postdoc f: absolutely . i agree . that 's a very good that 's a very good uh , suggestion . and that was that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . i did n't get to that point but so there are numbers , then there are acronyms , and then um , there 's a he she wants the uh , actually a an explicit marker of what type of comment this is , so i curly b inside the curly brackets i 'm gon na put either `` voc `` for vocalized , like cough or like laugh or whatever , `` nonvoc `` for door - slam , and `` gloss `` for things that have to do with if they said a s a spoken form with this m this pronunciation error . grad c: right . postdoc f: i already had that convention phd b: oh that 's great . postdoc f: but i i have n't been asking these people to do it systematically cuz i think it most ha most efficiently handled by uh by a a filter . that was what i was always planing on . so that , you know you get a whole long list exactly what you 're saying , you get a whole list of things that say `` curly bracket laugh curly bracket `` , phd b: mm - hmm . postdoc f: then y you know it 's it 's you you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in sort of a voc space , phd b: yeah . postdoc f: so man so many ways that error prone . phd b: right . right . postdoc f: so , um , um i 'm i 'm going to convert that via a filter , into these tagged uh , subcategorized comments , and same thing with you know , we see you get a subset when you do what you 're saying , phd b: mm - hmm . postdoc f: you end up with a s with uh , you 're collapsing across a frequency you just have the tokens phd b: mm - hmm . postdoc f: and you can um , have a filter which more efficiently makes those changes . but the numbers and acronyms have to be handled by hand , because , you know i mean , jus grad c: you do n't know what they could be . phd b: yeah . postdoc f: yeah now timit 's clear um and plp is clear but uh there are things that are not so well known , in or or have variant u u uses like the numbers you can say `` nine two `` or you can say `` ninety - two `` , grad c: so how are you doing the postdoc f: and uh i 'd handle the numbers individually . grad c: how are you doing the uh , acronyms so if i say pzm what would it appear on the transcript ? postdoc f: it would be separate the letters would be separated in space grad c: ok . postdoc f: and potentially they 'll have a curly bracket thing afterwards e but i 'm not sure if that 's necessary , clarifying what it is , grad c: mm - hmm . postdoc f: so gloss of whatever . grad c: right . postdoc f: i do n't know if that 's really necessary to do that . maybe it 's a nice thing to do because of it then indicating this is uh , a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's uh the you know , { comment } uh enumerated , or i grad c: mm - hmm . postdoc f: it 's not a good way of saying but it 's it 's the specific uh way of stating these these letters . grad c: right . so it sounds good . postdoc f: and so anyway , the clean those are those things and then channelized is to then um , get it into this multichannel format . and at that point then it 's ready for use by liz and don . but that 's been my top priority beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins . phd a: yeah . grad c: right . postdoc f: and uh , thilo had a e e a breakthrough with this this last week in terms of getting the channel - based um uh s s speech - nonspeech segmentation um , up and running and i have n't i have n't been able to use that yet cuz i 'm working s re this is my top priority get the data clean , and channelized . phd a: i actually gave grad c: have you also been doing spot checks , jane ? postdoc f: oh yes . grad c: okay , good . postdoc f: well you see that 's part of the cleaning process . i spent um actually um i have a segment of ten minutes that was transcribed by two of our transcribers , grad c: oh good . good . postdoc f: and i went through it last night , it 's it 's almost spooky how similar these are , word for word . and there are some differences in commas cuz commas i i left them discretion at commas . grad c: right . postdoc f: uh and so because it 's not part of our st of our ne needed conventions . professor e: mm - hmm . postdoc f: and um , and so they 'll be a difference in commas , but it 's word - by - word the same , in in huge patches of the data . and i have t ten minute stretch where i can where i can show that . and and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . so um , the one i i the colloquial speech person picked up `` gobbledy - gook `` . phd b: hmm . postdoc f: and the other one did n't . and on this side , this one 's picking up things like `` neural nets `` and the one that 's good on the sp o on th the vocabulary on the uh colloquial did n't . grad c: right . phd b: when for the person who missed `` gobbledy - gook `` what did they put ? postdoc f: it was an interesting approximation , put in parentheses , cuz i have this convention that , i if they 're not sure what it was , they put it in parentheses . phd b: oh . postdoc f: so they tried to approximate it , but it was phd b: oh good . postdoc f: it was spelled gabbl phd b: sort of how it sounds . yeah . postdoc f: yes . more of an attempt to i mean apparently it was very clear to her that these the a this this was a sound these are the sounds , grad c: it was a technical term that she did n't recognize , phd b: yeah . postdoc f: but yeah . but she knew that she did n't know it . maybe it was a technical ter exactly . but she even though her technical perception is just really uh you know i 've i 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses grad c: right . postdoc f: then cuz `` neural nets `` and oh she has some things that are oh `` downsampled `` , she got that right . phd b: hmm . postdoc f: and some of these are rather uh unexpected . grad c: obscure , yeah . postdoc f: but ch ten solid uh m ch s chunk of ten solid minutes where they both coded the same data . professor e: and and again the main track that you 're working with is elev eleven hours ? postdoc f: and um professor e: is that right ? postdoc f: yes exactly . professor e: yeah , ok . postdoc f: and that 's part of this eleven hours . professor e: is that is that that including digits ? yeah . postdoc f: yes it is . professor e: so let 's say roughly ten hours or so of postdoc f: mm - hmm . professor e: i mean it 's probably more than that but but with of of non - digits . phd a: yeah . postdoc f: it 'd be more than that because i my recollection is the minutes that da digits do n't take more than half a minute . per person . professor e: oh , ok . postdoc f: but um the the total set that i gave them is twelve hours of tape , professor e: oh , i see . postdoc f: but they have n't gotten to the end of that yet . professor e: oh , i see . postdoc f: so they 're still working some of them are two of them are still working on completing that . yeah . phd b: boy , they 're moving right along . professor e: yeah . postdoc f: yeah . they are . mm - hmm . they 're very efficient . there 're some who have more hours that they devote to it than others . phd b: mm - hmm . professor e: mm - hmm . postdoc f: yeah . professor e: so what what what 's the deal with with your phd a: the channel u thing ? professor e: yeah . phd a: oh , it 's just uh , i ran the recognizer uh , the { comment } speech - nonspeech detector on different channels and , it 's just in uh in this new multi - channel format and output , and i just gave one one meeting to to liz who wanted to to try it for for the recognizer professor e: oh , i see . phd a: as uh , apparently the recognizer had problems with those long chunks of speech , which took too much memory or whatever , professor e: right . phd a: and so she she will try that i think professor e: yeah . phd a: and i 'm i 'm working on it . so , i hope grad c: is this anything different than the hmm system you were using before ? professor e: yeah . phd a: no . uh , i mmm , use some some different features but not not grad c: mm - hmm . phd a: the basic thing is this hmm base . grad c: so there 's still no no knowledge using different channels at the same time . phd a: there is some , uh as the energy is normalized across channels grad c: you know what i mean ? across all of them . phd a: yeah . grad c: ok . phd a: so . but basically that 's one of the main changes . grad c: mm - hmm . professor e: mm - hmm . what are some of the other features ? besides the energy ? you said you 're trying some different features , or something . phd a: oh i just uh mmm , i just use um our loudness - based things now as they before there were they were some in in the log domain and i i changed this to the to the professor e: cu - cube root ? phd a: yeah . to no , i changed this to the to the to the loudness thingy with the with the grad c: hmm . professor e: ah . phd a: how do you call it ? i 'm not sure . with the , uh professor e: fletcher munson ? no . phd a: i 'm not sure about the term . professor e: oh , ok . phd a: uh , i 'll look it up . and say it to you . professor e: yeah , alright . phd a: uh , ok , and yeah . that 's that 's basically the the the thing . yeah , and i and i tried t to normalize uh uh the features , there 's loudness and modified loudness , um , within one channel , professor e: ok . phd a: because they 're , yeah to to be able to distinguish between foreground and background speech . and it works quite well . but , not always . professor e: uh - huh . uh - huh . phd a: so . professor e: ok . grad c: good . professor e: um , let 's see . i think the uh were were you basically done with the transcription part ? so i guess the next thing is this uh bleep editing . grad c: right . so the the idea is that we need to have we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they do n't want . so i 've written a bunch of tools that will generate web pages , uh with the transcription in it so that they can click on them and piece pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . and then , it 's a form , html form , so they can submit it and it will end up sending me email with the times that they want excluded . and so , uh , some of the questions on this is what do we do about the privacy issue . and so i thought about this a little bit and i think the best way to do it is every participant will have a password , professor e: yeah . grad c: a single password . each person will have a single password , user name and password . and then each meeting , we 'll only allow the participants who were at that meeting to look at it . and that way each person only has to remember one password . professor e: i i ca n't help but wonder if this is maybe a little more elaborate than is needed . i mean if people have uh , i mean , for me i would actually want to have some pieces of paper that had the transcription and i would sort of flip through it . and then um if i thought it was ok , i 'd say `` it 's ok `` . grad c: mm - hmm . professor e: and , i uh i mean it depends how this really ends up working out , but i guess my thought was that the occasion of somebody wondering whether something was ok or not and needing to listen to it was gon na be extremely rare . grad c: right , i mean so th th th the fact that you could listen to it over the web is a minor thing that i had already done for other reasons . professor e: ok . grad c: and so that that 's a minor part of it , i just wanted some web interface so that people you did n't actually have to send everyone the text . so m what my intention to do is that as the transcripts become ready , um i would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just uh , tell them , `` here 's the web page `` , um , `` you need a password `` . so th th question number one is how do we distribute the passwords , and question number two is how else do we wan na provide this information if they want it . professor e: that 's i think what i was sort of saying is that if you just say `` here is a here is `` i mean this maybe it sounds paleolithic but but i just thought if you handed them some sheets of paper , that said , uh , `` here 's what was said in this transcription is it ok with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's ok `` . grad c: i think that um there are a subset of people who will want printouts that we can certainly provide . professor e: and then they 'd hand it back to you . grad c: but certainly i would n't want a printout . these are big , and i would much rather be ha be able to just sit and leaf through it . professor e: you find it easier to go through a large i mean how do you read books ? grad c: well i certainly read books by hand . but for something like this , i think it 's easier to do it on the web . professor e: really ? i mean , it grad c: cuz you 're gon na get , you know , if i i 'm i 'm in a bunch of meetings and i do n't wan na get a stack of these . i wan na just be able to go to go to the web site { comment } and visit it as i want . professor e: going to a web site is easy , but flipping through a hundred pounds a hundred pages of stuff is not easy on the web . grad c: well , i do n't think it 's that much harder than , paper . so . professor e: really ? postdoc f: i have one question . so are you thinking that um the person would have a transcript and go strictly from the transcript ? because i i do think that there 's a benefit to being able to hear the tone of voice and the professor e: so here 's the way i was imagining it , and maybe i 'm wrong , postdoc f: yeah . professor e: but the way i imagined it was that um , the largest set of people is gon na go `` oh yeah , i did n't say anything funny in that meeting just go ahead , where 's the where 's the release ? `` and then there 'll be a subset of people , right ? ok there 's i mean think of who it is we 've been recording mostly . phd a: yeah . professor e: ok there 'll be a subset of people , who um , will say uh `` well , yeah , i really would like to see that . `` and for them , the easiest way to flip through , if it 's a really large document , i mean unless you 're searching . searching , of course , should be electronic , but if you 're not so if you provide some search mechanism you go to every place they said something or something like that , phd a: yeah . professor e: but see then we 're getting more elaborate with this thing . um if if uh you do n't have search mechanisms you just sort of have this really , really long document , i mean whenever i 've had a really , really long document that it was sitting on the web , i 've always ended up printing it out . i mean , so it 's it 's i mean , you you 're you 're not necessarily gon na be sitting at the desk all the time , you wan na figure you have a train ride , and there 's all these situations where where i i mean , this is how i was imagining it , anyway . and then i figured , that out of that group , there would be a subset who would go `` hmm you know i 'm really not sure about this section here , `` and then that group would need it s it seems like i if i 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . so that uh , now we have to worry about privacy , grad c: well , no fre for the most professor e: we have to worry about all these passwords , for different people grad c: for the most frequent case they just say `` it 's ok `` and then they 're done . and i think almost everyone would rather do that by email than any other method . professor e: mm - hmm . postdoc f: the other thing too is it seems like professor e: um , yeah , that 's true . postdoc f: go ahead . grad c: i mean , cuz you do n't have to visit the web page if you do n't want to . phd a: yeah . professor e: i guess yeah , i guess we do n't need their signature . i guess an email ok is alright . grad c: oh that was another thing i i had assumed that we did n't need their signature , that it that an email approval was sufficient . but i do n't actually know . phd b: are are people going to be allowed to bleep out sections of a meeting where they were n't speaking ? grad c: yes . if someone feels strongly enough about it , then i i i think they should be allowed to do that . postdoc f: i also mm - hmm . phd b: so that means other people are editing what you say ? professor e: uh i do n't know about that . grad c: yeah . phd b: i do n't know if i like that . grad c: well , the only other choice is that the person would say `` no , do n't distribute this meeting at all `` , and i would rather they were able to edit out other people then just say `` do n't distribute it at all `` . professor e: but th what they signed in the consent form , was something that said you can use my voice . grad c: well , but if if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient . professor e: right ? yeah . yeah , but that 's our decision then . right ? grad c: um , i do n't think so . i mean , because if i object to the conversation . professor e: i think it is . grad c: if i say `` we were having a conversation , and i consider that conversation private , `` and i consider that your side of it is enough for other people to infer , i wan na be able to bleep out your side . postdoc f: the i agree that the consent forms were uh , i cons agree with what adam 's saying , that um , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or did n't say them . professor e: i see . ok , well , if that 's what it said . postdoc f: and the other thing is from the standpoint of the l of the l i 'm not a law lawyer , but it strikes me that uh , we would n't want someone to say `` oh yes , i was a little concerned about it but it was too hard to access `` . so i think it 's kind of nice to have this facility to listen to it . now in terms of like editing it by hand , i mean i think it 's i some people would find that easier to specify the bleep part by having a document they edited . but but it seems to me that sometimes um , you know i if a person had a bad day , and they had a tone in their voice that they did n't really like , you know it 's nice it 's nice to be able to listen to it and be sure that that was ok . grad c: i mean i can certainly provide a printable version if people want it . um . professor e: um i mean it 's also a mixture of people , i mean some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not . grad c: yep . professor e: others would consider it this uh a a set of skills that they would have to gain . you know ? grad c: well i think most of the people in the meetings are the former . professor e: it depends on what meetings . postdoc f: that 's true . phd b: so far . grad c: so . professor e: in the meetings so far , yeah . grad c: yep . professor e: but we 're trying to expand this , right ? grad c: right . professor e: so i i i actually think that paper is the more universal thing . grad c: and that well , but if they want to print it out that 's alright . postdoc f: mm - hmm . yeah . grad c: i think everyone in the meeting can access the web . professor e: no , i think we have to be able to print it out . it 's not just if they want to print it out . i i think grad c: ok , so does that mean that i ca n't use email ? or what ? postdoc f: cuz you could send it through email you 're thinking . professor e: i i th grad c: well , i do n't think i professor e: well we there was this grad c: well i do n't think we can send the text through email because of the privacy issues . professor e: no . postdoc f: good . for security ? phd a: yeah . postdoc f: yeah , ok good . professor e: right . grad c: um . so giving them , you think a web site to say , `` if you wan na print it out here it is `` , is not sufficient ? postdoc f: good point . phd a: yeah . i professor e: certainly for everybody who 's been in the meetings so far it would be sufficient . grad c: yeah , i 'm just thinking for people that that 's not sufficient for , what the only sufficient thing would be for me to walk up to them and hand it to them . professor e: i 'm just wondering about postdoc f: you could mail it to them . phd a: yeah . postdoc f: get an a mailing address . grad c: equivalent . phd a: but postdoc f: but i think it 's easier to drop in the box . phd a: just put the button on on the web page which say `` please send me the the scripts `` . grad c: that 's right . postdoc f: oh that 's interesting . phd a: yeah . phd b: what um when you display it on the web page , what are what are you showing them ? utterances , or ? grad c: mm - hmm . phd b: and so can they bleep within an utterance ? grad c: no . whole utterances only . phd b: whole utterances . grad c: and that was just convenience for my sake , that it 's uh , uh it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . because this way i can just delete an entire line out of a transcript file rather than have to do it by hand . professor e: there 's another aspect to this which maybe is part of why this is bothering me . um , i think you 're really trying very hard to make this as convenient as possible for people to do this . phd b: mmm . grad c: i mean that 's why i did the web form , because for me that would be my most convenient . professor e: i i i understand . phd b: i know where you 're going . professor e: i think that 's the bad idea . grad c: oh . professor e: see because you 're gon you 're uh really . you 're gon na end up with all these little patchy things , whereas really what we want to do is have the the the bias towards letting it go . because nob you know it there was a one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . nobody 's gon na get hurt . nobody 's being l libeled . you know , this is this we 're we 're covering we 're playing the lawyer 's game , and we 're playing we 're we 're we 're looking for the extreme case . if we really orient it towards that extreme case , make it really easy , we 're gon na end up encouraging a headache . that i think that 's i 'm sort of psyching myself out here , i i 'm trying to uh grad c: i guess i do n't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out . professor e: but i i think that 's well , it 's grad c: so . phd b: i think what morgan 's saying is the easier it is , the more is gon na be bleeped . professor e: but i and and it really depends on what kind of research you 're doing . i think some researchers who are gon na be working with this corpus years from now are really gon na be cursing the fact that there 's a bunch of stuff in there { comment } that 's missing from the dialogue . grad c: mm - hmm . professor e: you know , it depends on the kind of research they 're doing , phd a: yeah . professor e: but it might be , uh it might be really a a pain . and , you know where it 's really gon na hurt somebody , in some way the one who said it or someone who is being spoken about , { comment } we definitely want to allow the option of it being bleeped out . but i really think we wan na make it the rare incidence . and and uh , i am just a little worried about making it so easy for people to do , and so much fun ! that they 're gon na go through and bleep out stuff . postdoc f: so much fun . professor e: and they can bleep out stuff they do n't like too , right from somebody else , as you say , you know , so `` well i did n't like what he said . `` grad c: well i do n't see any way of avoiding that . i mean , we have to provi we have promised that we would provide them the transcript and that they can remove parts that they do n't like . so that the professor e: yeah . no , no , i i i do n't grad c: the only question is professor e: you - you 've talked me into that , but i i just think that we should make it harder to do . grad c: the problem is if it 's harder for them it 's also harder for me . whereas this web interface , i just get email , it 's all formatted , it 's all ready to go and i can just insert it . professor e: so maybe you do n't give them access to the web interface unless they really need it . so so so postdoc f: well i guess yeah . professor e: i 'm sorry so so so maybe this is a s a way out of it . postdoc f: hmm . professor e: you 've provided something that 's useful for you to do handle , and useful for someone else if they need it . but i think the issue of privacy and ease and so forth should be that uh , they get access to this if they really need it . grad c: well phd b: so you 're saying the the sequence would be more like first adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting . professor e: right . phd b: and then if they do n't , you 're done . if they do , then he provides them access to the the web site . grad c: well , to some extent i have to do that anyway because as i said we have to distribute passwords . professor e: w w phd b: or a printed - out form . professor e: there 's there grad c: so , professor e: y but you do n't necessarily have to distribute passwords is what i 'm saying . grad c: well , but professor e: so phd b: only if they want it . grad c: what i 'm saying is that i ca n't just email them the password because that 's not secure . so they have to call me and ask . professor e: no , no , no . but you are n't necessarily giving them right . but we do n't even necessarily need to end up distributing passwords at all . phd a:  grad c: well , we do because of privacy . we ca n't just make it openly available on the web . professor e: no , no . you 're missing the point . postdoc f: mm - hmm . professor e: we 're we 're trying i we 're trying to make it less of an obvious just l l l l uh fall off a log , to do this . postdoc f: not everyone gets a password , unless they ask for it . professor e: right ? so th so what i would see , is that first you contact them and ask them if they would like to review it for to check for the postdoc f: yeah . professor e: not just for fun , ok ? but to to check this for uh things that they 're worried about having said or if they 're willing to just send an approval of it , at from their memory . um and , uh , and we should think carefully actually we should review go through how that 's worded , ok ? then , if someone uh wants to review it , uh , and i know you do n't like this , but i 'm offering this as a suggestion , is that is that we then give them a print out . and then if they say that `` i have a potential problem with these things , `` then , you you say `` ok well you might wan na hear this in context to s think if you need that , `` you issue them a password , i in the grad c: but the the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . because that means multiple contacts every time for every single meeting every time anyone wants anything . i would much prefer to have all be automatic , they visit the web site if they want to . obviously they do n't have to . professor e: i know you 'd prefer it , but the proble grad c: yeah . professor e: we have grad c: so i think you 're thinking people are going to arbitrarily start bleeping and i just do n't think that 's gon na happen . professor e: there 's a problem with it . postdoc f: i 'm also concerned about the spirit of the of the informed consent thing . cuz i think if they feel that uh , it 's i th i th you know , if it turns out that something gets published in this corpus that someone really should have eliminated and did n't detect , then it could have been because of their own negligence that they did n't pursue that next level and get the password and do that , um , but but they might be able to argue `` oh well it was cumbersome , and i was busy and it was gon na take me too much time to trace it down `` . so it could that the burden would come back onto us . so i 'm a little bit worried about uh , making it harder for them , from the legal standpoint . professor e: well you can go too far in that direction , and you need to find somewhere between i think , postdoc f: yeah . grad c: it seems to me that sending them email , saying `` if you have an o - ok reply to this email and say ok , professor e: because uh - huh . grad c: if you have a problem with it contact me and i 'll give you a password `` , seems like is a perfectly , reasonable compromise . and if they want a printout they can print it out themselves . postdoc f: or we could print it up for them , phd a: yeah . postdoc f: i mean we could offer that but but there 's uh , another aspect to that and that is that in the informed consent form , um , my impression is that they that we offered them at the very least that they definitely would have access to the transcript . and and i ha professor e: yeah . postdoc f: i do n't know that there 's a chance of really skipping that stage . i mean i i thought that you were maybe i misinterpreted what you said but it 's professor e: having access to it does n't necessarily mean , that having it grad c: having it . postdoc f: giving it to them . grad c: well the in professor e: right ? it just means they have the right to have it . postdoc f: ok . grad c: the consent form is right in there if anyone wants to look at it , postdoc f: alright . fine . ok . fair enough . grad c: so . professor e: yeah . grad c: d you want me to grab one ? postdoc f: sh - sh well i could i 'm closer . grad c: yeah , but you 're wired postdoc f: i could grad c: are n't you ? postdoc f: yeah . that is true . professor e: um . yeah , i mean i do n't wan na fool them , postdoc f: i do n't know professor e: i just meant that e every ev any time you say anything to anyone there is in fact a a bias that is presented , postdoc f: oh yeah yeah oh i know . professor e: right ? grad c: `` if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` professor e: of and postdoc f: yeah that 's true . yeah . grad c: `` once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community . professor e: yeah . grad c: there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . `` postdoc f: hmm . well that 's more open than i realized . grad c: well , i mean it the one question is definitely clear with anything as opposed to just what you said . professor e: i phd a: yeah . professor e: yeah , uh no that it tha postdoc f: tha - that 's true . that 's more severe , but the next one says the transcript will be around . professor e: that 's right . postdoc f: and it does n't { comment } really say we 'll send it to you , or wi it 'll be available for you on the web , or anything . phd b: i think it probably leaves it open how we get it to them . professor e: i i postdoc f: at least it more often . yeah . it means also we do n't have to g to give it to them . i mean like like morgan was saying they they grad c: they just have to make sure that it is available to them . postdoc f: it 's available to them if they ask for it . professor e: yeah , ok , so . wh um i think i have an idea that may be sat may satisfy both you and me in this which is , um , it 's a it we just go over carefully how these notes to people are worded . so i i just want it to be worded in such a way where it gives the strong impre it gives very , i mean nothing hidden , v very strongly the bias that we would really like to use all of these data . grad c: right . professor e: that that we really would rather it was n't a patchwork of things tossed out , postdoc f: good . professor e: that it would be better for , um , our , uh , field if that is the case . but if you really think something is gon na and i do n't think there 's anything in the legal aspects that that is hurt by our expressing that bias . postdoc f: great . great , great . professor e: and then then my concern about which postdoc f: yeah . i agree . professor e: you know you might be right , it may be it was just paranoia on my part , uh but people just see i 'm @ @ worried about this interface so much fun that people start bleeping stuff out { comment } just as just because they can . grad c: it 's just a check box next to the text , it 's not any fun at all . professor e: yeah . well i do n't know . i kind of had fun when you played me something that was bleeped out . you know . grad c: well , but they wo n't get that feedback . professor e: i grad c: all no because it does n't automatically bleep it at the time . professor e: oh they wo n't ? grad c: it just sends me professor e: oh good . so you have n't made it so much fun . grad c: right . professor e: oh good . grad c: it just sends me the time intervals . professor e: ok , grad c: and then at some point i 'll incorporate them all and put bleeps . i mean i do n't wan na have t ha do that yet until we actually release the data professor e: yeah . grad c: because um , then we have to have two copies of every meeting and we 're already short on disk space . professor e: yeah . grad c: so i i wan na i just keep the times until we actually wan na release the data and then we bleep it . professor e: ok . alright , so i think yeah so if we have if i again let 's you know , sort of circulate the the wording on each of these things and get it right , grad c: well since you seem to feel heart uh , strongest about it , would you like to do the first pass ? professor e: but but ok . uh , fair enough . turn about is fair play , postdoc f: al - also it ther there is this other question , the legal question that that adam 's raised , uh about whether we need a concrete signature , or email c i suffices or whatever professor e: sorry . grad c: yeah . postdoc f: and i do n't know how that works . i there 's something down there about `` if you agree to `` professor e: i 'm i 'm i 'm i thought i i thought about it with one of my background processes grad c: i do n't think so . professor e: and i uh it 's uh it 's uh , it 's fine to do the email . postdoc f: ah . fine . grad c: yeah because thi th they 're signing here that they 're agreeing to the paragraph which says `` you 'll be given an opportunity . `` professor e: ok . postdoc f: good . ok . professor e: yeah . grad c: and so i do n't think they need another signature . professor e: and well and furthermore i it 's now fairly routine in a lot of arrangements that i do with people on contracts and so forth that that uh if it 's if it 's that sort of thing where you 're you 're saying uh `` ok i agree , we want eighty hours of this person at such - and - such amount , and i agree that 's ok , `` uh if it 's a follow up to some other agreement where there was a signature it 's often done in email now grad c: right . professor e: so it 's it 's ok . postdoc f: great . professor e: um . grad c: so i guess i probably should at the minimum , think about how to present it in a printed form . i 'm not really sure what 's best with that . the problem is a lot of them are really short , postdoc f: well grad c: and so i do n't necessarily wan na do one per line . but i do n't know how else to do it . postdoc f: well i s i also have this i i think it 's nice you have it uh , viewab her { comment } hearable on the on the web for those who might wonder about um , the non nonverbal side , i mean i i agree that our bias should be as as expressed here , and but i i think it 's nice that a person could check . cuz sometimes you know you the words on a on the page , come out soun sounding different in terms of the social dynamics if they hear it . grad c: hmm . professor e: mm - hmm . mm - hmm . postdoc f: and i realize we should n't emphasize that people { comment } you know , should n't borrow trouble . what it comes down to but grad c: yeah i think actually my opinion probably is that the only time someone will need to listen to it is if the transcript is uh not good . you know , if if there are lots of mumbles and parentheses and things like that . postdoc f: oh , you know , or what if there was an error in the transcript that did n't get detected and there was a whole uh i segment a against some personal i th grad c: right . that was all mumbled ? phd a: yeah . grad c: i think microsoft is postdoc f: yeah exactly phd a: oh , grad c: sorry transcribers . postdoc f: or or even or even { comment } there was a a line you know about how `` hmm - mmm - mmm { comment } bill gates duh - duh - duh - duh . `` professor e: yeah . postdoc f: but but it was all the words were all visible , but they did n't end up i some there was a slip in the transcript . phd a: oh , god . grad c: they 're gon na hate this meeting . phd a: yeah . postdoc f: yeah that 's true . grad c: actually liz will like it . you know , but . professor e: liz will like it . we had a pretty strong disagreement going there . grad c: yep , yep , that 's right . professor e: yeah . postdoc f: yeah . so i do n't know . i mean , i i guess we 're assuming that the transcript is a close enough approximation and that that my double checking will be so close to absolutely perfect that it that nothing will slip by . grad c: mm - hmm . professor e: but it the some something might sometime , and they uh if if it 's something that they said , they might i i i mean , you might be very accurate in putting down what they actually said , postdoc f: mm - hmm . professor e: but , when they hear it , themselves , they may hear something different because they know what they meant . postdoc f: i do n't know how to notate that . phd b: sarcasm , postdoc f: yeah , that 's right . phd b: how do you how do you indicate sarcasm ? postdoc f: yeah that 's right . professor e: no , i 'm serious . so the so i the so we might we might get some feedback from people that such - and - such was , you know , not not really what i said . grad c: yeah . well that would be good to get , definitely . professor e: yeah , but , yeah , sure . grad c: just for corrections . professor e: yeah . grad c: so um , in terms of password distribution , i think phone is really the only way to do it , phone and in person . or mail , physical mail . postdoc f: yeah . or if for leave it on their voice mail . phd b: any sub - word level thing . grad c: any sub - wor yeah , ok . i mean you could do it with pgp or things like that but it 's too complex . postdoc f: you know i just realized something , which is of e th this question about the uh the possible mismatch of i mean i well , and actually also the lawyer saying that um , we should n't really have them have the people believing that they will be cleared by our checks . you know ? professor e: mm - hmm . postdoc f: i mean . so it 's like i in a way it 's it 's nice to have the responsibility still on them to listen to the tape and and hear the transcript , to have that be the professor e: well yeah , but you ca n't dep i mean , most people will not wan na take the time to do that , though . postdoc f: yeah , ok , fair enough . and they 're s they 're absorbing the responsibility themselves . professor e: and they they have to postdoc f: so it 's not it 's not um yeah , good . professor e: but i mean if you were at a meeting , and and you you do n't think , at least , that you said anything funny and the meeting was about , you know , some some funny thing about semantics or something , or uh grad c: you probably wo n't listen to it . professor e: yeah . postdoc f: it is true that tec that the content is technical , i and so i and we 're not having these discussions which professor e: yeah . postdoc f: i i mean , when i listen to these things , i do n't find things that are questionable , in other people 's speech or in my own . professor e: yeah . you would think it would be rare , postdoc f: just it should be very rare . professor e: i mean we 're not talking about the energy crisis or something , people have postdoc f: yeah . yeah , ok . grad c: how about them energy crises . professor e: yeah . i think we 're uh grad c: done ? professor e: kind of done . actually , i was gon na di - did you have anything n that 's going on , or grad d: not really . no . um , my project is going along but um , i 'm really just here to um fill the project uh the overall progress . i do n't really have anything specific to to talk about . professor e: yeah . that 's fine . i just did n't wan na go by you , if you had something . grad d: oh , ok . professor e: you do n't have anything to say . phd b: no . professor e: nah . grad c:  professor e: transcribers , he was rattling the b marbles in his brain back and forth just then this this grad c: shall we do digits ? professor e: oh yeah . grad c: um , oh by the way i did find a bunch grad d: it um grad c: uh , we should count out how many more digits to forms do we have back there ? phd b: there were quite a few . uh . grad c: that 's what i thought . i f i was going through them all and i found actually a lot filed in with them , that were blanks , that no one had actually read . phd b: mmm . grad c: and so we still have more than i thought we did . phd b: oh good . grad c: so , we have a few more digits before we 're done . phd b: you know having this headset reminds me of like working at burger king or something . grad c: oops . postdoc f: oh , did you do that ? phd a: burger king grad c: i 'd like a burger with that , phd b: no i never did . grad c: do you want fries with that ? professor e: wow . phd b: but i feel like i could now . grad c: and { pause }","output":"efforts by speaker fe008 are in progress to ensure that transcripts are clean ( i.e . spell checked ) , channelized , and conform to set conventions regarding the coding of numbers , acronyms , and explicit comments ( e.g . door slams , coughs , and laughter ) . subsequent efforts by speaker fe008 will be to tighten up boundaries on the time bins . inter-annotator agreement was reported to be very good . speaker mn014 's multi-channel speech\/non-speech segmenter is in use ."},{"instruction":"summarize the whole meeting .","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"the group members mainly talked about the details of the belief-net framework . they first discussed the way to make the definition of user and situation clear and set up the standards , e.g. , user thrift , based on user 's budget . then they turned to the discussion about endpoint decision . they mentioned approaches including setting features\/modes of like selling , fixing and exhibiting , and this inspired the group members to design user compatibility nodes of which value would depend on the user status and situation . they further discussed go-there decision , which is related to the previous idea using the similar set of the ontologies . finally , they shifted the topic to different probability computation methods for belief-nets and thought of solutions to issues with limited data annotation ."},{"instruction":"summarize the discussion about value for user and situation models .","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"first , grad e proposed a question about better discriminating the definition of user and situation models , and it was necessary to set values for the models . then , they discussed the issues in terms of the user 's running budget , which was vital for the outcome of decisions . they tried to design a set of terms to describe the user 's financial policy , such as thrift , average , spendy , or more finer scale ones ."},{"instruction":"what did the group members think of the value of user budget when discussing value for user and situation models ?","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"the reason why they mentioned user budget was that they wanted to take this example to further discuss the value for user model . also , user budget was an important factor for the outcomes of decisions . then , they tried to decide which set of words could represent the budget better . finally , they found that the words that could describe financial policy of users , such as user thrift , was appropriate ."},{"instruction":"summarize the discussion about go-there decision .","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"grad e proposed the idea that go-there decision was also worth thinking about . professor b suggested that the decision could stick to the discourse properties as a placeholder . with regard to the lack of ontologies , professor b thought that it could use the same properties like exhibiting and selling . grad e doubted the choice of binary eva values , but professor b insisted that it was still necessary to make this choice . then the group members discussed the layout of belief-nets , for example , the connection between go-there nodes and other ones such as endpoints . and professor b reminded me that the belief-nets should not have loops ."},{"instruction":"what did grad e say when discussing go-there decision ?","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"grad e first started the topic about go-there decision , and then proposed the question about how to represent discourse . though professor b insisted on using true-and-false values , grad e challenged professor b 's opinion by taking examples about whether people really wanted to go some place or not when they asked how to get there ."},{"instruction":"summarize the discussion about probability computation .","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"professor b first emphasized the necessity of combining influences mathematically and asked grad d to further explain the potential solutions . then the students discussed the computation methods including weighted combination and mixture of experts , based on the mechanism of belief-nets . but there was no consensus on which method should be applied in belief-nets ."},{"instruction":"what did grad d say about mixture of experts when discussing probability computation ?","input":"grad a: alright , so i 'm - i should read all of these numbers ? professor b: ok . grad e: piece of paper ? i could borrow ? grad a: oh yeah . professor b: ok , so uh i um i do n't know whether ami 's coming or not um but i think we oughta just get started . grad e: nancy is uh currently in berkeley but not here ? grad c: nancy 's still stick ? professor b: do n't know . anyway grad e: ok . professor b: oh , so there you go . anyway , so my idea f for today and we can uh decide that that is n't the right thing to do was to at spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually i had uh specific s suggestion to start first with the path ones . the database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's and the idea was we were gon na do two things grad c: is your mike on ? professor b: ah . oh right , well . yeah . we were gon na do two things one of which is just lay out the influence structure of what we think influences what grad d: that 's funny . professor b: and then as a uh separate but related task uh particularly bhaskara and i were going to try to decide what kinds of belief nodes are needed in order to um do what we what we need to do . once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . so i did n't did you get a chance to look at all yet ? grad d: yeah , i looked at some of that stuff . professor b: great . ok so let 's start with the uh belief - nets , the general influence stuff and then we 'll then we 'll also at some point break and talk about the techy stuff . grad e: well i think one could go there 's i think we can di discuss everything . first of all this i added , i knew from sort of basically this has to be there right ? um professor b: oh are you gon na go there or not ? yeah , so one i grad e: given given uh uh not transverse the castle , the decision is does the person want to go there or is it just professor b: right , true . does have to be there . and i 'm sure we 'll find more as we go that grad e: and hmm ? so go - there in the first place or not is definitely uh one of the basic ones . we can start with that . interesting effect . um is this basically true or false or maybe we 'll get professor b: well grad d: which one ? grad e: what ? grad a: `` go there `` . grad e: m right . professor b: so there is this question about grad e: here we we actually get just probabilities , professor b: yeah . grad e: right for each down here . professor b: when we 're yeah when we 're done . so so grad e: hmm . professor b: the the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all , grad e: mm - hmm . professor b: right ? and so that a decision would be do we want that so you could two different things you could do , you could have all those values for go - there or you could have go - there be binary and given that you 're going there when . grad e: when . how . professor b: yeah and so forth . grad e: why , professor b: so i 'll let grad e: yeah . professor b: we 'll see . grad e: hmm ? grad a: i mean it seems that you could um uh it seems that those things would be logically independent like you would wan na have them separate or binary , go - there and then the the possibilities of how to go there because professor b: ok , that 's let 's start that way . grad a: because , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time . grad e: hmm . hmm . ok . and so i 've tried to come up with some initial things one could observe so who is the user ? everything that has user comes from the user model everything that has situation comes from the situation model - a . we should be be clear . but when it comes to sort of writing down when you when you do these things is it here ? you sort of have to a write the values this can take . professor b: right . grad e: and here i was really uh in some s sometimes i was really sort of standing in front of a wall feeling very stupid because um this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? so maybe my understanding there is too impoverished . grad a: hmm . professor b: no uh grad e: how can i write here that this is something , a number that cr keeps on changing ? but ok . thus is understandable ? grad a: think so . grad c: yes . grad e: so here for example . professor b: you 've s have you seen this before at all keith , these belief - net things ? grad a: uh , no , but i think i 'm following it . so far . grad e: so here is the the we had that the user 's budget may influence the outcome of decisions . professor b: yeah . grad d: hmm . grad e: there we wanted to keep sort of a running total of things . grad d: is this like a number that represents how much money they have left to spend ? ok , h well i mean how is it different from user finance ? grad e: um the finance is sort of here thought of as as the financial policy a person carries out in his life , he is he cheap , average , or spendy ? grad d: alright . grad e: and um i did n't come uh maybe a user i do n't know , i did n't want to write greediness , but grad a: yeah . hmm . professor b: or cheapness . grad e: welcome . grad a: user thrift . grad e: welcome . professor b: thrift , that 's good . grad d: yeah . professor b: great . grad e: there it is . professor b: yeah . so keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff . grad a: mm - hmm . professor b: so this is not just a display , this is actually a gui to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end . grad a: ok . ok . grad e: and it 's so simple even i can use it . grad a: wow , that is simple . grad e: ok , so here was ok , i can think of uh people being cheap , average , or spendy or we can even have a a finer scale moderately cheap , professor b: does n't matter . grad e: does n't matter . agree there but here um i was n't sure what to write in . professor b: let 's go ahead . grad d: well , i mean you 've written in you 've written in what uh seems to be required like what else is is do you want ? grad e: if that 's permissible then i 'm happy . professor b: well yeah . so here 's here 's what 's permissible is that you can arrange so that the um the value of that is gon na have to be updated and n it 's not a belief update , right ? it 's you took some actions , you spent money and stuff , so the update of that is gon na have to be essentially external to the belief - net . right ? grad e: yeah . professor b: and then what you 're going to need is uh for the things that it influences . well let 's first of all let 's see if it does influence anything . and if it does influence anything then you 're gon na need something that converts from the the number here to something that 's relevant to the decision there . so it could be ra they create different ranges that are relevant for different decisions or whatever but for the moment this is just a node that is conditioned externally and might influence various things . grad e: hmm . yeah this is where um ok anyways let 's forget it . professor b: well that 's fine . well anyway , go ahead . grad e: ok , and so this , oh that grad d: the other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you do we wan na propagate beliefs every single time it 's updated or only when we need to ? professor b: yeah , that 's a good question . and uh does it have a lazy mode ? i do n't remember . grad d: uh well , i mean , in srini 's thing there was this thing there was this um option like proper inferences which suggests that uh does n't happen , automatically . professor b: oh right . yeah . s probably does . yeah someone has to track that down , but i but uh and and and i think actually uh grad e: i just accidentally oops . professor b: one of the we w items for the uh user home base uh should be uh essentially non - local . i they 're only there for the day and they do n't have a place that they 're staying . grad d: well grad e: oh just uh accidentally erased this , i i just had values here such as uh um is he s we had in our list we had `` is he staying in our hotel ? `` , `` is he staying with friends ? `` , and so forth professor b: yeah . grad e: uh so we 're ok . professor b: so it 's clear where w w w where we are right now . so my suggestion is we just pick uh grad e: something down here ? professor b: one , you know one uh particular one of the uh well let 's do the first first one let 's do the one that we sort of already think we did so w that was the of the endpoint ? grad e: mm - hmm . and um oops . grad d: is hmm grad e: ah , grad d: so it 's true or false ? professor b: no , that 's that 's a grad e: ok . no no no , eva . grad d: so grad e: missed that one . grad c: what 's the difference between mode and endpoint ? grad d: i thought mode , yeah . professor b: although that grad e: um mode was um professor b: well , that 's grad d: mode of transportation ? grad e: yeah . grad d: ok . also true or false . grad e: mm - hmm . professor b: no , he has he has n't filled them in yet , is what 's true . grad d: yeah , ok . grad e: did i or did n't i ? ah . probably nothing done yet , oh i just did it on the upper ones , ok . makes sense . ok , so this was eva . maybe we can think of more things , cross grad d: yeah . grad a: climb , rob . professor b: ok . grad e: climb , emerge professor b: no no no , these are ju that 's just a point , grad c: uh grad d: well some of those are subsumed by approach . professor b: this is ju grad c: would it be an endpoint if you were crossing over it ? grad a: the charles bridge , you know . professor b: yeah , would be a f for a given segment . you know , you y you go first go the town square grad c: well i eh grad a: no , i mean , if you go to re you know if you go to prague or whatever one of your your key points that you have to do is cross the charles bridge and does n't really matter which way you cross which where you end up at the end but the part the good part is walking over it , so . professor b: that 's subtle , but true . anyway so let 's just leave it three with three for now grad e: mm - hmm , mmm . yeah . professor b: and let 's see if we can get it linked up just to get ourselves started . grad e: ok , we professor b: you 'll see it you 'll see something comes up immediately , that the reason i wan na do this . grad e: w well the uh user was uh definitely more likely to enter if he 's a local professor b: right . right . grad e: more likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um professor b: we did , but the three things w that that it contributed to this in fact , the other two are n't up there . so one was the ontology grad e: we 'll d what type of building is it ? professor b: yeah . grad e: yeah . professor b: and the and the third thing we talked about was something from the discourse . grad e: what he has mentioned before . professor b: ok , so this is w right , so what w i what we seem to need here , this is why it starts getting into the technical stuff grad a: mm - hmm professor b: the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . so each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations grad a: mm - hmm professor b: so if we wanted to do that would have to put in uh three intermediate nodes grad e: uh we can load it up it you know very simple . grad a: so professor b: and then what you and i have to talk about is , ok if we 're doing that and they get combined somehow uh how do they get combined ? but the they 're they 're undoubtedly gon na be more things to worry about . grad e: so this was adjusted for this one mode thing . grad d: oh yes . professor b: yeah . grad e: so that 's w w in our uh in in johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something . professor b: oh , it was called mode , so this this is m mode here means the same as endpoint . grad e: is now this endpoint . grad c: right . professor b: ok , why do n't we ch can we change that ? grad e: we can just rename that , yeah . professor b: alright . you know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's i do n't think what we would currently do . grad a: can i ask about `` slurred `` and `` angry `` as inputs to this ? professor b: that 's a grad a: what why ? grad d: like they 're either true or false grad e: the prosody ? grad a: ok . grad d: and they uh oh i see . grad c: if the if the person talking is angry or slurs their speech they might be tired or , you know grad a: mm - hmm . ok . drunk . grad d: therefore grad c: and , you know , possibly uh grad a: less likely to enter . grad c: some , grad a: hmm . grad c: yeah . grad d: uh i was thinking less likely to view professor b: yeah . but that 's - that seems to , yeah . so so my advice to do is is get this down to what we think is actually likely to to be a a strong influence . grad a: ok . professor b: but yeah , that was what he had in mind . grad d: right . professor b: so let 's think about this this question of how do we wan na handle so there 're two separate things . one is uh at least two . one is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing bhaskara , is uh can we arrange so that i think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . so the let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter grad a: mm - hmm . professor b: ok , et cetera . so that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow . grad a: mm - hmm . professor b: now grad e: seems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in in in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um professor b: right . right . grad e: if it 's exhibiting itself it is a landmark , professor b: yeah . grad e: meaning more likely to be viewed professor b: yep . grad e: if it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered . professor b: i uh that 's i think that 's completely right and um i think that 's good , right ? so what what that says is that we might be able to uh take and in particular so so the ones we talked about were uh exhibiting and selling grad e: accessibility . professor b: no , accessibility meant grad e: if it 's closed one probably wo n't enter . or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it , professor b: ok . grad e: given that he knows it , of course . professor b: alright . so let me suggest this . uh w could you move those up about halfway . uh the ones that you th and selling i guess . grad e: yeah , all all of these if it 's fixing things selling things , or servicing things professor b: right . so here here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of of uh selling , f fixing , or servicing . so that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . does that seem right ? so we di grad c: basic you 're basically just merging those for just the sake of endpoint decision ? professor b: if we yes . grad c: yeah . grad a: mm - hmm . professor b: so if well it may be more than endpoint decisions , so the idea would be that you might wan na merge those three grad e: these three ? professor b: yeah . eh ser s uh selling , fixing , and servicing . grad e: yeah . grad d: what ex um and so either those is true f or false ? professor b: uh uh well it it i here 's where it gets a little tricky . grad d: so professor b: uh from the belief - net point of view it is from another point of view of course it 's interest it 's it 's important to know what it 's selling or servicing and so forth . grad a: yeah . professor b: so for this decision it 's just uh true or false grad d: ok . yeah . professor b: and in th this is a case where the or seems just what you want . grad d: ok . professor b: that that if any of those things is true then it 's the kind of place that you uh grad e: um more likely to enter . professor b: are more likely to enter . grad d: so you just wan na have them all pointing to a summary thing ? professor b: you could , yeah . yeah , so let 's do that . no no , no eh to to an inter no , an intermediate node . grad d: t grad e: oh , ok . professor b: that 's the p part of the idea , is grad e: um is is that the object type node ? professor b: i d grad e: so are they the is it the kind of object that sells , fixes , or services things ? professor b: well , o open up object type and let 's see what its values are . grad e: oh i just created it , it has none so far . professor b: oh , well ok first of all it 's not objects , we called them entities , right ? grad e: yeah . and then we have sort of the um professor b: let 's say i put commercial . grad e: yeah , i w i was just gon na commercial action inside where people p professor b: well could n't i do let 's do commercial uh landmark and grad e: and where was the accessible , yeah . professor b: well accessible i think is different cuz that 's tempor that that varies temporally , grad e: yeah . professor b: whereas this is a grad e: mm - hmm . grad c: what would a hotel fall under ? professor b: i would call that a service , but but i do n't know . grad c: well i mean in terms of entity type ? professor b: say w w well it 's co i would s a a again for this purpose i think it 's commercial . someplace you want to go in to do some kind of business . grad c: ok . grad d: um what does the underscore - t at the end of each of those things signify ? grad e: um things . so places that service things sell things or fix things and pe places that e exhibit things . grad d: uh - huh . ok . ok . that also points to entity type i guess . grad a: so we 're deriving um this the this feature of whether the the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? could n't you have it as just a primitive feature of the entity ? professor b: well you could , that 's a that 's a choice . grad a: ok . professor b: so uh grad a: i mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else professor b: yeah , the problem with it is that it sort of putting in a feature just for one decision , grad a: and hmm . professor b: now w we may wind up having to do that this i anyway , this i grad a: ok . professor b: at a mental level that 's what we we 're gon na have to sort out . grad a: ok . professor b: so , you know what does this look like , what are what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions grad a: mm - hmm . professor b: and what 's the best way to organize this so that um it 's clean and and consistent and all that sort of stuff . grad a: ok . i 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably you would n't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something . grad e: well i think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things , grad a: mm - hmm . grad e: it 's not either or mmm certainly a place can be a hotel and a famous site . grad a: mm - hmm . grad e: many come to mind . things can be generally um a landmark and be accessible . ie a a castle or can be a landmark a or not accessible , some statue grad a: mm - hmm . grad e: you know can go inside . professor b: ok . anyway so let me suggest you do something else . uh which is to get rid get rid of that l long link between who the user and the endpoint . grad e: could we just move it like this ? professor b: no no , i do n't want the link there at all . grad e: oh , ok . professor b: because what we 're gon na want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we we what we talked about is three separate endpoint decisions , so let 's make a new node grad e: yeah . yeah . grad c: just as a suggestion maybe you could `` save as `` to keep your old one nice and clean and so you can mess with this one . grad e: mmm . the old one was not that not that important , i think but grad c: ok , well , not a big deal then . grad e: let 's do it then . grad c: well the is n't there a `` save as `` inside of java base ? grad e: but i can just take this grad c: ok . grad e: copy it somewhere else . this was user something professor b: well this was grad e: or professor b: uh let 's p put it this let 's do endpoint underbar - u . grad e: end point ? professor b: i endpoint , e end poi this is sa grad e: ah . professor b: it 's the endpoint grad e: gotcha , yeah . professor b: let 's say underbar - u , so that 's the endpoint decision uh as seen through the grad c: as related from the user model . professor b: right . so let 's let 's actually yeah so lin you can link that up to the grad e: should i rename this too ? professor b: uh yeah , so that , i guess that 's endpoint uh grad e: it 's underscore - e . professor b: underscore - e for entity , and we may change all this , but . right . and grad e: ok , should n't i be able to move them all ? no . or ? can i ? where ? what ? professor b: oh i d eh i do n't know . actually , i guess the easiest thing would move mo move the endpoint , well , go ahead . just do whatever . grad e: was n't this possible ? professor b: well . grad e: yeah . grad c: i think you have to be in move mode before grad e: uh - huh . ok . professor b: good . right . grad e: so now we 're looking for user related things that um professor b: yeah . and uh maybe th maybe it 's just one who is the user , i do n't know , maybe maybe there 's more . grad a: huh . grad e: well if he 's usi if he 's in a car right now what was that people with harry drove the car into the cafe professor b: never mind . uh anyway , this is crude . now but the now so so but then the question is uh so and and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse . grad e: well let 's should we finish this , professor b: sure , grad e: i mean but surely the user interests professor b: ok . grad c: the user thrift , the user budget . grad e: yeah , yeah professor b: well , maybe , i again , i d well , ok , put em in but what we 're gon na wan na do is actually uh grad c: well is grad e: here this was one of my problems we have the user interest is a is a vector of five hundred values , so um that 's from the user model , grad d: oh you mean level of interest ? grad e: mm - hmm , no not levels of interest but things you can be interested in . grad a: well professor b: somebody else has built this user model . grad d: oh i see , grad e: gothic churches versus baroque townhouses versus grad d: right . so why is it oh it , so it 's like a vector of five hundred one 's or zero 's ? grad e: yea - n is that grad d: like for each thing are we are you interested in it or not ? grad e: yeah uh i i think grad d: i see . grad a: hmm . professor b: ok . so uh you cou and so here let me give you two ways to handle that . alright ? one is um you could ignore it . but the other thing you could do is have an and this will give you the flavor of the of what you could have a node that 's that was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user . grad e: mm - hmm . uh . professor b: so you could have a k a `` fit `` node and again that would have to be computed by someone else grad e: mm - hmm . professor b: but uh so that uh grad e: just as a mental note uh professor b: yeah , that 's all . grad e: mm - hmm . and and should we say that this interests eh affects the likelihood of of entering ? professor b: yeah . i mean , we could . grad e: yeah . and also if it 's an expensive place to enter , this may also professor b: ok . grad d: budget . grad a: user schedule . `` do i have time to go in and climb all the way to the top of the koelner dome { comment } or do i just have to `` `` time to take a picture of the outside ? `` grad e: schedule ? professor b: right . grad c: it seems like everything in a user model a affects professor b: well that 's what we do n't wan na do , see that se cuz then we get into huge combinatorics and stuff like that grad c: yeah . grad a: mm - hmm . professor b: an grad c: cuz if the , i mean , and if the user is tired , the user state , grad d: well grad c: right , it would affect stuff , but i ca n't see why e anything w everything in the model would n't be professor b: well , but grad d: right . professor b: well , that that 's we ca n't do that , so we we 're gon na have to grad c: yeah . professor b: but this is a good discussion , we 're gon na have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and and his energy grad c: yeah , just seems like it 'd push the problem back a level . grad d: right . professor b: it does . grad a: mm - hmm . grad c: yeah , but grad d: no but , it 's more than that , like the the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore . professor b: so it yeah , there are two advantages . that 's tha there 's one technical one grad c: sh - sh yeah , professor b: and the other is it it gets used grad c: s so we 'd basically be doing subgrouping ? subgrouping , basically into mo grad d: yeah . grad c: so basically make it more tree like going backwards ? grad d: right . grad a: yeah . professor b: right . but it there 's two advantages , one is the technical one that you do n't wind up with such big exponential uh cbt 's , grad e: bhaskara ? professor b: the other is it can be it presumably can be used for multiple decisions . grad a: mm - hmm . professor b: so that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u grad d: right . professor b: not only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . anyway th so in general this is the design , this is really design problem . grad e: yeah . professor b: ok , you 've got a signal , a d set of decisions um how do we do this ? grad e: what do i have under user state anyhow cuz i named that already something . oh that 's tired , fresh , yeah . maybe should be renamed into physical state . professor b: or fat user fatigue even . grad a: hmm . grad e: that 's with a `` g `` ? grad a: mm - hmm . professor b: whatever . grad e: then we can make a user state . professor b: what 's th what we 're talking about is compatibility . uh or something , i do n't know , but . grad c: i guess the the question uh is it 's hard for me to imagine how everything would n't just contribute to user state again . or user compatibility . professor b: oh but the thing is that we uh uh we had some things that uh grad e: that do n't . professor b: that do n't grad e: the user interests and the user who who who the user is are completely apart from the fact whether he is tired broke grad c: sure , but other i thought though the node we 're creating right now is user compatibility to the current action , right ? professor b: the right grad c: seems like everything in the user model would contribute to whether or not the user was compatible with something . professor b: uh maybe not . i mean the that 's the the issue is um would even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . and anyway we 're gon na have to find some way to cl uh get this sufficiently simple to make it feasible . grad e: maybe um if we look at the if we split it up again into sort of um if we look at the uh the endpoint again we we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . viewing usually is cheap or free . grad a: mm - hmm . grad e: is that always true ? i do n't know . grad c: well , with the way we 're defining it i think yeah . professor b: w w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you grad e: and so is approaching . professor b: yeah . grad a: well what about the grand canyon , right ? no , never mind . i mean are there are there large things that you would have to pay to get up close to like , i mean never mind , not in the current professor b: no we have to enter the park . grad a: ok . professor b: eh almost by definition um paying involves entering , grad a: yeah . professor b: ge going through some grad a: ok . right , sure . professor b: right . uh so let me suggest we switch to another one , i mean clearly there 's more work to be done on this grad e: mm - hmm . professor b: but i think it 's gon na be more instructive to to think about uh other decisions that we need to make in path land . and what they 're gon na look like . grad c: so you can save this one as and open up the old one , right and and then everything would be clean . you could do it again . professor b: why , i think it 's worth saving this one but i think i 'd i 'd like to keep this one grad d: yeah . professor b: cuz i wan na see if if we 're gon na reuse any of this stuff . grad c: mm - hmm . grad e: um so this might be what next ? professor b: well you tell me , so in terms of the uh planner what 's what 's a good one to do ? grad e: well let 's th this go there or not i think is a good one . professor b: uh grad e: is a very basic one . so what makes things more likely that professor b: well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse . grad e: so professor b: so keith this is gon na get into your world because uh we 're gon na want to know you know , which constructions indicate various of these properties grad a: mm - hmm . mm - hmm . professor b: s and so i i do n't yet know how to do this , i guess we 're gon na wind up pulling out uh discourse properties like we have object properties and we do n't know what they are yet . grad a: mm - hmm . professor b: so that that the go - there decision will have a node from uh discourse , and i guess why do n't we just stick a discourse thing up there to be as a placeholder for grad e: we we also had discourse features of course for the endpoint . professor b: of of course . grad e: identified that professor b: yeah . grad e: and so again re that 's completely correct , we have the user model , the situation model here , we do n't have the discourse model here yet . much the same way as we did n't we do n't have the ontology here . professor b: well the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth . grad e: really . professor b: so in some sense it 's it 's there . grad e: mm - hmm . professor b: but the discourse we do n't have it represented at all yet . grad e: yeah . um this be specific for second year ? um and and we probably will have uh something like a discourse for endpoint . professor b: but if we do it 'll have the three values . grad e: hmm ? professor b: it 'll have the eva values if if we have it . grad e: yeah . yeah . ok just for starters and here discourse um professor b: for go - there , probably is true and false , let 's say . that 's what we talked about . grad e: um well , i think um we 're looking at the the little data that we have , so people say how do i get to the castle and this usually means they wan na go there . grad a: mm - hmm . grad e: so this should sort of push it in one direction professor b: right . grad e: however people also sometimes say how do i get there in order to find out how to get there without wanting to go there . professor b: mm - hmm . grad e: and sometimes um people say where is it grad a: mm - hmm . grad e: because they wan na know where it is but in most cases they probably professor b: yeah , but that does n't change the fact that you 're you want these two values . grad e: oh yeah , true . so this is sort of some external thing that takes all the discourse stuff and then says here it 's either yep , yay , a , or nay . yeah . ok ? professor b: and they 'll be a y uh , a user go - there and maybe that 's all , i do n't know . grad d: situation go - there , i mean , because it 's whether it 's open or not . grad e: mm - hmm . professor b: ok , good . grad d: that definitely interes professor b: yep . grad d: but that now that kind of um what 's the word grad a: hmm . grad d: um the that interacts with the uh eva thing if they just wan na view it then it 's fine to go there when it 's closed whereas if they want to um professor b: right . grad d: so professor b: right , so that 's that 's where it starts getting to be uh uh essentially more interesting , so what uh bhaskara says which is completely right is if you know that they 're only going to view it then it does n't matter whether it 's closed or not grad a: mm - hmm . professor b: in terms of uh uh you know , whether whether you wan na go there . grad d: the time of day , grad a: mm - hmm . grad d: right i well , right . grad c: it does matter though if there 's like a strike or riot or something . professor b: absolutely there are other situational things that do matter . grad d: right . so yeah , that 's what i said just having one situational node may not be enough because this that node by itself would n't distinguish professor b: well i i it can have di various values . yeah , but we eh you you 're right it might not be enough . grad d: yeah , i mean , see i 'm i 'm thinking that any node that begins with `` go - there `` is either gon na be true or false . grad a: well , what whoops . professor b: yeah . grad a: right . professor b: ah . i see that could be . grad a: also , that node , i mean the go - there s s node would just be fed by separate ones for grad e: mm - hmm . grad a: you know , there 's different things , the strikes and the professor b: could be . yeah . n grad d: like situation traffic and so on . grad a: yeah , the time of day . professor b: yeah . yeah . so so now the other thing that bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gon na get very messy from the endpoint uh decision grad d: i guess the final professor b: maybe the t they 're final re and , i guess the very bottom endpoint decision uh to the go - there node . and i do n't worry about layout , grad d: yeah . professor b: i mean then we 'll go we 'll go nuts but grad d: mmm . grad e: mm - hmm . grad d: maybe we could um have intermediate node that just the endpoint and the go - there s node sort of fed into ? professor b: could be , yeah . grad d: right . because that 's what we , i mean that 's why this situation comes up . professor b: yeah . well the go - there , actually the endpoint node could feed feed into the go - there s that 's right , grad d: yeah , right . professor b: so the endpoint node , grad e: mm - hmm . professor b: make that up t t to the go - there then grad e: yeah . professor b: and again we 'll have to do layout at some point , but something like that . now it 's gon na be important not to have loops by the way . uh really important in in the belief worl net world not to have loops grad e: i was just gon na professor b: uh grad d: yes . grad e: how long does it take you to to compute uh professor b: no it 's much worse than that . it if i loo it it it it it 's not def i it 's not well defined if you 're there are loops , grad d: it things do n't converge , yeah . grad e: uh r recursive action ? professor b: you just you have to there are all sorts of ways of breaking it up so that there is n't uh ok . grad e: uh but this is n't , this is this line is just coming from over here . grad d: yeah . professor b: yeah , no it 's not a loop yet , i 'm just saying we we , in no , in grad d: yeah . well , but the good thing is we we could have loopy belief propagation which we all love . grad e: mmm . professor b: right . ok , so anyway , so that 's another decision . uh what 's what 's another decision you like ? grad e: ok , these have no parents yet , but i guess that sort of does n't matter . right ? professor b: well , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is is a mystery . grad e: i mean this is sort of this comes from traffic and so forth , yeah . sh - should we just make some professor b: sure , if you want . grad e: um if there 's parking maybe mmm oh who cares . ok . and if he has seen it already or not and so forth , professor b: right . grad e: ok . um and discourse is something that sort of should we make a keith note here ? professor b: sure . grad e: that sort of comes from keith . professor b: mm - hmm . grad e: just sort of so we do n't forget . oops . have to get used to this . ok , whoops . grad a: um actually professor b: and then also the discourse endpoint , i i guess endpoint sub - d is if you wan na make it consistent . grad c: wh - ah . grad e: mm - hmm . grad a: um actually is this the the right way to have it where um go there from the user and go there from the situation just sort of do n't know about each other but they both feed the go there decision because is n't the , i mean professor b: i think so . s grad a: uh , hmm ok . but that still allows for the possibility of the of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from professor b: maybe not , a right . grad a: that all that that kind of decision making happens at the go - there node . professor b: uh y you yeah you i you if you needed to do that . grad a: uh . if you needed it to do that . professor b: yeah . grad a: but uh ok i was just thinking i guess maybe i 'm conflating that user node with possible possible asking of the user professor b: yeah . grad a: you know hey there 's a strike on , uh does that affect whether or not you wan na go or something professor b: ah . good point , i do n't i do n't know how we 're going to t uh grad a: or yeah , so that might not come out of a user model but , you know , directly out of interaction . professor b: right . uh i gu yes my curr you know , do n't yeah yeah yeah that 's enough . grad e: yeah . professor b: uh my current idea on that would be that each of these decision nodes has questions associated with it . grad a: mm - hmm . professor b: and the question would n't itself be one of these conditional things grad a: ok . professor b: you know , given that you know there 's a strike do you still wan na go ? grad a: yeah . professor b: but uh if you told him a bunch of stuff , then you would ask him do you wan na go ? grad a: mm - hmm . ok . professor b: but i think trying to formulate the conditional question , that sounds too much . grad a: right , right . yeah . right , sure , ok . professor b: to me . grad e: mm - hmm . professor b: alright , but let me let let 's stay with this a minute grad e: but professor b: because i want to do a little bit of organization . before we get more into details . the organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed keith is going to to worry about the various constructions that people might use grad a: mm - hmm . professor b: and johno has committed himself to being the parser wizard , grad a: alright . professor b: so what 's going to happen is that eventually like by the time he graduates , ok uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . i j wa i i assume everybody knows that , i just wan na you know , get closure that that 'll be the game then , grad a: mm - hmm . professor b: so the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . and now some of those will get fancier like mode of transportation and stuff so it is n't by any means uh necessarily a simple thing that you want out . so uh if there is an and there is mode of transportation grad e: and it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us professor b: yeah . grad e: and then what 's the discourse history give us . professor b: yeah , well that , well , we 'll have to decide uh how much of th where that goes . grad a: mm - hmm . grad e: that 's uh two things then . grad a: mm - hmm . grad e: mmm . professor b: an and it 's not clear yet . i mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there , grad a: mm - hmm . professor b: wow , what does that mean and uh grad e: mm - hmm grad a: now . mm - hmm . professor b: alright . so grad e: but is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each each decision on the very bottom we sort of get the sub - e , sub - d , sub - u and maybe a sub - o `` o `` for `` ontology `` um meta node professor b: i do n't know . grad e: but it might just professor b: it could be . grad e: could be professor b: this is this is getting into the thing i wan na talk about next , grad e: so this professor b: which is s if that 's true uh how do we wan na combine those ? o or when it 's true ? grad e: but this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions . professor b: yeah . grad d: yeah . grad e: and four you we can handle . professor b: no . grad d: yeah . grad e: it 's too much ? professor b: well i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big cpt , it 's not s completely impossi i mean it 's it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn . grad e: right , true . professor b: uh but , you know it 's four to the fourth . it 's pretty big . uh . grad c: two fifty - six , professor b: yeah . grad c: is that what that professor b: yeah , i mean it 's and i do n't think it 's gon na g e i do n't think it 'll get worse than that by the way , so le that 's a that 's a good grad d: mmm yeah . grad e: but but four did n't we decide that all of these had true or false ? so is it 's four professor b: uh for go there , but not f but not for the other one 's three values for endpoint already . grad c: yeah . grad d: yeah , i mean you need actually three to the five because uh well i mean if if it has four inputs and then it itself has three values grad c: right . grad d: so i mean it can get big fast . grad e: um for endpoint ? no it 's it 's sh professor b: ev - it 's the eva . grad e: yeah , down here , but this one only has two . professor b: no . grad d: no it still has three , professor b: since ta they will still have three . grad d: eva . professor b: each so you 're uh uh from each point of view you 're making the same decision . grad a: mm - hmm . mm - hmm . professor b: so from the point of view of the ob of the entity grad e: want to view that , yeah yeah . c sl professor b: yeah . grad e: yeah grad d: this and also , i mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift professor b: right . grad d: so even professor b: those are not necessarily binary . s so we 're we 're gon na have to use some t care in the knowledge engineering to not have this explode . and in fact i think it does n't in the sense that um read it , you know actually with the underlying semantics and stuff i think it is n't like you have two hundred and fifty - six different uh ways of of thinking about whether this user wants to go to some place . alright . so we we just have to figure out what the regularities are and and code them . but um what i was gon na suggest next is maybe we wan na work on this a little longer but i do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there . grad a: mm - hmm . professor b: so th yes they so these things all affect it , grad a: right . professor b: how do they affect it ? and belief - nets have their own beliefs about uh what are good ways to do that . so is it it 's it 's clearer n clear enough what the issue is , grad d: right . professor b: right ? so do we wan na switch that now or we wan na do some more of this ? grad e: r basically w we just need to sort of in order to get some closure on this figure out how we 're gon na get this picture sort of uh completely messy . professor b: well , here he here 's one of the things that that i th you sh you no , i do n't know how easy it is to do this in the interface but you it would be great if you could actually just display at a given time uh all the things that you pick up , you click on `` endpoint `` , ok and everything else fades grad e: mm - hmm . professor b: and you just see the links that are relevant to that . and i does anybody remember the gui on this ? grad c: uh d i would almost say the other way to do that would be to open u or make you know n - many belief - nets and then open them every time you wanted to look at a different one grad e: mm - hmm . grad c: vers cuz uh grad e: it 's probably pretty easy do it to do it in html , just grad c: yeah , but grad e: uh grad d: html ? grad e: yeah i have each of these thing each of the end belief - nets be be a page and then you click on the thing and then li consider that it 's respective , professor b: yeah the well the b grad d: ok . grad e: but professor b: anyway so uh it clear that even with this if we put in all the arrows nobody is gon na be able to read the diagram . grad c: yeah . professor b: alright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway i i let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences a , a , and b how do they get combined mathematically , how do we display them is an issue , but um grad c: i do n't , yeah i just do n't think this has been designed to support something like that . grad d: yeah . yeah , i i mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes . professor b: right . yeah , and um i that seems like a perfectly feasible thing to get into , but um we have to know what we want first . ok , so why do n't you tell us a little bit about decision nodes and what what the choices might be for these ? grad d: so ah , sorry . i guess that 's grad c: you can technically wear that as you 're talking . grad d: yeah , it 's right , i guess i can do that . grad a: darn . professor b: put it in your , yeah . grad d: i guess this board works fine . so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . right ? so as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these s have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . so what um helps us in our situation is that these all have values in the same set , right ? these are all like saying ev or a , right ? so it 's not just a generalized situation like i mean basically we wan na just take a combination of we wan na view each of these as experts ea who are each of them is making a decision based on some factors and we wan na sort of combine their decisions and create you know , um sorta weighted combination . grad e: hmm . rover , the rover decision . grad d: the what decision ? grad e: rover . all of their outputs combined to make a decision . grad a: hmm . grad d: yeah . yeah . so the problem is to specify the uh so the conditional property of this given all those , right ? that 's the way belief - nets are defined , like each node given its parents , right ? so um that 's what we want , we want for example p of um let 's call this guy y and let 's call these x - one , x - two xn , right . so we want probability that y equals , you know , for example um e given that these guys are i 'll just refer to this as like x um hat or something , uh the co like all of them ? given that for example the data says you know , a , v , a , e , or something right ? professor b: yep . grad d: so we would like to do this kind of combination . professor b: alright , so um is that uh i yeah , i just wan na make sure everybody is with us before he goes on . grad a: i think so , yeah . professor b: it 's it 's cl e is is it clear what he wants to compute ? grad a: mm - hmm . grad d: right . so , right . so basically um what we do n't wan na do is to for every single combination of e and v and a and every single letter e , s give a number grad a: mm - hmm . grad d: because that 's obviously not desirable . what we wan na do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ? grad a: hmm . grad d: so those are the two things that we uh need . so what uh i guess , what jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? so for example here two people have voted for a , one has voted for v , and one has voted for e , so we could say that the probabilities are , you know , probability of being e is one over four , because one person voted for e out of four and similarly , probability of so this is probability of e s and then probability of a given all that is um two out of four and probability of v is one out of four . right ? so that 's step that 's the uh yeah that 's the that 's the basic uh thing . now grad e: um yeah . grad d: is that all ok ? grad e: and that one outcome , that 's professor b: what ? grad e: it 's x x - one voted for a x - two voted for v grad a: mm - hmm . grad e: and so forth ? professor b: y right . yep . grad d: yeah . grad e: yeah . professor b: s so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption , grad e: that 's the outcome . grad a: mm - hmm . right . professor b: so that grad d: yeah . yeah . so step two is um right . so we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh grad c: x - one matters more i than x - two or grad d: right . sure , so we do n't wan na like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh w - one , w - two , w - three , and w - four grad a: hmm . grad d: right ? and in order for this to be a valid probability distribution for each um x - hat , we just need that the w 's sum to one . so they can be for example , you know you you could have point one , point three , point two , and point four , say . grad e: that 's one . grad d: and that 'd be one . so that um also seems to work fine . and uh grad c: so i jus just to make sure i understand this , so in this case um we would still compute the average ? grad d: you 'd compute the weighted average , so the probability of e would be uh grad c: ok , so so it 'd be so in this case the probability that y equals a would be uh { comment } w one times grad a: point three . grad c: or a or let 's see , one full quarter times point one grad d: not one quarter , grad a: no . grad d: so these numbers have been replaced with point one , point three , point two , and point four . so you can view these as gone . grad c: ok . grad d: probability of grad c: ok . grad d: yeah . yeah . ok . so , alright . so this is uh step two . so the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . so the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called `` h `` , ok ? this is a hidden variable . and what this is is it gets its input from x - one , x - two , x - three , and x - four , and what it does is it decides which of the experts is to be trusted in this particular situation . right ? and then these guys all come here . ok . so this is sightly uh more complicated . so what 's going on is that um this h node looks at these four values of those guys and it decides in given these values which of these is n't likely to be more reliable or most reliable . so h produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? now this guy he looks at the value of h say it 's two , and then he just selects the uh thing . that 's all there is to say , i guess about it . right , so you can have a mixture that grad e: mm - hmm . grad d: right . grad a: so so the function of the thing that comes out of h is very different from the function of the other inputs . it 's driving how the other four are interpreted . ok . grad d: yeah . yeah . grad c: so h passes a vector on to the next node ? grad d: it could . grad c: it could ? a vector of the weights as the se grad d: yeah , it could grad c: oh . grad d: sorry ? grad a: well a vector with three zero 's and one one , right ? grad c: oh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems grad d: right , so i mean the way you desc grad c: w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , could n't you ? ok . grad a: um does h have to have another input to tell it alpha , beta , whatever , or is the that 's determined by what the experts are saying , like the type of situ ok . hmm . ok . ok . i mean it it just seems that like without that that outside input that you 've got a situation where , you know , like if if uh x - one says no , you know , a low value coming out of x - on or i if x - one says no then ignore x - one , you know , i mean that seems like that 'd be weird , grad d: yeah , well could be things like if x - two and x - three say yes then i ignore x - one also . grad a: right ? oh , ok . ok . alright , right . grad c: oh the situations that h has , are they built into the net or ok , so they they could either be hand coded or learned or ok . grad d: yeah . grad c: based on training data , ok . grad d: yeah . yes . grad c: so you specify one of these things for every one of those possi possible situations . oh yeah . grad d: yeah . um well , i mean to learn them we need data , where are we gon na get data ? well i mean we need data with people intentions , right ? grad a: right , right . grad d: which is slightly tricky . right . grad a: uh - huh . grad d: mm - hmm . but what 's the data about like , are we able to get these nodes from the data ? grad a: like how thrifty the user is , or do we have access to that ? mm - hmm . oh right . oh good . ok . grad d: yeah . grad a: mm - hmm . mm - hmm . ok . grad d: yeah , but that 's my question , like how do we i mean , how do we have data about something like um um endpoint sub - e , or endpoint sub uh you know s s ? grad c: well , basically you would say , based on in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was , grad d: mmm . mmm . grad c: right ? grad d: so this is what we wan na learn . yep . right . hmm . yeah . i do n't think , well you have a can you bring up the function thing ? um w where is the thing that allows you to sort of grad c: that 's on the added variable , is n't it ? grad d: oh function properties , is that it ? hmm , i guess not . yeah , that 's grad a: no . grad d: right . ok . and um it so e either it 'll allow us to do everything which i think is unlikely , i think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such cpu 's on your own in the java base format . yeah . yeah . yeah , i was assuming that 's what we 'd always do because yeah i was assuming that 's what we 'd always do , it 's right . yeah . grad c: ah . well in terms of java base i think it 's basically what you see is what you get in i do n't yeah , i would be surprised if it supports anything more than what we have right here . grad a: so yeah . yeah . by the way um uh just talking about uh about that general end of things uh is there gon na be data soon from what people say when they 're interacting with the system and so on ? like , i mean , what kind of questions are being given being asked ? cuz ok . yeah yeah . ok . ok . fey , you mean . ok . ok . o ok . ok . i 'm just wondering , because in terms of , you know , i mean uh w the figure i was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , i mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , i mean i know we 're going for sort of a rough and ready . mm - hmm . mm - hmm . ok . ok . i mean , i i i i was uh i was talking about the , you know , if you wanted to do it really in detail and we do n't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do i do , i wan na see what people are using , so well , it will inspire me . right , sure sure . right . yeah , sure . sure . yeah . ok . touche . good enough .","output":"grad d first said that different experts were reliable in different situations and it was necessary to organically combine them to make the network adapt to diverse situations . the network could be divided into several parts and the network would decide which of the experts would be trusted in this particular situation . grad d then answered other group members ' questions about the layout of mixture of expert models and their detailed computation process ."},{"instruction":"summarize the meeting","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"the group discussed the first version of the bayes-net used to work out a user 's intentions when asking for directions from a navigation device . three intentions were identified : vista ( to view ) , enter ( to visit ) and tango ( to approach ) . the structure of the belief-net comprises , firstly , a feature layer , which includes linguistic , discourse and world knowledge information that can be gleaned from the data . it is possible for these variables to form thematic clusters ( eg `` entrance '' , `` type of object '' , `` verb '' ) , each one with a separate middle layer . at this stage , all the actual probabilities are ad-hoc and hand-coded . however , there has been progress in the design and organisation of experiments , that will eventually provide data more useful and appropriate for this task ."},{"instruction":"what did grad b say about the structure of the belief net ?","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"it is necessary for the belief-net to have at least one layer of nodes between the features and the final output . this makes the structure more flexible in terms of coding feature-layer probabilities ."},{"instruction":"what was the next step on features ?","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"the next stage is to refine the set of feature nodes and identify possible clusters . although , in theory , traditional ai plan recognition techniques could also be helpful for inferring intentions , the schemas involved are too elaborate for this task ."},{"instruction":"summarize what was said on intentionality","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"there was a demonstration of the structure and the function of a toy version of the belief-net for the intentionality task . the features nodes include things like prosody , discourse , verb choice , `` landmark-iness '' of a building , time of day and whether the admission fee was discussed ."},{"instruction":"how would the middle layer work ?","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"the values these nodes take feed into the middle layer nodes identified as hidden variables of the user\/device interaction , such as whether the user is on tour , running an errand or in a hurry . these , in turn , help infer whether the user wants to see , enter or simply approach a building ."},{"instruction":"what was the importance of smartkom ?","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"smartkom , although it does not code for intentions as specified in this task , provides a model of the discourse , which can be useful for the detection of features through querying and anaphora resolution ."},{"instruction":"what was said about hiring ?","input":"grad c: nice . grad d: ok . grad a: to to handle . grad d: is that good ? grad c: right . yeah , i 've have never handled them . grad b: goats eat cans , to my understanding . tin cans . grad d: did we need to do these things ? grad c: wow . grad d: ok . grad b: could i hit hit f - seven to do that ? on the robert ? grad a: i 'm grad b: oh , the remote will do it ok . grad d: ok . grad b: cuz i 'm already up there ? grad a: in control here . grad b: you are in control . already ? grad d: wow , we 're all so high tech here . yet another p powerpoint presentation . grad b: i well it makes it easier to do grad d: certainly does . grad b: so , we were ah ! grad c: johno , where are you ? grad b: ok . so , let 's see . which one of these buttons will do this for me ? aha ! ok . grad c: should you go back to the first one ? grad b: do i wan na go back to the first one ? grad c: well grad b: ok . grad d: i 'm sorry i grad c: well , i mean , just to grad b: ok . introduce . grad d: ok . grad c: yeah , um well , `` the search for the middle layer `` . it 's basically uh talks about uh it just refers to the fact that uh one of main things we had to do was to decide what the intermediate sort of nodes were , grad d: i can read ! i 'm kidding . grad c: you know , because grad d: mm - hmm . grad a: but if you really want to find out what it 's about you have to click on the little light bulb . grad b: although i 've i 've never i do n't know what the light bulb is for . i did n't i install that into my powerpoint presentation . grad a: it opens the assistant that tells you that the font type is too small . grad b: ah . grad a: do you wan na try ? grad d: ach u grad b: i 'd prefer not to . grad a: ok . continue . grad d: it 's a needless good idea . is that the idea ? grad a: why are you doing this in this mode and not in the presentation mode ? grad d: ok . grad b: because i 'm gon na switch to the javabayes program grad a: oh ! ok . of course . mm - hmm . grad b: and then if i do that it 'll mess everything up . grad d: i was wondering . grad b: is that ok ? grad d: yeah , it 's ok . grad a: sure . grad c: can you maximize the window ? grad d: proceed . grad b: you want me to wait , what do you want me to do ? grad c: can you maximize the window so all that stuff on the side is n't does n't appear ? grad a: no , it 's ok . it 's it 'll work . grad b: well i can do that , but then i have to end the presentation in the middle so i can go back to open up grad c: ok , fine . grad b: here , let 's see if i can grad c: alright . grad d: very nice . grad b: is that better ? ok . grad c: yeah . grad b: uh i 'll also get rid of this `` click to add notes `` . ok . grad d: perfect . grad b: so then the features we decided or we decided we were talked about , right ? uh the the prosody , the discourse , verb choice . you know . we had a list of things like `` to go `` and `` to visit `` and what not . the `` landmark - iness `` of uh i knew you 'd like that . grad d: nice coinage . grad b: thank you . uh , of a of a building . whether the and this i we actually have a separate feature but i decided to put it on the same line for space . `` nice walls `` which we can look up because i mean if you 're gon na get real close to a building in the tango mode , right , there 's got ta be a reason for it . and it 's either because you 're in route to something else or you wan na look at the walls . the context , which in this case we 've limited to `` business person `` , `` tourist `` , or `` unknown `` , the time of day , and `` open to suggestions `` , is n't actually a feature . it 's `` we are open to suggestions . `` grad d: right . can i just ask the nice walls part of it is that uh , in this particular domain you said be i it could be on two different lines but are you saying that in this particular domain it happens the that landmark - iness cor is correlated with grad b: oh grad c: no . we have a separate grad b: they 're separate things . grad c: feature . grad d: their being nice w grad b: yeah . grad d: ok . grad b: i either could put `` nice walls `` on its own line or `` open to suggestions `` off the slide . grad c: like you could have a p grad d: and and by `` nice `` you mean grad c: you like you could have a post office with uh you know , nice murals or something . grad b: right . grad d: ok . grad b: or one time i was at this grad d: so `` nice walls `` is a stand in for like architecturally it , uh significant grad b: but see the thing is , if it 's grad c: architecturally appealing from the outside . grad d: or something like that . ok . grad b: yeah but if it 's architecturally significant you might be able to see it from like you m might be able to `` vista `` it , grad a: mm - hmm . grad b: right ? and be able to grad a: appreciate it . grad d: mm - hmm . grad b: yeah , versus , like , i was at this place in europe where they had little carvings of , like , dead people on the walls or something . grad d: mm - hmm . grad b: i do n't remember w grad d: uh - huh . grad b: it was a long time ago . grad d: there 's a lot of those . grad b: but if you looked at it real close , you could see the the in intricacy of the of the walls . grad d: ok . so that count as counts as a nice wall . grad a: mm - hmm . grad b: right . grad d: the ok . right . grad a: the grad d: something you want to inspect at close range because it 's interesting . grad b: exactly . grad d: ok . grad a: hmm . grad b: robert ? grad a: well there there is a term that 's often used . that 's `` saliency `` , or the `` salience `` of an object . and i was just wondering whether that 's the same as what you describe as `` landmark - iness `` . but it 's really not . i mean an object can be very salient grad d: hmm . grad a: but not a landmark at all . grad d: not a landmark at all . there 's landmark for um , touristic reasons and landmark for i do n't know navigational reasons or something . grad a: yep . grad b: right . grad c: yeah , we meant , uh , touristic reasons . grad b: yeah . grad d: ok . grad a: hmm . grad b: right . grad d: ok . but you can imagine maybe wanting the oth both kinds of things there for different um , goals . grad a: hmm . grad c: yeah . grad b: right . grad d: right ? grad b: but yeah . tourist - y landmarks also happen to be would n't could n't they also be they 're not exclusive groups , are they ? like non - tourist - y landmarks and grad a: or it can be als grad b: direct navigational grad d: they 're not mutually exclusive ? grad b: yeah . grad d: right . grad b: ok . grad d: right . definitely . grad b: ok , so our initial idea was not very satisfying , because uh our initial idea was basically all the features pointing to the output node . uh . grad d: so , a big flat structure . grad b: right . grad d: right ? grad c: yep . grad b: and uh , so we reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped . i do n't know belief - nets very well . grad c: well usually , i mean , you know , n if you have n features , then it 's two to the n or exponential in n . grad b: and they would n't look pretty . so . grad c: yeah , they 'd all be like pointing to the one node . grad a: mm - hmm . grad b: uh . so then our next idea was to add a middle layer , right ? so the thinking behind that was we have the features that we 've drawn from the communication of some like , the someone s the person at the screen is trying to communicate some abstract idea , like `` i 'm `` the the abstract idea being `` i am a tourist i want to go to this place . `` right ? so we 're gon na set up features along the lines of where they want to go and what they 've said previously and whatnot . and then we have the means that they should use . right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist or whether they 're running an errand or something like that along those lines . or yes , we could things we could n't extract the from the data , the hidden variables . yes , good . so then the hidden variables hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to like or th grad c: want to do vista , grad b: right . grad c: right ? because if you want to view things you would n't be in a hurry . grad b: or they might be more likely to be using the place that they want to go to as a like a navigational point to go to another place . grad d: mm - hmm . grad b: whether the destination was their final destination , whether the destination was closed . those are all and then `` let 's look at the belief - net `` { comment } ok . so that means that i should switch to the other program . um right now it 's still kind of in a toy version of it , because we did n't know the probabilities of or well i 'll talk about it when i get the picture up . grad a: no one knows it . grad b: ok . so this right what we let 's see . what happens if i maximize this ? there we go . but uh so . the mode basically has three different outputs . the probability whether the probability of a vista , tango , or enter . um the `` context `` , we simplified . basically it 's just the businessman , the tourist , unknown . `` verb used `` is actually personally amusing mainly because it 's it 's just whether the verb is a tango verb , an enter verb , or a vista verb . grad c: yeah , that one needs a lot of grad d: and are those mutually exclusive sets ? grad b: no . grad c: not at all . that 's that that needs a lot of work . grad d: right . grad c: but uh that would 've made the probably significantly be more complicated to enter , grad d: got it . uh - huh . grad c: so we decided that for the purposes of this it 'd be simpler to just have three verbs . grad d: yeah . simple . grad b: yeah . grad d: stab at it . yep . grad b: right . um why do n't you mention things about this , bhaskara , that i am not that are not coming to my mind right now . grad c: ok , so yeah , so note the four nodes down there , the sort of , the things that are not directly extracted . actually , the five things . the `` closed `` is also not directly extracted i guess , from the uh grad b: well i it 's grad c: hmm . grad d: from the utterance ? grad b: it 's so it sort of is grad c: actually , no , wait . grad b: because it 's because have the the time of day grad c: it is . ok , `` closed `` sort of is . grad b: and the close it just had the er and what time it closed . grad c: right , so f right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh sort of you know probabilistically depends on the other things . grad d: inferred from the other ones ? grad c: yeah . grad d: ok . grad c: and the mode , you know , depends on all those things only . grad b: yeah the the actual parse is somewhere up around in here . grad c: yeah . so we have n't uh , managed like we do n't have nodes for `` discourse `` and `` parse `` , although like in some sense they are parts of this belief - net . grad d: mm - hmm . grad c: but uh the idea is that we just extract those features from them , so we do n't actually have a node for the entire parse , grad d: mm - hmm . grad b: right . grad c: because we 'd never do inference on it anyway , so . grad d: so some of the the top row of things what 's what 's `` disc admission fee `` ? grad c: whether they discuss the admission fees . so we looked at the data and in a lot of data people were saying things like `` can i get to this place ? `` grad d: oh . grad c: `` what is the admission fee ? `` . so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , grad d: uh - huh . grad b: right . grad d: ok . grad c: so . grad d: i see . grad b: there were there 'd be other things besides just the admission fee , but you know , we did n't have grad d: mm - hmm . grad c: that was like our example . grad a: mm - hmm . grad b: that was the initial one that we found . grad d: ok . so there are certain cues that are very strong either lexical or topic - based um , concept cues grad b: from the discourse that yeah . grad d: for one of those . and then in that second row or whatever that row of time of day through that so all of those some of them come from the utterance and some of them are sort of either world knowledge or situational things . grad b: right . grad d: right ? so that you have no distinction between those and ok . grad b: one , uh uh . um , anything else you want to say bhaskara ? grad c: um . grad d: `` unmark @ @ time of day `` grad c: yeah , i m i mean grad a: yeah . they 're they 're are a couple of more things . grad b: one thing uh grad a: i mean uh . i would actually suggest we go through this one more time so we we all uh , agree on what what the meaning of these things is at the moment and maybe what changes we grad b: yeah , th ok . so one thing i i 'm you know unsure about , is how we have the discus uh the `` admission fee `` thing set up . so one thing that we were thinking was by doing the layers like this , uh we kept um things from directly affecting the mode beyond the concept , but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , grad a: mm - hmm . grad b: right ? versus pointing to just at `` tourist `` , grad d: mm - hmm . grad b: ok ? grad d: mm - hmm . grad b: but we just decided to keep all the things we extracted to point at the middle and then down . grad a: mm - hmm . why is the landmark ok . the landmark is facing to the tourists . that 's because we 're talking about landmarks as touristic landmarks not as possible um grad b: right . grad c: yeah . grad b: navigational landmarks , grad d: navigational cue . grad a: navigational landmarks grad b: yeah . grad a: so mm - hmm . then grad b: yeah , that would be whatever building they referred to . grad d: prosody . grad c: right . so let 's see . the variables . grad a: mm - hmm . grad c: disc - `` admission fee `` is a binary thing , `` time of day `` is like morning , afternoon , night . is that the deal ? yeah . grad b: that 's how we have it currently set up , grad a: yep . grad b: but it could be , you know , based upon hour grad c: yeah . yeah . grad a: whatever granularity . grad b: or dis we could discrete it des descret - ize it . grad c: yeah . grad a: uh - huh . grad c: yeah . grad d: mm - hmm . grad c: yeah . normally context will include a huge amount of information , but um , we are just using the particular part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , i guess . grad a: yep . grad d: ok . so that 's given in their input . grad b: right . grad c: so right , grad d: right ? grad c: so it 's not really all of context . similarly prosody is not all of prosody but simply for our purposes whether or not they appear tense or relaxed . grad a: mm - hmm . that 's very nice , huh ? grad d: ok . grad a: the the so the context is a switch between tourist or non - tourist ? grad c: and grad a: or also unknown ? grad b: or un unknown , grad a: ok . grad b: yeah . grad c: yeah . unknown , right ? grad d: so final dest so it seems like that would really help you for doing business versus tourist , grad c: which is th which one ? grad d: but ok . so the the context being um , e i do n't know if that question 's sort of in general , `` are you `` i mean the ar ar are do they allow business people to be doing non - business things at the moment ? grad c: yeah , it does . grad d: ok . so then you just have some probabilities over grad c: everything is probablistic , and there 's always grad d: ok . over which which of those it is . grad c: yeah . um , right . so then landmark is oh , sorry . `` verb used `` is like , right now we only have three values , but in general they would be a probability distribution over all verbs . grad d: mm - hmm . grad c: rather , let me rephrase that . it it can take values in the set of all verbs , that they could possibly use . grad d: mm - hmm . grad c: um `` nice walls `` is binary , `` closed `` is binary `` final destination `` , again yeah , all those are binary i guess . and `` mode `` is one of three things . grad a: so , the the middle layer is also binary ? no . grad c: yeah , anything with a question mark after it in that picture is a binary node . grad a: uh . it yeah . but all those things without question marks are also binary . right ? grad c: which things ? grad a: nice walls ? grad b: wi grad d: mm - hmm . grad c: oh . `` nice walls `` is uh something that we extract from our world knowledge . grad a: mm - hmm . grad c: yeah , a oh yeah . sorry . it is binary . grad b: it is binary but it does n't have question mark because it 's extracted . grad c: that 's true . yeah . ok , i see your point . grad a: yeah . ok . grad b: yeah . grad a: i i gotcha . grad d: uh - huh . grad c: yeah , similarly `` closed `` , i guess . grad a: so we can either be in a hurry or not , but we can not be in a medium hurry at the moment ? grad c: well , we to do that we would add another uh value for that . grad a: mm - hmm . ok . grad c: and that would require s updating the probability distribution for `` mode `` as well . grad a: mm - hmm . grad c: because it would now have to like uh take that possibility into account . grad d: mm - hmm . take a conti grad a: mm - hmm . grad d: so um , of course this will happen when we think more about the kinds of verbs that are used in each cases grad a: yeah , yeah . grad c: yeah . grad d: but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would that would help you like it 's a conjunction of , i do n't know , you know , the verb used and some other stuff that that would determine grad c: right . other syntactic information you mean ? grad d: yeah . exactly . grad c: yeah . grad d: um . grad a: well the the sort of the landmark is is sort of the object right ? the argument in a sense ? grad d: usually . i i do n't know if that 's always the case i i guess have n't looked at the data as much as you guys have . so . um . grad a: that 's always warping on something some entity , grad d: mm - hmm . mm - hmm . grad a: and um uh maybe at this stage we will we do want to uh sort of get uh modifiers in there grad b: hmm . yeah . grad a: because they may also tell us whether the person is in a hurry or not grad b: i want to get to the church quickly , grad c: yeah . grad d: mm - hmm . grad b: and uh grad c: yeah , right . grad d: that would be a cue . grad a: what 's the fastest way grad c: yeah , correct . grad d: mm - hmm . um . ok . grad b: right . excellent . do we have anything else to say about this ? grad c: we can do a little demo . grad b: oh the yeah , we could . but the demo does n't work very well . grad a: no , then it would n't be a demo i was just gon na s grad c: i mean we can do a demo in the sense that we can um , just ob observe the fact that this will , in fact do inference . grad b: observe nodes . grad c: so we can , you know , set some of the uh nodes and then try to find the probability of other nodes . grad d: yeah . go ahead . grad b: ok . dat - dat - dah . what should i observe ? grad c: just se set a few of them . you do n't have to do the whole thing that we did last time . just like uh , maybe the fact that they use a certain verb grad b: ok . grad c: actually forget the verb . grad b: ok . grad c: just uh i do n't know , say they discussed the admission fee grad b: ok . grad c: and uh the place has nice walls grad b: i love nice walls , ok ? i 'm a big fan . grad c: and it 's night . grad d: it 's starting to grow on me grad b: and the time of day is night ? grad c: yeah , no wait . that that does n't uh it 's not really consistent . they do n't discuss the admission fee . make that false . grad b: alright . grad c: and it 's night . grad b: oh , they ok . oh whoops . i forgot to uh grad c: that did n't work . grad b: ach ! grad d: i 'd like to do that again . grad b: one thing that bugs me about javabayes is you have to click that and do this . grad d: yeah . that seems kind of redundant but . grad c: ok . grad b: that all you want ? grad c: yes . grad b: ok . so let 's see . i want to query , grad c: `` go `` and , right , `` query `` . grad b: right ? the mode . ok , and then on here so let 's see . grad c: so that is the probability that they 're entering , vista - ing or tango - ing . grad d: mm - hmm . grad b: yeah . grad c: and uh grad d: so slightly biased toward `` tango `` ing grad c: yeah . grad b: if it 's night time , they have not discussed admission fee , and the n walls are nice . grad d: ok . grad b: so , yeah . i guess that sort of makes sense . the reason i say the demo does n't work very well is yesterday we uh observed everything in favor of taking a tour , and it came up as `` tango `` , right ? over and over again . we could n't we could n't figure out how to turn it off of `` tango `` . grad d: so . uh - huh . grad c: it loves the tango . grad d: huh ! um . grad c: well , that 's obviously just to do with our probabilities . grad b: yeah , yeah . grad c: like , we totally hand - tuned the probabilities , grad d: yeah . grad c: right . we were like `` hmm , well if the person does this and this and this , let 's say forty percent for this , grad d: ok . grad c: fifty per `` like , you know . so obviously that 's gon na happen . grad b: yeah . grad d: right . grad a: yeah but it it grad d: maybe the bias toward `` tango `` ing was yours , then ? grad b: yeah , grad c: yeah . grad b: that 's that 's at grad c: it 's so we have to like fit the probabilities . grad b: spent my youth practicing the tango de la muerte . grad d: so , the real case ? grad a: however you know , it the purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . and so th grad d: mm - hmm . grad a: and grad b: we would actually i guess once we look at the data more we 'll get more hidden nodes , grad a: mm - hmm . grad c: yeah . grad b: but i 'd like to see more . not because it would expedite the probabilities , cuz it would n't . it would actually slow that down tremendously . grad c: um . well , yeah , i guess . grad b: but . grad c: not that much though . only a little early . grad b: no , i think we should have uh exponentially more middle nodes than features we 've extracted . i 'm ju i 'm just jo grad c: ok . grad d: so . are `` doing business `` versus `` tourist `` they refer to your current task . like like current thing you want to do at this moment . grad c: um . yeah , well that 's that 's an interesting point . whether you 're it 's whether it 's not grad d: and are th grad c: i think it 's more like `` are you are tourist ? are you in ham - like heidelberg for a `` grad d: oh , so , i thought that was directly given by the context switch . grad c: that 's a different thing . what if the context , which is not set , but still they say things like , `` i want to go uh , see the uh the the castle and uh , et cetera . `` grad a: is it grad b: well the i kind of thought of `` doing business `` as more of running an errand type thing . grad c: yeah . business on the other hand is , uh , definitely what you 're doing . grad a: so if you run out of cash as a tourist , and and and you need to go to the at grad b: so i wi th grad d: ok . oh , i see , you may have a task . wh you have to go get money and so you are doing business at that stage . grad a: mmm . grad b: right . grad c: yeah . grad a: `` how do i get to the bank ? `` grad d: i see . hmm . grad c: and that 'll affect whether you want to enter or you if you kinda thing . grad d: ok . so the `` tourists `` node should be um , very consistent with the context node . right ? if you say that 's more their in general what their background is . grad c: yeah , i think this context node is a bit of a i do n't know , like in d uh do we wan na have like it 's grad d: are you assuming that or not ? like is that to be i mean if that 's accurate then that would determine tourist node . grad c: if the context were to set one way or another , that like strongly uh um , says something about whether whether or not they 're tourists . grad d: mm - hmm . grad c: so what 's interesting is when it 's not when it 's set to `` unknown `` . grad d: mm - hmm . mm - hmm . grad a: we - what set the they set the context to `` unknown `` ? grad d: ok . grad b: ok . grad c: right now we have n't observed it , so i guess it 's sort of averaging over all those three possibilities . grad a: mm - hmm . grad d: mm - hmm . grad b: right . grad c: but yes , you can set it to un `` unknown `` . grad a: and if we now do leave everything else as is the results should be the same , grad b: oops . grad a: right ? grad b: no . grad c: well no , because we th - the way we set the probabilities might not have yeah , it 's it 's an it 's an issue , right ? like grad a: pretty much the same ? grad c: yeah , it is . so the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then `` unknown `` as an actual value . what 's common is you just like do n't observe the variable , grad d: yeah . grad a: yep . grad c: right , and then just marginalizes grad d: yeah . grad c: but uh we did n't do this because we felt that there 'd i guess we were thinking in terms of a switch that actually grad b: we were thi yeah , grad a: mm - hmm . grad b: we were th grad c: but uh i do n't know y what the right thing is to do for that . i 'm not i do n't know if i totally am happy with the way it is . grad a: why do n't we can we , um how long would it take to to add another node on the observatory and , um , play around with it ? grad c: another node on what ? grad b: uh , well it depends on how many things it 's linked to . grad a: let 's just say make it really simple . if we create something that for example would be um so th some things can be landmarks in your sense but they can never be entered ? so for example s a statue . grad c: good point . grad a: yeah ? grad b: right . grad d: mm - hmm . grad a: so maybe we wan na have `` landmark `` meaning now `` enterable landmark `` versus , um something that 's simply just a vista point , for example . grad b: yeah , that 's true . grad a: yeah ? uh , a statue or um grad c: so basically it 's addressing a variable that 's `` enterable or not `` . so like an `` enterable , question mark `` . grad b: also you know , did n't we have a size as one ? the size of the landmark . grad c: what ? grad b: cuz if it 's grad c: um . not when we were doing this , grad b: yeah . grad c: but i guess at some point we did . grad b: for some reason i had that ok , that was a thought that i had at one point but then went away . grad c: so you want to have a a node for like whether or not it can be entered ? grad a: well , for example , if we include that , yeah ? grad c: yeah . grad a: um , accessibility or something , yeah ? `` is it can it be entered ? `` grad c: hmm . grad a: then of course , this is sort of binary as well . grad c: yeah . grad a: and then um , there 's also the question whether it may be entered . in the sense that , you know , if it 's tom the house of tom cruise , you know , it 's enterable but you may not enter it . you know ? you 're not allowed to . grad c: yeah . grad a: unless you are , whatever , his his divorce lawyer or something . grad c: yeah . grad a: yeah ? and um and these are very observable sort of from the from the ontology sort of things . grad b: way does it actually help to distinguish between those two cases though ? whether it 's practically speaking enterable , or actually physically enterable or not ? grad a: y y if if you 're running an errand you maybe more likely to be able to enter places that are usually not al w you 're not usually not allowed to uh m grad d: it seems like it would for uh , uh determining whether they wan na go into it or not . grad b: well i can see why grad d: cuz they grad a: let 's get this uh b clearer . s so it 's matrix between if it 's not enterable , period . grad b: whether it 's a whether it 's a public building , and whether it 's actually has a door . grad a: yeah , exactly . grad b: ok . grad a: this is sort of uh grad b: so tom cruise 's house is not a public building grad d: mm - hmm . grad b: but it has a door . but the thing is grad c: mm - hmm . grad d: right . grad b: ok , sh explain to me why it 's necessary to distinguish between whether something has a door and is not public . or , if something it seems like it 's equivalent to say that it does n't have a door a and it grad a: mm - hmm . grad b: or `` not public `` and `` not a door `` are equivalent things , grad a: yeah . grad b: it seems like in practice . grad a: right . yeah . so we would have what does it mean , then , that we have to we have an object type statue . that really is an object type . so there is there 's gon na be a bunch of statues . grad b: right . grad a: and then we have , for example , an object type , hmm , that 's a hotel . how about hotels ? grad b: ok . grad a: so , the most famous building in heidelberg is actually a hotel . it 's the hotel zum ritter , which is the only renaissance building in heidelberg that was left after the big destruction and for the thirty years war , blah - blah - blah . grad b: hmm . does it have nice walls ? grad a: it has wonderful walls . um - and lots of detail , c and carvings , engravings and so forth , grad b: excellent . grad a: so . but , um , it 's still an unlikely candidate for the tango mode i must say . but . um . so s so if you are a d well it 's very tricky . so i guess your question is so far i have no really arg no real argument why to differentiate between statues as statues and houses of celebrities , from that point of view . huh . ok . let let 's do a can we add , just so i can see how it 's done , uh , a `` has door `` property or ? grad b: ok . grad c: what would it , uh , connect to ? like , what would , uh , it affect ? grad a: um , i think , um , it might affect oh actually it 's it it would n't affect any of our nodes , right ? grad c: what i was thinking was if you had a like grad a: oh it 's it affects th the `` doing business `` is certainly not . grad b: you could affect theoretically you could affect `` doing business `` with `` has door `` . grad c: yeah . ok . grad d: hmm . grad a: it should , um , inhibit that , grad c: right . grad b: let 's see . grad a: right ? grad c: yeah , i do n't know if javabayes is nice about that . it might be that if you add a new thing pointing to a variable , you just like it just overwrites everything . but you can check . grad b: well , we have it saved . so . we can rel open it up again . grad c: ok . it 's true . grad b: the safety net . grad d: i think you could just add it . i mean , i have before ok . whew ! grad c: well that 's fine , but we have to see the function now . has it become all point fives or not ? grad d: oh , right . grad b: let 's see . so this is `` has door `` uh , true , false . that 's acceptable . and i want to edit the function going to that , right ? oh no . grad c: no . this is fine , grad b: right . it was fine . grad c: this business . grad b: added this one . grad c: yep . grad b: this grad c: what would be nice if it is if it just like kept the old function for either value but . nope . did n't do it . grad d: oh . grad b: oh wait , it might be did we w yes , that 's not good . grad c: that 's kind of annoying . grad a: ok , so just dis dismiss everything . close it and and load up the old state so it does n't screw screw that up . grad b: let 's see . oops . grad c: hmm . grad a: maybe you can read in ? grad c: ha - so have you used javabayes a lot ? grad d: yes . really i ha i 've i have n't used it a lot and i have n't used it in the last you know many months so grad c: ok . grad d: um , uh , we can ask someone . grad c: it might be worth uh asking around . grad d: um . grad c: like , we looked at sort of uh a page that had like a bunch of grad d: yeah . srini grad c: ok . yeah , s i guess he 'd be the person . grad d: srini 's the one to ask i would say . grad c: yeah . grad d: um . he might know . grad c: cuz yeah . grad d: and . grad c: i mean in a way this is a lot of good features in java it 's cra has a gui and it 's uh grad d: mm - hmm . grad c: i guess those are the main two things . it does learning , it has grad d: mm - hmm . grad b: no it does n't , actually . grad d: yeah . grad b: i did n't think it did learning . grad c: what ? grad b: maybe it did a little bit of learning , grad c: ok . grad b: i do n't remember . grad c: oh right . maybe you 're right . ok . right . but uh it 's free . grad b: which is w quite positive , yeah . grad c: but uh , yeah . maybe another thing that uh but i mean its interface is not the greatest . so . grad b: but actually it had an interface . grad d: mm - hmm . grad b: a lot of them were like , you know . grad d: yep . grad a: command line . grad b: huh . grad a: what is the c code ? can w can we see that ? how do you write the code grad b: the c grad a: or do you actually never have to write any code there ? grad c: yeah . there is actually a text file that you can edit . but it 's you do n't have to do that . grad b: there 's like an xml format for bayes - nets . grad c: is it xml ? grad b: the - there is one . i do n't know if this uses it . grad c: oh , i see . no this does n't use it . grad b: but it grad c: i did n't think it did . grad b: yeah , the the grad c: you can look at the text file . grad b: yeah . grad c: but do you have it here ? grad b: uh , yes i do actually . grad c: well , maybe you do n't . grad b: let me see . grad c: oh yes , of course . grad b: oh man , grad c: like , there 's the grad b: i did n't n is there an ampersand in dos ? grad c: nope . just s l start up a new dos . grad b: we - that 's alright . i can probably double cli click on it . grad c: or yeah , right . grad a: n uh grad b: let 's see . grad c: yep . grad b: let 's see , come on . grad c: it 'll ask you what you what it wants what you want to open it with and see what bat , i guess . grad b: one of these days , it should open this , theoretically . grad a: go right mouse . open with . grad b: oh there we go . grad c: that 's oh ! grad b: maybe it was just grad a: oh . grad b: oh ! w ah , it was dead . to the world . grad d: god ! grad b: ok . grad a: through the old notepad . that 's my favorite editor . grad b: i like i like word pad because it has the uh the returns , grad a: wordpad ? i grad b: the carriage returns on some of them . grad a: mm - hmm . ok . grad b: you know how they get `` auto - fills `` i guess , grad a: mmm - hmm . grad b: or whatever you call it . grad c: anyway , there it is . grad a: so this is sort of lisp - y ? no . grad c: uh , yeah . grad b: it just basically looks like it just specifies a bunch of grad a: mm - hmm . grad c: yeah . that 's how actual probability tables are specified . grad b: yeah . grad c: as , like , lists of numbers . grad d: mm - hmm . grad c: so theoretically you could edit that . grad d: mm - hmm . grad b: it just that it 's grad c: but they 're not very friendly . grad d: mm - hmm . grad b: yeah the ordering is n't very clear on grad c: so you 'd have to like figure out like you have to go and grad d: right . the layout of the table . grad c: yeah . grad d: yeah . grad b: actually we could write a program that could generate this . grad c: well i yeah . i think so . grad b: yeah you could . grad d: you could . grad c: it 's not grad b: we were doing it grad c: yeah we can maybe write an interface th for uh entering probability distributions easily , something like like a little script . that might be worth it . grad a: and that might do . grad d: yeah . i actually seem to recall srini complaining about something to do with entering probability so this is probably grad c: the other thing is it is in java grad d: yeah , it 's yeah . grad c: so . grad b: we could manipulate the source itself ? grad d: yeah . grad b: or grad a: do you have the true source files or just the class ? grad b: i do n't know if he actually grad c: yeah . uh , yeah . we do grad b: does he grad c: i i saw directory called `` source `` , grad b: oh . grad d: mm - hmm . grad b: i did n't e grad c: or yeah . go up one ? grad b: up one . ah yes , good . grad c: yeah . grad b: `` source `` . that 's that 's quite nice . grad c: i do n't know if it actually manipulate the source , though . that might be a bit complicated . grad a: mm - hmm . grad c: i think it might it might be simpler to just have a script that , you know it 's , like , friendly , grad d: the d the data tables . grad c: it allows you enter things well . grad d: yeah . grad b: right . grad a: but if th if there is an xml file that or format that it can also read i mean it just reads this , right ? when it starts . grad c: mm - hmm . grad b: yeah i know there is an i was looking on the we web page and he 's updated it for an xml version of i guess bayes - nets . there 's a bayes - net spec for in xml . grad a: mm - hmm . grad c: he 's like this guy has ? grad b: yeah . grad c: the javabayes guy ? so but , e he does n't use it . so in what sense has he updated it ? grad b: well th you can either you ca or you can read both . grad c: oh . i see . grad b: to my understanding . grad c: ok . that would be awesome . grad d: oh . grad b: because uh well at least the uh i could have misread the web page , i have a habit of doing that , but . grad a: ok , wonderful . grad c: ok . grad a: so you got more slides ? grad b: do i have more slides ? um yes , one more . `` future work `` . i think every presentation have a should have a `` future work `` slide . but uh it 's basically we already talked about all this stuff , so . grad c: um . the additional thing is i guess learning the probabilities , also . e that 's maybe , i do n't know if grad b: uh that 's future future work . grad c: does that 's yeah . grad b: right . grad c: very future . grad a: mm - hmm . grad b: and of course if you have a presentation that does n't have something that does n't work at all , then you have `` what i learned `` , as a slide . grad d: ca n't you have both ? grad b: you could . my first approach failed . grad d: right . grad b: what i learned . ok , so i think that uh our presentation 's finished . grad a: good . grad b: i know what i like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room . grad a: so the uh grad d: i missed my turn . grad b: no i earlier i went and bhaskara went and you did it . you did it . grad a: it 's like yawning . grad d: it 's like yawning . grad a: and this announcement was in stereo . grad c: ha . grad a: ok . so this means um grad b: should i pull up the net again ? grad d: yeah . could you put the the um , net up again ? grad b: yes . there we go . grad d: thanks . grad b: and actually i was cuz i got a wireless mike on . grad d: so a more general thing than `` discussed admission fee `` um , could be i i 'm just wondering whether the context , the background context of the discourse might be i do n't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , i do n't know if that might be grad a: mm - hmm . i think we grad d: uh , and and into that node would be various various things that that could have specifically come up . grad a: i think a a sort of general strategy here you know , this is this is excellent because um it gets you thinking along these terms is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before . grad d: mm - hmm . right . grad a: and um let 's make those four . and maybe there are two um so maybe this could be sort of a separate region of the net , which has two has it 's own middle layer . maybe this , you know , has some kind of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual phenomenon that you can observe . so things that point towards grad b: so instead of single node , for like , if they said the word `` admission fee `` grad d: exactly . grad b: `` admission fee `` , or maybe , you know , `` how much to enter `` grad d: yeah . grad b: or you know something , other cues . grad d: opening hours or something like that . grad b: exactly . that would all f funnel into one node that would constitute entrance requirements or something like that . grad a: so `` pay a visit `` grad d: mm - hmm . grad a: uh uh d grad c: sure . grad a: yeah ? grad c: yeah . grad d: i mean it sort of get into plan recognition kinds of things in the discourse . i mean that 's like the bigger um , version of it . grad a: exactly . yeah ? and then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a in a in a route um , sort of proceeding past these things , so this would be just something that where you want to pass it . hmm ? is that it ? however these are of course then the the nodes , the observed nodes , for your middle layer . so this again points to `` final destination `` , `` doing business `` , `` tourist hurry `` and so forth . grad d: mm - hmm . grad b: ok . grad a: yeah ? and so then we can say , `` ok . we have a whole region `` in a e grad d: that 's a whole set of discourse related cues to your middle layer . grad a: yeah , exactly . and this is just then just one . grad d: right ? grad a: so e because at the end the more we um add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . it 's going to get very ugly . but with this way we could say `` ok , these are the discourse phenomena . they ra may have there own hidden layer that points to some of the the real hidden layer , um or the general hidden layer . grad c: sure . grad a: and the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . and maybe there 's a hidden layer for that . grad c: yep . grad a: and so forth and so forth . then we have context . grad c: yeah . so essentially a lot of those nodes can be expanded into little bayes - nets of their own . grad a: yep . grad d: mm - hmm . grad a: precisely . so . grad b: one thing that 's kind of been bugging me when i more i look at this is that the i guess , the fact that the there 's a complete separation between the observed features and in the output . grad c: yeah . grad b: i mean , it makes it cleaner , but then uh i mean . grad c: that 's true . grad b: for instance if the discourse does grad d: what do you mean by that ? grad b: well for instance , the `` discourse admission fee `` node seems like it should point directly to the grad d: uh - huh . grad b: or increase the probability of `` enter directly `` versus `` going there via tourist `` . grad c: yeah . or we could like add more , uh , sort of middle nodes . like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door . grad a: mm - hmm . grad b: right . grad c: so it 's like there are those are the two options . either like make an arrow directly or put a new node . grad b: yeah , grad d: hmm . grad b: that makes sense . grad a: yeah . and if it if you do it if you could connect it too hard you may get such phenomenon that like `` so how much has it cost to enter ? `` and the answer is two hundred fifty dollars , and then the persons says um `` yeah i want to see it . `` yeah ? meaning `` it 's way out of my budget `` um grad b: there are places in germany where it costs two hundred fifty dollars to enter ? grad a: um , nothing comes to mind . without thinking too hard . um , maybe , yeah of course , um opera premiers . grad b: really ? grad a: so you know . grad d: hmm . grad a: or or any good old pink floyd concert . grad b: i see . if you want to see `` the magic flute `` or something . grad a: yeah . grad d: or maybe um , a famous restaurant . or , i do n't know . there are various things that you might w not want to eat a meal there but your own table . grad b: the spagos of heidelberg . grad a: i think that the h i mean nothing beats the the admission charge prices in japan . so there , two hundred dollars is is moderate for getting into a discotheque . you know . then again , everything else is free then once you 're ins in there . grad c: really . grad a: food and drink and so forth . so . i mean . but i you know , i we can something somebody can have discussed the admission fee and u the answer is s if we um , you know , um still , based on that result is never going to enter that building . grad b: hmm . grad a: you know ? because it 's just too expensive . grad b: oh yeah , i think i see . so the discourse refers to `` admission fee `` but it just turns out that they change their mind in the middle of the discourse . grad d: yeah . you have to have some notion of not just i mean there 's a there 's change across several turns of discourse grad b: right . grad a: mm - hmm . grad d: so i do n't know how if any of this was discussed but how i if it all this is going to interact with whatever general uh , other other discourse processing that might be happen . grad a: mm - hmm . grad c: yeah . { comment } yeah . grad d: i mean . grad b: what sort of discourse processing is uh are the how much is built into smartkom and grad a: it works like this . the uh , um i mean . the first thing we get is that already the intention is sort of t they tried to figure out the intention , right ? simply by parsing it . and this um m wo n't differentiate between all modes , yeah ? but at least it 'll tell us `` ok here we have something that somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is is is happening , and um , if the discourse takes a couple of turns before everything all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate elaborate modules . it 's it 's actually the the whole memory of the entire system , that knows what wh who said what , which was what was presented . it helps an an anaphora resolution and it and it fills in all the structures that are omitted , so , um , because you say `` ok , how can i get to the castle ? `` oh , how how much is it ? `` and um `` yeah i would like uh um to g let 's do it `` and so forth . so even without an a ana anaphora somebody has to make sure that information we had earlier on is still here . grad b: mm - hmm . grad a: because not every module keeps a memory of everything that happened . so whenever the uh , um person is not actually rejecting what happened before , so as in `` no i really do n't want to see that movie . i 'd rather stay home and watch tv `` um what movie was selected in what cinema in what town is is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model discourse model , yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . so a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen grad b: hmm . grad a: so it 's a it 's a rather huge huge thing but um { comment } um we can sort of it has a very clear interface . we can query it whether admission fees were discussed in the last turn and and the turn before that or you know how deep we want to search grad b: ok . grad a: um which is a question . how deep do we want to sear , you know ? um but we should try to keep in mind that , you know , we 're doing this sort of for research , so we we should find a limit that 's reasonable and not go , you know , all the way back to adam and eve . you know , did that person ever discuss admissions fee fees in his entire life ? and the dialogues are pretty pretty you know concise and anyway . grad d: so one thing that might be helpful which is implicit in the use of `` admission fee discussion `` as a cue for entry , is thinking about the plans that various people might have . like all the different sort of general schemas that they might be following ok . this person is um , finding out information about this thing in order to go in as a tourist or finding out how to get to this place in order to do business . um , because then anything that 's a cue for one of the steps would be slight evidence for that overall plan . um , i do n't know . they 're in in non in sort of more traditional ai kinds of plan recognition things you sort of have you know , some idea at each turn of agent doing something , `` ok , wha what plans is this a consistent with ? `` and then get s some more information and then you see `` here 's a sequence that this sort of roughly fits into `` . it it might be useful here too . grad a: mm - hmm . grad d: i i do n't know how you know you 'd have to figure out what knowl what knowledge representation would work for that . grad a: i mean the u u grad b: hmm . grad a: it 's in the these these these plan schemas . i mean there are some some of them are extremely elaborate , you know . `` what do you need need to buy a ticket ? `` grad d: mm - hmm . grad a: you know ? and it it 's fifty steps , grad d: mm - hmm . mm - hmm . grad a: huh ? just for buying a ticket at a ticket counter , you know , and and maybe that 's helpful to look at it to look at those . it 's amazing what human beings can do . w when we talked uh we had the example , you know , of you being uh a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says new york and you say track seven , huh ? and it 's because you know that that person actually is following , you know you execute a whole plan of going through a hundred and fifty steps , you know , without any information other than `` new york `` , huh ? inferring everything from the context . so , works . um , even though there is probably no train from here to new york , right ? grad d: mmm . not direct . grad b: you 'd uh probably have to transfer in chicago . grad a: mm - hmm . but uh it 's possible . um , no you probably have to transfer also somewhere else . right ? is that t san francisco , chicago ? grad b: i think grad a: is that possible ? grad b: one time i saw a report on trains , and i think there is a l i do n't know if i thought there was a line that went from somewhere , maybe it was sacramento to chicago , grad a: mm - hmm . grad b: but there was like a california to chicago line of some sort . grad a: hmm . grad b: i could be wrong though . it was a while ago . grad d: the transcontinental railroad , does n't that ring a bell ? grad b: yeah but i do n't know if it 's still grad d: i think it has to exist somewhere . grad b: they might have blown it up . grad a: well it never went all the way , right ? i mean you always had to change trains at omaha , grad d: well most of the way . grad a: right ? one track ended there and the other one started at five meters away from that grad d: uh . mm - hmm . yeah . grad a: and sort of grad d: well . you seem to know better than we do so . grad a: yeah ? has anybody ever been on an amtrak ? grad d: i have . but not transcontinentally . grad b: i 'm frightened by amtrak myself . grad c: what ? why ? grad b: i just they seem to have a lot of accidents on the amtrak . grad c: really ? grad a: their reputation is very bad . grad b: yeah . yeah . grad a: huh ? it 's not maybe reality . grad d: it 's not like german trains . like german trains are really great so . grad a: but you know , i do n't know whether it 's which ones are safer , you know , statistically . grad d: um , but they 're faster . grad c: yeah . grad a: much faster . mm - hmm . grad c: and there 's much more of them . yeah , they 're yeah , it 's way better grad a: yeah i used um amtrak quite a bit on the east coast and i was surprised . it was actually ok . grad d: mm - hmm . grad a: you know , on boston new york , grad d: yeah . grad a: new york rhode island , grad c: yeah . grad a: whatever , grad c: i 've done that kind of thing . grad a: boston . grad d: mm - hmm . grad a: yeah . but that 's a different issue . grad b: this is going to be an interesting transcript . grad a: hmm ? grad c: i i want to see what it does with uh `` landmark - iness `` . that 's grad b: yeah . grad d: let 's all say it a few more times . grad b: it 'd help it figure it out . grad c: so . grad d: just kidding . right . grad c: yeah . grad d: so by the way tha that structure that robert drew on the board was like more um , cue - type - based , right , here 's like we 're gon na segment off a bit of stuff that comes from discourse and then some of the things we 're talking about here are more you know , we mentioned maybe if they talk about um , i do n't know , entering or som you know like they might be more task - based . grad b: hmm . grad d: so i i do n't know if there there 's obviously some m more than one way of organizing the variables into something grad a: i think that um what you guys did is really nicely sketching out different tasks , and maybe some of their conditions . grad d: so . mm - hmm . grad a: one task is more likely you 're in a hurry when you do that kind of s doing business , grad d: mm - hmm . grad a: and and less in a hurry when uh you 're a tourist um tourists may have never have final destinations , you know because they are eternally traveling around so maybe what what what happened what might happen is that we do get this sort of task - based middle layer , grad d: mm - hmm . grad a: and then we 'll get these sub - middle layers , that are more cue - based . grad d: mm - hmm . that feed into those ? grad a: nah ? grad d: mm - hmm . grad a: might be might be a nice dichotomy of of the world . so , um i suggest w to for to proceed with this in in the sense that maybe throughout this week the three of us will will talk some more about maybe segmenting off different regions , and we make up some some toy a observable `` nodes `` is that what th grad b: refined y re just refine the grad a: what 's the technical term ? grad c: ok . for which ? grad a: for the uh nodes that are observable ? the `` outer layer `` ? grad c: just observable nodes , grad b: the features , grad c: evidence nodes ? grad b: i do n't know , whatever you grad a: feature ma make up some features for those identify four regions , grad c: yeah . grad a: maybe make up some features for each region and uh and uh , uh and uh middle layer for those . and then these should then connect somehow to the more plan - based deep space grad c: yeah . grad b: basically just refine some of the more general nodes . grad a: yep . the - they they will be aud ad - hoc for for for some time to come . grad c: yeah , this is totally like the probabilities and all are completely ad - hoc . we need to look at all of them . i mean but , they 're even like i mean like , close to the end we were like , uh , you know we were like uh really ad - hoc . grad d: it 's a even distribution . like , whatever . grad c: right ? cuz if it 's like , uh if it 's four things coming in , right ? and , say , some of them have like three possibilities and all that . so you 're thinking like like a hundred and forty four or something possible things numbers to enter , grad d: and that 's terrible . grad c: right ? so . grad b: some of them are completely absurd too , like they want to enter , but it 's closed , grad d: that 's uh well grad b: it 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like grad c: yeah , the only like possible interpretation is that they are like come here just to rob the museum or something to that effect . grad b: confused . grad d: in which case you 're supposed to alert the authorities , and see appropriate action . grad b: yeah . grad c: yeah . yeah , another thing to do , um , is also to , um i guess to ask around people about other bayes - net packages . is srini gon na be at the meeting tomorrow , do you know ? grad d: maybe . grad a: the day after tomorrow . grad c: wait grad d: quite possibly . grad a: wednesday . grad c: day after tomorrow . grad d: oh , oh , sorry . grad c: yeah . grad d: sorry , wednesday , grad b: who 's talking on wednesday ? grad c: maybe we can ask him about it . grad d: yeah . mmm . grad b: i have n't j jerry never sent out a sent out an email , did he , ever ? grad c: no . but he mentioned at the last meeting that someone was going to be talking , i forget who . grad a: oh , is n't ben ? grad c: uh . grad d: ben ? grad a: ben , then , grad d: i think it 's ben actually , grad a: ben . grad b: ah ! grad d: yeah , um , giving his job talk i think . um , sorry . i was just reading the screen . grad a: ok . grad b: yeah . grad c: oh . grad a: so the uh that will be one one thing we could do . i actually uh , have um , also we can uh , start looking at the smartkom tables and i will grad b: right . grad a: i actually wanted to show that to you guys now but um . grad b: do you want to trade ? grad a: um , no i i actually made a mistake because it it fell asleep and when linux falls asleep on my machine it 's it does n't wake up ever , so i had to reboot grad d: oh , no . grad a: and if i reboot without a network , i will not be able to start smartkom , because i need to have a network . grad b: uh grad a: so we 'll do that t maybe uh grad c: but . ok . but once you start sart start smartkom you can be on you do n't have to be on a network anymore . is that the deal ? grad a: yep . grad c: ah , interesting . grad b: why does smartkom need a network ? grad a: um it looks up some stuff that , you know , is is that is in the written by the operating system only if it if you get a dhcp request , so it you know , my computer does not know its ip address , you know ? grad b: ah . grad a: you know . so . unless it boots up with networking . grad b: it 's plugged in . yeah . grad a: and i do n't have an ip address , they ca n't look up they do n't know who localhost is , and so forth and so forth . grad d: hmm . grad a: always fun . but it 's a , um , simple solution . we can just um , go downstairs and and and look at this , but maybe not today . the other thing um i will oh yeah , ok , i have to report um , data collection . we interviewed fey , grad d: mm - hmm . grad a: she 's willing to do it , meaning be the wizard for the data collection , also maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . so that looks good . jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . and i talked to liz about this and it looks as if friday afternoon will be the time when we have a first trial run for the data . grad c: so who would be the subject of this trial run ? grad a: pardon me ? grad c: who will there be a is one is you one of you gon na be the subject ? like are you grad a: um liz also volunteered to be the first subject , which i think might be even better than us guys . grad d: good . grad b: one of us , yeah . grad a: if we do need her for the technical stuff , then of course one of you has to sort of uh jump in . grad b: i like how we 've you guys have successfully narrowed it down . `` is one of you going to be the subject ? `` is one of you jump in . grad d: reference . i have n't done it yet . grad c: well i just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . grad d: oh plants ? e u someone who can plant difficult things . grad c: yeah . i mean that 's what we wan na check , right ? grad a: um , grad d: well , in this case it 's a p it 's a sort of testing of the wizard rather than of the subject . grad c: is n't that what it is ? grad d: it 's uh grad a: yes w we we would like to test the wizard , but you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic grad c: i guess that would be reasonable . grad d: yeah . grad a: you know , set up as grad b: yeah . i know . that 's probably a good enough test of grad d: uh - huh . grad a: yeah . grad c: sort of having an actively antagonistic , uh grad d: yeah . that might be a little unfair . um . grad a: yeah . grad d: i 'm sure if we uh , you think there 's a chance we might need liz for , whatever , the technical side of things ? i 'm sure we can get other people around who do n't know anything um , if we want another subject . grad a: yeah , yeah . grad d: you know . like i can drag ben into it or something . although he might cause problems but . so , is it a experimental setup for the um , data collection totally ready determined ? grad b: i like that . `` test the wizard . `` i want that on a t - shirt . grad a: um i think it 's it 's it 's i mean experimental setup u on the technical issue yes , except we st i think we still need uh a recording device for the wizard , just a tape recorder that 's running in a room . grad d: mm - hmm . grad a: but um in terms of specifying the scenario , um uh uh we 've gotten a little further grad d: mm - hmm . grad a: but um we wanted to wait until we know who is the wizard , and have the wizard partake in the ultimate sort of definition probe . so so if if on friday it turns out that she really likes it and and we really like her , then nothing should stop us from sitting down next week and { comment } getting all the details completely figured out . grad d: mm - hmm . grad a: and um grad d: ok . so the ideal task um , will have whatever i do n't know how much the structure of the evolving bayes - net will af affect like we wan na we wan na be able to collect as much of the variables that are needed for that , grad a: mmm - yea - some . grad d: right ? in the course of the task ? well not all of them but you know . grad a: bu - e e e i 'm even this this tango , enter , vista is sort of , itself , an ad - hoc scenario . grad d: mm - hmm . mm - hmm . grad a: the the basic u um idea behind the uh data collection was the following . the data we get from munich is very command line , simple linguistic stuff . grad d: mm - hmm . grad a: hardly anything complicated . no metaphors whatsoever . grad d: mm - hmm . grad a: not a rich language . so we wanted just to collect data , to get that that that elicits more , uh , that elicits richer language . grad d: mm - hmm . grad a: and we actually did not want to constrain it too much , grad d: mm - hmm . grad a: you know ? just see what people say . and then maybe we 'll discover the phenomenon the phenomena that we want to solve , you know , with whatever engine we we come up with . um . so this this this is a parallel track , you know , there they hopefully meet , grad d: ok . so in other words this data collection is more general . grad a: but since grad d: it could it could be used for not just this task . grad a: it should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being grad d: mm - hmm . grad a: and the sort of differences there . so it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . and uh nothing has changed { comment } since then , so . uh . and secondly , now that of course we have sort of started to lick blood with this , and especially since um johno ca n't stop tango - ing , we may actually include , you know , those those intentions . so now i think we should maybe have at least one navigational task with with sort of explicit uh grad d: mm - hmm . grad a: not ex it 's implicit that the person wants to enter , grad d: mm - hmm . grad a: and maybe some task where it 's more or less explicit that the person wants to take a picture , grad d: mm - hmm . grad a: or see it or something . so that we can label it . i mean , that 's how we get a corpus that we can label . grad d: mm - hmm . exactly . grad a: whereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . yep . grad b: alrighty . grad c: ok . grad a: that was that . grad b: so is this the official end of the meeting now ? grad c: yep . grad d: looks like it . grad c: so what 's `` economics , the fallacy `` ? grad a: ma grad b: i just randomly label things . so that has nothing to do with economics or anything . grad c: oh , really ? grad a: maybe we ought to switch off these things before we continue . grad c: ok . grad d: ok . switching o","output":"experiments for the collection of new data will start soon , since someone who will recruit subjects and help run the experiments has already been hired and the designing of the experiments has also progressed significantly ."},{"instruction":"summarize the meeting","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"the participants discussed results from the experiments that had been conducted . switching between tasks in the same language had smaller errors than multilingual models . the professor thought that increasing the parameters of the net for larger multi-lingual models would be helpful . the team decided that they should experiment further with different linguistic features . they also discussed how they could speed up their work by relying on greater computational resources ."},{"instruction":"summarize the discussion about the effect of training on different languages","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"using multiple languages led to more diversity which potentially hindered the model performance . the professor was skeptical about discussing the results since they had not received any good ones so far ."},{"instruction":"what did phd d explain about the multilingual model ?","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"phd d explained that the multilingual model , trained on french , spanish , and english , was trained with higher frame rates . it has slightly poorer results when delta was not used . all in all , the addition of english did not seem to help the model ."},{"instruction":"what did the professor think about the use of english ?","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"the professor thought that the model did not get hurt that much because of the removal of english . he also thought it would be worthwhile to train on one language and test on another ."},{"instruction":"summarize the discussion on managing the complexity of the model","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"the team discussed the size of the neural net , which was just a simple net . at the time , it had 27 outputs , but the professor recommended that they use a larger net , with perhaps more features . they discussed the effect that removing silent frames could have on the model . the professor recommended having a bigger hidden layer , though he did not think that would substantially improve performance . currently , however , the team was facing computational limitations ."},{"instruction":"what did the team discuss about ibm computers ?","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"the team was concerned about the availability of computational resources . the professor informed them that they had received two 550 megahertz processors by ibm . though , they were originally expecting eight 800 megahertz processors ."},{"instruction":"what did the team think about delays ?","input":"professor b: ok . phd c: oh , i do n't phd a: i think i 'm zero . professor b: wow ! unprecedented . phd c: hello , hello , hello , hello . phd e: ah grad f: wh - what causes the crash ? phd a: did you fix something ? phd c: hello . phd e: five , five . phd c: hello , hello . grad f: oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: uh , you think that 's you ? oh . phd c: aaa - aaa - aaa . grad f: yeah , ok , mine 's working . phd c: ok . that 's me . professor b: ok . ok . so , um i guess we are um gon na do the digits at the end . uh phd d: channel channel three , yeah . phd c: channel two . phd d: ok . phd e: mmm , channel five ? does n't work ? professor b: yeah , that 's the mike number there , uh uh , mike number five , and channel channel four . phd c: two . phd a: is it written on her sheet , i believe . phd e: no ? ah , phd d: mike four . grad f: watch this . phd e: era el cuatro . grad f: yep , that 's me . phd e: yeah . phd a: but , channel phd e: yeah yeah yeah . professor b: this is you . phd e: ok . i saw that . ah yeah , it 's ok . professor b: yeah . and i 'm channel uh two i think , phd c: ooo . professor b: or channel phd c: i think i 'm channel two . professor b: oh , i 'm channel must be channel one . channel one ? phd e: channel i decided to talk about that . professor b: yes , ok . ok . so uh i also copied uh the results that we all got in the mail i think from uh from ogi and we 'll go go through them also . so where are we on on uh our runs ? phd d: uh so . uh we so as i was already said , we we mainly focused on uh four kind of features . professor b: excuse me . phd d: the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . professor b: mm - hmm . phd d: uh , and we focused for the the test part on the english and the italian . um . we 've trained uh several neural networks on so on the ti - digits english and on the italian data and also on the broad uh english uh french and uh spanish databases . mmm , so there 's our result tables here , for the tandem approach , and um , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: ok . our our uh there 's a we 're pausing for a photo phd c: chicken on the grill . try that corner . phd a: how about over th from the front of the room ? phd c: yeah , it 's longer . professor b: we 're pausing for a photo opportunity here . uh . uh . so . grad f: oh wait wait wait wait wait . wait . phd c: get out of the yeah . grad f: hold on . hold on . professor b: ok . grad f: let me give you a black screen . professor b: he 's facing this way . what ? ok , this this would be a good section for our silence detection . grad f: ok . phd c: mm - hmm . professor b: um oh . grad f: musical chairs everybody ! professor b: ok . so um , you were saying about the training data yeah . phd d: yeah , so if the network is trained on the task data um tandem works pretty well . and uh actually we have uh , results are similar only on , phd a: do you mean if it 's trained only on on data from just that task , phd d: yeah . phd a: that language ? phd d: just that task . but actually we did n't train network on uh both types of data i mean uh phonetically ba phonetically balanced uh data and task data . phd a: mmm . phd d: we only did either task task data or uh broad data . phd a: mm - hmm . phd d: um yeah . so , professor b: so how i mean clearly it 's gon na be good then phd a: so what 's th professor b: but the question is how much worse is it if you have broad data ? i mean , my assump from what i saw from the earlier results , uh i guess last week , was that um , if you trained on one language and tested on another , say , that the results were were relatively poor . phd d: mmm . yeah . professor b: but but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: if we use the same language ? professor b: no , no , no . different lang so um if you train on ti - digits and test on italian digits , you do poorly , let 's say . phd d: mm - hmm . professor b: i do n't have the numbers in front of me , phd d: but yeah but i did not uh do that . professor b: so i 'm just imagining . e so , you did n't train on timit and test on on italian digits , say ? phd d: we no , we did four four kind of of testing , actually . the first testing is with task data so , with nets trained on task data . so for italian on the italian speech @ @ . the second test is trained on a single language um with broad database , but the same language as the t task data . professor b: ok . phd d: but for italian we choose spanish which we assume is close to italian . the third test is by using , um the three language database professor b: w which in phd d: and the fourth is professor b: it has three languages . that 's including the w the the phd d: this includes professor b: the one that it 's phd d: yeah . phd a: in phd d: but not digits . i mean it 's phd a: the three languages is not digits , professor b: right . phd a: it 's the broad data . ok . phd d: yeah and the fourth test is uh excluding from these three languages the language that is the task language . professor b: oh , ok , yeah , so , that is what i wanted to know . phd d: yeah . professor b: i just was n't saying it very well , i guess . phd d: uh , yeah . so um for uh ti - digits for ins example uh when we go from ti - digits training to timit training uh we lose uh around ten percent , uh . the error rate increase u of of of ten percent , relative . professor b: relative . right . phd d: so this is not so bad . and then when we jump to the multilingual data it 's uh it become worse and , well around uh , let 's say , twenty perc twenty percent further . professor b: ab - about how much ? phd d: so . yeah . professor b: twenty percent further ? phd d: twenty to to thirty percent further . yeah . phd a: and so , remind me , the multilingual stuff is just the broad data . right ? it 's not the digits . phd d: yeah . phd a: so it 's the combination of two things there . it 's removing the task specific training and it 's adding other languages . phd d: yeah . yeah . phd a: ok . phd d: but the first step is al already removing the task s specific from from phd a: already , right right right . phd d: so . phd a: so they were sort of building here ? phd d: and we lose phd a: ok ? phd d: yeah . uh so , basically when it 's trained on the the multilingual broad data um or number so , the the ratio of our error rates uh with the baseline error rate is around uh one point one . professor b: yes . and it 's something like one point three of of the uh phd d: so . professor b: i i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: no no no . uh same language we are at uh for at english at o point eight . so it improves , compared to the baseline . but so . le - let me . professor b: i i i 'm sorry . phd d: tas - task data professor b: i i i meant something different by baseline phd d: we are u yeah . professor b: so let me let me um , so , um phd d: mmm . professor b: ok , fine . let 's let 's use the conventional meaning of baseline . phd d: hmm . professor b: i i by baseline here i meant uh using the task specific data . phd d: oh yeah , the f yeah , ok . professor b: but uh uh , because that 's what you were just doing with this ten percent . phd d: yeah . professor b: so i was just i just trying to understand that . phd d: yeah . sure . professor b: so if we call a factor of w just one , just normalized to one , the word error rate that you have for using ti - digits as as training and ti - digits as test , phd d: mmm . professor b: uh different words , i 'm sure , phd d: mm - hmm . professor b: but but uh , uh the same task and so on . phd d: mm - hmm . professor b: if we call that `` one `` , then what you 're saying is that the word error rate for the same language but using uh different training data than you 're testing on , say timit and so forth , it 's one point one . phd d: mm - hmm . yeah , it 's around one point one . professor b: right . and if it 's phd d: yeah . professor b: you do go to three languages including the english , it 's something like one point three . that 's what you were just saying , i think . phd d: ye uh , more actually . phd a: one point four ? phd d: if i yeah . phd a: so , it 's an additional thirty percent . phd d: what would you say ? around one point four professor b: ok . phd d: yeah . professor b: and if you exclude english , from this combination , what 's that ? phd d: if we exclude english , um there is not much difference with the data with english . professor b: aha ! phd d: so . yeah . professor b: that 's interesting . that 's interesting . do you see ? because uh , phd d: uh . professor b: so no , that that 's important . so what what it 's saying here is just that `` yes , there is a reduction in performance , when you do n't um have the s when you do n't have um phd a: task data . professor b: wait a minute , th th the phd d: hmm . professor b: no , actually it 's interesting . so it 's so when you go to a different task , there 's actually not so different . it 's when you went to these so what 's the difference between two and three ? between the one point one case and the one point four case ? i 'm confused . phd a: it 's multilingual . phd d: yeah . the only difference it 's is that it 's multilingual um professor b: cuz in both in both both of those cases , you do n't have the same task . phd d: yeah . yeah sure . professor b: so is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d: uh yeah . grad f: yeah , a fraction of it . phd d: a part of it , yeah . professor b: how m how much bigger is it ? phd d: um it 's two times , grad f: yeah , um . phd d: actually ? yeah . um . the english data no , the multilingual databases are two times the broad english data . we just wanted to keep this , w well , not too huge . so . professor b: so it 's two times , but it includes the but it includes the broad english data . phd d: i think so . do you uh , yeah . professor b: and the broad english data is what you got this one point one with . so that 's timit basically right ? phd d: yeah . grad f: mm - hmm . professor b: so it 's band - limited timit . this is all eight kilohertz sampling . phd d: mm - hmm . grad f: mm - hmm . phd d: yeah . grad f: downs right . professor b: so you have band - limited timit , gave you uh almost as good as a result as using ti - digits on a ti - digits test . ok ? phd d: hmm ? professor b: um and um but , when you add in more training data but keep the neural net the same size , it um performs worse on the ti - digits . ok , now all of this is this is noisy ti - digits , i assume ? both training and test ? phd d:  professor b: yeah . ok . um ok . well . we we we may just need to uh so i mean it 's interesting that h going to a different different task did n't seem to hurt us that much , and going to a different language um it does n't seem to matter the difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . phd d: mmm . professor b: it sounds like um uh we may need to have more of uh things that are similar to a target language or i mean . you have the same number of parameters in the neural net , you have n't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set . that that could be . um so , what about so these are results with uh th that you 're describing now , that they are pretty similar for the different features or or uh phd d: uh , let me check . uh . professor b: yeah . phd d: so . this was for the plp , professor b: yeah . phd d: um . the yeah . for the plp with jrasta the the we this is quite the same tendency , with a slight increase of the error rate , uh if we go to to timit . and then it 's it gets worse with the multilingual . um . yeah . there there is a difference actually with b between plp and jrasta is that jrasta seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . mmm . professor b: i have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? cuz we 're all sort of if we c if we could look at it , while we 're talking , i think it 'd be phd d: yeah , yeah . ok . professor b: uh uh , i 'll i 'll sing a song or dance or something while you do it , too . phd a: so um grad f: alright . phd a: go ahead . ah , while you 're gone i 'll ask s some of my questions . professor b: yeah . phd a: um . professor b: yeah . uh , this way and just slightly to the left , yeah . phd a: the um what was was this number forty or it was roughly the same as this one , he said ? when you had the two language versus the three language ? professor b: um . that 's what he was saying . phd a: that 's where he removed english , grad f: yeah . phd a: right ? professor b: right . grad f: it sometimes , actually , depends on what features you 're using . professor b: yeah . but but i it sounds like grad f: um , but he mm - hmm . professor b: i mean . that 's interesting because it it seems like what it 's saying is not so much that you got hurt uh because you uh did n't have so much representation of english , because in the other case you do n't get hurt any more , at least when it seemed like uh it it might simply be a case that you have something that is just much more diverse , phd a: mm - hmm . professor b: but you have the same number of parameters representing it . phd a: mm - hmm . i wonder were um all three of these nets using the same output ? this multi - language uh labelling ? grad f: he was using uh sixty - four phonemes from sampa . phd a: ok , ok . grad f: yeah . phd a: so this would from this you would say , `` well , it does n't really matter if we put finnish into the training of the neural net , if there 's gon na be , you know , finnish in the test data . `` right ? professor b: well , it 's it sounds i mean , we have to be careful , cuz we have n't gotten a good result yet . phd a: yeah . professor b: and comparing different bad results can be tricky . phd a: hmm . professor b: but i i i i think it does suggest that it 's not so much uh uh cross language as cross type of speech . phd a: mm - hmm . professor b: it 's it 's um but we did oh yeah , the other thing i was asking him , though , is that i think that in the case yeah , you you do have to be careful because of com compounded results . i think we got some earlier results in which you trained on one language and tested on another and you did n't have three , but you just had one language . so you trained on one type of digits and tested on another . didn - was n't there something of that ? where you , say , trained on spanish and tested on on ti - digits , or the other way around ? something like that ? phd e: no . professor b: i thought there was something like that , that he showed me last week . we 'll have to wait till we get phd a: yeah , that would be interesting . professor b: um , this may have been what i was asking before , stephane , but but , um , was n't there something that you did , where you trained on one language and tested on another ? i mean no no mixture but just grad f: i 'll get it for you . phd d: uh , no , no . professor b: we 've never just trained on one lang phd d: training on a single language , you mean , and testing on the other one ? professor b: yeah . phd d: uh , no . phd e: not yet . phd d: so the only task that 's similar to this is the training on two languages , and { comment } that professor b: but we 've done a bunch of things where we just trained on one language . right ? i mean , you have n't you have n't done all your tests on multiple languages . phd d: uh , no . either thi this is test with uh the same language but from the broad data , or it 's test with uh different languages also from the broad data , excluding the so , it 's it 's three or three and four . phd e: the early experiment that phd a: did you do different languages from digits ? phd d: uh . no . you mean training digits on one language and using the net to recognize on the other ? phd a: digits on another language ? phd d: no . professor b: see , i thought you showed me something like that last week . you had a you had a little phd d: uh , no , i do n't think so . professor b: um what phd c: these numbers are uh ratio to baseline ? professor b: so , i mean wha what 's the phd d: so . professor b: this this chart this table that we 're looking at is um , show is all testing for ti - digits , or ? grad f: bigger is worse . phd d: so you have uh basically two uh parts . grad f: this is error rate , i think . phd c: ratio . grad f: no . no . phd d: the upper part is for ti - digits grad f: yeah , yeah , yeah . phd d: and it 's divided in three rows of four four rows each . grad f: mm - hmm . professor b: yeah . phd d: and the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . and then the lower part is for italian and it 's the same the same thing . phd a: so , so the upper part is training ti - digits ? phd d: so . it 's it 's the htk results , i mean . so it 's htk training testings with different kind of features phd a: ah . phd d: and what appears in the uh left column is the networks that are used for doing this . professor b: hmm . phd d: so . uh yeah . professor b: well , what was is that i what was it that you had done last week when you showed do you remember ? wh - when you showed me the your table last week ? phd d: it - it was part of these results . mmm . mmm . phd a: so where is the baseline for the ti - digits located in here ? phd d: you mean the htk aurora baseline ? phd a: yeah . phd d: it 's uh the one hundred number . it 's , well , all these numbers are the ratio with respect to the baseline . phd a: ah ! ah , ok , ok . professor b: so this is word word error rate , so a high number is bad . phd d: yeah , this is a word error rate ratio . phd e: yeah . phd a: ok , i see . phd d: yeah . so , seventy point two means that we reduced the error rate uh by thirty thirty percent . phd a: ok , ok , gotcha . phd d: so . professor b: ok , so if we take phd d: hmm . professor b: uh um let 's see plp uh with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: yeah . professor b: um and `` multi - english `` refers to what ? phd d: to timit . mmm . then you have uh mf , ms and me which are for french , spanish and english . and , yeah . actually i i uh forgot to say that the multilingual net are trained on uh features without the s derivatives uh but with increased frame numbers . mmm . and we can we can see on the first line of the table that it it it 's slightly slightly worse when we do n't use delta but it 's not not that much . professor b: right . so w w so , i 'm sorry . i missed that . what 's mf , ms and me ? phd a: multi - french , multi - spanish phd d: so . multi - french , multi - spanish , and multi - english . professor b: uh ok . so , it 's uh broader vocabulary . then and phd d: yeah . professor b: ok so i think what i 'm what i saw in your smaller chart that i was thinking of was was there were some numbers i saw , i think , that included these multiple languages and it and i was seeing that it got worse . i i think that was all it was . you had some very limited results that at that point phd d: yeah . professor b: which showed having in these these other languages . in fact it might have been just this last category , having two languages broad that were where where english was removed . so that was cross language and the and the result was quite poor . what i we had n't seen yet was that if you added in the english , it 's still poor . phd d: yeah . professor b: uh um now , what 's the noise condition um of the training data phd d: still poor . professor b: well , i think this is what you were explaining . the noise condition is the same it 's the same uh aurora noises uh , in all these cases for the training . phd d: yeah . yeah . professor b: so there 's not a statistical sta a strong st statistically different noise characteristic between uh the training and test phd d: no these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . at least at least for the first for the well - matched , grad f: well matched condition . professor b: right . phd d: yeah . professor b: so there 's some kind of a a an effect from having these uh this broader coverage um now i guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . to try the same t with the exact same training , do testing on the other languages . phd d: mmm . professor b: on on um so . um , oh i well , wait a minute . you have this here , for the italian . that 's right . ok , so , so . phd d: yeah . yeah , so for the italian the results are uh stranger um mmm . so what appears is that perhaps spanish is not very close to italian because uh , well , when using the the network trained only on spanish it 's the error rate is almost uh twice the baseline error rate . professor b: mm - hmm . phd d: mmm . uh . professor b: well , i mean , let 's see . is there any difference in so it 's in the uh so you 're saying that when you train on english and uh and and test on phd d: yeah . professor b: no , you do n't have training on english testing phd d: there there is another difference , is that the noise the noises are different . professor b: in in what ? phd d: well , for for the italian part i mean the uh the um networks are trained with noise from aurora ti - digits , phd e: aurora - two . phd d: mmm . professor b: and the noise is different in th phd d: yeah . and perhaps the noise are quite different from the noises in the speech that italian . professor b: do we have any um test sets uh in any other language that um have the same noise as in the aurora ? phd d: and phd e: mmm , no . phd d: no . phd a: can i ask something real quick ? in in the upper part in the english stuff , it looks like the very best number is sixty point nine ? and that 's in the uh the third section in the upper part under plp jrasta , sort of the middle column ? phd d: yeah . phd a: i is that a noisy condition ? phd d: yeah . phd a: so that 's matched training ? is that what that is ? phd d: it 's no , the third part , so it 's uh highly mismatched . so . training and test noise are different . phd a: so why do you get your best number in would n't you get your best number in the clean case ? phd c: well , it 's relative to the um baseline mismatching phd d: yeah . phd a: ah , phd d: yeah . yeah . phd a: ok so these are not ok , alright , i see . phd c: yeah . phd a: ok . and then so , in the in the um in the non - mismatched clean case , your best one was under mfcc ? that sixty - one point four ? phd d: yeah . but it 's not a clean case . it 's a noisy case but uh training and test noises are the same . phd a: oh ! so this upper third ? phd d: so yeah . phd a: uh that 's still noisy ? phd d: yeah . phd a: ah , ok . phd d: so it 's always noisy basically , phd a: mm - hmm . phd d: and , well , the phd a: i see . phd d: mmm . professor b: ok ? um so uh , i think this will take some looking at , thinking about . but , what is uh what is currently running , that 's uh , i that just filling in the holes here or or ? { comment } pretty much ? phd d: uh , no we do n't plan to fill the holes professor b: ok . phd d: but actually there is something important , is that um we made a lot of assumption concerning the on - line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to htk . um mmm . so basically d if you look at the at the left of the table , the first uh row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for italian uh with straight mmm , plp features using on - line normalization . professor b: mm - hmm . phd d: mmm . and the , mmm what 's in the table , just at the left of the plp twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and uh forty - two are the results obtained by uh pratibha with uh his on - line normalization uh her on - line normalization approach . phd a: where is that ? seventy - nine , fifty professor b: uh , it 's just sort of sitting right on the uh the column line . phd d: so . phd e: fifty - one ? this phd a: oh i see , ok . professor b: uh . yeah . phd d: just uh yeah . so these are the results of ogi with on - line normalization and straight features to htk . and the previous result , eighty - six and so on , are with our features straight to htk . professor b: yes . yes . phd d: so what we see that is there is that um uh the way we were doing this was not correct , but still the networks are very good . when we use the networks our number are better that uh pratibha results . phd e: we improve . professor b: so , do you know what was wrong with the on - line normalization , or ? phd d: yeah . there were diff there were different things and basically , the first thing is the mmm , alpha uh value . so , the recursion uh part . um , i used point five percent , which was the default value in the in the programs here . and pratibha used five percent . professor b: uh phd d: so it adapts more quickly professor b: yes . yeah . phd d: um , but , yeah . i assume that this was not important because uh previous results from from dan and show that basically the both both values g give the same same uh results . it was true on uh ti - digits but it 's not true on italian . professor b: mm - hmm . phd d: uh , second thing is the initialization of the stuff . actually , uh what we were doing is to start the recursion from the beginning of the utterance . and using initial values that are the global mean and variances measured across the whole database . professor b: right . right . phd d: and pratibha did something different is that he uh she initialed the um values of the mean and variance by computing this on the twenty - five first frames of each utterance . mmm . there were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used c - zero instead of log energy . uh , but the main differences concerns the recursion . so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . professor b: ok . phd d: we it it 's slightly uh different because i do n't exactly initialize the same way she does . actually i start , mmm , i do n't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd c: mm - hmm . professor b: yeah . phd d: i i use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . but , well it 's similar . so uh i retrained the networks with these well , the the the networks are retaining with these new features . professor b: mm - hmm . phd d: and , yeah . professor b: ok . phd d: so basically what i expect is that these numbers will a little bit go down but perhaps not not so much professor b: right . phd d: because i think the neural networks learn perhaps to professor b: right . phd d: even if the features are not normalized . it it will learn how to normalize and professor b: ok , but i think that given the pressure of time we probably want to draw because of that especially , we wan na draw some conclusions from this , do some reductions in what we 're looking at , phd d: yeah . professor b: and make some strong decisions for what we 're gon na do testing on before next week . so do you are you w did you have something going on , on the side , with uh multi - band or on on this , phd d: yeah i professor b: or ? phd d: no , i we plan to start this uh so , act actually we have discussed uh @ @ um , these what we could do more as a as a research and and we were thinking perhaps that uh the way we use the tandem is not uh , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks if we trained the networks on the on a language and a t or a specific task , professor b: mm - hmm . phd d: um , what we ask is to the network is to put the bound the decision boundaries somewhere in the space . professor b: mmm . phd d: and uh mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . and so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: i di phd d: but the way the feature gives the the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: it 's a trade - off , phd d: so professor b: right ? any - anyway go ahead . phd d: yeah . so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks . doing something like , um um phonemes within context and , well , basically context dependent phonemes . professor b: maybe . i mean , i i think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . right . phd d: yeah but , we know that professor b: and in fact , th things get better with context dependent versions . right ? phd d: ye - yeah but here it 's something different . we want to have features professor b: yeah . phd d: uh well , um . professor b: yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing uh , things that vary w over context . phd d: mm - hmm . professor b: uh , and you 're putting it all together , ignoring the differences in context . that that 's true for the hybrid system , it 's true for a tandem system . so , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . phd d: yeah . professor b: ok ? but i it 's it 's a big deal to get that . i i 'm i 'm sort of and once you the other thing is that once you represent start representing more and more context it is uh much more um specific to a particular task in language . so um uh , the the acoustics associated with uh a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . we already actually do n't have a huge amount of training data um phd d: yeah , but mmm , i mean , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: right . phd d: and uh binary decisions about phonemes . nnn uh it 's professor b: almost . but i mean it it it does give a distribution . phd d: yeah . professor b: it 's and and it is true that if there 's two phones that are very similar , that uh the i it may prefer one but it will give a reasonably high value to the other , too . phd d: yeah . yeah , sure but uh so basically it 's almost binary decisions and um the idea of using more classes is to get something that 's less binary decisions . professor b: oh no , but it would still be even more of a binary decision . it it 'd be even more of one . because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: but yeah , but professor b: that would be even even more distinct of a binary decision . i actually would have thought you 'd wan na go the other way and have fewer classes . phd d: yeah , but if professor b: uh , i mean for instance , the the thing i was arguing for before , but again which i do n't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: mmm . mm - hmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . but if you go to very very fine categories , it 's very binary . phd d: mmm . yeah , but i think yeah , perhaps you 're right , but you have more classes so you you have more information in your features . so , um you have more information in the uh professor b: mm - hmm . true . phd d: posteriors vector um which means that but still the information is relevant professor b: mm - hmm . phd d: because it 's it 's information that helps to discriminate , professor b: mm - hmm . phd d: if it 's possible to be able to discriminate among the phonemes in context . professor b: well it 's it 's it 's an interesting thought . phd d: but the professor b: i mean we we could disagree about it at length phd d: mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: mmm . professor b: and and we 'll see . but but what i 'm more concerned with now , as an operational level , is uh , you know , phd d: mmm . professor b: what do we do in four or five days ? uh , and so we have to be concerned with are we gon na look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: mmm . professor b: um , are we going to look at multi - band ? are we gon na look at combinations of things ? uh , what questions are we gon na ask , uh now that , i mean , we should probably turn shortly to this o g i note . um , how are we going to combine with what they 've been focusing on ? uh , uh we have n't been doing any of the l d a rasta sort of thing . phd d: mm - hmm . professor b: and they , although they do n't talk about it in this note , um , there 's um , the issue of the um mu law business uh versus the logarithm , um , so . phd d: mm - hmm . professor b: so what i what is going on right now ? what 's right you 've got nets retraining , are there is there are there any h t k trainings testings going on ? phd d: n phd e: i i i 'm trying the htk with eh , plp twelve on - line delta - delta and msg filter together . professor b: the combination , i see . phd e: the combination , yeah . but i have n't result at this moment . professor b: msg and and plp . phd e: yeah . professor b: and is this with the revised on - line normalization ? phd e: ye - uh , with the old older , phd d: yeah . professor b: old one . so it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it we have the hope that it maybe it 's not making too much difference , phd e: yeah . but we can know soon . professor b: but but phd e: maybe . professor b: yeah . phd e: i do n't know . phd d: yeah . professor b: uh , ok . phd d: uh so there is this combination , yeah . working on combination obviously . phd e: mm - hmm . phd d: um , i will start work on multi - band . and we plan to work also on the idea of using both features and net outputs . phd e:  phd d: um . and we think that with this approach perhaps we could reduce the number of outputs of the neural network . um , so , get simpler networks , because we still have the features . so we have um come up with um different kind of broad phonetic categories . and we have basically we have three types of broad phonetic classes . well , something using place of articulation which which leads to nine , i think , broad classes . uh , another which is based on manner , which is is also something like nine classes . and then , something that combine both , and we have twenty f twenty - five ? grad f: twenty - seven . phd d: twenty - seven broad classes . so like , uh , oh , i do n't know , like back vowels , front vowels . professor b: so what you do um i just wan na understand phd d: um for the moments we do not do n't have nets , professor b: so you have two net or three nets ? was this ? how many how many nets do you have ? no nets . phd d: i mean , it 's just were we just changing the labels to retrain nets with fewer out outputs . phd e: begin to work in this . we are @ @ . professor b: right . but but i did n't understand phd d: and then mm - hmm . professor b: uh . the software currently just has uh a allows for i think , the one one hot output . so you 're having multiple nets and combining them , or ? uh , how are you how are you coming up with if you say uh if you have a place characteristic and a manner characteristic , how do you phd d: it - it 's the single net , phd a: i think they have one output . phd d: yeah . professor b: oh , it 's just one net . phd d: it 's one net with um twenty - seven outputs phd e: yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: i see . i see , ok . phd d: yeah . so it 's well , it 's basically a standard net with fewer classes . professor b: so you 're sort of going the other way of what you were saying a bit ago instead of yeah . phd d: yeah , but i think yeah . b b including the features , yeah . grad f: but including the features . phd e: yeah . phd d: i do n't think this will work alone . i think it will get worse because well , i believe the effect that of of too reducing too much the information is basically basically what happens professor b: uh - huh . phd d: and professor b: but you think if you include that plus the other features , phd d: but yeah , because there is perhaps one important thing that the net brings , and ogi show showed that , is the distinction between sp speech and silence because these nets are trained on well - controlled condition . i mean the labels are obtained on clean speech , and we add noise after . so this is one thing and but perhaps , something intermediary using also some broad classes could could bring so much more information . uh . professor b: so so again then we have these broad classes and well , somewhat broad . i mean , it 's twenty - seven instead of sixty - four , basically . and you have the original features . phd d: yeah . professor b: which are plp , or something . phd d: yeah . professor b: and then uh , just to remind me , all of that goes into uh , that all of that is transformed by uh , uh , k - kl or something , or ? phd d: mm - hmm . there will probably be , phd e: mu . phd d: yeah , one single kl to transform everything professor b: right . phd d: or uh , phd e: no transform the plp phd d: per phd e: and only transform the other i 'm not sure . professor b: well no , phd d: this is still something that professor b: i think i see . phd d: yeah , we do n't know professor b: so there 's a question of whether you would phd e: two e @ @ it 's one . phd d: yeah . professor b: right . whether you would transform together or just one . yeah . might wan na try it both ways . but that 's interesting . so that 's something that you 're you have n't trained yet but are preparing to train , and phd d: yeah . professor b: yeah . um yeah , so i think hynek will be here monday . phd d: mmm . professor b: monday or tuesday . so phd d: uh , yeah . professor b: so i think , you know , we need to choose the choose the experiments carefully , so we can get uh key key questions answered uh before then phd d: mm - hmm . professor b: and leave other ones aside even if it leaves incomplete tables someplace , uh uh , it 's it 's really time to time to choose . phd d: mm - hmm . professor b: um , let me pass this out , by the way . um these are did did did i interrupt you ? phd e: yeah , i have one . professor b: were there other things that you wanted to phd d: uh , no . i do n't think so . phd e:  phd d: yeah , i have one . grad g: oh , thanks . professor b: ah ! ok . ok , we have lots of them . phd e: we have one . professor b: ok , so um , something i asked so they 're they 're doing the the vad i guess they mean voice activity detection so again , it 's the silence so they 've just trained up a net which has two outputs , i believe . um i asked uh hynek whether i have n't talked to sunil i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities . phd d: mm - hmm . professor b: uh . to get the speech voice activity detection , or else just using the silence , if there 's only one silence output . um and , he did n't think they had , um . but on the other hand , maybe they can get by with a smaller net and maybe sometimes you do n't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: mm - hmm . professor b: so um their uh the results look pretty good . um , i mean , not uniformly . phd d: yeah . professor b: i mean , there 's a an example or two that you can find , where it made it slightly worse , but uh in in all but a couple examples . phd d: mmm . professor b: uh . phd e: but they have a question of the result . um how are trained the the lda filter ? how obtained the lda filter ? phd d: mmm . professor b: i i 'm sorry . i do n't understand your question . phd e: yes , um the lda filter needs some training set to obtain the filter . maybe i do n't know exactly how they are obtained . professor b: it 's on training . phd e: training , with the training test of each you understand me ? professor b: no . phd e: yeah , uh for example , lda filter need a set of a set of training to obtain the filter . professor b: yes . phd e: and maybe for the italian , for the td te on for finnish , these filter are are obtained with their own training set . professor b: yes , i do n't know . that 's that 's so that 's a that 's a very good question , then now that it i understand it . it 's `` yeah , where does the lda come from ? `` in the in earlier experiments , they had taken lda from a completely different database , right ? phd e: yeah . yeah , because maybe it the same situation that the neural network training with their own phd d: mmm . phd e: set . professor b: so that 's a good question . where does it come from ? yeah , i do n't know . um , but uh to tell you the truth , i was n't actually looking at the lda so much when i i was looking at it i was mostly thinking about the the vad . and um , it ap it ap oh what does what does asp ? oh that 's phd d: the features , yeah . yeah . phd e: i do n't understand also professor b: it says `` baseline asp `` . phd e: what is what is the difference between asp and uh baseline over ? phd c: asp . phd d: yeah , i do n't know . phd e: this is professor b: anybody know any phd c: oh . there it is . professor b: um cuz there 's `` baseline aurora `` above it . phd c: mm - hmm . professor b: and it 's this is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: well , it says baseline asp is twenty - three mill minus thirteen . phd e: yeah . professor b: yeah , it says what it is . but i do n't how that 's different from phd c: from the baseline . { comment } ok . professor b: i think this was i think this is the same point we were at when when we were up in oregon . phd e: yeah . phd d: i think i think it 's the c - zero using c - zero instead of log energy . phd e: ah , ok , mm - hmm . phd d: yeah , it 's this . professor b: oh . ok . phd e: yeah . phd d: it should be that , yeah . phd a: they s they say in here that the vad is not used as an additional feature . professor b: should n't it be phd d: because phd a: does does anybody know how they 're using it ? professor b: yeah . so so what they 're doing here is , i phd d: yeah . professor b: if you look down at the block diagram , um , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: but that professor b: and then they have a median filter of it . phd a: mm - hmm . professor b: and so um , basically they 're trying to find stretches . the median filter is enforcing a i it having some continuity . phd a: mm - hmm . professor b: you find stretches where the combination of the frame wise vad and the the median filter say that there 's a stretch of silence . and then it 's going through and just throwing the data away . phd c: hmm . professor b: right ? so um phd a: so it 's it 's i do n't understand . you mean it 's throwing out frames ? before professor b: it 's throwing out chunks of frames , yeah . there 's the the median filter is enforcing that it 's not gon na be single cases of frames , or isolated frames . phd a: yeah . professor b: so it 's throwing out frames and the thing is um , what i do n't understand is how they 're doing this with h t phd a: yeah , that 's what i was just gon na ask . professor b: this is phd a: how can you just throw out frames ? professor b: yeah . well , you you can , phd d: i professor b: right ? i mean y you you phd d: yeah . professor b: it stretches again . for single frames i think it would be pretty hard . phd a: yeah . professor b: but if you say speech starts here , speech ends there . phd a: mm - hmm . professor b: right ? phd c: huh . phd d: yeah . yeah , you can basically remove the the frames from the feature feature files . professor b: yeah . yeah , so i mean in the i i in the in the decoding , you 're saying that we 're gon na decode from here to here . phd d: i t phd a: mm - hmm . professor b: i think they 're they 're they 're treating it , you know , like uh well , it 's not isolated word , but but connected , you know , the the phd a: in the text they say that this this is a tentative block diagram of a possible configuration we could think of . so that sort of sounds like they 're not doing that yet . professor b: well . no they they have numbers though , right ? so i think they 're they 're doing something like that . i think that they 're they 're i think what i mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . in other words , it 's uh i mean from the point of view of of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: yeah . yeah . i 'm just wondering what exactly did they do up in this table if it was n't this . professor b: um . but it 's the thing is it 's that that that 's that 's i i certainly it would be tricky about it intrans in transmitting voice , uh uh for listening to , is that these kinds of things uh cut speech off a lot . phd a: mm - hmm . professor b: right ? and so um phd a: plus it 's gon na introduce delays . professor b: it does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . phd a: mmm . professor b: and the lda introduces delays , and b what he 's suggesting this here is a parallel path so that it does n't introduce uh , any more delay . i it introduces two hundred milliseconds of delay but at the same time the lda down here i do n't know wh what 's the difference between tlda and slda ? phd c: temporal and spectral . professor b: ah , thank you . phd e: temporal lda . professor b: yeah , you would know that . phd c: yeah professor b: so um . the temporal lda does in fact include the same so that i think he well , by by saying this is a b a tentative block di diagram i think means if you construct it this way , this this delay would work in that way phd a: ah . professor b: and then it 'd be ok . they they clearly did actually remove silent sections in order because they got these word error rate results . so um i think that it 's it 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . whereas to whether this would actually be in a final standard , i do n't know . um . uh , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . so it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . so this might just be a temporary thing . but but , on the other hand , and maybe maybe it 's a decent idea . so um the question we 're gon na wan na go through next week when hynek shows up i guess is given that we 've been if you look at what we 've been trying , we 're uh looking at uh , by then i guess , combinations of features and multi - band uh , and we 've been looking at cross - language , cross task issues . and they 've been not so much looking at the cross task uh multiple language issues . but they 've been looking at uh at these issues . at the on - line normalization and the uh voice activity detection . and i guess when he comes here we 're gon na have to start deciding about um what do we choose from what we 've looked at to um blend with some group of things in what they 've looked at and once we choose that , how do we split up the effort ? uh , because we still have even once we choose , we 've still got uh another month or so , i mean there 's holidays in the way , but but uh i think the evaluation data comes january thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: when they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: well , see they , i i think they 're um . i do n't know the the specifics of how they 're doing it . they 're they 're getting around the way the recognizer works because they 're not allowed to um , change the scripts for the recognizer , i believe . phd a: oh , right . maybe they 're just inserting some nummy frames or something ? professor b: so . uh . uh , you know that 's what i had thought . but i do n't i do n't think they are . phd a: hmm . professor b: i mean that 's sort of what the way i had imagined would happen is that on the other side , yeah you p put some low level noise or something . probably do n't want all zeros . phd a: hmm . professor b: most recognizers do n't like zeros but but you know , put some epsilon in or some rand phd a: yeah . professor b: sorry epsilon random variable in or something . phd a: some constant vector . i mean i w or something professor b: maybe not a constant but it does n't , uh do n't like to divide by the variance of that , but i mean it 's phd a: that 's right . but something that what i mean is something that is very distinguishable from speech . professor b: mm - hmm . phd a: so that the the silence model in htk will always pick it up . professor b: yeah . so i i that 's what i thought they would do . or else , uh uh maybe there is some indicator to tell it to start and stop , i do n't know . phd a: hmm . professor b: but whatever they did , i mean they have to play within the rules of this specific evaluation . phd a: yeah . professor b: we c we can find out . phd a: cuz you got ta do something . otherwise , if it 's just a bunch of speech , stuck together professor b: no they 're phd a: yeah . professor b: it would do badly phd a: yeah , right . professor b: and it did n't so badly , right ? so they did something . phd a: yeah , yeah . professor b: yeah . uh . so , ok , so i think this brings me up to date a bit . it hopefully brings other people up to date a bit . and um um i think uh , i wan na look at these numbers off - line a little bit and think about it and and talk with everybody uh , outside of this meeting . um , but uh no i mean it sounds like i mean there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . and now we 're seem to be kind of in a position to actually uh , look at stuff and and and compare things . so i think that 's that 's pretty good . um i do n't know what the one of the things i wonder about , coming back to the first results you talked about , is is how much , uh things could be helped by more parameters . and uh and uh how many more parameters we can afford to have , in terms of the uh computational limits . because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , i wonder if having twice as many parameters would help . phd d: mm - hmm . professor b: uh , just have a bigger hidden layer . uh but i doubt it would help by forty per cent . but but uh phd d: yeah . professor b: just curious . how are we doing on the resources ? disk , and phd d: i think we 're alright , professor b: ok . phd d: um , not much problems with that . professor b: computation ? phd d: it 's ok . professor b: we phd d: well this table took uh more than five days to get back . professor b: yeah . yeah , well . phd d: but yeah . professor b: are were you folks using gin ? that 's a that just died , you know ? phd d: mmm , no . you were using gin { comment } perhaps , yeah ? no . phd e: no . professor b: no ? oh , that 's good . grad f: it just died . professor b: ok . yeah , we 're gon na get a replacement server that 'll be a faster server , actually . phd e: yes . professor b: that 'll be it 's a seven hundred fifty megahertz uh sun phd d: hmm . { comment } mm - hmm . professor b: uh but it wo n't be installed for a little while . phd c: tonic . professor b: u go ahead . grad g: do we do we have that big new ibm machine the , i think in th professor b: we have the little tiny ibm machine that might someday grow up to be a big ibm machine . it 's got s slots for eight , uh ibm was donating five , i think we only got two so far , processors . we had originally hoped we were getting eight hundred megahertz processors . they ended up being five fifty . so instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . and more are supposed to come soon and there 's only a moderate amount of dat of memory . so i do n't think anybody has been sufficiently excited by it to spend much time uh with it , but uh hopefully , they 'll get us some more parts , soon and uh , yeah , i think that 'll be once we get it populated , that 'll be a nice machine . i mean we will ultimately get eight processors in there . and uh and uh a nice amount of memory . uh so it 'll be a pr pretty fast linux machine . grad g: and if we can do things on linux , some of the machines we have going already , like swede ? professor b: mm - hmm . grad g: um it seems pretty fast . professor b: mm - hmm . grad g: but i think fudge is pretty fast too . professor b: yeah , i mean you can check with uh dave johnson . i mean , it it 's i think the machine is just sitting there . and it does have two processors , you know and somebody could do you know , uh , check out uh the multi - threading libraries . and i mean i it 's possible that the i mean , i guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there are n't five or eight . there 's there 's there 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . but . notice how i said somebody and turned my head your direction . that 's one thing you do n't get in these recordings . you do n't get the do n't get the visuals but grad g: i is it um mostly um the neural network trainings that are um slowing us down or the htk runs that are slowing us down ? professor b: uh , i think yes . uh , is n't that right ? i mean i think you 're you 're sort of held up by both , right ? if the if the neural net trainings were a hundred times faster you still would n't be anything running through these a hundred times faster because you 'd be stuck by the htk trainings , phd d: mmm . professor b: right ? phd d: yeah . professor b: but if the htk i mean i think they 're both it sounded like they were roughly equal ? is that about right ? phd d: yeah . professor b: yeah . grad g: because , um i think that 'll be running linux , and sw - swede and fudge are already running linux so , um i could try to get um the train the neural network trainings or the htk stuff running under linux , and to start with i 'm wondering which one i should pick first . professor b: uh , probably the neural net cuz it 's probably it it 's it 's um well , i i do n't know . they both htk we use for um this aurora stuff um um , i think it 's not clear yet what we 're gon na use for trainings uh well , there 's the trainings uh is it the training that takes the time , or the decoding ? uh , is it about equal between the two ? for for aurora ? phd d: for htk ? professor b: for yeah . for the aurora ? phd d: uh training is longer . professor b: ok . phd d: yeah . professor b: ok . well , i do n't know how we can i do n't know how to do we have htk source ? is that yeah . phd d: mmm . professor b: you would think that would fairly trivially the training would , anyway , th the testing uh i do n't i do n't think would parallelize all that well . but i think that you could certainly do d um , distributed , sort of ah , no , it 's the each individual sentence is pretty tricky to parallelize . but you could split up the sentences in a test set . phd a: they have a they have a thing for doing that and th they have for awhile , in h t and you can parallelize the training . professor b: yeah ? phd a: and run it on several machines professor b: aha ! phd a: and it just basically keeps counts . and there 's something a final thing that you run and it accumulates all the counts together . professor b: i see . phd d: mmm . phd a: i do n't what their scripts are set up to do for the aurora stuff , but phd d: yeah . professor b: something that we have n't really settled on yet is other than this aurora stuff , uh what do we do , large vocabulary training slash testing for uh tandem systems . cuz we had n't really done much with tandem systems for larger stuff . cuz we had this one collaboration with cmu and we used sphinx . uh , we 're also gon na be collaborating with sri and we have their have theirs . um so i do n't know um . so i i think the the advantage of going with the neural net thing is that we 're gon na use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: ok . professor b: whereas , w exactly which hmm gaussian - mixture - based hmm thing we use is gon na depend uh so with that , maybe we should uh go to our digit recitation task . and , it 's about eleven fifty . canned . uh , i can i can start over here . great , uh , could you give adam a call . tell him to he 's at two nine seven seven . grad f: oh . professor b: ok . i think we can @ @ you know herve 's coming tomorrow , right ? herve will be giving a talk , yeah , talk at eleven . did uh , did everybody sign these consent er everybody has everyone signed a consent form before , on previous meetings ? you do n't have to do it again each time yes . microphones off","output":"the team talked about delays when discussing the removal of frames that were silent . this could possibly improve model performance at the cost of a small delay ."},{"instruction":"what was the overall discussion of the meeting ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"in this meeting , the speakers addressed issues that related to their meeting annotation progress . they talked about the types and variability of the future meetings . this led to them speaking about how to use their recording equipment if they got groups outside of their own departments to record meetings . additionally , they discussed how to handle the storage of meetings on disk . they eventually address how to handle speech overlap and speaker anonymity , which were two crucial issues ."},{"instruction":"what were some of the ideas proposed about future meeting recordings ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"phd f wanted the group to record different meetings with the same group to help in tasks such as summarization , the professor d however , wanted random meeting participants to have diversity that would be instrumental in acoustical research ."},{"instruction":"what was said on getting fluent english speakers ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"postdoc e was championing the need to get proficient english speakers so as to allow for a stable language model . this did not mean limiting the type of accents that the speakers had but rather ensuring the speakers could proficiently follow the english grammar when they expressed themselves ."},{"instruction":"what were the options that were discussed on the location of the recording equipment ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"one proposed solution was to set up another room in the linguistics department . this needed a dedicated partner and safety of the equipment for it to work . professor d talked about making the equipment portable allowing it to be transported from meeting to meeting ."},{"instruction":"what did the group say on portable equipment ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"the group wanted to introduce portable equipment so as to get more meetings from different groups . however , this was challenged by the complexity of setting up the recording equipment ."},{"instruction":"what were grad b \u2019 s updates on meeting disk storage ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"grad b said that archiving of the data by creating a clone had been done , though it took eleven hours . however , grad b commented that accessing the data would be much faster . this archiving had freed ten gigabytes of free space . additionally , two copies would be made : one offisite , another onsite ."},{"instruction":"what were other ways to get more space ?","input":"grad b: ok , phd f: that 's looks strange . grad b: now we 're on and it seems to be working . postdoc e: oh there we go . phd c: one two three four five six phd a: that is weird . postdoc e: this looks good . phd a: it 's like when it 's been sitting for a long time or something . grad b: so , i mean i do n't know what it is . but all all i know is that it seems like every time i am up here after a meeting , and i start it , it works fine . and if i 'm up here and i start it and we 're all sitting here waiting to have a meeting , it gives me that error message and i have not yet sat down with been able to get that error message in a point where i can sit down and find out where it 's occurring in the code . phd a: next time you get it maybe we should write it down . grad b: yep , we will . one of these days . professor d: yeah . postdoc e: was it a pause , or ? ok . was it on `` pause `` or something ? grad b: no . postdoc e: ok . do n't know . professor d: so uh so the uh , the new procedural change that just got suggested , which i think is a good idea is that um , we do the digit recordings at the end . and that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and do n't have the time , uh , then they can run off . it 'll mean we 'll get somewhat fewer uh , sets of digits , but um , i think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . so , i th i think i think we should start doing that . um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh i do n't know . wh - what what were some of the points again about that ? is it phd f: uh , well , ok , i 'll back up . professor d: yeah . phd f: um , at the previous at last week 's meeting , this meeting i was griping about wanting to get more data and i i talked about this with jane and adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new this new student di does wan na work with us , phd a: well , great . phd f: th the guy that was at the last meeting . phd a: great . phd f: and he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , phd a: what a deal . phd f: uh yeah . grad b: and what 's he interested in , specifically ? phd f: so he 's comes from a signal - processing background , but i liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , grad b: mm - hmm . great . phd f: so he 's just getting his feet wet in that . anyway , i thought ok , maybe we should have enough data so that if he starts he 'd be starting in january , next semester that we 'd have , you know , enough data to work with . grad b: right . phd f: but , um , jane and adam brought up a lot of good points that just posting a note to berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . so , i thought about that and i think it 's still possible , um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one one - time grad b: one offs ? phd f: yeah , just because it would be very hard to process the data in all senses , both to get the , um to figure out what type of meeting it is and to do any kind of higher level work on it , like well , i was talking to morgan about things like summarization , or what 's this meeting about . i mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . so . then i was um , talking to morgan about some new proposed work in this area , sort of a separate issue from what the student would be working on where i was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who did n't attend to listen to . and in that uh , regard , i thought we definitely w will need it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . so this this meeting is one of them , although i 'm not sure i can participate if i you know , i would feel very strange being part of a meeting that you were then analysing later for things like summarization . grad b: mm - hmm . phd f: um , and then there are some others that menti that morgan mentioned , like the front - end meeting and maybe a networking group meeting . grad b: right . yep . yeah , we 're we 're hoping that they 'll let us start recording regularly . phd f: so so if that were the case then i think we 'd have enough . grad b: so . mm - hmm . phd f: but basically , for anything where you 're trying to get a summarization of some kind of meeting { comment } meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we did n't really have a good grasp on what does it mean to summarize , grad b: yeah . phd f: but rather we should have different meetings by the same group but hopefully that have different summaries . and then we need a couple that of we do n't wan na just have one group because that might be specific to that particular group , but @ @ three or four different kinds . grad b: yeah , we have a lot of overlap between this meeting and the morning meeting . professor d: s so phd c: yeah . phd f: see , i 've never listened to the data for the front - end meeting . grad b: yeah , we we 've only had three . professor d: yeah . grad b: so . phd f: ok . but maybe that 's enough . so , in general , i was thinking more data but also data where we hold some parameters constant or fairly similar , grad b: mm - hmm . phd f: like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . grad b: um professor d: now , let l l let me just give you the other side to that cuz i ca because i i do n't disagree with that , but i think there is a complimentary piece to it too . uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have lots of different people . phd f: right . right . professor d: as many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and and uh , phd c: mm - hmm . professor d: i mean , sure , if we can get more from them , fine , postdoc e: mm - hmm . phd f: right . professor d: but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . phd f: yeah , i definitely agree with that . phd c: yeah . postdoc e: mm - hmm . phd f: definitely . phd c: yeah . postdoc e: can i can i say about that that the the issues that i think adam and i raised were more a matter of advertising so that you get more native speakers . because i think if you just say an and in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in english that that uh , it would be useful for for purposes you know . professor d: mm - hmm . postdoc e: but you know , i think i 've been i 've i i 've gathered data from undergrads at on campus and if you just post randomly to undergrads i think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . and and the english you 'd have the language models would be really hard to build professor d: well , you want to i postdoc e: because it would not really be it would be an interlanguage rather than than a professor d: well , ok , uh , first place , i i i do n't think we 'd just want to have random people come down and talk to one another , i think there should be a meeting that has some goal and point cuz i i think that 's what we 're investigating , postdoc e: ok . phd f: it has to be a a pre - existing meeting , like a meeting that would otherwise happen anyway . professor d: so grad b: right . professor d: yeah , yeah . postdoc e: ok . grad b: yep . professor d: so i was i was thinking more in terms of talking to professors uh , and and and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their hold their meeting down here . phd f: that 's i think what we and i agree with . postdoc e: oh , interesting ! phd c: yeah . postdoc e: oh , i see . oh , interesting ! professor d: uh , that 's the first point . the second point is um i think that for some time now , going back through berp i think that we have had speakers that we 've worked with who had non - native accents and i th i think that postdoc e: oh , oh . i 'm not saying accents . u the accent 's not the problem . professor d: oh , ok . postdoc e: no , it 's more a matter of uh , proficiency , e e just simply fluency . professor d: yeah . postdoc e: i mean , i deal with people on on campus who i think sometimes people , undergraduates um in computer science uh , have language skills that make , you know that their their fluency and writing skills are not so strong . professor d: oh ! you 're not talking about foreign language at all . grad b: yeah . yeah , just talking about . professor d: you 're just talking about postdoc e: well , e i just think , grad b: we all had the same thought . postdoc e: but you know , it 's like when you get into the graduate level , uh , no problem . i mean , i 'm not saying accents . phd c: uh - huh . professor d: yeah , then we 're completely gone . postdoc e: i 'm say i 'm saying fluency . grad b: mm - hmm . professor d: it 's the the habits are already burnt in . postdoc e: well , yeah . i 'm just saying fluency . professor d: but grad b: well , i think that , um i think that the only thing we should say in the advertisement is that the meeting should be held in english . and and i think if it 's a pre - existing meeting and it 's held in english , { comment } i i think it 's probably ok if a few of the people do n't have uh , g particularly good english skills . professor d: yeah . postdoc e: ok , now can i can i say the other aspect of this from my perspective which is that um , there 's there 's this this issue , you have a corpus out there , it should be used for for multiple things cuz it 's so expensive to put together . grad b: right . professor d: right . postdoc e: and if people want to approach um , i so i know e e you know this the idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , professor d: uh - huh . postdoc e: but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , professor d: mm - hmm . mm - hmm . postdoc e: if you have a choice between people who are pr more proficient in um , i more fluent , more more close to being academic english , then it would seem to me to be a good thing . professor d: i guess i maybe hmm . i postdoc e: because otherwise y you do n't have the ability to have uh , so if if you have a bunch of idiolects that 's the worst possible case . if you have people who are using english as a as an interlanguage because they they do n't uh , they ca n't speak in their native languages and but their interlanguage is n't really a match to any existing , uh , language model , professor d: uh - huh . postdoc e: this is the worst case scenario . phd c: yeah . yeah . professor d: well , that 's pretty much what you 're going to have in the networking group . postdoc e: and grad b: right . professor d: because because they most the network group is almost entirely germans and spaniards . postdoc e: well oh . but the thing is , i think that these people are of high enough level in their in their language proficiency that professor d: i see . postdoc e: and i 'm not objecting to accents . professor d: ok . postdoc e: i i 'm i 'm just thinking that we have to think at a at a higher level view , could we have a language model , a a grammar a grammar , basically , that um , wo would be a a possibility . professor d: uh - huh . postdoc e: so y so if you wanted to bring in a model like dan jurafsky 's model , an and do some top - down stuff , it to help th the bottom - up and merge the things or whatever , uh , it seems like um , i do n't see that there 's an argument professor d: mm - hmm . postdoc e: i 'm i what i think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . professor d: mm - hmm . postdoc e: that 's that 's my point . which which includes both top - down and bottom - up . phd c: it 's difficult . professor d: ok . phd c: yeah . professor d: ok , well , i i let 's let 's see what we can get . i mean , it it i think that if we 're aiming at at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , postdoc e: yes , that 's fine . that 's fine . exactly . and my point in m in my note to liz was i think that undergrads are an iff iffy population . professor d: but ok . ok . phd f: i definitely agree with that , i mean , for this purpose . professor d: ok . grad b: well , not to mention the fact that i would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . phd c: yeah . postdoc e: grads and professors , fine . phd c: yeah . grad b: so . professor d: oh , you age - ist ! grad b: what 's that ? well , age - ist . { comment } the `` eighteen `` is because of the consent form . postdoc e: age - ist . phd c: yeah . phd f: right , yeah . grad b: we 'd hafta get find their parent to sign for them . phd c: `` age - ist `` . yeah . yeah . professor d: yes . postdoc e: yeah , that 's true . grad b: so . phd f: i have a uh , um , question . well , morgan , you were mentioning that mari may not use the k equipment from ibm if they found something else , cuz there 's a professor d: they 're they 're yeah , they 're d they 're uh assessing whether they should do that or y do something else , hopefully over the next few weeks . phd f: cuz i mean , one remote possibility is that if we st if we inherited that equipment , if she were n't using it , could we set up a room in the linguistics department ? and and i mean , there there may be a lot more or or in psych , or in comp wherever , in another building where we could um , record people there . i think we 'd have a better chance grad b: i think we 'd need a real motivated partner to do that . we 'd need to find someone on campus who was interested in this . phd f: right , but right . but if there were such a i mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . grad b: yep . phd f: so it 's just a just a thought if they end up not using the the hardware . professor d: well , the other thing yeah , i mean the other thing that i was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . grad b: right . professor d: uh . but . um , and grad b: well , i know that space is really scarce on at least in cs . you know , to to actually find a room that we could use regularly might actually be very difficult . professor d: uh yeah . phd f: but you may not need a separate room , you know , grad b: that 's true . professor d: yeah . phd f: the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something grad b: true . mm - hmm . yep . professor d: well , maybe john would let us put it into the phonology lab or something . phd f: huh . grad b: yep . professor d: you know . phd f: i i think it 's not out of the question . grad b: yeah , i think it would be interesting because then we could regularly get another meeting . professor d: yeah . phd f: um . so . grad b: another type of meeting . phd c: yeah . phd f: right . phd c: but i i i think you need , uh , another portable thing a another portable equipment to to do , eh , more e easier the recording process , eh , out from icsi . phd f: right . grad b: hmm . professor d: yeah . grad b: right . phd c: eh and probably . i do n't know . professor d: yeah . phd c: eh , if you you want to to record , eh , a seminar or a class , eh , in the university , you you need it - it would be eh eh very difficult to to put , eh , a lot of , eh , head phones eh in different people when you have to to record only with , eh , this kind of , eh , d device . professor d: yeah . grad b: yeah , but i think if we if we wan na just record with the tabletop microphones , that 's easy . phd c: oh - yeah . grad b: right ? that 's very easy , phd c: ye - yeah , yeah . grad b: but that 's not the corpus that we 're collecting . phd c: yeah . professor d: actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . we realized that , um , when we were talking about this that , ok , there 's these different things that we want to do with it . so , um , it 's true that we wan na be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . but on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . so , a a as per the example that we wan na have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings but we can also have another part that 's , uh , just one or two meetings of each of a of a range of them and that 's ok too . uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? i mean , we really wan na have a substantial amount recorded this way , that 's why we did it . but what about for th for these issues of summarization , a lot of these higher level things you do n't really need the distant microphone . phd f: right , i mean , i c i think there 's grad b: and you do n't really need the close microphone , you mean . professor d: you actually do n't . phd c: yeah . phd f: yea - yeah yeah , you actually do n't really even need any fancy microphone . postdoc e: which one did you mean ? professor d: you d you do n't ne it does n't you just need some microphone , somewhere . grad b: ye - yeah . yep . phd f: you can use found data . grad b: tape recorder . phd c: yeah . professor d: yeah . postdoc e: oh . phd c: yeah . phd f: you you can . professor d: you need some microphone , phd f: you can grad b: mm - hmm . professor d: but i mean phd f: use um , but i think that any data that we spend a lot of effort to collect , professor d: yeah . phd f: you know , each person who 's interested in i mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . professor d: right . phd f: and so in my case , um , i think there w there is enough data for some kinds of projects and not enough for others . grad b: not enough for others , right . phd f: and so i 'm looking and thinking , `` well i 'd be glad to walk over and record people and so forth if it 's to help th in my interest . `` grad b: mm - hmm . phd f: and other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal professor d: right . so that phd c: yeah . professor d: but i think that i 'm raising that cuz i think it 's relevant exactly for this idea up there that if you think about , `` well , gee , we have this really complicated setup to do , `` well maybe you do n't . grad b: yeah . for some of it . professor d: maybe if if if really all you want is to have a a a recording that 's good enough to get a uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . phd f: right . grad b: yep . professor d: i mean , we we could have a fairly we could just get a dat machine and phd f: well , i agree with jane , though , on the other hand that phd c: yeah . phd f: so that might be true , you may say for instance , summarization , or something that sounds very language oriented . you may say well , `` oh yeah , you just do that from transcripts of a radio show . `` i mean , you do n't even need the speech signal . professor d: right . phd f: but what you what i was thinking is long term what would be neat is to be able to pick up on um suppose you just had a distant microphone there and you really wanted to be able to determine this . there 's lots of cues you 're not gon na have . grad b: right . professor d: yeah . phd f: so i do think that long term you should always try to satisfy the greatest number of of interests and have this parallel information , which is really what makes this corpus powerful . phd c: yeah . grad b: special ? yep . professor d: i i i i i agree . phd f: otherwise , you know , lots of other sites can propose individual studies , so professor d: uh but i i think that the uh i we ca n't really underestimate the difficulty should n't really u underestimate the difficulty of getting a setup like this up . grad b: yep . professor d: and so , uh it took quite a while to get that together and to say , `` oh , we 'll just do it up there , `` phd f: ok . professor d: if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . talking about something that has all of these different facets that we have here , it wo n't happen quickly , it wo n't be easy , and there 's all sorts of issues about th you know keeping the equipment safe , or else hauling it around , and all sorts of o phd f: so then maybe we should try to bring people here . grad b: here . professor d: i think the first priority should be to pry { comment } to get try to get people to come here . phd f: i mean , that 's that 's ok , so professor d: we 're set up for it . postdoc e: mm - hmm . professor d: the room is is really , uh , underused . phd f: ok . professor d: uh phd f: right . postdoc e: i thought the free lunch idea was a great idea . grad b: yeah , i thought so too . phd c: yeah . professor d: free lunch is good . phd f: yeah , i and i think we can get people to come here , that but the issue is you definitely wan na make sure that the kind of group you 're getting is the right group so that you do n't waste a lot of your time and the overhead in bringing people down . postdoc e: mm - hmm . phd a: no crunchy food . professor d: yeah . phd f: so { comment } well , it would be lunch afterwards . grad b: well , i was thinking , lunch after . postdoc e: yeah . phd f: right . and they 'd have to do their digits or they do n't get dessert . grad b: yep . professor d: yeah , they have to do their digits or they do n't { comment } get they do n't { comment } get their food . phd f: yeah . grad b: um , i had a i spoke with some people up at haas business school who volunteered . professor d: yeah grad b: should i pursue that ? phd f: oh , definitely , yeah . grad b: yeah . so . they they originally they 've decided not to do go into speech . professor d: yeah . grad b: so i 'm not sure whether they 'll still be so willing to volunteer , but i 'll send an email and ask . professor d: tell them about the free lunch . grad b: i 'll tell them about the free lunch . phd f: yeah . grad b: and they 'll say there 's no such thing . phd f: yeah . grad b: so . phd f: i 'd love to get people that are not linguists or engineers , cuz these are both weird grad b: right . professor d: yeah . phd c: yeah . professor d: the the the oth the other h phd f: well , i know , i should n't say that . grad b: that 's alright . no , the they they 're very weird . phd f: we need a wider sampling . phd a: `` beep . `` phd c: yeah . professor d: uh , `` beep `` grad b: the problem with engineers is `` beep . `` professor d: uh , the the they make funny sounds . the o the o the other the other thing is , uh , that we we talked about is give to them uh , burn an extra cd - rom . grad b: yep . let them have their meeting . professor d: and give them so if they want a basically and audio record of their phd f: well , i thought that was i thought he meant , `` give them a music cd , `` like they g then he said a cd of the of their speech professor d: oh . phd f: and i guess it depends of what kind of audience you 're talking to , but you know , i personally would not want a cd { comment } of my meeting , grad b: mmm . of the meeting ? phd f: but maybe yeah , maybe you 're professor d: if you 're having some planning meeting of some sort and uh you 'd like phd f: right . { comment } right . right . phd a: oh , that 's a good idea . grad b: it 'd be fun . i think it would just be fun , you know , if nothing else , you know . phd c: yeah . professor d: yeah . phd f: right . grad b: it 's a novelty item . professor d: but it als it it it also i think builds up towards the goal . phd f: right . professor d: we 're saying , `` look , you know , you 're gon na get this . is - is is n't that neat . then you 're gon na go home with it . it 's actually p it 's probably gon na be pretty useless to you , grad b: yep . professor d: but you 'll ge appreciate , you know , where it 's useful and where it 's useless , phd f: right . professor d: and then , we 're gon na move this technology , so it 'll become useful . `` phd c: yeah . professor d: so . phd f: no , i think that 's a great idea , actually . phd a: what if you could tell them that you 'll give them the the transcripts when they come back ? postdoc e: alth phd f: but we might need a little more to incentivize them , { comment } that 's all . grad b: oh , yeah . i mean , anyone can have the transcripts . so . i thought we could point that out . professor d: oh yeah . postdoc e: yeah . phd f: well , that 's interesting . postdoc e: i hav i have to uh raise a little eensy - weensy concern about doing th giving them the cd immediately , because of these issues of , you know , this kind of stuff , { comment } where maybe you know ? professor d: good point . that 's a very good point . postdoc e: so . professor d: so we can so we can postdoc e: we could burn it after it 's been cleared with the transcript stage . professor d: r right . postdoc e: and then they they get a cd , but just not the same day . phd f: oh , right . grad b: yeah , that 's right . phd f: if it should be the same cd - rom that we distribute publically , grad b: that 's a good point . right , it ca n't be the internal one . phd f: right ? professor d: although it 's phd f: otherwise they 're not allowed to play it for anyone . postdoc e: there we go . grad b: that 's right . postdoc e: oh , i like that . well put . well put . so , after the transcript screening phase . grad b: yeah , that 's true . postdoc e: things have been weeded out . phd f: otherwise we 'd need two lawyer stages . postdoc e: yeah , that 's right , say { comment } `` yeah , well , i got this cd , and , your honor , i `` grad b: yeah . phd f: that 's a good point . professor d: yeah so that 's so let 's start with haas , and yeah . phd f: sorry to have to sorry i have to leave . professor d: oh , that 's fine . phd f: i will be here full - time next week . grad b: ok , see you . professor d: ok . grad b: no . bye . professor d: that 's alright . phd a: see you . professor d: ok . phd c: see you . professor d: so , uh let 's see . so that was that topic , and then um , i guess another topic would be where are we in the whole disk resources question for grad b: we are slowly slowly getting to the point where we have uh enough sp room to record meetings . so i uh did a bunch of archiving , and still doing a bunch of archiving , i i 'm in the midst of doing the p - files from uh , broadcast news . and it took eleven hours { comment } to do to uh copy it . phd c: eleven ? grad b: and it 'll take another eleven to do the clone . phd a: where did you copy it to ? grad b: well , it 's abbott . it 's abbott , so it just but it 's it 's a lot of data . professor d: sk - it 's copying from one place on abbott to another place on abbott ? grad b: tape . phd c: tape ? phd a: oh , on the tape . professor d: oh ! grad b: i did an archive . professor d: i 'm sorry . phd a: ah ! grad b: so i 'm archiving it , and then i 'm gon na delete the files . phd c: oh . grad b: so that will give us ten gigabytes of free space . phd c: eleven hours ? phd a: wow ! phd c: oh . postdoc e: yeah , the archiving m program does take a long time . grad b: and and phd c: yeah . grad b: yep . and so one that that will be done , like , in about two hours . and so uh , at that point we 'll be able to record five more meetings . so . phd c: yeah . postdoc e: one thing the good news about that that is that once once it 's archived , it 's pretty quick to get back . phd c: yeah . professor d: is it ? postdoc e: i mean , it it it the other direction is fast , but this direction is really slow . grad b: right . professor d: hmm . grad b: well , especially because i 'm generating a clone , also . phd c: yeah . grad b: so . and that takes a while . phd c: yeah . postdoc e: yeah , ok . phd a: generating a clone ? postdoc e: yeah , that 's a good point . grad b: two copies . postdoc e: yeah . phd a: oh ! grad b: one offsite , one onsite . phd a: oh ! hunh ! professor d: s postdoc e: now , what will uh is the plan to g to so stuff will be saved , it 's just that you 're relocating it ? i mean , so we 're gon na get more disk space ? or did i ? grad b: no , the the these are the p - files from broadcast news , which are regeneratable regeneratable postdoc e: ok . oh , good . i see . grad b: um , if we really need to , but we had a lot of them . and for the full , uh , hundred forty hour sets . postdoc e: ok . grad b: and so they they were two gigabytes per file and we had six of them or something . phd c: yeah . postdoc e: wow . wow . professor d: w w we are getting more space . we are getting , uh , another disk rack and and four thirty - six gigabyte disks . uh so uh but that 's not gon na happen instantaneously . postdoc e: wonderful . grad b: or maybe six . professor d: or maybe six ? grad b: the sun , ha uh , takes more disks than the andatico one did . the sun rack takes { comment } th - one took four and one took six , or maybe it was eight and twelve . whatever it was , it was , you know , fifty percent more . professor d: how many how much phd a: is there a difference in price or something ? grad b: well , what happened is that we we bought all our racks and disks from andatico for years , according to dave , and andatico got bought by another company and doubled their prices . phd a: oh ! phd c: oh . grad b: and so , uh , we 're looking into other vendors . `` we `` by `` we `` of course i mean dave . postdoc e: wow . phd a: mm - hmm . grad b: so . phd a: hmm . i 've been looking at the , uh , aurora data and , um , first first look at it , there were basically three directories on there that could be moved . one was called aurora , one was spanish , which was carmen 's spanish stuff , and the other one was , um , spine . grad b: spine . phd a: and so , um , i wrote to dan and he was very concerned that the spine stuff was moving to a non - backed - up disk . so , um , i realized that well , probably not all of that should be moved , just the cd - rom type data , the the static data . so i moved that , and then um , i asked him to check out and see if it was ok . before i actually deleted the old stuff , um , but i have n't heard back yet . i told him he could delete it if he wanted to , i have n't checked today to see if he 's deleted it or not . and then carmen 's stuff , i realized that when i had copied all of her stuff to xa , i had copied stuff there that was dynamic data . and so , i had to redo that one and just copy over the static data . and so i need to get with her now and delete the old stuff off the disk . and then i lo have n't done any of the aurora stuff . i have to meet with , uh , stephane to do that . so . professor d: so , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the broadcast news , but , we have some other disks , some of which you 're using for aurora , but are we g do we have some other other space now ? grad b: yep . so , so , uh , we have space on the current disk right now , where meeting recorder is , and that 's probably enough for about four meetings . professor d: yeah . phd a: is that the one that has is that dc ? professor d: yeah . grad b: so . yep . no , no , well , it 's wherever the meeting recorder currently is . i think it 's di . phd a: ok , i but the stuff i 'm moving from aurora is on the dc disk that we grad b: i do n't remember . th - i think it 's dc - it 's whatever that one is . phd a: ok , dc . grad b: i just do n't remember , it might be dc . phd a: yeah . grad b: and that has enough for about four more meetings right now . yeah , i mean we were at a hundred percent and then we dropped down to eighty - six for reasons i do n't understand . professor d: mm - hmm . grad b: um , someone deleted something somewhere . and so we have some room again . and then with broadcast news , that 's five or six more meetings , so , you know , we have a couple weeks . uh , so , yeah , i think i think we 're ok , until we get the new disk . phd c: ok . phd a: so should , um one question i had for you was , um , we need we sh probably should move the aurora an and all that other stuff off of the meeting recorder disk . is there another backed - up disk that you know of that would ? grad b: we should put it onto the broadcast news one . that 's probably the best thing to do . and that way we consolidate meeting recorder onto one disk rather than spreading them out . phd a: ok . right . right . do you know what happen to know what disk that is off ? ok . grad b: no . i mean , i can tell you , i just do n't know off the top of my head . phd a: yeah . ok . alright , i 'll find out from you . grad b: but , so we could ' jus just do that at the end of today , once the archive is complete , and i 've verified it . phd a: ok . grad b: cuz that 'll give us plenty of disk . professor d: uh , ok , @ @ { comment } so , uh , then i guess th the last thing i 'd had on my my agenda was just to hear hear an update on what what jose has been doing , phd c: uh - huh . ok . professor d: so phd c: i have , eh , the result of my work during the last days . professor d: ok . phd c: thank you for your information because i i read . eh , and the the last , eh , days , eh , i work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the the meeting recording project . grad b: yeah . professor d: uh - huh . phd c: and i have , eh , some ideas . eh , this information is very very useful . because you have the the the distribution , now . postdoc e: i 'm glad to hear it . glad to hear it . phd c: but for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , problem . grad b: i 've seen it already . phd c: it 's a real problem , { comment } a frequently problem { comment } uh , because you have overlapping zones eh , eh , eh , all the time . postdoc e: yeah . yeah . grad b: yep . phd c: yeah . grad b: throughout the meeting . phd c: eh , by a moment i have , eh , nnn , the , eh , n i i did a mark of all the overlapped zones in the meeting recording , with eh , a exact mark . grad b: mm - hmm . oh , you did that by hand ? phd c: heh ? that 's eh , yet b b yeah , by b b by hand by hand because , eh , eh `` why . `` grad b: can i see that ? can i get a copy ? professor d: oh . phd c: my my idea is to work phd a: wow ! phd c: i i i do i don i do n't @ @ i do n't know , eh , if , eh , it will be possible because i i i have n't a lot eh , enough time to to to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to to work in in the line of , eh , automatic segmenter . grad b: mm - hmm . phd c: eh but eh , eh , in my opinion , we need eh , eh , a reference eh session to t to to evaluate the the the tool . grad b: yes , absolutely . and so are you planning to do that or have you done that already ? phd c: and no , no , with i grad b: have you done that or are you planning to do that ? phd c: sorry ? no , i i plan to do that . grad b: ok . darn ! phd c: i plan i plan , but eh , eh , the idea is the is the following . now , eh , i need ehm , to detect eh all the overlapping zones exactly . i i will i will eh , talk about eh , in the in the blackboard about the my ideas . postdoc e: yeah . professor d: mm - hmm . postdoc e: duration . phd c: eh , um , eh this information eh , with eh , exactly time marks eh , for the overlapping zones eh overlapping zone , and eh , a speaker a a pure speech eh , eh , speaker zone . i mean , eh zones eh of eh speech of eh , one speaker without any any eh , noise eh , any any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . and , i need t true eh , silence for that , because my my idea is to to study the nnn the the set of parameters eh , what , eh , are more m more discriminant to eh , classify . grad b: right . phd c: the overlapping zones in cooperation with the speech eh zones . the idea is to eh to use eh , i 'm not sure to eh yet , but eh my idea is to use a a cluster eh algorithm or , nnn , a person strong in neural net algorithm to eh to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . phd a: mmm . phd c: and my idea is eh , it would be interesting to to have eh , a control set . and my control set eh , will be the eh , silence , silence without eh , any any noise . professor d: mm - hmm . postdoc e: which means that we 'd still you 'd hear the grad b: yeah , fans . phd c: yeah , acoustic with this . { comment } with with , yeah , the background . postdoc e: yeah . { comment } that 's interesting . this is like a ground level , with it 's not it 's not total silence . phd c: eh , i i mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , professor d: mm - hmm . phd c: eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the in the eh speech . grad b: so so you intend to hand - mark those and exclude them ? professor d: mm - hmm . postdoc e: mm - hmm . phd c: yeah , i have mark in in in in that not in all in all the the file , grad b: mm - hmm . phd c: only eh , eh , nnn , mmm , i have eh , ehm i do n't remind { comment } what is the the the the quantity , but eh , i i have marked enough speech on over and all the overlapping zones . i have , eh , two hundred and thirty , more or less , overlapping zones , and is similar to to this information , grad b: whew ! mm - hmm . postdoc e: great . great . phd c: because with the program , i cross the information of uh , of jane { comment } with eh , my my segmentation by hand . and is eh , mor more similar . postdoc e: excellent . glad to hear it . good . phd c: but sorry , sorry . professor d: go ahead . phd c: and the the idea is , eh , i i will use , eh , i want my idea is , eh , to eh { comment } to classify . grad b: i should 've got the digital camera . oh well . phd c: i i need eh , the exact eh , mark of the different , eh , eh , zones because i i want to put , eh , for eh , each frame a label indicating . it 's a sup supervised and , eh , hierarchical clustering process . i i i put , eh , eh , for each frame a label indicating what is th the type , what is the class , eh , which it belong . grad b: mm - hmm . phd c: eh , i mean , the class you will overlapping speech `` overlapping `` is a class , eh , `` speech `` @ @ the class that 's grad b: nonspeech . phd a: these will be assigned by hand ? phd c: a i i i ha i h i i put the mark by hand , phd a: based on the uh - huh . phd c: because , eh , my idea is , eh , in in the first session , i need , eh , i i need , eh , to be sure that the information eh , that , eh , i i will cluster , is is right . because , eh , eh , if not , eh , i will i will , eh , return to the speech file to analyze eh , what is the problems , grad b: well , training , and validation . sure . mm - hmm . phd c: eh . and i i 'd prefer i would prefer , the to to have , eh , this labeled automatically , but , eh , eh , fro th i need truth . phd a: you need truth . hmm . grad b: yeah , but this is what you 're starting with . phd c: yeah . yeah . yeah . yeah . postdoc e: i 've got ta ask you . so , uh , the difference between the top two , i so so i start at the bottom , so `` silence `` is clear . by `` speech `` do you mean speech by one sp by one person only ? phd c: speech yeah . postdoc e: so this is un ok , and then and then the top includes people speaking at the same time , or or a speaker and a breath overlapping , someone else 's breath , or or clicking , overlapping with speech so , that that 's all those possibilities in the top one . phd c: yeah . yeah . is grad b: one or two or more . phd c: one , two , three . but no , by th by the moment n yeah . yeah . yeah . yeah . yeah . postdoc e: ok . phd c: eh , in the first moment , because , eh , eh , i i have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , or three speaker , or is is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . postdoc e: so it 's basi it 's basically speech wi som with with something overlapping , which could be speech but does n't need to be . phd c: no , no , es especially eh , overlapping speech from , eh , different eh , eh , speaker . eh professor d: no , but there 's but , i think she 's saying `` where do you in these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? `` phd c: ah ! professor d: which category do you put that in ? postdoc e: yeah , that 's right . that 's my question . phd c: yeah . yeah , he here i i put eh speech from eh , from , eh , one speaker without , eh , eh , any any any events more . postdoc e: oh ! professor d: right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? phd c: where ? where what is the class ? professor d: which catege which category ? postdoc e: like a c phd c: no . by the moment , no . grad b: yeah , yeah , that 's what he was saying before . phd c: for for the by the @ @ no , @ @ because i i i i want to limit the the nnn , the the study . professor d: oh , so you not not marked . postdoc e: oh . so you do n't i i it 's not in that professor d: ok . got it . fine . so so phd a: so you 're not using all of the data . grad b: yeah , so that 's what he was saying before , is that he excluded those . phd c: the all i exactly . grad b: yeah . phd c: yeah , you mean professor d: yeah . postdoc e: so you 're ignoring overlapping events unless they 're speech with speech . phd c: yeah , be yeah . professor d: yeah , that 's fine . postdoc e: ok . phd c: `` why ? why ? what 's the reason ? `` because i it 's the first study . the first professor d: oh , no no , it 's a perfectly sensible way to go . we just wondered trying to understand what what you were doing . postdoc e: we 're just phd c: yeah . postdoc e: yeah . professor d: ok . postdoc e: yeah cuz you 've talked about other overlapping events in the past . phd c: yeah . postdoc e: so , this is this is a subset . phd c: yeah . in the in the future , the the idea is to to extend the class , phd a: is is phd c: to consider all the all the information , you you mentioned before professor d: yeah . yeah , i i do n't think we were asking for that . postdoc e: ok . phd c: but eh , the the first idea because eh , i do n't know what hap what will happen { comment } with the study . professor d: we were jus just trying to understand postdoc e: yeah . yeah , we just wanted to know what the category was here . grad b: right . professor d: yeah . sure . phd a: is your silence category pure silence , or ? phd c: yeah . i it 's pure phd a: what if there was a door - slam or something ? phd c: no , no , it 's pure silence . phd a: pure silence . phd c: it 's the control set . phd a: ok . phd c: ok ? it 's the control set . it 's pure si pure silence { comment } with the with the machine on the on the roof . professor d: what you well w i i think what you m i think what you mean is that it 's nonspeech segments that do n't have impulsive noises . grad b: with the fan . phd c: yeah . professor d: right ? cuz you 're calling what you 're calling `` event `` is somebody coughing or clicking , or rustling paper , or hitting something , which are impulsive noises . phd c: yeah . professor d: but steady - state noises are part of the background . phd c: yeah . professor d: which , are being , included in that . right ? phd c: h here yet , yet i i i i i think i i think , eh , there are that some kind of noises that , eh , do n't do n't wanted to to be in that , eh , in that control set . professor d: yeah . postdoc e: so it 's like a signal - noise situation . yeah . professor d: well yeah . phd c: but i prefer , i prefer at at the first , eh , the the silence with eh , this eh this kind of the of eh of noise . postdoc e: well , steady state . professor d: right , it 's i mean , it 's `` background `` might be might be a better word than `` silence `` . phd c: yeah . professor d: it 's just sort of that the the background acoustic phd c: yeah . grad b: right . so fine . go on . phd c: yeah . professor d: yeah . phd c: is is is only ok . professor d: yeah . phd c: and , um , with this information the idea is eh , eh , nnn , i have a label for for each , eh , frame and , eh with a cluster eh algorithm i and postdoc e: well , we needed to get the categories , yeah . phd c: sorry . and eh i am going to prepare a test bed , eh , well , eh , a a set of feature structure eh , eh , models . grad b: right . phd c: and my idea is grad b: `` tone `` , whatever . phd c: so so on because i have a pitch extractor yet . professor d: right . grad b: mm - hmm . phd c: i have to to test , but eh i phd a: you have your own ? phd c: yeah , yeah , yeah . phd a: oh ! phd c: i ha i have prepare . is a modified version of of of a pitch tracker , eh , from , eh , standar - eh stanford university in stanford ? no . from , eh , em , cambridge university . phd a: oh ! what 's it written in ? phd c: eh , em , i i i do n't remember what is the the name of the of the author , because i i have several i have eh , eh , em , eh , library tools , from eh , festival and of from edinburgh eh , from cambridge , eh , and from our department . phd a: ah . professor d: mm - hmm . mm - hmm . phd c: and and i have to because , in general the pitch tracker , does n't work { comment } very well and grad b: bad . right . but , you know , as a feature , it might be ok . so , we do n't know . phd c: yeah . yeah . this this is and th the idea is to to , eh , to obtain , eh , for example , eh , eh diff eh , eh , different well , no , a great number of eh fec for example , eh , eh , twenty - five , eh , thirty thirty parameters , eh , for for each one . and in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh to classify the different , eh , what is the the the the front - end approach to classify eh , the different , eh , frames of each class eh and what is the the , nnn , nnn , nnn , eh , what is the , the error eh , of the data grad b: supervised clustering . mm - hmm . phd c: this is the the eh , first idea postdoc e: mm - hmm . phd c: and the second is try to eh , to use some ideas eh , similar to the linear discriminant analysis . grad b: mm - hmm . phd c: eh ? eh , similar , because the the idea is to to study what is the contribution of eh , each parameter to the process of classify correctly the different the different parameters . grad b: mm - hmm . what sort of classifier ar ? phd c: eh , the the the classifier is nnn by the moment is eh is eh , similar , nnn , that the classifier used eh , in a quantifier vectorial quantifier is eh , used to to eh , some distance to to put eh , a vector eh , in in a class different . grad b: unimodal ? phd c: is yeah ? w with a model , is is only to cluster using a eh , @ @ or a similarity . postdoc e: mm - hmm . grad b: so is it just one cluster per phd c: a another possibility it to use eh a netw netw a neural network . grad b: right . phd c: but eh what 's the p what is my idea ? what 's the problem i i i i see in in in if you you use the the neural network ? if w when this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you you ca n't you ca n't eh , eh put up with your hand { comment } in the different parameter , grad b: right , you ca n't analyse it . phd c: but eh if you use a neural net is is a good idea , but eh you do n't know what happened in the interior of the neural net . professor d: well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . phd c: yeah . professor d: it 's hard to w w what you it 's hard to tell on a neural net is what 's going on internally . phd c: yeah . professor d: but it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . phd c: yeah . yeah . professor d: um , but grad b: well , using something simpler first i think is probably fine . professor d: well , this is n't tru if if if you really wonder what different if if phd c: yeah . grad b: decision tree . phd c: but professor d: yeah , then a decision tree is really good , but the thing is here he 's he 's not he 's not like he has one you know , a bunch of very distinct variables , like pitch and this he 's talking about , like , a all these cepstral coefficients , and so forth , grad b: right . phd c: yeah . yeah . grad b: right . phd c: yeah . professor d: in which case a a any reasonable classifier is gon na be a mess , and it 's gon na be hard to figure out what what uh phd c: and grad b: right . phd c: i i i will include too the the the differential de derivates too . grad b: deltas , professor d: yeah . grad b: yeah . so . professor d: i i mean , i think the other thing that one i mean , this is , i think a good thing to do , to sort of look at these things at least see what i 'd i 'd let me tell you what i would do . i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . phd c: yeah . professor d: ok ? like like c - one , c - two , something like that , so that you can visualize it . phd c: yeah . professor d: and look at these different examples and look at scatter plots . phd c: yeah . professor d: ok , so before you do build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . phd c: yeah . professor d: that i think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . phd c: yeah . professor d: and the second thing is , once you actually get to the point of building these classifiers , @ @ what this lacks so far is the temporal properties . so if you 're just looking at a frame and a time , you do n't know anything about , you know , the structure of it over time , and so you may wan na build @ @ build a markov model of some sort uh , or or else have features that really are based on um on on some bigger chunk of time . phd c: yeah . grad b: context window ? phd c: yeah . yeah . professor d: but i think this is a good place to start . but do n't uh anyway , this is my suggestion , is do n't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even even if it 's k - nearest - neighbors , you still wo n't know phd c: yeah . yeah , yeah . professor d: what it 's doing , even you know it 's uh , i think to know what it 's to have a better feeling for what it 's grad b: yep . professor d: look at at som some picture that shows you , `` here 's these things uh , uh are offer some separation . `` and , uh , in lpc , uh , the thing to particularly look at is , i think is something like , uh , the residual phd c: yeah . professor d: um so . phd c: yeah . s postdoc e: can i ask ? it strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . so , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gon na be a b a big informative area there , it seems to me . phd c: yeah , because yeah yeah . yeah . yeah . i yeah . but eh i i is my my my own vision , of the of the project . grad b: so , some sort of that 's postdoc e: mm - hmm . phd c: i eh the the meeting recorder project , for me , has eh , two eh , w has eh several parts , several p objective professor d: mm - hmm . phd c: eh , because it 's a a great project . but eh , at the first , in the acoustic , eh , eh , parts of the project , eh i think you eh we have eh two main eh objective . one one of these is to eh to detect the change , the acoustic change . and for that , if you do n't use , eh , eh , a speech recognizer , eh broad class , or not broad class to to try to to to label the different frames , i think the ike criterion or bic criterion eh will be enough to detect the change . postdoc e: ok . phd c: and probably . { comment } i i i i would like to to t prove . uh , probably . when you you have , eh , eh s eh the transition of speech or or silence eh to overlap zone , this criterion is enough with probably with , eh , this kind of , eh , eh the the the more eh use eh use eh used eh em normal , regular eh parameter mf - mfcc . you you have to to to find you can find the the mark . you can find the nnn , the the acoustic change . but eh eh i i understand that you your objective is to eh classify , to know that eh that zone not is only { comment } a new zone in the in the file , that eh you have eh , but you have to to to know that this is overlap zone . because in the future you will eh try to to process that zone with a non - regular eh eh speech recognizer model , i suppose . professor d: mm - hmm . phd c: you you will pretend { comment } to to to process the overlapping z eh zone with another kind of algorithm professor d: mm - hmm . phd c: because it 's very difficult to to to obtain the transcription from eh using eh eh a regular , normal speech recognizer . that , you know , i i i think is the idea . and so eh the , nnn the the system eh will have two models . postdoc e: clustering . phd c: a model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh the mark , the change and another another model will @ @ or several models , to try s but eh several model eh robust models , sample models to try to classify the difference class . postdoc e: ok . grad b: i 'm i 'm i 'm sorry , i did n't understand you what you said . what what model ? postdoc e:  phd c: eh , the the classifiers of the of the n to detect the different class to the different zones before try to to recognize , eh with eh to transcribe , with eh a speech recognizer . grad b: mm - hmm . phd c: and my idea is to use eh , for example , a neural net postdoc e: so p phd c: with the information we obtain from this eh this eh study of the parameter with the selected parameter to try to eh to put the class of each frame . eh for the difference zone grad b: features . yeah . phd c: you you eh , eh have obtained in the first eh , step with the for example , bic eh , eh criterion compare model postdoc e: mm - hmm . phd c: and you i do n't - u professor d: ok , but , i i think in any event we 're agreed that the first step is phd c: i postdoc e: yeah . professor d: because what we had before for for uh , speaker change detection did not include these overlaps . phd c: yeah . professor d: so the first thing is for you to to build up something that will detect the overlaps . phd c: yeah . professor d: right ? so again , i think the first thing to do to detect the overlaps is to look at these uh , in in in in grad b: features ? phd c: yeah . professor d: well , i again , the things you 've written up there i think are way too way too big . phd c: yeah . professor d: ok ? if you 're talking about , say , twelfth twelfth - order uh mfcc 's or something like that it 's just way too much . phd c: yeah . professor d: you wo n't be able to look at it . all you 'll be able to do is put it into a classifier and see how well it does . phd c: yeah . professor d: whereas i think if you have things if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the the different classes separate themselves out , you 'll have much more insight about what 's going on . phd c: it will be enough . professor d: well , you 'll you 'll get a feeling for what 's happening , you know , phd c: yeah . professor d: so if you look at suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , and then you look at the third and there 's not and not too much there , you may just take first and second - order cepstral coefficients , phd c: yeah . yeah . professor d: right ? and with lpc , i think lpc per se is n't gon na tell you much more than than than the other , maybe . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , will say how well , uh the low - order lpc model 's fitting it , which should be pretty poorly for two two or more people speaking at the same time , and it should be pretty well , for w for for one . phd c: yeah . yeah . yeah . professor d: and so i i again , if you take a few of these things that are are prob um { comment } promising features and look at them in pairs , uh , i think you 'll have much more of a sense of `` ok , i now have uh , doing a bunch of these analyses , i now have ten likely candidates . `` and then you can do decision trees or whatever to see how they combine . phd c: yeah . yeah . phd a: i 've got a question . phd c: yeah . this postdoc e: interesting . phd c: sorry . postdoc e: hmm . phd c: but eh , eh eh eh eh i do n't know it is the first eh way to to do that and i would eh like to to know what eh , your opinion . eh all this study in the f in the first moment , i i w i i will pretend to do { comment } with eh eh equalizes speech . the the equalizes speech , the speech eh , the mixes of speech . grad b: with postdoc e: with what ? with what ? grad b: right . mixed . phd c: the the mix , mixed speech . postdoc e: `` mixed `` . thank you . phd c: eh , why ? because eh the spectral distortion is { comment } more eh a lot eh clearer , very much clearer if we compare with the pda . grad b: right . phd c: pda speech file is eh it will be eh difficult . i postdoc e: so it 's messier . phd c: yeah , postdoc e: the the pda is messier . phd c: fff ! { comment } because the n the noise eh to sp the signal - to - noise relation is eh is is low . professor d: ok . grad b: yeah , i think that that 's a good way to start . phd c: and , i do n't know grad b: but . phd c: i do n't know eh uh i i that eh the the result of the of the study eh with eh with eh this eh this speech , the mix speech eh will work exactly with the eh pda files . grad b: it would be interesting in itself to see . well , i think that would be an interesting result . phd c: eh what , i i mean , what what is the effect of the low ' signal to to to noise relation , you know , eh with professor d: n u we well , i think i think i think it 's not a it 's not at all unreasonable . it makes sense to start with the simpler signal because if you have features which do n't are n't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . phd c: yeah . professor d: and so , if you can get @ @ { comment } uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features look at them , look at how these different classes that you 've marked , separate themselves , { comment } and then collect , uh in pairs , and then collect ten of them or something , and then proceed with a bigger classifier . phd c: yeah . yeah . professor d: and then if you can get that to work well , then you go to the other signal . and then , and you and you know , they wo n't work as well , but how m you know , how much grad b: right . phd c: yeah . yeah . yeah . professor d: and then you can re - optimize , and so on . grad b: yeah . but it i think it would be interesting to try a couple with both . because it i think it would be interesting to see if some features work well with close mixed , and and do n't professor d: hmm . phd c: ah , yeah , yeah yeah yeah . professor d: that 's well , the it it 's it 's true that it also , it could be useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . sure . phd c: but grad b: mm - hmm . phd c: i i i i think that the the eh parameter we found , eh , eh worked with both eh , speech file , postdoc e: that 's good . phd c: but eh what is the the the relation of eh of the performance when eh you use eh the , eh eh speech file the pda speech files . professor d: hmm . phd c: yeah , i do n't know . professor d: right . phd c: but it i i i i think it will be important . because eh people eh eh , different groups eh has eh experience with this eh kind of problem . is eh is not easy eh to to solve , because if you i i i have seen the the the speech file from eh pda , and s some parts is { comment } very difficult because you you do n't see the spectrum the spectrogram . grad b: right . yeah , they 're totally hidden . phd c: is very difficult to apply eh , eh a parameter to detect change when you do n't see . professor d: yeah . yeah . well , that that that 's another reason why very simple features , things like energy , and things things like harmonicity , and residual energy are uh , yeah are are better to use than very complex ones because they 'll be more reliable . phd c: but i suppose grad b: are probably better , yep . phd c: yeah , yeah yeah , i i i will put eh the energy here . yeah . yeah . yeah . professor d: ch - chuck was gon na ask something i guess . phd c: you have a question . phd a: yeah , i maybe this is a dumb question , but w i thought it would be i thought it would be easier if you used a pda professor d: nah . phd a: because ca n't you , could n't you like use beam - forming or something to detect speaker overlaps ? i mean grad b: well , if you used the array , rather than the signal from just one . phd a: uh - huh . professor d: yeah , no , you you 're you 're right grad b: but that 's professor d: that in fact , if we made use of the fact that there are two microphones , you do have some location information . which we do n't have with the one and and so that 's phd a: is that not allowed with this project ? professor d: uh , well , no , i mean , we we do n't have any rules , r really . phd a: but i did n't mean i w given given the goal . professor d: i think i i think i think it 's it 's it 's a it 's an additional interesting question . phd a: i mean , is is that violation of the phd c: oh . no . yeah . professor d: i mean , i think you wan na know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . phd a: mm - hmm phd c: yeah . professor d: uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . phd c: yeah . professor d: but , we do n't n even know yet what the effect of detecting having the ability to detect overlaps is . you know , maybe it does n't matter too much . phd a: right . right . ok . phd c: yeah . yeah . professor d: so , this is all pretty early stages . phd a: i see . phd c: yeah . yeah , yeah , yeah . professor d: but no , you 're absolutely right . that 's a good thing to consider . phd a: ok . postdoc e: there there is a complication though , and that is if a person turns their back to the to the pda , then some of the positional information goes away ? phd c: yeah . professor d: well , it it it does , i it d it does , but the the the issue is that that phd a: no , it 's not it 's not that so much as postdoc e: and then , and if they 're on the access { comment } on the axis of it , that was the other thing i was thinking . grad b: mm - hmm . postdoc e: he you mentioned this last time , that that if if you 're straight down the midline , then then the r the left - right 's gon na be different , grad b: yeah , we hav need to put it on a little turntable , phd c: i i i i i th grad b: and phd a: well , it 's phd c: yeah . postdoc e: and and and in his case , i mean , he 's closer to it anyway . phd c: yeah . yeah . postdoc e: it seems to me that that it 's not a p uh , you know , it 's this the topograph the topology of it is is a little bit complicated . grad b: but it 's another source of information . phd c: i i yeah . phd a: i do n't i do n't know ho phd c: i i i think sorry . i i i think because the the the distance between the two microph eh , microphone , eh , in the pda is very near . but it 's uh from my opinion , it 's an interesting idea to to try to study the binaural eh problem eh , with information , because i i found difference between the the speech from from each micro eh , in the pda . phd a: i would guess grad b: yep . professor d: yeah , it 's timing difference . it - it 's not amplitude , postdoc e: oh yeah ! oh i agree ! and we use it ourselves . professor d: right ? s right . postdoc e: i mean , i know i n i know that 's a very important cue . grad b: yep . phd c: yeah . postdoc e: but i 'm just i 'm just saying that the way we 're seated around a table , is not the same with respect to each to each person with respect to the pda , phd c: no . no . no , no , no . postdoc e: so we 're gon na have a lot of differences with ref respect to the speaker . professor d: that 's that 's fine . phd a: but th i do n't think that matters , though . phd c: but professor d: that 's so so i @ @ { comment } i think the issue is , `` is there a clean signal coming from only one direction ? `` phd a: right . professor d: if it 's not coming from just one direction , if it if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , phd c: yeah . professor d: wherever they are . phd a: so it 's sort of like how how confused is it about where the beam is . professor d: is it a is it phd c: yeah . professor d: yeah , is there a narrow is there a narrow beam pattern or is it a a distributed beam pattern ? so if there 's a distributed beam pattern , then it looks more like it 's it 's uh , multiple people . phd c: yeah . professor d: wherever you are , even if he moves around . postdoc e: ok . yeah . ok , it just it just seemed to me that uh , that this is n't the ideal type of separation . i mean , i i think it 's i can see the value o professor d: oh , ideal would be to have the wall filled with them , but i mean but the thing is just having two mikes if you looked at that thing on on dan 's page , it was when when there were two people speaking , and it looked really really different . phd c: yeah . postdoc e: yeah , ok . phd c: yeah . yeah . grad b: yep . postdoc e: oh yeah yeah . ok . phd a: what looked different ? phd c: yeah . postdoc e: yeah . professor d: uh , well , basic he was looking at correlation . grad b: cross - co cross - correlation . phd c: correlation , yeah . professor d: just cross - correlation between two sides . phd a: did - sorry , b uh i 'm not sure what dan 's page is that you mean . he was looking at the two professor d: so cross - correlation is pretty sensitive . postdoc e: uh , his a web page . professor d: you take the signal from the two microphones and you cros and you cross - correlate them with different lags . grad b: subtract them . phd a: ok . postdoc e: mm - hmm . phd a: uh - huh . phd c: yeah . grad b: and you find they get peaks . professor d: ok . so when one person is speaking , then wherever they happen to be at the point when they 're speaking , then there 's a pretty big maximum right around that point in the l in in the lag . phd a: ok . ok . professor d: so if at whatever angle you are , at some lag corresponding to the time difference between the two there , you get this boost in the in in the cross - correlation value function . phd a: so so if there 's two grad b: and if there are multiple people talking , you 'll see two peaks . professor d: it 's spread out . phd c: yeah . postdoc e: well , let me ask you , if if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? phd c: yeah . professor d: yeah . the - the oh , i 'm sorry , postdoc e: no ? professor d: if they 're right next to one another ? phd a: if i was if i was here and morgan was there and we were both talking , it would n't work . professor d: i i postdoc e: next next one over n over { comment } on this side of the p pda . grad b: right . phd c: yeah . postdoc e: there we go . good example , the same one i 'm asking . phd c: yeah . professor d: yeah , e i see . phd a: yes . phd c: yeah . postdoc e: versus you versus you know , and we 're catty - corner across the table , and i 'm farther away from this one and you 're farther away from that one . grad b: or or even if , like , if people were sitting right across from each other , you could n't tell the difference either . phd c: yeah . yeah . yeah . professor d: yeah . oh , yeah . postdoc e: it seems like that would be pretty strong . phd c: yeah . postdoc e: across the same axis , you do n't have as much to differentiate . phd c: yeah . professor d: well , we d yeah , we do n't have a third dimension there . yeah , so it 's postdoc e: and so my point was just that it 's it 's gon na be differentially differentially varia valuable . grad b: right . postdoc e: i mean , it 's not to say i mean , i certainly think it 's extremely val { comment } and we we humans n n depend on you know , these these binaural cues . phd c: yeah , yeah . professor d: but it 's almost but it 's almost a i think what you 're talking about i there 's two things . postdoc e: but . grad b: must do . { comment } yeah . professor d: there 's a sensitivity issue , and then there 's a pathological error uh issue . so th the one where someone is just right directly in line is sort of a pathological error . postdoc e: yes . yeah . phd c: yeah . professor d: if someone just happens to be sitting right there then we wo n't get good information from it . postdoc e: ok . and i and if there so it and if it 's the two of you guys on the same side professor d: uh , if they 're if they 're close , it 's just a question of the sensitivity . grad b: yep . professor d: so if the sensitivity is good enough and we just we just do n't have enough , uh , experience with it to know how postdoc e: yeah . ok . yeah yeah , ok . yeah . grad b: but phd c: yeah . postdoc e: oh i 'm not i 'm not trying to argue against using it , by any means . i just wanted to point out that that weakness , that it 's topo topologically impossible to get it perfect for everybody . professor d: yeah . mm - hmm . grad b: and i think dan is still working on it . so . he actually he wrote me about it a little bit , so . postdoc e: great . no , i do n't mean to discourage that at all . professor d: i mean , the other thing you can do uh , if i mean , i we 're assuming that it would be a big deal just to get somebody convince somebody to put two microphones in the pda . but if you h put a third in , you could put in the other axis . and then you know then you 're sort of yeah , then then you pretty much could cover phd a: once you got two postdoc e: interesting . phd c: yeah . phd a: well what about just doing it from these mikes ? postdoc e: interesting . phd a: you know ? phd c: yeah . grad b: yep . phd c: it will be more interesting to study the pzm because the the the separation i i think professor d: uh @ @ { comment } but - but that 's i mean , we can we 'll be all of this is there for us to study . grad b: then they 're much broader . yeah , we can do whatever we want . phd c: yeah . professor d: but but but the thing is , uh , one of the at least one of the things i was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a pda . grad b: whatever you 're interested in . phd c: yeah . phd a: that 's what i was asking about , what are the constraints ? phd c: yeah . yeah . yeah . professor d: right . yeah . phd c: yeah . professor d: well , that 's that 's the constraint of one question that i think both adam and i were were were interested in . grad b: well phd a: mm - hmm . grad b: yep . phd a: mm - hmm . phd c: yeah . professor d: uh , but you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? some people at at uh , yeah , at brown and and and and at uh um and at cape , grad b: big micro @ @ arrays . phd c: yeah . phd a: did n't they have something at cape ? professor d: they both have these , you know , big arrays on the wall . and you know , if you could do that , you 've got microphones all over the place grad b: very finely . professor d: uh , you know p tens of microphones , and and uh phd a: oh ! i saw a demo . phd c: oh , right , oh , yeah . professor d: and if you do that then you can really get very nice uh kind of selectivity phd a: yeah . grad b: oh , i saw one that was like a hundred microphones , a ten by ten array . professor d: yeah . yeah . phd a: and you could in a noisy room , they could have all kinds of noises and you can zoom right in on somebody . phd c: hundred . grad b: and they had very precision . phd c: yeah . yeah . grad b: right . phd c: very complex , uh yeah . professor d: ye - pretty much . yeah . grad b: it was all in software and they and you could pick out an individual beam and listen to it . phd a: that is cool . professor d: yeah . grad b: it was yeah , it was interesting . phd c: yeah . professor d: but , the reason why i have n't focused on that as the fir my first concern is because um , i 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . and you ca n't just always go , `` well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up `` . phd c: yeah . phd a: no , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . phd c: yeah . phd a: it has all these mikes and it has a plug - in jack to the pda . postdoc e: interesting . grad b: but i think professor d: the other thing actually , that gets at this a little bit of something else i 'd like to do , is what happens if you have two p d grad b: yep . phd c: yeah . professor d: and they communicate with each other ? and then you know , they 're in random positions , the likelihood that i mean , basically there would n't be any l likely to be any kind of nulls , if you even had two . if you had three or four it 's yeah . phd a: ooo ! grad b: that 's on my web pages . phd a: network ! grad b: yeah . postdoc e: interesting . grad b: though all sorts of interesting things you can do with that , postdoc e: interesting . grad b: i mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . postdoc e: hmm . phd c: yeah . professor d: yeah . grad b: so it 's it would be neat . postdoc e: ah ! phd a: i still like my rug on the wall idea , so if anybody patents that , then grad b: but i think postdoc e: well , you could have strips that you stick to your clothing . grad b: in terms of phd a: yeah ! grad b: yeah . phd a: hats ? grad b: in terms of the research th research , it 's really it 's whatever the person who is doing the research wants to do . phd a: shirts . grad b: so if if jose is interested in that , that 's great . but if if he 's not , that 's great too . professor d: yeah . phd c: yeah , yeah . professor d: yeah . um , i i i i i would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . grad b: catch some tea ? um . professor d: so grad b: well , i had a couple things that i did wan na bring out . professor d: ok . grad b: one is , do we need to sign new these again ? postdoc e: well , it 's slightly different . so i i would say it would be a good idea . phd a: are they new ? postdoc e: cuz it it 's slightly different . grad b: yep . phd a: oh . professor d: oh , this morning we did n't sign anything cuz we said that if anybody had signed it already , we did n't have to . grad b: yeah , i i should 've checked with jane first , but the ch the form has changed . postdoc e: it 's slightly different . grad b: so we may wan na have everyone sign the new form . professor d: ah - oh . phd c: ok . grad b: um , i had some things i wanted to talk about with the thresholding stuff i 'm doing . postdoc e: i had to make one grad b: but , if we 're in a hurry , we can put that off . um and then also anonymity , how we want to anonymize the data . uh . postdoc e: well , should i i mean i have some results to present , but i mean i guess we wo n't have time to do that this time . but it seems like um the anonymization is uh , is also something that we might wan na discuss in greater length . professor d: um . i mean , wha what postdoc e: if if we 're about to wind down , i think what i would prefer is that we uh , delay the anonymization thing till next week , and i would like to present the results that i have on the overlaps . phd a: we still have to do this , too , right ? professor d: right . phd a: digits ? professor d: right . grad b: no - well , we do n't have to do digits . professor d: well , why do n't we uh , so @ @ ok . @ @ { comment } it sounds like u uh , there were there were a couple technical things people would like to talk about . why do n't we just take a couple minutes to to briefly { comment } do them , and then and then and then and then and then we grad b: ok , go ahead , jane . postdoc e: i 'd oh , i 'd prefer to have more time for my results . e could i do that next week maybe ? professor d: ok . oh , yeah . sure . postdoc e: ok , that 's what i 'm asking . professor d: oh yeah , yeah . postdoc e: and i think the anonymization , if y if you want to proceed with that now , i just think that that 's that 's a discussion which also n really deserves a lo a you know , more that just a minute . professor d: we could s grad b: mm - hmm . postdoc e: i really do think that , because you raised a couple of possibilities yourself , you and i have discussed it previously , and there are different ways that people approach it , e and i think we should grad b: alright . we 're we 're just we 're getting enough data now that i 'd sort of like to do it now , before i get overwhelmed with once we decide how to do it postdoc e: well , ok . grad b: going and dealing with it . postdoc e: it 's just yeah . ok . i i 'll give you the short version , but i do think it 's an issue that we ca n't resolve in five minutes . grad b: mm - hmm . postdoc e: ok , so the the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . those we wo n't be able to change . if someone says `` hey , roger so - and - so `` . grad b: right . postdoc e: so that 's gon na stay that person 's name . grad b: yep . postdoc e: now , in terms of like the transcript , the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? grad b: no , because then that would give you a mapping , and you do n't wan na have a mapping . postdoc e: ok , so first decision is , we 're gon na anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . phd a: i do n't grad b: no . because that would give you a mapping between the speaker 's real name and the tag we 're using , and we do n't want postdoc e: i i do n't think you understood what i what i said . grad b: ok . postdoc e: so uh , so in within the context of an utterance , someone says `` so , roger , what do you think ? `` ok . then , uh , it seems to me that well , maybe i uh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . phd a: right , you do n't wan na do that . grad b: we do n't we wan na we ha we want the transcript to be `` roger `` . phd a: yeah . grad b: because if we made the the transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . postdoc e: ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , then and , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 's who 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis . grad b: oh . ugh ! that 's a good point . postdoc e: now , if you want to , you know , i mean , in some cases , i i i know that susan ervin - tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except professor d: yeah yeah , once you get to the publication you can certainly do that . postdoc e: and and i cer and i so , i mean , the question then becomes one level back . um , how important is it for a person to be identified by first name versus full name ? well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to they 'll be reviewing the transcripts , to see if there 's something they do n't like { comment } ok . so , maybe , uh , maybe that 's enough protection . on the other hand , this is a small this is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from the from the first name . however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . grad b: right . phd c: mmm . postdoc e: so , is it really , um { comment } you know ? grad b: ugh ! postdoc e: now , in terms of like so i i did some results , which i 'll report on n next time , which do mention individual speakers by name . grad b: mm - hmm . postdoc e: now , there , the human subjects committee is very precise . you do n't wan na mention subjects by name in published reports . now , it would be very possible for me to take those data put them in a in a study , and just change everybody 's name for the purpose of the publication . and someone who looked professor d: you can go , you know , uh , `` z `` uh , for instance . postdoc e: yeah , exactly . does n't matter if professor d: uh . um , yeah , i mean , t it does n't i mean , i 'm not knowledgeable about this , but it certainly does n't bother me to have someone 's first name in in the in the transcript . postdoc e: that 's the same thing you saw . grad b: ok . professor d: uh , i think you do n't wan na have their full name to be uh , listed . postdoc e: yeah , and and in the form that they sign , it does say `` your first name may arise in the course of the meetings `` . grad b: yeah . professor d: and so phd a: well professor d: yeah . so again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , `` frank said this `` and then you wan na connect it to something later , you 've got ta have this part where that 's `` frank colon `` . postdoc e: or `` your name `` . grad b: yeah , shoot ! professor d: right ? postdoc e: yeah , and and you know , even more i i uh , immediate than that just being able to , uh well , it just seems like to track track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . grad b: mm - hmm . postdoc e: s i you know , `` you raised the point , so - and - so `` , it 's be kind of nice to be able to know who `` you `` was . grad b: shoot ! professor d: yeah . grad b: i i 'm thinking too much . postdoc e: and ac { comment } and actually you remember furthermore , you remember last time we had this discussion of how you know , i was sort of avoiding mentioning people 's names , professor d: yeah , i was too . yeah . postdoc e: and and it was and we made the decision that was kind of artificial . well , i mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . grad b: yep . well , i would sug i i do n't wan na change the names in the transcript , phd c: yeah . professor d: yeah . grad b: but that 's because i 'm focused so much on the acoustics instead of on the discourse , and so i think that 's a really good point . postdoc e: misleading . professor d: yeah . grad b: you 're right , this is going to require more thought . professor d: yeah . l let me just back up this to make a a brief comment about the , uh , what we 're covering in the meeting . uh i realize when you 're doing this that uh i mean , i did n't realize that you had a bunch of things that you wanted to talk about . uh , and so , uh and so i was proceeding some somewhat at random , frankly . so i think what would be helpful would be uh , i and i 'll i 'll mention this to to liz and andreas too , that um , before the meeting if anybody could send me , any any , uh , uh , agenda items that they were interested in and i 'll i 'll take the role of organizing them uh , into into the agenda , postdoc e: ok . sure . professor d: but i 'd be very pleased to have everyone else completely make up the agenda . i 've no desire to to make it up , but if if no one 's told me things , then i 'm just proceeding from my my guesses , and and uh , and i ye yeah , i i 'm sorry it ended up with your out your time to i mean , i 'm just always asking jose what he 's doing , you know , and and so it 's there 's uh , there 's obviously other things going on . grad b: mm - hmm . postdoc e: oh , it 's not a problem . not a problem . yeah . i just i just could n't do it in two minutes . grad b: how will we how would the person who 's doing the transcript even know who they 're talking about ? do you know what i 'm saying ? phd a: `` the person who 's doing the transcript `` { comment } the ibm people ? grad b: yeah . i mean , so so how is that information gon na get labeled anyway ? postdoc e: how do you mean , who what they 're who they 're talking about ? grad b: i mean , so if i 'm saying in a meeting , `` oh and bob , by the way , wanted wanted to do so - and - so `` , postdoc e: how do you mean ? phd a: they 're just gon na write `` bob `` on it or do @ @ grad b: if you 're doing yeah , @ @ they 're just gon na write `` bob `` . and so . if you 're if you 're doing discourse analysis , postdoc e: they wo n't be able to change it themselves . professor d: what ar how are they gon na do any of this ? grad b: yeah , really . postdoc e: well , i i 'm betting we 're gon na have huge chunks that are just totally un untranscribable by them . professor d: i mean , they 're gon na say speaker - one , or speaker - two or speaker i mean i i phd a: they ca n't do that . phd c: yeah , i think grad b: well , the current one they do n't do speaker identity . phd c:  grad b: because in naturallyspeaking , or , excuse me , in viavoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . professor d: so it may just be one long transcript of a bunch of words . grad b: yep . postdoc e: oh . i think that my understanding from yen is it yen - ching ? is that how you pronounce her name ? professor d: uh yu - ching , yu - ching . yeah . postdoc e: oh , uh yu - ching ? yu - ching ? grad b: y yu - ching . postdoc e: was that um , they will that they will adopt the part of the conventions that that we discussed , where they put speaker identifier down . but , you know , h they wo n't know these people , so i think it 's well , they 'll they 'll adopt some convention but we have n't specified to them so they 'll do something like speaker - one , speaker - two , is what i bet , but i 'm betting there 'll be huge variations in the accuracy of of their labeling the speakers . we 'll have to review the transcripts in any case . professor d: and it and it may very well be i mean , since they 're not going to sit there and and and worry ab about , uh , it being the same speaker , they may very well go the eh the the first se the first time it changes to another speaker , that 'll be speaker - two . postdoc e: yeah . professor d: and the next time it 'll be speaker - three even if it 's actually speaker - one . postdoc e: you know uh - huh . you know , that would be a very practical solution on their part . phd c: yeah . it 's a good idea . professor d: yeah . postdoc e: and and but then we would need to label it . grad b: yeah we we can probably regenerate it pretty easily from the close - talking mikes . phd c: yeah . yeah , i think postdoc e: and that 's ok . phd c:  postdoc e: yes , i was thinking , the temp the time values of when it changes . phd c: yeah . professor d: yeah . grad b: so . but i mean that does n't this does n't answer the the question . phd c: yeah . professor d: but that postdoc e: that 'd be very efficient . grad b: the p it 's a good point , `` which what do you do for discourse tracking ? `` phd c: because y y you do n't know to know , eh you do n't need to know what i what is the iden identification of the of the speakers . you only eh want to know grad b: hmm . for for acoustics you do n't but for discourse you do . professor d: well , you do . phd c: ah , for discourse , yeah . yeah . yeah . professor d: yeah . if if if if someone says , uh , `` what what is jose doing ? `` and then jose says something , you need to know that that was jose responding . phd c: yeah , yeah . yeah . yeah . yeah , yeah , yeah . yeah . yeah , grad b: ugh , { comment } that 's a problem . professor d: uh , so . postdoc e: mm - hmm . phd c: yeah . postdoc e: unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . phd a: that would be hard . postdoc e: well , people are very flexible . you know ? i mean , so when we did this las last week , i felt that you know , now , andreas may , uh , @ @ { comment } uh , he he i sometimes people think of something else at the same time and they miss a sentence or something , and and because he missed something , then he missed the r the initial introduction of who we were talking about , and was was unable to do the tracking . phd a: mm - hmm . postdoc e: but i felt like most of us were doing the tracking and knew who we were talking about and we just were n't mentioning the name . so , people are really flexible . phd c: yeah . phd a: but , you know , like , at the beginning of this meeting or , you i think said , you know , or s liz , said something about um , uh , `` is mari gon na use the equipment ? `` i mean , how would you say that ? postdoc e: yeah ? phd a: i mean , you have to really think , you know , about what you 're saying bef grad b: if you wanted to anonymize . phd c: yeah . yeah , is professor d: `` is you know who up in you know where ? `` phd a: yeah . yeah . grad b: mm - hmm . professor d: right ? use the phd a: i think it would be really hard if we made a policy where we did n't say names , plus we 'd have to tell everybody else . grad b: yeah , darn ! i mean , what i was gon na say is that the other option is that we could bleep out the names . postdoc e: well , it phd c: yeah . grad b: but then , again that kills your discourse analysis . phd a: right . postdoc e: uh - huh . phd a: yeah . grad b: ugh ! professor d: yeah . phd c: yeah . postdoc e: yeah . phd a: i i think the i think i do n't know , my own two cents worth is that you do n't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . postdoc e: that 's that 's the issue . grad b: well , but that but that as i said , that that that works great for the acoustics , but it it hurts you a lot for trying to do discourse . postdoc e: well . phd a: why ? postdoc e: mm - hmm . grad b: because you do n't have a map of who 's talking versus their name that they 're being referred to . phd c: yeah . professor d: yeah . th - bec phd c: yeah . phd a: i thought we were gon na get it labelled speaker - one , speaker - two grad b: sure but , h then you have to know that jose is speaker - one and phd a: why do you have to know his name ? professor d: ok , so suppose someone says , `` well i do n't know if i really heard what uh , what jose said . `` phd a: yeah . phd c: yeah . professor d: and then , jose responds . phd a: yeah . professor d: and part of your learning about the dialogue is jose responding to it . but it does n't say `` jose `` , it says `` speaker - five `` . phd a: ok . phd c: yeah . yeah . professor d: so uh u phd a: oh , i see , you wan na associated the word `` jose `` in the dialogue with the fact that then he responded . professor d: right . grad b: someone who 's doing discourse would wan na do that . professor d: and so , if we pass out the data to someone else , and it says `` speaker - five `` there , we also have to pass them this little guide that says that speaker - five is jose , grad b: and that violates our privacy . professor d: and if were gon na do that we might as well { comment } give them `` jose `` say it was `` jose `` . phd c: yeah . yeah . grad b: and that violates our privacy issue . phd c: yeah . postdoc e: mm - hmm . yeah . phd c: yeah . postdoc e: now , i i think that we have these two phases in the in the data , which is the one which is o our use , university of washington 's use , ibm , sri . professor d: yeah . postdoc e: and within that , it may be that it 's sufficient to not uh change the to not incorporate anonymization yet , but always , always in the publications we have to . grad b: mm - hmm . postdoc e: and i think also , when we take it that next step and distribute it to the world , we have to . but i but i don that 's that 's a long way from now and and it 's a matter of between now and then of d of deciding how grad b: making some decisions ? postdoc e: i i it you know , it may be s that we we 'll need to do something like actually x out that part of the um the audio , and just put in brackets `` speaker - one `` . grad b: yeah . for the public one . phd c: the ? ? grad b: you know , what we could do also is have more than one version of release . phd c: yeah . postdoc e: you know . grad b: one that 's public and one one that requires licensing . and so the licensed one would w we could it would be a sticky limitation . postdoc e: uh - huh . grad b: you know , like well , we can talk about that later . postdoc e: i think that 's risky . i think that the public should be the same . i think that when we do that world release , it should be the same . professor d: i i agree . i i agree with jane . postdoc e: for a bunch of reasons , legal . professor d: i i think that we we have a need to have a consistent licensing policy of some sort , and postdoc e: but i also think a consistent licensing policy is important . phd a: well , one thing to to take into consideration is w are there any um for example , the people who are funding this work , they want this work to get out and be useful for discourse . phd c: yeah . phd a: if we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know grad b: well , depending on how much editing we do , you might be able to still have it useful . because for discourse you do n't need the audio . right ? so you could bleep out the names in the audio . phd a: mm - hmm . grad b: and use the anonymized one through the transcript . phd a: but if you release both professor d: uh . postdoc e: excuse me . we we do need audio for discourse . grad b: but , n excuse me , but you could bleep out just the names . professor d: she no , but she 's saying , from the argument before , she wants to be able to say if someone said `` jose `` in their in their thing , and then connect to so to what he said later , then you need it . grad b: right . but in the transcript , you could say , everywhere they said `` jose `` that you could replace it with `` speaker - seven `` . professor d: oh i see . i see . postdoc e: yeah . but i i also wan na say that people grad b: and then it would n't meet match the audio anymore . but it would be still useful for the postdoc e: uh - huh . phd a: but if both of those are publically available postdoc e: yeah . that 's good . grad b: but they right . professor d: and th and the other thing is if if if liz were here , what she might say is that she wants to look if things that cut across between the audio and the dialogue , postdoc e: well , you see ? so , it 's complicated . professor d: and so , uh , postdoc e: mm - hmm . yeah . professor d: yeah . sorry . postdoc e: i think we have to think about w @ @ { comment } how . i think that this ca n't be decided today . grad b: yeah , ok , good point . postdoc e: but it 's g but i think it was good to introduce the thing and we can do it next time . professor d: yeah . grad b: i did n't think when i wrote you that email i was n't thinking it was a big can of worms , but i guess it is . phd c: ok . professor d: ok . yeah , a lot of these things are . grad b: discourse . postdoc e: well it discourse , you know also i wanted to make the point that that discourse is gon na be more than just looking at a transcript . grad b: yeah , ab absolutely . oh , yeah , sure . postdoc e: it 's gon na be looking at a t you know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this confronting this problem . phd a: maybe we should just not allow anybody to do research on discourse , postdoc e: so . phd a: and then , we would n't have to worry about it . phd c: ok . postdoc e: yeah , we should just market it to non - english speaking countries . phd c: ok . professor d: uh , maybe we should only have meetings between people who do n't know one another and who are also amnesiacs who do n't know their own name . grad b: did you read the paper on eurospeech ? postdoc e: we could have little labels . i i i wan na introduce my reservoir dogs solution again , which is everyone has like `` mister white `` , `` mister pink `` , `` mister blue `` . phd a: mister white . grad b: yeah . did you read the paper a few years ago where they were reversing the syllables ? they were di they they had the utterances . and they would extract out the syllables and they would play them backwards . phd a: but so , the syllables were in the same order , with respect to each other , but the acous grad b: everything was in the same order , but they were the individual syll { comment } syllables were played backwards . and you could listen to it , and it would sound the same . phd a: what did it sound like ? grad b: people had no difficulty in interpreting it . so what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people ca n't understand it . professor d: oh , well that 's there 's an easy way to do that . jus - jus just play it all backwards . grad b: oh right . the speech recognizer 's totally symmetric , is n't it . professor d: what , what does the speech recognizer care ? grad b: ah , anyway . professor d: um , postdoc e: oh , do we do digits ? or ? what do we do ? grad b: uh ok , we 'll quickly do digits . professor d: let 's do digits . yeah , we we we already missed the party . postdoc e: or do we just quit ? grad b: ok . professor d: so . postdoc e: yeah . grad b: ok , go off here . phd a: i think it would be fun sometime to read them with different intonations . like as if you were talking like , `` nine eight six eight seven ? `` postdoc e: well , you know , in the in the one i transcribed , i did find a couple instances i found one instance of contrastive stress , where it was like the string had a li so it was like `` nine eight two four , nine nine two four `` . phd a: oh , really . so they were like looking ahead , postdoc e: and phd a: huh ? postdoc e: well , they differed . i mean , at that that session i did feel like they did it more as sentences . but , um , sometimes people do it as phone numbers . { comment } i mean , i 've i am sort of interested in in and sometimes , you know , i s and i i never know . when i do it , i i ask myself what i 'm doing each time . phd a: yeah , yeah . grad b: yep . phd a: well , i was thinking that it must get kind of boring for the people who are gon na have to transcribe this postdoc e: and i phd a: they may as well throw in some interesting intonations . grad b: well , except , postdoc e: i like your question intonation . grad b: yeah . postdoc e: that 's very funny . i have n't heard that one . grad b: we have the transcript . we have the actual numbers they 're reading , so we 're not necessarily depending on that . ok , i 'm gon na go off .","output":"professor d said they would be getting another disk rack that would bring in four thirty-six gigabyte disks , increasing the space . additionally , the directories of aurora data , carmen \u2019 s data and spine were likely to be moved ."},{"instruction":"summarize the meeting","input":"grad a: ah , so comfortable . grad f: smooth . grad a: mm - hmm . good . i know that he 's going to like , taiwan and other places to eat . so . grad d: on ? am i on ? grad a: yep . yep . grad d: i think i 'm on ? grad b: yeah . grad d: good . good . grad a: bye . grad b: actually grad f: i just had one of the most frustrating meetings of my career . grad a: it 's definitely not the most frustrating meeting i 've ever had . grad d: you a you 're you remember you 're being recorded at this point . grad a: oh , yeah , so , w we did n't yet specify with whom . professor e: yeah . grad f: yeah . professor e: right . grad a: but um . professor e: uh , right . grad a: so that 's why keith and i are going to be a little dazed for the first half m the meeting . professor e: uh . grad f: huh . yeah , i 'm just gon na sit here and professor e: right . yeah , i i i avoided that as long as i could for you guys , grad f: growl . professor e: but , uh grad f: yeah . grad a: mm - hmm . grad f: for which we thank you , by the way . grad a: are very appreciative , yeah . professor e: right . grad f: i know you were you were doing that , but , anyway . grad d: oh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ? grad f: oh , i could tell you had a rough day , man ! grad d: nah . grad a: what ? grad d: i love that story . grad f: yeah , it 's a great story . grad c: ok . grad f: oh my goodness . grad c: oh yeah , um , liz suggested we could start off by uh , doing the digits all at the same time . grad a: what ? grad d: all at the same time . i do n't know if i would get distracted and confused , probably . professor e: e grad a: really ? do we have to like , synchronize ? professor e: well , i think you 're supposed to ok . we can do this . grad f: are you being silly ? grad d: oh wait do we have t professor e: everybody 's got different digits , grad c: yep . professor e: right ? grad d: yeah , do we have to time them at the same time or just overlapping grad f: uh . grad a: you 're kidding . grad c: no , no , just just start whenever you want . professor e: no . grad a: and any rate ? professor e: e yeah , the grad f: alright . professor e: well , they they have s they have the close talking microphones for each of us , grad a: yeah , that 's true . professor e: so grad c: yeah . professor e: yeah , there 's separate channels . grad f: alright . grad a: ok . grad c: yeah . professor e: so when i say grad f: just plug one ear . grad a: you lose . professor e: ok . grad f: ok , bye ! that was a great meeting ! professor e: right . grad d: alright . grad f: so - now , uh , why ? grad c: just to save time . grad f: ok . grad c: does matter for them . grad a: are we gon na start all our meetings out that way from now on ? professor e: no . grad a: oh . too bad . i kinda like it . grad f: well , could we ? grad d: it 's strangely satisfying . grad a: yeah . it 's a ritual . grad d: are we to r just to make sure i know what 's going on , we 're talking about robert 's thesis proposal today ? is that grad c: we could . grad d: true ? grad a: we are ? grad c: we might . grad a: ok . grad d: is professor e: well , you you had s you said there were two things that you might wan na do . one was rehearse your i i talk grad d: oh yes , and that too . grad c: not not rehearse , i mean , i have just not spent any time on it , so i can show you what i 've got , get your input on it , and maybe some suggestions , that would be great . and the same is true for the proposal . i will have time to do some revision and some additional stuff on various airplanes and trains . so , um . i do n't know how much of a chance you had to actually read it grad a: i have n't looked at it grad c: because grad a: yet , grad c: but you could always send me comments per electronic mail grad a: but i will . grad c: and they will be incorporated . grad a: ok . grad c: um , the it basically says , well `` this is construal `` , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model to do some inferences in terms of what is being construed as what grad a: hmm . grad c: in our beloved tourism domain . but , with a focus on grad a: can i s sorry . grad f: i think i need a copy of this , yes . grad c: hmm ? grad d: ok , we can we can we can pass pass my , uh we can pass my extra copy around . grad f: i is there an extra copy around ? grad a: uh . he sent it . ok . you can keep it . grad d: er , actually , my only copy , now that i think about it , grad f: alrigh grad a: ok . grad c: um , i do n't i , uh i do n't need it . grad d: but . i already read half of it , so it 's ok . grad c: um , actually this is the the newest version after your comments , grad f: ok . grad c: and professor e: yeah , no i s i s i see this has got the castle in it , and stuff like that . grad c: yeah . professor e: yep . grad d: oh , maybe the version i did n't have that i mine the w did the one you sent on the email have the professor e: yeah . grad d: that was the most recent one ? professor e: uh , yeah , i think so . grad c: yep . grad d: ok . cuz i read halfway but i did n't see a castle thing . grad a: i 'm changing this . just so you know . grad c: yeah , grad a: but , anyway . grad c: um , if you would have checked your email you may have received a note from yees asking you to send me the , uh , up - to - d grad a: oh . oh , sorry . ok . sorry . grad c: current formalism thing that you presented . grad a: ok . i will . ok . ok . ok . grad c: but for this it does n't matter . but , uh grad a: we can talk about it later . that 's not even ready , so . um , ok ! go on t to , uh , whatever . grad c: and grad a: i 'm making changes . `` do n't worry about that . `` ok . mmm - mmm . oh ! ok , sorry , go on . grad c: and any type of comment whether it 's a spelling or a syntax or grad a: mm - hmm . grad c: readability grad f: there 's only one `` s `` in `` interesting `` . grad c: hmm ? grad f: there 's only one `` s `` in `` interesting `` . on page five . grad c: interesting . grad a: anyway . and y uh , email any time , but most usefully before grad d: the twenty - first i 'm assuming . grad a: the twenty - first ? grad c: twenty - ninth . professor e: no , this is the twenty - first . grad f: that 's grad d: what , today 's the twenty - first ? grad f: well , better hurry up then ! grad d: oh , man ! grad a: before the twenty - ninth , grad c: the twenty - ninth . grad a: ok . grad d: ok . grad c: that 's when i 'm meeting with wolfgang wahlster to sell him this idea . grad a: mm - hmm . ok . grad c: ok ? then i 'm also going to present a little talk at eml , about what we have done here and so of course , i 'm i 'm gon na start out with this slide , so the most relevant aspects of our stay here , and um , then i 'm asking them to imagine that they 're standing somewhere in heidelberg and someone asks them in the morning the cave forty - five is a is a well - known discotheque which is certainly not open at that that time . and so grad f: ok . grad c: they 're supposed to imagine that , you know , do they think the person wants to go there , or just know where it is ? uh , which is probably not , uh , the case in that discotheque example , or in the bavaria example , you just want to know where it is . and so forth . so basically we can make a point that here is ontological knowledge but if it 's nine nine pm in the evening then the discotheque question would be , for example , one that might ask for directions instead of just location . um , and so forth and so forth . that 's sort of motivating it . then what have we done so far ? we had our little bit of , um , um , smartkom stuff , that we did , um , everth grad f: oh , you 've got the parser done . sorry . grad c: that 's the not the construction parser . that 's the , uh , tablet - based parser , grad f: ok . grad a: easy parser . grad f: ok . grad c: and the generation outputter . grad d: halfway done ? yeah . grad c: that 's done . grad a: mmm . grad c: you have to change those strategies , grad d: ok . grad c: right ? that 's , ten words ? grad d: yeah . well , i it , you know . maybe twelve . grad c: twelve ? ok . and , um , and fey is doing the synthesis stuff as we speak . that 's all about that . then i 'm going to talk about the data , you know these things about uh , actually i have an example , probably . two s can you hear that ? or should i turn the l volume on . grad f: mm - hmm . grad a: i could hear it . grad d: i i can hear it . grad f: i heard it . grad d: they might not hear it in the well maybe they will . i do n't know . grad a: this was an actual , um , subject ? ah . grad c: mm - hmm . grad f: sounds like fey . grad a: yeah . grad c: but they 're they 're mimicking the synthesis when they speak to the computer , grad f: oh , ok . grad c: the you can observe that all the time , they 're trying to match their prosody onto the machine . grad f: oh really . interesting . oh , it 's pretty slow . grad c: yeah , you have to grad a: wh grad f: the system breaking . grad a: what is the s ? oh ! grad c: ok . and so forth and so forth . um , i will talk about our problems with the rephrasing , and how we solved it , and some preliminary observations , also , um , i 'm not gon na put in the figures from liz , but i thought it would interesting to , uh , um , point out that it 's basically the same . um , as in every human - human telephone conversation , and the human - computer telephone conversation is of course quite d quite different from , uh , some first , uh , observations . then sort of feed you back to our original problem cuz , uh how to get there , what actually is happening there today , and then maybe talk about the big picture here , e tell a little bit as much as i can about the ntl story . i i wa i do wan na , um i 'm not quite sure about this , whether i should put this in , um , that , you know , you have these two sort of different ideas that are or two different camps of people envisioning how language understanding works , and then , talk a bit about the embodied and simulation approach favored here and as a prelude , i 'll talk about monkeys in italy . and , um , srini was gon na send me some slides but he did n't do it , so from but i have the paper , i can make a resume of that , and then i stole an x - schema from one of your talks i think . grad a: oh . i was like , `` where 'd you get that ? `` ok . grad f: yeah , that looks familiar . grad a: `` looks familiar . `` grad c: i think that 's bergen , chang , something , or the other . grad a: uh . professor e: whatever . grad a: ok . grad c: um , and that 's now i 'm not going to bring that . so that 's basically what i have , so far , and the rest is for airplanes . so x - schemas , then , i would like to do talk about the construction aspect and then at the end about our bayes - net . grad a: mm - hmm . grad c: end of story . anything i forgot that we should mention ? oh , maybe the fmri stuff . should i mention the fact that , um , we 're also actually started going to start to look at people 's brains in a more direct way ? professor e: you certainly can . i mean i y i you know , i do n't know grad a: you might just wan na like , tack that on , as a comment , to something . professor e: right , um . grad c: `` future activities `` something . professor e: well , the time to mention it , if you mention it , is when you talk about mirror neurons , then you should talk about the more recent stuff , about the kicking grad c: yeah . professor e: and , you know , the yeah , yeah and that the plan is to see to what extent the you 'll get the same phenomena with stories about this , so that grad c: mm - hmm . professor e: and that we 're planning to do this , um , which , we are . so that 's one thing . um . depends . i mean , there is a , um , whole language learning story , ok ? grad c: yeah . professor e: which , uh , actually , i i even on your five - layer slide , you you 've got an old one that that leaves that off . grad c: yeah , i i i do have it here . grad a: hmm . professor e: yeah . grad c: um . and , of course , you know , the the big picture is this bit . professor e: right . grad c: but , you know , it would but i do n't think i i am capable of of do pulling this off and doing justice to the matter . i mean , there is interesting stuff in her terms of how language works , so the emergentism story would be nice to be you know , it would be nice to tell people how what 's happening there , plus how the , uh , language learning stuff works , professor e: ok , so , so anyway , i i agree that 's not central . grad c: but grad a: mm - hmm . professor e: what you might wan na do is , um , and may not , but you might wan na this is rip off a bunch of the slides on the anal there the there we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , and , um , how the construction and simulation that ho that whole th grad c: yeah , th that that 's c that comes up to the x - schema slide , grad a: ok , right . grad c: so basically i 'm gon na steal that from nancy , grad a: ok , i can give you a more recent if you want grad c: one of nancy 's st grad a: well , that might have enough . grad c: uh , i yeah , but i also have stuff you trash you left over , professor e: ok . grad c: your quals and your triple - ai . professor e: the quals w the the the quals slides would be fine . grad a: yeah . professor e: you could get it out of there , or some grad a: which i can even email you then , you know , like there probably was a little few changes , not a big deal . yeah , you could steal anything you want , i do n't care . which you 've already done , obviously . so . sorry grad c: well , i i do n't feel bad about it at all grad a: no , you should n't . grad c: because because you are on the , uh , title . grad a: oh , that 's great , that 's great . grad c: i mean on the the , you 're that 's see , that 's you . grad a: i 'm glad to see propagation . professor e: yeah . yeah . grad a: mmm . grad c: hmm ? propagated ? grad a: yes . grad c: i mean i might even mention that this work you 're doing is sort of also with the mpi in leipzig , so . grad a: it 's it 's certainly related , um , grad c: because , um , eml is building up a huge thing in leipzig . grad a: might wan na say . is it ? grad c: so it it 's on biocomputation . would professor e: yeah , it 's different , this is the , uh , dna building , or someth the double helix building . grad c: yeah . professor e: yeah . grad a: kind of a different level of analysis . professor e: the yeah it was it turns out that if if you have multiple billions of dollars , y you can do all sorts of weird things , and grad d: wait , they 're building a building in the shape of dna , grad a: what ? grad d: is that what you said ? professor e: roughly , yeah . grad f: oh ! oh boy ! grad a: o professor e: including cr cross - bridges , grad a: what ? professor e: and grad a: oh my god ! grad f: that 's brilliant ! hhh . professor e: you d you really now i i spent the last time i was there i spent maybe two hours hearing this story which is , um grad a: of what grad d: y you definitely wan na w do n't wan na waste that money on research , grad a: the building ? grad d: you know ? professor e: right . grad d: that 's horrible . professor e: right . well , no , no , y i there 's infinite money . see you th you th you then fill it with researchers . grad a: and give them more money . they just want a fun place for them to to work . professor e: right . right . grad f: and everybody gets a trampoline in their office . grad c: well , the the offices are actually a little the , think of um , ramps , coming out of the double helix and then you have these half - domes , glass half - domes , and the offices are in in the glass half - dome . grad a: really ? professor e: yeah . grad f: alright , let 's stop talking about this . grad a: does it exist yet ? professor e: yeah . grad a: they are w now building it ? grad c: uh , as a model . grad a: hmm . grad c: but i th professor e: so , yeah , i think that 's that 's a good point , th th that the date , the , uh , a lot of the this is interacting with , uh , people in italy but also definitely the people in leipzig and the the b the combination of the biology and the leipzig connection might be interesting to these guys , yeah . ok . ok . anyway ! enough of that , let 's talk about your thesis proposal . grad c: yeah , if somebody has something to say . professor e: yep . grad f: you might want to , uh , double - check the spellings of the authors ' names on your references , you had a few , uh , misspells in your slides , there . like i believe you had `` jackendorf `` . professor e: um . grad f: uh , unless there 's a person called `` jackendorf `` , grad a: on that one ? professor e: no , no , no . grad f: yeah . but that 's the only thing i noticed in there . grad a: in the presentation ? grad f: in the presentation . grad a: i 'll probably i c might have i 'll probably have comments for you separately , not important . anyway . grad c: oh , in the presentation here . grad a: yeah , that 's what he was talking about . grad f: yeah . grad c: i was ac actually worried about bibtex . uh . no , that 's quite possible . that 's copy and paste from something . professor e: so i did note i i it looks like the , uh , metaphor did n't get in yet . grad c: uh , it did , there is a reference to srini professor e: well , s reference is one thing , the question is is there any place oh , did you put in something about , grad a: metonymy and metaphor here , right ? professor e: uh , the individual , we 'd talked about putting in something about people had , uh oh yeah , ok . good . i see where you have it . so the top of the second of pa page two you have a sentence . grad c: mm - hmm . professor e: but , what i meant is , i think even before you give this , to wahlster , uh , you should , unless you put it in the text , and i do n't think it 's there yet , about we talked about is the , um , scalability that you get by , um , combining the constructions with the general construal mechanism . is that in there ? grad c: yeah , mmm . um . professor e: uh , ok , so where where is it , cuz i 'll have to take a look . grad c: um , but i i did not focus on that aspect but , um ehhh , um , it 's just underneath , uh , um , that reference to metaphor . so it 's the last paragraph before two . so on page two , um , the main focus professor e: uh , ok . yeah . grad c: but that 's really grad a: that 's not about that , is it ? grad c: yeah . professor e: no , it it it s says it but it does n't say it does n't it d it d grad c: why . professor e: yeah , it does n't give the punch line . grad c: mm - hmm . professor e: cuz let me tell the gang what i think the punch line is , because it 's actually important , which is , that , the constructions , that , uh , nancy and keith and friends are doing , uh , are , in a way , quite general but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . and the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at at the base level , it should com uh , interact with all the metonymies and metaphors so that all of the projections of it also should work . grad f: mm - hmm . professor e: and , similarly , if you introduce a new metaphor , it should then uh , compose with all of the constructions . grad f: mm - hmm . yeah . professor e: and it to the extent that that 's true then then it 's a big win over anything that exists . grad d: so does that mean instead of having tons and tons of rules in your context - free grammar you just have these base constructs and then a general mechanism for coercing them . grad f: yeah . professor e: mm - hmm . so that , you know , for example , uh , in the metaphor case , that you have a kind of direct idea of a source , path , and goal and any metaphorical one and abstract goals and all that sort of stuff { comment } you can do the same grammar . grad d: mmm . professor e: and it is the same grammar . but , um , the trick is that the the way the construction 's written it requires that the object of the preposition for example be a container . well , `` trouble `` is n't a container , but it gets constr construed as a c container . grad d: right . professor e: et cetera . so that 's that 's where this , um , grad d: so with construal you do n't have to have a construction for every possible thing that can fill the rule . professor e: right . so 's it 's it it 's a very big deal , i i in this framework , and the thesis proposal as it stands does n't , um , i do n't think , say that as clearly as it could . grad c: no , it does n't say it at all . no . even though one could argue what if there are basic cases , even . i mean , it seems like nothing is context - free . professor e: oh , nothing is context - free , but there are basic cases . that is , um , there are physical containers , there are physical paths , there you know , et cetera . grad c: but `` walked into the cafe and ordered a drink , `` and `` walked into the cafe and broke his nose , `` that 's sort of professor e: oh , it does n't mean that they 're unambiguous . grad c: mmm . yeah . professor e: i mean , a cafe can be construed as a container , or it can be construed you know as as a obstacle , grad f: uh - huh . professor e: or as some physical object . so there are multiple construals . and in fact that 's part of what has to be done . this is why there 's this interaction between the analysis and the construal . grad c: mm - hmm . yep . professor e: the b the the double arrow . grad c: yep . professor e: so , uh , yeah , i mean , it does n't magically make ambiguity go away . grad c: no . professor e: but it does say that , uh , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle . grad c: mm - hmm . professor e: and if that 's not consistent with other things , then you 've got ta reject that reading . grad c: yep . grad d: you con you conditioned me with your first sentence , and so i thought , `` why would he walk into the cafe and then somehow break his nose ? `` uh , oh , uh grad f: he slipped on the wet floor . professor e: right . grad c: you do n't find that usage , uh uh , i checked for it in the brown national corpus . professor e: yeah . grad c: the `` walk into it `` never really means , w as in walked smack professor e: but `` run into `` does . grad c: yeah , but , y y if you find `` walked smacked into the cafe `` or `` slammed into the wall `` professor e: yeah , no , but `` run into `` does . grad c: mm - hmm . professor e: because you will find `` run into , `` uh , grad d: cars run into telephone poles all the time . professor e: well , or `` into the cafe `` for that m grad c: right . professor e: you know `` his car ran into the cafe . `` grad c: yeah . or you can run into an old friend , or run . professor e: well , you can `` run into `` in that sense too . grad a: yeah , `` run into `` might even be more impact sense than , you know , container sense . professor e: but , uh , right . grad f: depends . professor e: but like , `` run into an old friend `` , it probably needs its own construction . i mean , uh , you know , george would have i 'm sure some exa complicated ex reason why it really was an instance of something else grad a: mm - hmm . mm - hmm . professor e: and maybe it is , but , um , there are idioms and my guess is that 's one of them , but , um i do n't know . grad a: all contact . i mean , there there 's contact that does n't social contact , whatever . i mean . professor e: uh . grad f: sudden surprising contact , professor e: yeah , but it 's it 's it 's it 's right . i yeah , it 's more grad f: right ? grad a: forceful . grad f: but of course , no , i i i mean it has a life of its own . it 's sort of partially inspired by the spatial professor e: well , this is this motivated but yeah grad f: yeah . professor e: oh yeah , mo for sure , motivated , but then you ca n't parse on motivated . grad f: yeah . yeah . right . professor e: uh , grad a: too bad . grad d: you should get a t - shirt that says that . professor e: ok . grad a: there 's there 's lots of things you could make t - shirts out of , but , uh , this has gotten i mean wh we do n't need the words to that . grad c: pro - probably not your marks in the kitchen , today . grad a: what ? oh , no no no no no no no no no , we 're not going there . grad c: not not your marks . grad a: ok . professor e: ok , so , um , grad f: in other news . professor e: anything else you want to ask us about the thesis proposal , you got grad c: well , professor e: we could look at a particular thing and give you feedback on it . grad c: well there actually the i what would have been really nice is to find an example for all of this , uh , from our domain . so maybe if we w if we can make one up now , that would be c incredibly helpful . grad a: so , w where it should illustrate professor e: ok . grad a: uh wh when you say all this , do you mean , like , i do n't know , the related work stuff , grad c: how grad a: as well as , mappings ? grad c: w well we have , for example , a canonical use of something professor e: right right r grad c: and y it 's , you know , we have some constructions and then it 's construed as something , and then we we may get the same constructions with a metaphorical use that 's also relevant to the to the domain . professor e: ok , f let 's let 's suppose you use `` in `` and `` on `` . i mean , that 's what you started with . grad c: mm - hmm . professor e: so `` in the bus `` and `` on the bus , `` um , that 's actually a little tricky in english because to some extent they 're synonyms . ok . grad c: i had two hours w with george on this , so it , professor e: ok , what did he say . grad a: did you ? grad c: um um . grad a: join the club . professor e: right . oh , h that 's grad c: `` on the bus `` is a m is a metaphorical metonymy that relates some meta path metaphorically and you 're on on that path and th w i mean it 's he there 's a platform notion , professor e: yeah , i i believe all that , it 's just grad c: right ? `` he 's on the standing on the bus waving to me . `` professor e: yeah . grad c: but th the regular as we speak `` j johno was on the bus to new york , `` professor e: yeah . yeah . grad c: um , uh , he 's that 's , uh , what did i call it here , the transportation schema , something , professor e: yeah . grad c: where you can be on the first flight , on the second flight , professor e: yeah . grad c: and you can be , you know , on the wagon . professor e: right . so so that that may or may not be what you what you want to do . i mean you could do something much simpler grad c: yeah . professor e: like `` under the bus , `` or something , where grad c: but it 's it 's unfortunately , this is not really something a tourist would ever say . so . professor e: well , unless he was repairing it or something , grad c: yeah . professor e: but yeah . grad c: but um . professor e: uh , but ok . grad c: so in terms of the this grad a: i see . grad c: we had we had initially we 'd started discussing the `` out of film . `` professor e: right . grad c: and there 's a lot of `` out of `` analysis , so , um , professor e: right . grad c: could we capture that with a different construal of grad a: yeah , it 's a little it 's , uh we 've thought about it before , uh t uh to use the examples in other papers , and it 's it 's a little complicated . cuz you 're like , it 's a state of there 's resource , grad f: out of out of film , in particular . grad a: right , and like , what is film , grad f: yeah . grad a: the state you know . you 're out of the state of having film , right ? and somehow film is standing for the re the resour the state of having some resource is just labeled as that resource . grad f: it 's grad a: i mean . grad f: yeah , i mean , grad a: it 's a little bit grad f: but and plus the fact that there 's also s i mean , can you say , like , `` the film ran out `` you know , or , maybe you could say something like `` the film is out `` grad a: yeah , is film the trajector ? grad f: so like the the film went away from where it should be , namely with you , or something , right ? you know . the the film the film is gone , right ? um , i never really knew what was going on , i mean i i find it sort of a little bit farfetched to say that that `` i 'm out of film `` means that i have left the state of having film or something like that , grad a: it 's weird . that grad f: but . grad a: or , `` having `` is also , um , associated with location , professor e: uh . grad a: right ? grad f: yeah . yeah . grad a: so if the film left , you know state is being near film . grad c: so running running out of something is different from being out of somewhere . professor e: or being out of something as , uh as well . so `` running out of it `` definitely has a process aspect to it . grad a: mm - hmm . but that 's from run , yeah . professor e: so , grad f: mm - hmm . professor e: b that 's ok , grad a: yeah . professor e: i mean b but the difference grad c: is the d the final state of running out of something is being out of it . professor e: is grad a: yeah . so th professor e: right . grad f: yeah . you got there . grad a: that part is fine . grad f: you got to out of it . professor e: yeah . grad f: yeah . professor e: but , uh grad f: hmm ! professor e: yeah , so so nob so no one has in in of the , uh , professional linguists , grad a: uh . professor e: they have n't there was this whole thesis on `` out of `` . grad a: there was ? who ? professor e: well , there i thought or there was a paper on it . grad f: out . professor e: huh ? grad f: there was one on on `` out `` or `` out of `` ? professor e: there was a well , it may be just `` out `` . yeah . grad f: ok . professor e: i think there was `` over `` but there was also a paper on `` out `` . grad f: yeah , lind - susan lindner , grad a: oh , yeah , you 're right . yeah . professor e: or something . grad f: right ? the the `` the syrup spread out `` ? professor e: yeah , and all that sort of stuff . grad f: that kind of thing ? grad a: yeah . and undoubtably there 's been reams of work about it in cognitive linguistics , professor e: ok . but anyway . we 're not gon na do that between now and next week . grad a: but . yeah . grad c: yeah . professor e: ok . so , um grad a: it 's not one of the y it 's more straightforward ones forward ones to defend , so you probably do n't want to use it for the purposes grad c: mm - hmm . professor e: right . grad a: th these are you 're addressing like , computational linguists , professor e: ok . grad a: right . or are you ? grad c: there 's gon na be four computational linguists , grad a: ok . but more emphasis on the computational ? or emphasis on the linguist ? grad c: computer it 's more there 's going to be the just four computational linguists , by coincidence , but the rest is , whatever , biocomputing people and physicists . grad a: oh , ok . professor e: no no no , but not for your talk . i 'm - we 're worrying about the th the thes grad c: oh , the thesis ! grad a: oh , i meant this , professor e: it 's just for one guy . grad c: that 's that 's computa should be very computational , grad a: you know , like ok . so i would try to i would stay away from one that involves weird construal stuff . grad c: and , uh , someth professor e: yeah . grad f: yeah . professor e: right . grad a: you know , it 's an obvious one grad f: totally weird stuff . grad c: i mean the the old bakery example might be nice , grad a: but , uh grad c: `` is there a bakery around here `` . so if you c we really just construe it as a grad f: yeah . grad a: around ? grad c: no , it 's the bakery itself grad a: oh . grad c: is it a building ? uh , that you want to go to ? or is it something to eat that you want to buy ? grad a: oh , oh yeah . yeah , we 've thought about that . right . right . grad c: and then grad a: nnn . no . what ? `` bakery `` ca n't be something you 're gon na eat . professor e: no , no . the question is d do you wan na do you wan na construe do you wan na constr - strue grad f: sh grad d: it 's a speech - act . professor e: r exactly . it 's because do you wan na c do you want to view the bakery as a p a place that that i for example , if y grad a: yeah . where you can get baked goods . professor e: well th well , that 's one . you want to buy something . but the other is , uh , yo you might have smelled a smell and are just curious about whether there 'd be a bakery in the neighborhood , or , grad f: mm - hmm . professor e: um , pfff you know , you wonder how people here make their living , and there 're all sorts of reasons why you might be asking about the existence of a bakery grad f: yeah . professor e: that does n't mean , `` i want to buy some baked goods . `` grad a: ok . professor e: but um , those are interesting examples but it 's not clear that they 're mainly construal examples . grad a: so it 's a lot of pragmatics , there , that grad f: yeah . grad c: mmm . professor e: there 's all sorts of stuff going on . grad a: might be beyond what you want to do . professor e: so let 's so let 's think about this from the point of view of construal . so let 's first do a so the metonymy thing is probably the easiest and a and actually the though , the one you have is n't quite grad a: you mean the s you mean `` the steak wants to pay `` ? professor e: n no not that one , that 's that 's a the sort of background . this is the t uh , page five . grad d: about plato and the book ? grad a: oh . professor e: no . grad a: um . grad c: no . grad a: how much does it cost ? professor e: just beyond that . grad f: onward . grad c: where is the castle ? professor e: yeah . grad f: a castle . grad c: how old is it ? how much does it cost ? grad d: oh . grad f: mm - hmm . grad a: to go in , that 's like grad f: two hundred million dollars . professor e: right . it 's not for sale . uh . so grad f: yeah , i think that 's a good example , actually . grad c: s grad a: yeah , that 's good . u grad c: but as nancy just su suggested it 's probably ellipticus . grad a: ellipsis . grad c: huh . grad a: like , `` it `` does n't refer to `` thing , `` it refers to acti you know , j thing standing for activ most relevant activity for a tourist you could think of it that way , but . professor e: yeah . grad f: well , shoot , is n't that i mean , that 's what grad c: well , i mean , my argument here is it 's it 's it 's the same thing as `` plato 's on the top shelf , `` grad f: figuring that out is what this is about . grad a: yeah , yeah , no , i i agree . grad c: i 'm con you know , th that you can refer to a book of plato by using `` plato , `` grad a: yeah . no no , i i 'm agreeing that this is a good , um grad c: and you can refer back to it , and so you can castles have as tourist sites , have admission fees , so you can say `` where is the castle , how much does it cost ? `` um . `` how far is it from here ? `` grad f: mm - hmm . grad c: so , you 're also not referring to the width of the object , or so , grad a: hmm . mm - hmm . grad c: www . grad f: mmm . professor e: ok . can we think of a nice metaphorical use of `` where `` in the tourist 's domain ? um . grad f: hmm . professor e: so you know it 's you you can sometimes use `` where `` f for `` when `` grad f: o professor e: in the sense of , you know , um , where wh where where was , um , `` where was heidelberg , um , in the thirty years ' war ? `` or something . grad c: mm - hmm . grad f: uh , yeah . professor e: you know , or some such thing . um . grad f: like what side were they on , grad a: what ? professor e: yeah . essentially , yeah . grad f: or ? grad a: ok . i was like , `` huh ? it was here . `` like { comment } um . professor e: but anyway th so there are there are cases like that . um , grad a: ah ! or like its developmental state or something like that , you could i guess you could get that . professor e: yeah . grad a: um . professor e: um . grad f: i mean , there 's also things like i mean , s um , i guess i could ask something like `` where can i find out about blah - blah - blah `` in a sort of does n't nece i do n't necessarily have to care about the spatial location , just give me a phone number professor e: yeah . there certainly is that , yeah . grad f: and i 'll call them or something like that ? professor e: you know , `` where could i learn its opening hours , `` or something . grad f: yeah . professor e: but that 's not metaphorical . grad a: hmm . professor e: it 's another grad f: yeah . professor e: so we 're thinking about , um , or we could also think about , uh grad c: well , i i i professor e: how about `` i 'm in a hurry `` ? grad a: state . professor e: it i but it 's a state and the the issue is , is that it may be just a usage , grad f: hmm ? professor e: you know , that it 's not particularly metaphorical , i do n't know . grad f: mmm . grad a: right . so you want a more exotic one version of that . grad f: oh . professor e: yeah . yeah , right . grad a: i 'm really into professor e: ah ! how about i i i you know , `` i 'm in i 'm in a state of exhaustion `` ? grad a: do you really say that ? professor e: or something like that , which a tourist w huh ? grad a: would you really say that ? professor e: a st uh , well , you can certainly say , um , you know , `` i 'm in overload . `` tu - stur tourists will often say that . grad f: yeah . grad d: i i 'm really into art . grad a: yeah , i was gon na say , like grad d: uh professor e: oh , you can do that ? really ? of course that 's that that 's definitely a , uh grad f: fixed . grad a: a fixed expression , yeah . professor e: that 's a , uh right . but . grad a: there 're too there 're all sorts of fixed expressions i do n't like uh `` i 'm out of sorts now ! `` professor e: right . grad a: like { comment } `` i 'm in trouble ! `` grad c: well i when , uh just f u the data that i 've looked at so far that rec professor e: yeah . grad c: i mean , there 's tons of cases for polysemy . professor e: right . grad a: uh - huh . grad c: so , you know , mak re making reference to buildings as institutions , as containers , as build professor e: right . grad c: you know , whatever . um , so ib in mus for example , in museums , you know , as a building or as something where pictures hang versus , you know , ev something that puts on exhibits , so forth . professor e: right . as an institution , grad c: but professor e: yeah . grad c: um . grad a: why do n't you want to use any of those ? grad c: hmm ? grad a: so y you do n't wan na use one that 's grad c: yeah , well no , but this that 's what i have , you know , started doing . professor e: the castle the that old castle one is sort of grad c: metonymy , polysemy . grad d: i love van gogh . professor e: yeah . grad a: `` i wan na go see the van gogh . `` professor e: ah ! grad f: oh geez . grad a: anyway , i 'm sorry . grad c: but i think the argument should be uh , can be made that , you know , despite the fact that this is not the most met metaphorical domain , because people interacting with hti systems try to be straightforward and less lyrical , professor e: yeah . grad c: construal still is , uh , you know , completely , um , key in terms of finding out any of these things , so , um . professor e: right . so that 's that 's that 's a that 's a reasonable point , that it in this domain you 're gon na get less metaphor and more metonymy . grad c: we , uh i with a i looked with a student i looked at the entire database that we have on heidelberg for cases of metonymy . professor e: and polysemy , and stuff like that . yeah . grad c: hardly anything . so not even in descriptions w did we find anything , um , relevant . grad f: i have to go . professor e: alright . yeah . grad c: but ok this is just something we 'll we 'll see , um , professor e: right . s see you . grad c: and deal with . professor e: ok , well . i guess if anybody has additional suggestions , grad c: i mean maybe the `` where is something `` question as a whole , you know , can be construed as , u i locational versus instructional request . professor e: w yeah . grad c: so , if we 're not talk about the lexic grad a: location versus what ? grad c: instruction . grad a: instruction . oh , directions ? yeah . professor e: sure . grad a: oh , i thought that was definitely treated as an example of construal . grad c: yeah . grad a: right ? grad c: yeah but then you 're not on the lexical level , that 's sort of one level higher . grad a: oh , you want a lexical example . grad c: but i do n't need it . professor e: well , you might want both . grad c: mm - hmm . grad a: yeah . grad c: also it would be nice to get ultimately to get a nice mental space example , professor e: we grad c: so , even temporal references are just in the spatial domain are rare . professor e: but it 's it 's easy to make up plausible ones . grad c: when when you 're getting information on objects . professor e: you know . grad c: so , i mean professor e: right , you know you know , where r yeah . what color was this in in in the nain nineteenth century . grad c: yeah . professor e: what was this p instead of wh what you know how was this painted , what color was this painted , um , was this alleyway open . grad c: yeah , maybe we can include that also in our second , uh , data run . professor e: uh . grad c: we c we can show people pictures of objects and then have then ask the system about the objects and engage in conversation on the history and the art and the architecture and so forth . professor e: mm - hmm . ok . so why do n't we plan to give you feedback electronically . wish you a good trip . all success . grad d: for some reason when you said `` feedback electronically `` i thought of that you ever see the simpsons where they 're like the family 's got the buzzers and they buzz each other when they do n't like what the other one is saying ? grad a: yeah . that 's the first one , i think . the very very first one . grad d: it was a very early one . i do n't know if it 's the first one . grad a: mmm . mmm .","output":"the meeting was taken up by discussion about a thesis proposal and a talk about to take place at eml . it was advised that more emphasis should be put on the role of construal in the understanding of metaphor and metonymy . base constructions deal with the norm , while further general domain mechanisms determine how the constructions are invoked depending on the context . several potential examples of polysemy were discussed in detail : `` walk\/run into '' , `` on the bus '' , `` out of film '' , `` where is x ? '' . however , none of them was an example of lexical polysemy resolved by construal straightforward enough to include in the proposal ; the tourist domain is not metaphor rich ."},{"instruction":"what \u2019 s the thesis about ?","input":"grad a: ah , so comfortable . grad f: smooth . grad a: mm - hmm . good . i know that he 's going to like , taiwan and other places to eat . so . grad d: on ? am i on ? grad a: yep . yep . grad d: i think i 'm on ? grad b: yeah . grad d: good . good . grad a: bye . grad b: actually grad f: i just had one of the most frustrating meetings of my career . grad a: it 's definitely not the most frustrating meeting i 've ever had . grad d: you a you 're you remember you 're being recorded at this point . grad a: oh , yeah , so , w we did n't yet specify with whom . professor e: yeah . grad f: yeah . professor e: right . grad a: but um . professor e: uh , right . grad a: so that 's why keith and i are going to be a little dazed for the first half m the meeting . professor e: uh . grad f: huh . yeah , i 'm just gon na sit here and professor e: right . yeah , i i i avoided that as long as i could for you guys , grad f: growl . professor e: but , uh grad f: yeah . grad a: mm - hmm . grad f: for which we thank you , by the way . grad a: are very appreciative , yeah . professor e: right . grad f: i know you were you were doing that , but , anyway . grad d: oh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ? grad f: oh , i could tell you had a rough day , man ! grad d: nah . grad a: what ? grad d: i love that story . grad f: yeah , it 's a great story . grad c: ok . grad f: oh my goodness . grad c: oh yeah , um , liz suggested we could start off by uh , doing the digits all at the same time . grad a: what ? grad d: all at the same time . i do n't know if i would get distracted and confused , probably . professor e: e grad a: really ? do we have to like , synchronize ? professor e: well , i think you 're supposed to ok . we can do this . grad f: are you being silly ? grad d: oh wait do we have t professor e: everybody 's got different digits , grad c: yep . professor e: right ? grad d: yeah , do we have to time them at the same time or just overlapping grad f: uh . grad a: you 're kidding . grad c: no , no , just just start whenever you want . professor e: no . grad a: and any rate ? professor e: e yeah , the grad f: alright . professor e: well , they they have s they have the close talking microphones for each of us , grad a: yeah , that 's true . professor e: so grad c: yeah . professor e: yeah , there 's separate channels . grad f: alright . grad a: ok . grad c: yeah . professor e: so when i say grad f: just plug one ear . grad a: you lose . professor e: ok . grad f: ok , bye ! that was a great meeting ! professor e: right . grad d: alright . grad f: so - now , uh , why ? grad c: just to save time . grad f: ok . grad c: does matter for them . grad a: are we gon na start all our meetings out that way from now on ? professor e: no . grad a: oh . too bad . i kinda like it . grad f: well , could we ? grad d: it 's strangely satisfying . grad a: yeah . it 's a ritual . grad d: are we to r just to make sure i know what 's going on , we 're talking about robert 's thesis proposal today ? is that grad c: we could . grad d: true ? grad a: we are ? grad c: we might . grad a: ok . grad d: is professor e: well , you you had s you said there were two things that you might wan na do . one was rehearse your i i talk grad d: oh yes , and that too . grad c: not not rehearse , i mean , i have just not spent any time on it , so i can show you what i 've got , get your input on it , and maybe some suggestions , that would be great . and the same is true for the proposal . i will have time to do some revision and some additional stuff on various airplanes and trains . so , um . i do n't know how much of a chance you had to actually read it grad a: i have n't looked at it grad c: because grad a: yet , grad c: but you could always send me comments per electronic mail grad a: but i will . grad c: and they will be incorporated . grad a: ok . grad c: um , the it basically says , well `` this is construal `` , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model to do some inferences in terms of what is being construed as what grad a: hmm . grad c: in our beloved tourism domain . but , with a focus on grad a: can i s sorry . grad f: i think i need a copy of this , yes . grad c: hmm ? grad d: ok , we can we can we can pass pass my , uh we can pass my extra copy around . grad f: i is there an extra copy around ? grad a: uh . he sent it . ok . you can keep it . grad d: er , actually , my only copy , now that i think about it , grad f: alrigh grad a: ok . grad c: um , i do n't i , uh i do n't need it . grad d: but . i already read half of it , so it 's ok . grad c: um , actually this is the the newest version after your comments , grad f: ok . grad c: and professor e: yeah , no i s i s i see this has got the castle in it , and stuff like that . grad c: yeah . professor e: yep . grad d: oh , maybe the version i did n't have that i mine the w did the one you sent on the email have the professor e: yeah . grad d: that was the most recent one ? professor e: uh , yeah , i think so . grad c: yep . grad d: ok . cuz i read halfway but i did n't see a castle thing . grad a: i 'm changing this . just so you know . grad c: yeah , grad a: but , anyway . grad c: um , if you would have checked your email you may have received a note from yees asking you to send me the , uh , up - to - d grad a: oh . oh , sorry . ok . sorry . grad c: current formalism thing that you presented . grad a: ok . i will . ok . ok . ok . grad c: but for this it does n't matter . but , uh grad a: we can talk about it later . that 's not even ready , so . um , ok ! go on t to , uh , whatever . grad c: and grad a: i 'm making changes . `` do n't worry about that . `` ok . mmm - mmm . oh ! ok , sorry , go on . grad c: and any type of comment whether it 's a spelling or a syntax or grad a: mm - hmm . grad c: readability grad f: there 's only one `` s `` in `` interesting `` . grad c: hmm ? grad f: there 's only one `` s `` in `` interesting `` . on page five . grad c: interesting . grad a: anyway . and y uh , email any time , but most usefully before grad d: the twenty - first i 'm assuming . grad a: the twenty - first ? grad c: twenty - ninth . professor e: no , this is the twenty - first . grad f: that 's grad d: what , today 's the twenty - first ? grad f: well , better hurry up then ! grad d: oh , man ! grad a: before the twenty - ninth , grad c: the twenty - ninth . grad a: ok . grad d: ok . grad c: that 's when i 'm meeting with wolfgang wahlster to sell him this idea . grad a: mm - hmm . ok . grad c: ok ? then i 'm also going to present a little talk at eml , about what we have done here and so of course , i 'm i 'm gon na start out with this slide , so the most relevant aspects of our stay here , and um , then i 'm asking them to imagine that they 're standing somewhere in heidelberg and someone asks them in the morning the cave forty - five is a is a well - known discotheque which is certainly not open at that that time . and so grad f: ok . grad c: they 're supposed to imagine that , you know , do they think the person wants to go there , or just know where it is ? uh , which is probably not , uh , the case in that discotheque example , or in the bavaria example , you just want to know where it is . and so forth . so basically we can make a point that here is ontological knowledge but if it 's nine nine pm in the evening then the discotheque question would be , for example , one that might ask for directions instead of just location . um , and so forth and so forth . that 's sort of motivating it . then what have we done so far ? we had our little bit of , um , um , smartkom stuff , that we did , um , everth grad f: oh , you 've got the parser done . sorry . grad c: that 's the not the construction parser . that 's the , uh , tablet - based parser , grad f: ok . grad a: easy parser . grad f: ok . grad c: and the generation outputter . grad d: halfway done ? yeah . grad c: that 's done . grad a: mmm . grad c: you have to change those strategies , grad d: ok . grad c: right ? that 's , ten words ? grad d: yeah . well , i it , you know . maybe twelve . grad c: twelve ? ok . and , um , and fey is doing the synthesis stuff as we speak . that 's all about that . then i 'm going to talk about the data , you know these things about uh , actually i have an example , probably . two s can you hear that ? or should i turn the l volume on . grad f: mm - hmm . grad a: i could hear it . grad d: i i can hear it . grad f: i heard it . grad d: they might not hear it in the well maybe they will . i do n't know . grad a: this was an actual , um , subject ? ah . grad c: mm - hmm . grad f: sounds like fey . grad a: yeah . grad c: but they 're they 're mimicking the synthesis when they speak to the computer , grad f: oh , ok . grad c: the you can observe that all the time , they 're trying to match their prosody onto the machine . grad f: oh really . interesting . oh , it 's pretty slow . grad c: yeah , you have to grad a: wh grad f: the system breaking . grad a: what is the s ? oh ! grad c: ok . and so forth and so forth . um , i will talk about our problems with the rephrasing , and how we solved it , and some preliminary observations , also , um , i 'm not gon na put in the figures from liz , but i thought it would interesting to , uh , um , point out that it 's basically the same . um , as in every human - human telephone conversation , and the human - computer telephone conversation is of course quite d quite different from , uh , some first , uh , observations . then sort of feed you back to our original problem cuz , uh how to get there , what actually is happening there today , and then maybe talk about the big picture here , e tell a little bit as much as i can about the ntl story . i i wa i do wan na , um i 'm not quite sure about this , whether i should put this in , um , that , you know , you have these two sort of different ideas that are or two different camps of people envisioning how language understanding works , and then , talk a bit about the embodied and simulation approach favored here and as a prelude , i 'll talk about monkeys in italy . and , um , srini was gon na send me some slides but he did n't do it , so from but i have the paper , i can make a resume of that , and then i stole an x - schema from one of your talks i think . grad a: oh . i was like , `` where 'd you get that ? `` ok . grad f: yeah , that looks familiar . grad a: `` looks familiar . `` grad c: i think that 's bergen , chang , something , or the other . grad a: uh . professor e: whatever . grad a: ok . grad c: um , and that 's now i 'm not going to bring that . so that 's basically what i have , so far , and the rest is for airplanes . so x - schemas , then , i would like to do talk about the construction aspect and then at the end about our bayes - net . grad a: mm - hmm . grad c: end of story . anything i forgot that we should mention ? oh , maybe the fmri stuff . should i mention the fact that , um , we 're also actually started going to start to look at people 's brains in a more direct way ? professor e: you certainly can . i mean i y i you know , i do n't know grad a: you might just wan na like , tack that on , as a comment , to something . professor e: right , um . grad c: `` future activities `` something . professor e: well , the time to mention it , if you mention it , is when you talk about mirror neurons , then you should talk about the more recent stuff , about the kicking grad c: yeah . professor e: and , you know , the yeah , yeah and that the plan is to see to what extent the you 'll get the same phenomena with stories about this , so that grad c: mm - hmm . professor e: and that we 're planning to do this , um , which , we are . so that 's one thing . um . depends . i mean , there is a , um , whole language learning story , ok ? grad c: yeah . professor e: which , uh , actually , i i even on your five - layer slide , you you 've got an old one that that leaves that off . grad c: yeah , i i i do have it here . grad a: hmm . professor e: yeah . grad c: um . and , of course , you know , the the big picture is this bit . professor e: right . grad c: but , you know , it would but i do n't think i i am capable of of do pulling this off and doing justice to the matter . i mean , there is interesting stuff in her terms of how language works , so the emergentism story would be nice to be you know , it would be nice to tell people how what 's happening there , plus how the , uh , language learning stuff works , professor e: ok , so , so anyway , i i agree that 's not central . grad c: but grad a: mm - hmm . professor e: what you might wan na do is , um , and may not , but you might wan na this is rip off a bunch of the slides on the anal there the there we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , and , um , how the construction and simulation that ho that whole th grad c: yeah , th that that 's c that comes up to the x - schema slide , grad a: ok , right . grad c: so basically i 'm gon na steal that from nancy , grad a: ok , i can give you a more recent if you want grad c: one of nancy 's st grad a: well , that might have enough . grad c: uh , i yeah , but i also have stuff you trash you left over , professor e: ok . grad c: your quals and your triple - ai . professor e: the quals w the the the quals slides would be fine . grad a: yeah . professor e: you could get it out of there , or some grad a: which i can even email you then , you know , like there probably was a little few changes , not a big deal . yeah , you could steal anything you want , i do n't care . which you 've already done , obviously . so . sorry grad c: well , i i do n't feel bad about it at all grad a: no , you should n't . grad c: because because you are on the , uh , title . grad a: oh , that 's great , that 's great . grad c: i mean on the the , you 're that 's see , that 's you . grad a: i 'm glad to see propagation . professor e: yeah . yeah . grad a: mmm . grad c: hmm ? propagated ? grad a: yes . grad c: i mean i might even mention that this work you 're doing is sort of also with the mpi in leipzig , so . grad a: it 's it 's certainly related , um , grad c: because , um , eml is building up a huge thing in leipzig . grad a: might wan na say . is it ? grad c: so it it 's on biocomputation . would professor e: yeah , it 's different , this is the , uh , dna building , or someth the double helix building . grad c: yeah . professor e: yeah . grad a: kind of a different level of analysis . professor e: the yeah it was it turns out that if if you have multiple billions of dollars , y you can do all sorts of weird things , and grad d: wait , they 're building a building in the shape of dna , grad a: what ? grad d: is that what you said ? professor e: roughly , yeah . grad f: oh ! oh boy ! grad a: o professor e: including cr cross - bridges , grad a: what ? professor e: and grad a: oh my god ! grad f: that 's brilliant ! hhh . professor e: you d you really now i i spent the last time i was there i spent maybe two hours hearing this story which is , um grad a: of what grad d: y you definitely wan na w do n't wan na waste that money on research , grad a: the building ? grad d: you know ? professor e: right . grad d: that 's horrible . professor e: right . well , no , no , y i there 's infinite money . see you th you th you then fill it with researchers . grad a: and give them more money . they just want a fun place for them to to work . professor e: right . right . grad f: and everybody gets a trampoline in their office . grad c: well , the the offices are actually a little the , think of um , ramps , coming out of the double helix and then you have these half - domes , glass half - domes , and the offices are in in the glass half - dome . grad a: really ? professor e: yeah . grad f: alright , let 's stop talking about this . grad a: does it exist yet ? professor e: yeah . grad a: they are w now building it ? grad c: uh , as a model . grad a: hmm . grad c: but i th professor e: so , yeah , i think that 's that 's a good point , th th that the date , the , uh , a lot of the this is interacting with , uh , people in italy but also definitely the people in leipzig and the the b the combination of the biology and the leipzig connection might be interesting to these guys , yeah . ok . ok . anyway ! enough of that , let 's talk about your thesis proposal . grad c: yeah , if somebody has something to say . professor e: yep . grad f: you might want to , uh , double - check the spellings of the authors ' names on your references , you had a few , uh , misspells in your slides , there . like i believe you had `` jackendorf `` . professor e: um . grad f: uh , unless there 's a person called `` jackendorf `` , grad a: on that one ? professor e: no , no , no . grad f: yeah . but that 's the only thing i noticed in there . grad a: in the presentation ? grad f: in the presentation . grad a: i 'll probably i c might have i 'll probably have comments for you separately , not important . anyway . grad c: oh , in the presentation here . grad a: yeah , that 's what he was talking about . grad f: yeah . grad c: i was ac actually worried about bibtex . uh . no , that 's quite possible . that 's copy and paste from something . professor e: so i did note i i it looks like the , uh , metaphor did n't get in yet . grad c: uh , it did , there is a reference to srini professor e: well , s reference is one thing , the question is is there any place oh , did you put in something about , grad a: metonymy and metaphor here , right ? professor e: uh , the individual , we 'd talked about putting in something about people had , uh oh yeah , ok . good . i see where you have it . so the top of the second of pa page two you have a sentence . grad c: mm - hmm . professor e: but , what i meant is , i think even before you give this , to wahlster , uh , you should , unless you put it in the text , and i do n't think it 's there yet , about we talked about is the , um , scalability that you get by , um , combining the constructions with the general construal mechanism . is that in there ? grad c: yeah , mmm . um . professor e: uh , ok , so where where is it , cuz i 'll have to take a look . grad c: um , but i i did not focus on that aspect but , um ehhh , um , it 's just underneath , uh , um , that reference to metaphor . so it 's the last paragraph before two . so on page two , um , the main focus professor e: uh , ok . yeah . grad c: but that 's really grad a: that 's not about that , is it ? grad c: yeah . professor e: no , it it it s says it but it does n't say it does n't it d it d grad c: why . professor e: yeah , it does n't give the punch line . grad c: mm - hmm . professor e: cuz let me tell the gang what i think the punch line is , because it 's actually important , which is , that , the constructions , that , uh , nancy and keith and friends are doing , uh , are , in a way , quite general but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . and the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at at the base level , it should com uh , interact with all the metonymies and metaphors so that all of the projections of it also should work . grad f: mm - hmm . professor e: and , similarly , if you introduce a new metaphor , it should then uh , compose with all of the constructions . grad f: mm - hmm . yeah . professor e: and it to the extent that that 's true then then it 's a big win over anything that exists . grad d: so does that mean instead of having tons and tons of rules in your context - free grammar you just have these base constructs and then a general mechanism for coercing them . grad f: yeah . professor e: mm - hmm . so that , you know , for example , uh , in the metaphor case , that you have a kind of direct idea of a source , path , and goal and any metaphorical one and abstract goals and all that sort of stuff { comment } you can do the same grammar . grad d: mmm . professor e: and it is the same grammar . but , um , the trick is that the the way the construction 's written it requires that the object of the preposition for example be a container . well , `` trouble `` is n't a container , but it gets constr construed as a c container . grad d: right . professor e: et cetera . so that 's that 's where this , um , grad d: so with construal you do n't have to have a construction for every possible thing that can fill the rule . professor e: right . so 's it 's it it 's a very big deal , i i in this framework , and the thesis proposal as it stands does n't , um , i do n't think , say that as clearly as it could . grad c: no , it does n't say it at all . no . even though one could argue what if there are basic cases , even . i mean , it seems like nothing is context - free . professor e: oh , nothing is context - free , but there are basic cases . that is , um , there are physical containers , there are physical paths , there you know , et cetera . grad c: but `` walked into the cafe and ordered a drink , `` and `` walked into the cafe and broke his nose , `` that 's sort of professor e: oh , it does n't mean that they 're unambiguous . grad c: mmm . yeah . professor e: i mean , a cafe can be construed as a container , or it can be construed you know as as a obstacle , grad f: uh - huh . professor e: or as some physical object . so there are multiple construals . and in fact that 's part of what has to be done . this is why there 's this interaction between the analysis and the construal . grad c: mm - hmm . yep . professor e: the b the the double arrow . grad c: yep . professor e: so , uh , yeah , i mean , it does n't magically make ambiguity go away . grad c: no . professor e: but it does say that , uh , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle . grad c: mm - hmm . professor e: and if that 's not consistent with other things , then you 've got ta reject that reading . grad c: yep . grad d: you con you conditioned me with your first sentence , and so i thought , `` why would he walk into the cafe and then somehow break his nose ? `` uh , oh , uh grad f: he slipped on the wet floor . professor e: right . grad c: you do n't find that usage , uh uh , i checked for it in the brown national corpus . professor e: yeah . grad c: the `` walk into it `` never really means , w as in walked smack professor e: but `` run into `` does . grad c: yeah , but , y y if you find `` walked smacked into the cafe `` or `` slammed into the wall `` professor e: yeah , no , but `` run into `` does . grad c: mm - hmm . professor e: because you will find `` run into , `` uh , grad d: cars run into telephone poles all the time . professor e: well , or `` into the cafe `` for that m grad c: right . professor e: you know `` his car ran into the cafe . `` grad c: yeah . or you can run into an old friend , or run . professor e: well , you can `` run into `` in that sense too . grad a: yeah , `` run into `` might even be more impact sense than , you know , container sense . professor e: but , uh , right . grad f: depends . professor e: but like , `` run into an old friend `` , it probably needs its own construction . i mean , uh , you know , george would have i 'm sure some exa complicated ex reason why it really was an instance of something else grad a: mm - hmm . mm - hmm . professor e: and maybe it is , but , um , there are idioms and my guess is that 's one of them , but , um i do n't know . grad a: all contact . i mean , there there 's contact that does n't social contact , whatever . i mean . professor e: uh . grad f: sudden surprising contact , professor e: yeah , but it 's it 's it 's it 's right . i yeah , it 's more grad f: right ? grad a: forceful . grad f: but of course , no , i i i mean it has a life of its own . it 's sort of partially inspired by the spatial professor e: well , this is this motivated but yeah grad f: yeah . professor e: oh yeah , mo for sure , motivated , but then you ca n't parse on motivated . grad f: yeah . yeah . right . professor e: uh , grad a: too bad . grad d: you should get a t - shirt that says that . professor e: ok . grad a: there 's there 's lots of things you could make t - shirts out of , but , uh , this has gotten i mean wh we do n't need the words to that . grad c: pro - probably not your marks in the kitchen , today . grad a: what ? oh , no no no no no no no no no , we 're not going there . grad c: not not your marks . grad a: ok . professor e: ok , so , um , grad f: in other news . professor e: anything else you want to ask us about the thesis proposal , you got grad c: well , professor e: we could look at a particular thing and give you feedback on it . grad c: well there actually the i what would have been really nice is to find an example for all of this , uh , from our domain . so maybe if we w if we can make one up now , that would be c incredibly helpful . grad a: so , w where it should illustrate professor e: ok . grad a: uh wh when you say all this , do you mean , like , i do n't know , the related work stuff , grad c: how grad a: as well as , mappings ? grad c: w well we have , for example , a canonical use of something professor e: right right r grad c: and y it 's , you know , we have some constructions and then it 's construed as something , and then we we may get the same constructions with a metaphorical use that 's also relevant to the to the domain . professor e: ok , f let 's let 's suppose you use `` in `` and `` on `` . i mean , that 's what you started with . grad c: mm - hmm . professor e: so `` in the bus `` and `` on the bus , `` um , that 's actually a little tricky in english because to some extent they 're synonyms . ok . grad c: i had two hours w with george on this , so it , professor e: ok , what did he say . grad a: did you ? grad c: um um . grad a: join the club . professor e: right . oh , h that 's grad c: `` on the bus `` is a m is a metaphorical metonymy that relates some meta path metaphorically and you 're on on that path and th w i mean it 's he there 's a platform notion , professor e: yeah , i i believe all that , it 's just grad c: right ? `` he 's on the standing on the bus waving to me . `` professor e: yeah . grad c: but th the regular as we speak `` j johno was on the bus to new york , `` professor e: yeah . yeah . grad c: um , uh , he 's that 's , uh , what did i call it here , the transportation schema , something , professor e: yeah . grad c: where you can be on the first flight , on the second flight , professor e: yeah . grad c: and you can be , you know , on the wagon . professor e: right . so so that that may or may not be what you what you want to do . i mean you could do something much simpler grad c: yeah . professor e: like `` under the bus , `` or something , where grad c: but it 's it 's unfortunately , this is not really something a tourist would ever say . so . professor e: well , unless he was repairing it or something , grad c: yeah . professor e: but yeah . grad c: but um . professor e: uh , but ok . grad c: so in terms of the this grad a: i see . grad c: we had we had initially we 'd started discussing the `` out of film . `` professor e: right . grad c: and there 's a lot of `` out of `` analysis , so , um , professor e: right . grad c: could we capture that with a different construal of grad a: yeah , it 's a little it 's , uh we 've thought about it before , uh t uh to use the examples in other papers , and it 's it 's a little complicated . cuz you 're like , it 's a state of there 's resource , grad f: out of out of film , in particular . grad a: right , and like , what is film , grad f: yeah . grad a: the state you know . you 're out of the state of having film , right ? and somehow film is standing for the re the resour the state of having some resource is just labeled as that resource . grad f: it 's grad a: i mean . grad f: yeah , i mean , grad a: it 's a little bit grad f: but and plus the fact that there 's also s i mean , can you say , like , `` the film ran out `` you know , or , maybe you could say something like `` the film is out `` grad a: yeah , is film the trajector ? grad f: so like the the film went away from where it should be , namely with you , or something , right ? you know . the the film the film is gone , right ? um , i never really knew what was going on , i mean i i find it sort of a little bit farfetched to say that that `` i 'm out of film `` means that i have left the state of having film or something like that , grad a: it 's weird . that grad f: but . grad a: or , `` having `` is also , um , associated with location , professor e: uh . grad a: right ? grad f: yeah . yeah . grad a: so if the film left , you know state is being near film . grad c: so running running out of something is different from being out of somewhere . professor e: or being out of something as , uh as well . so `` running out of it `` definitely has a process aspect to it . grad a: mm - hmm . but that 's from run , yeah . professor e: so , grad f: mm - hmm . professor e: b that 's ok , grad a: yeah . professor e: i mean b but the difference grad c: is the d the final state of running out of something is being out of it . professor e: is grad a: yeah . so th professor e: right . grad f: yeah . you got there . grad a: that part is fine . grad f: you got to out of it . professor e: yeah . grad f: yeah . professor e: but , uh grad f: hmm ! professor e: yeah , so so nob so no one has in in of the , uh , professional linguists , grad a: uh . professor e: they have n't there was this whole thesis on `` out of `` . grad a: there was ? who ? professor e: well , there i thought or there was a paper on it . grad f: out . professor e: huh ? grad f: there was one on on `` out `` or `` out of `` ? professor e: there was a well , it may be just `` out `` . yeah . grad f: ok . professor e: i think there was `` over `` but there was also a paper on `` out `` . grad f: yeah , lind - susan lindner , grad a: oh , yeah , you 're right . yeah . professor e: or something . grad f: right ? the the `` the syrup spread out `` ? professor e: yeah , and all that sort of stuff . grad f: that kind of thing ? grad a: yeah . and undoubtably there 's been reams of work about it in cognitive linguistics , professor e: ok . but anyway . we 're not gon na do that between now and next week . grad a: but . yeah . grad c: yeah . professor e: ok . so , um grad a: it 's not one of the y it 's more straightforward ones forward ones to defend , so you probably do n't want to use it for the purposes grad c: mm - hmm . professor e: right . grad a: th these are you 're addressing like , computational linguists , professor e: ok . grad a: right . or are you ? grad c: there 's gon na be four computational linguists , grad a: ok . but more emphasis on the computational ? or emphasis on the linguist ? grad c: computer it 's more there 's going to be the just four computational linguists , by coincidence , but the rest is , whatever , biocomputing people and physicists . grad a: oh , ok . professor e: no no no , but not for your talk . i 'm - we 're worrying about the th the thes grad c: oh , the thesis ! grad a: oh , i meant this , professor e: it 's just for one guy . grad c: that 's that 's computa should be very computational , grad a: you know , like ok . so i would try to i would stay away from one that involves weird construal stuff . grad c: and , uh , someth professor e: yeah . grad f: yeah . professor e: right . grad a: you know , it 's an obvious one grad f: totally weird stuff . grad c: i mean the the old bakery example might be nice , grad a: but , uh grad c: `` is there a bakery around here `` . so if you c we really just construe it as a grad f: yeah . grad a: around ? grad c: no , it 's the bakery itself grad a: oh . grad c: is it a building ? uh , that you want to go to ? or is it something to eat that you want to buy ? grad a: oh , oh yeah . yeah , we 've thought about that . right . right . grad c: and then grad a: nnn . no . what ? `` bakery `` ca n't be something you 're gon na eat . professor e: no , no . the question is d do you wan na do you wan na construe do you wan na constr - strue grad f: sh grad d: it 's a speech - act . professor e: r exactly . it 's because do you wan na c do you want to view the bakery as a p a place that that i for example , if y grad a: yeah . where you can get baked goods . professor e: well th well , that 's one . you want to buy something . but the other is , uh , yo you might have smelled a smell and are just curious about whether there 'd be a bakery in the neighborhood , or , grad f: mm - hmm . professor e: um , pfff you know , you wonder how people here make their living , and there 're all sorts of reasons why you might be asking about the existence of a bakery grad f: yeah . professor e: that does n't mean , `` i want to buy some baked goods . `` grad a: ok . professor e: but um , those are interesting examples but it 's not clear that they 're mainly construal examples . grad a: so it 's a lot of pragmatics , there , that grad f: yeah . grad c: mmm . professor e: there 's all sorts of stuff going on . grad a: might be beyond what you want to do . professor e: so let 's so let 's think about this from the point of view of construal . so let 's first do a so the metonymy thing is probably the easiest and a and actually the though , the one you have is n't quite grad a: you mean the s you mean `` the steak wants to pay `` ? professor e: n no not that one , that 's that 's a the sort of background . this is the t uh , page five . grad d: about plato and the book ? grad a: oh . professor e: no . grad a: um . grad c: no . grad a: how much does it cost ? professor e: just beyond that . grad f: onward . grad c: where is the castle ? professor e: yeah . grad f: a castle . grad c: how old is it ? how much does it cost ? grad d: oh . grad f: mm - hmm . grad a: to go in , that 's like grad f: two hundred million dollars . professor e: right . it 's not for sale . uh . so grad f: yeah , i think that 's a good example , actually . grad c: s grad a: yeah , that 's good . u grad c: but as nancy just su suggested it 's probably ellipticus . grad a: ellipsis . grad c: huh . grad a: like , `` it `` does n't refer to `` thing , `` it refers to acti you know , j thing standing for activ most relevant activity for a tourist you could think of it that way , but . professor e: yeah . grad f: well , shoot , is n't that i mean , that 's what grad c: well , i mean , my argument here is it 's it 's it 's the same thing as `` plato 's on the top shelf , `` grad f: figuring that out is what this is about . grad a: yeah , yeah , no , i i agree . grad c: i 'm con you know , th that you can refer to a book of plato by using `` plato , `` grad a: yeah . no no , i i 'm agreeing that this is a good , um grad c: and you can refer back to it , and so you can castles have as tourist sites , have admission fees , so you can say `` where is the castle , how much does it cost ? `` um . `` how far is it from here ? `` grad f: mm - hmm . grad c: so , you 're also not referring to the width of the object , or so , grad a: hmm . mm - hmm . grad c: www . grad f: mmm . professor e: ok . can we think of a nice metaphorical use of `` where `` in the tourist 's domain ? um . grad f: hmm . professor e: so you know it 's you you can sometimes use `` where `` f for `` when `` grad f: o professor e: in the sense of , you know , um , where wh where where was , um , `` where was heidelberg , um , in the thirty years ' war ? `` or something . grad c: mm - hmm . grad f: uh , yeah . professor e: you know , or some such thing . um . grad f: like what side were they on , grad a: what ? professor e: yeah . essentially , yeah . grad f: or ? grad a: ok . i was like , `` huh ? it was here . `` like { comment } um . professor e: but anyway th so there are there are cases like that . um , grad a: ah ! or like its developmental state or something like that , you could i guess you could get that . professor e: yeah . grad a: um . professor e: um . grad f: i mean , there 's also things like i mean , s um , i guess i could ask something like `` where can i find out about blah - blah - blah `` in a sort of does n't nece i do n't necessarily have to care about the spatial location , just give me a phone number professor e: yeah . there certainly is that , yeah . grad f: and i 'll call them or something like that ? professor e: you know , `` where could i learn its opening hours , `` or something . grad f: yeah . professor e: but that 's not metaphorical . grad a: hmm . professor e: it 's another grad f: yeah . professor e: so we 're thinking about , um , or we could also think about , uh grad c: well , i i i professor e: how about `` i 'm in a hurry `` ? grad a: state . professor e: it i but it 's a state and the the issue is , is that it may be just a usage , grad f: hmm ? professor e: you know , that it 's not particularly metaphorical , i do n't know . grad f: mmm . grad a: right . so you want a more exotic one version of that . grad f: oh . professor e: yeah . yeah , right . grad a: i 'm really into professor e: ah ! how about i i i you know , `` i 'm in i 'm in a state of exhaustion `` ? grad a: do you really say that ? professor e: or something like that , which a tourist w huh ? grad a: would you really say that ? professor e: a st uh , well , you can certainly say , um , you know , `` i 'm in overload . `` tu - stur tourists will often say that . grad f: yeah . grad d: i i 'm really into art . grad a: yeah , i was gon na say , like grad d: uh professor e: oh , you can do that ? really ? of course that 's that that 's definitely a , uh grad f: fixed . grad a: a fixed expression , yeah . professor e: that 's a , uh right . but . grad a: there 're too there 're all sorts of fixed expressions i do n't like uh `` i 'm out of sorts now ! `` professor e: right . grad a: like { comment } `` i 'm in trouble ! `` grad c: well i when , uh just f u the data that i 've looked at so far that rec professor e: yeah . grad c: i mean , there 's tons of cases for polysemy . professor e: right . grad a: uh - huh . grad c: so , you know , mak re making reference to buildings as institutions , as containers , as build professor e: right . grad c: you know , whatever . um , so ib in mus for example , in museums , you know , as a building or as something where pictures hang versus , you know , ev something that puts on exhibits , so forth . professor e: right . as an institution , grad c: but professor e: yeah . grad c: um . grad a: why do n't you want to use any of those ? grad c: hmm ? grad a: so y you do n't wan na use one that 's grad c: yeah , well no , but this that 's what i have , you know , started doing . professor e: the castle the that old castle one is sort of grad c: metonymy , polysemy . grad d: i love van gogh . professor e: yeah . grad a: `` i wan na go see the van gogh . `` professor e: ah ! grad f: oh geez . grad a: anyway , i 'm sorry . grad c: but i think the argument should be uh , can be made that , you know , despite the fact that this is not the most met metaphorical domain , because people interacting with hti systems try to be straightforward and less lyrical , professor e: yeah . grad c: construal still is , uh , you know , completely , um , key in terms of finding out any of these things , so , um . professor e: right . so that 's that 's that 's a that 's a reasonable point , that it in this domain you 're gon na get less metaphor and more metonymy . grad c: we , uh i with a i looked with a student i looked at the entire database that we have on heidelberg for cases of metonymy . professor e: and polysemy , and stuff like that . yeah . grad c: hardly anything . so not even in descriptions w did we find anything , um , relevant . grad f: i have to go . professor e: alright . yeah . grad c: but ok this is just something we 'll we 'll see , um , professor e: right . s see you . grad c: and deal with . professor e: ok , well . i guess if anybody has additional suggestions , grad c: i mean maybe the `` where is something `` question as a whole , you know , can be construed as , u i locational versus instructional request . professor e: w yeah . grad c: so , if we 're not talk about the lexic grad a: location versus what ? grad c: instruction . grad a: instruction . oh , directions ? yeah . professor e: sure . grad a: oh , i thought that was definitely treated as an example of construal . grad c: yeah . grad a: right ? grad c: yeah but then you 're not on the lexical level , that 's sort of one level higher . grad a: oh , you want a lexical example . grad c: but i do n't need it . professor e: well , you might want both . grad c: mm - hmm . grad a: yeah . grad c: also it would be nice to get ultimately to get a nice mental space example , professor e: we grad c: so , even temporal references are just in the spatial domain are rare . professor e: but it 's it 's easy to make up plausible ones . grad c: when when you 're getting information on objects . professor e: you know . grad c: so , i mean professor e: right , you know you know , where r yeah . what color was this in in in the nain nineteenth century . grad c: yeah . professor e: what was this p instead of wh what you know how was this painted , what color was this painted , um , was this alleyway open . grad c: yeah , maybe we can include that also in our second , uh , data run . professor e: uh . grad c: we c we can show people pictures of objects and then have then ask the system about the objects and engage in conversation on the history and the art and the architecture and so forth . professor e: mm - hmm . ok . so why do n't we plan to give you feedback electronically . wish you a good trip . all success . grad d: for some reason when you said `` feedback electronically `` i thought of that you ever see the simpsons where they 're like the family 's got the buzzers and they buzz each other when they do n't like what the other one is saying ? grad a: yeah . that 's the first one , i think . the very very first one . grad d: it was a very early one . i do n't know if it 's the first one . grad a: mmm . mmm .","output":"the thesis proposal presents the idea of `` construal '' and makes claims as to how inferences are drawn in a probabilistic relational model by using information from the ontology , situation , user and discourse models . it was advised that more emphasis should be put on the role of construal in the understanding of metaphor and metonymy ."},{"instruction":"what was said about eml talk ?","input":"grad a: ah , so comfortable . grad f: smooth . grad a: mm - hmm . good . i know that he 's going to like , taiwan and other places to eat . so . grad d: on ? am i on ? grad a: yep . yep . grad d: i think i 'm on ? grad b: yeah . grad d: good . good . grad a: bye . grad b: actually grad f: i just had one of the most frustrating meetings of my career . grad a: it 's definitely not the most frustrating meeting i 've ever had . grad d: you a you 're you remember you 're being recorded at this point . grad a: oh , yeah , so , w we did n't yet specify with whom . professor e: yeah . grad f: yeah . professor e: right . grad a: but um . professor e: uh , right . grad a: so that 's why keith and i are going to be a little dazed for the first half m the meeting . professor e: uh . grad f: huh . yeah , i 'm just gon na sit here and professor e: right . yeah , i i i avoided that as long as i could for you guys , grad f: growl . professor e: but , uh grad f: yeah . grad a: mm - hmm . grad f: for which we thank you , by the way . grad a: are very appreciative , yeah . professor e: right . grad f: i know you were you were doing that , but , anyway . grad d: oh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ? grad f: oh , i could tell you had a rough day , man ! grad d: nah . grad a: what ? grad d: i love that story . grad f: yeah , it 's a great story . grad c: ok . grad f: oh my goodness . grad c: oh yeah , um , liz suggested we could start off by uh , doing the digits all at the same time . grad a: what ? grad d: all at the same time . i do n't know if i would get distracted and confused , probably . professor e: e grad a: really ? do we have to like , synchronize ? professor e: well , i think you 're supposed to ok . we can do this . grad f: are you being silly ? grad d: oh wait do we have t professor e: everybody 's got different digits , grad c: yep . professor e: right ? grad d: yeah , do we have to time them at the same time or just overlapping grad f: uh . grad a: you 're kidding . grad c: no , no , just just start whenever you want . professor e: no . grad a: and any rate ? professor e: e yeah , the grad f: alright . professor e: well , they they have s they have the close talking microphones for each of us , grad a: yeah , that 's true . professor e: so grad c: yeah . professor e: yeah , there 's separate channels . grad f: alright . grad a: ok . grad c: yeah . professor e: so when i say grad f: just plug one ear . grad a: you lose . professor e: ok . grad f: ok , bye ! that was a great meeting ! professor e: right . grad d: alright . grad f: so - now , uh , why ? grad c: just to save time . grad f: ok . grad c: does matter for them . grad a: are we gon na start all our meetings out that way from now on ? professor e: no . grad a: oh . too bad . i kinda like it . grad f: well , could we ? grad d: it 's strangely satisfying . grad a: yeah . it 's a ritual . grad d: are we to r just to make sure i know what 's going on , we 're talking about robert 's thesis proposal today ? is that grad c: we could . grad d: true ? grad a: we are ? grad c: we might . grad a: ok . grad d: is professor e: well , you you had s you said there were two things that you might wan na do . one was rehearse your i i talk grad d: oh yes , and that too . grad c: not not rehearse , i mean , i have just not spent any time on it , so i can show you what i 've got , get your input on it , and maybe some suggestions , that would be great . and the same is true for the proposal . i will have time to do some revision and some additional stuff on various airplanes and trains . so , um . i do n't know how much of a chance you had to actually read it grad a: i have n't looked at it grad c: because grad a: yet , grad c: but you could always send me comments per electronic mail grad a: but i will . grad c: and they will be incorporated . grad a: ok . grad c: um , the it basically says , well `` this is construal `` , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model to do some inferences in terms of what is being construed as what grad a: hmm . grad c: in our beloved tourism domain . but , with a focus on grad a: can i s sorry . grad f: i think i need a copy of this , yes . grad c: hmm ? grad d: ok , we can we can we can pass pass my , uh we can pass my extra copy around . grad f: i is there an extra copy around ? grad a: uh . he sent it . ok . you can keep it . grad d: er , actually , my only copy , now that i think about it , grad f: alrigh grad a: ok . grad c: um , i do n't i , uh i do n't need it . grad d: but . i already read half of it , so it 's ok . grad c: um , actually this is the the newest version after your comments , grad f: ok . grad c: and professor e: yeah , no i s i s i see this has got the castle in it , and stuff like that . grad c: yeah . professor e: yep . grad d: oh , maybe the version i did n't have that i mine the w did the one you sent on the email have the professor e: yeah . grad d: that was the most recent one ? professor e: uh , yeah , i think so . grad c: yep . grad d: ok . cuz i read halfway but i did n't see a castle thing . grad a: i 'm changing this . just so you know . grad c: yeah , grad a: but , anyway . grad c: um , if you would have checked your email you may have received a note from yees asking you to send me the , uh , up - to - d grad a: oh . oh , sorry . ok . sorry . grad c: current formalism thing that you presented . grad a: ok . i will . ok . ok . ok . grad c: but for this it does n't matter . but , uh grad a: we can talk about it later . that 's not even ready , so . um , ok ! go on t to , uh , whatever . grad c: and grad a: i 'm making changes . `` do n't worry about that . `` ok . mmm - mmm . oh ! ok , sorry , go on . grad c: and any type of comment whether it 's a spelling or a syntax or grad a: mm - hmm . grad c: readability grad f: there 's only one `` s `` in `` interesting `` . grad c: hmm ? grad f: there 's only one `` s `` in `` interesting `` . on page five . grad c: interesting . grad a: anyway . and y uh , email any time , but most usefully before grad d: the twenty - first i 'm assuming . grad a: the twenty - first ? grad c: twenty - ninth . professor e: no , this is the twenty - first . grad f: that 's grad d: what , today 's the twenty - first ? grad f: well , better hurry up then ! grad d: oh , man ! grad a: before the twenty - ninth , grad c: the twenty - ninth . grad a: ok . grad d: ok . grad c: that 's when i 'm meeting with wolfgang wahlster to sell him this idea . grad a: mm - hmm . ok . grad c: ok ? then i 'm also going to present a little talk at eml , about what we have done here and so of course , i 'm i 'm gon na start out with this slide , so the most relevant aspects of our stay here , and um , then i 'm asking them to imagine that they 're standing somewhere in heidelberg and someone asks them in the morning the cave forty - five is a is a well - known discotheque which is certainly not open at that that time . and so grad f: ok . grad c: they 're supposed to imagine that , you know , do they think the person wants to go there , or just know where it is ? uh , which is probably not , uh , the case in that discotheque example , or in the bavaria example , you just want to know where it is . and so forth . so basically we can make a point that here is ontological knowledge but if it 's nine nine pm in the evening then the discotheque question would be , for example , one that might ask for directions instead of just location . um , and so forth and so forth . that 's sort of motivating it . then what have we done so far ? we had our little bit of , um , um , smartkom stuff , that we did , um , everth grad f: oh , you 've got the parser done . sorry . grad c: that 's the not the construction parser . that 's the , uh , tablet - based parser , grad f: ok . grad a: easy parser . grad f: ok . grad c: and the generation outputter . grad d: halfway done ? yeah . grad c: that 's done . grad a: mmm . grad c: you have to change those strategies , grad d: ok . grad c: right ? that 's , ten words ? grad d: yeah . well , i it , you know . maybe twelve . grad c: twelve ? ok . and , um , and fey is doing the synthesis stuff as we speak . that 's all about that . then i 'm going to talk about the data , you know these things about uh , actually i have an example , probably . two s can you hear that ? or should i turn the l volume on . grad f: mm - hmm . grad a: i could hear it . grad d: i i can hear it . grad f: i heard it . grad d: they might not hear it in the well maybe they will . i do n't know . grad a: this was an actual , um , subject ? ah . grad c: mm - hmm . grad f: sounds like fey . grad a: yeah . grad c: but they 're they 're mimicking the synthesis when they speak to the computer , grad f: oh , ok . grad c: the you can observe that all the time , they 're trying to match their prosody onto the machine . grad f: oh really . interesting . oh , it 's pretty slow . grad c: yeah , you have to grad a: wh grad f: the system breaking . grad a: what is the s ? oh ! grad c: ok . and so forth and so forth . um , i will talk about our problems with the rephrasing , and how we solved it , and some preliminary observations , also , um , i 'm not gon na put in the figures from liz , but i thought it would interesting to , uh , um , point out that it 's basically the same . um , as in every human - human telephone conversation , and the human - computer telephone conversation is of course quite d quite different from , uh , some first , uh , observations . then sort of feed you back to our original problem cuz , uh how to get there , what actually is happening there today , and then maybe talk about the big picture here , e tell a little bit as much as i can about the ntl story . i i wa i do wan na , um i 'm not quite sure about this , whether i should put this in , um , that , you know , you have these two sort of different ideas that are or two different camps of people envisioning how language understanding works , and then , talk a bit about the embodied and simulation approach favored here and as a prelude , i 'll talk about monkeys in italy . and , um , srini was gon na send me some slides but he did n't do it , so from but i have the paper , i can make a resume of that , and then i stole an x - schema from one of your talks i think . grad a: oh . i was like , `` where 'd you get that ? `` ok . grad f: yeah , that looks familiar . grad a: `` looks familiar . `` grad c: i think that 's bergen , chang , something , or the other . grad a: uh . professor e: whatever . grad a: ok . grad c: um , and that 's now i 'm not going to bring that . so that 's basically what i have , so far , and the rest is for airplanes . so x - schemas , then , i would like to do talk about the construction aspect and then at the end about our bayes - net . grad a: mm - hmm . grad c: end of story . anything i forgot that we should mention ? oh , maybe the fmri stuff . should i mention the fact that , um , we 're also actually started going to start to look at people 's brains in a more direct way ? professor e: you certainly can . i mean i y i you know , i do n't know grad a: you might just wan na like , tack that on , as a comment , to something . professor e: right , um . grad c: `` future activities `` something . professor e: well , the time to mention it , if you mention it , is when you talk about mirror neurons , then you should talk about the more recent stuff , about the kicking grad c: yeah . professor e: and , you know , the yeah , yeah and that the plan is to see to what extent the you 'll get the same phenomena with stories about this , so that grad c: mm - hmm . professor e: and that we 're planning to do this , um , which , we are . so that 's one thing . um . depends . i mean , there is a , um , whole language learning story , ok ? grad c: yeah . professor e: which , uh , actually , i i even on your five - layer slide , you you 've got an old one that that leaves that off . grad c: yeah , i i i do have it here . grad a: hmm . professor e: yeah . grad c: um . and , of course , you know , the the big picture is this bit . professor e: right . grad c: but , you know , it would but i do n't think i i am capable of of do pulling this off and doing justice to the matter . i mean , there is interesting stuff in her terms of how language works , so the emergentism story would be nice to be you know , it would be nice to tell people how what 's happening there , plus how the , uh , language learning stuff works , professor e: ok , so , so anyway , i i agree that 's not central . grad c: but grad a: mm - hmm . professor e: what you might wan na do is , um , and may not , but you might wan na this is rip off a bunch of the slides on the anal there the there we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , and , um , how the construction and simulation that ho that whole th grad c: yeah , th that that 's c that comes up to the x - schema slide , grad a: ok , right . grad c: so basically i 'm gon na steal that from nancy , grad a: ok , i can give you a more recent if you want grad c: one of nancy 's st grad a: well , that might have enough . grad c: uh , i yeah , but i also have stuff you trash you left over , professor e: ok . grad c: your quals and your triple - ai . professor e: the quals w the the the quals slides would be fine . grad a: yeah . professor e: you could get it out of there , or some grad a: which i can even email you then , you know , like there probably was a little few changes , not a big deal . yeah , you could steal anything you want , i do n't care . which you 've already done , obviously . so . sorry grad c: well , i i do n't feel bad about it at all grad a: no , you should n't . grad c: because because you are on the , uh , title . grad a: oh , that 's great , that 's great . grad c: i mean on the the , you 're that 's see , that 's you . grad a: i 'm glad to see propagation . professor e: yeah . yeah . grad a: mmm . grad c: hmm ? propagated ? grad a: yes . grad c: i mean i might even mention that this work you 're doing is sort of also with the mpi in leipzig , so . grad a: it 's it 's certainly related , um , grad c: because , um , eml is building up a huge thing in leipzig . grad a: might wan na say . is it ? grad c: so it it 's on biocomputation . would professor e: yeah , it 's different , this is the , uh , dna building , or someth the double helix building . grad c: yeah . professor e: yeah . grad a: kind of a different level of analysis . professor e: the yeah it was it turns out that if if you have multiple billions of dollars , y you can do all sorts of weird things , and grad d: wait , they 're building a building in the shape of dna , grad a: what ? grad d: is that what you said ? professor e: roughly , yeah . grad f: oh ! oh boy ! grad a: o professor e: including cr cross - bridges , grad a: what ? professor e: and grad a: oh my god ! grad f: that 's brilliant ! hhh . professor e: you d you really now i i spent the last time i was there i spent maybe two hours hearing this story which is , um grad a: of what grad d: y you definitely wan na w do n't wan na waste that money on research , grad a: the building ? grad d: you know ? professor e: right . grad d: that 's horrible . professor e: right . well , no , no , y i there 's infinite money . see you th you th you then fill it with researchers . grad a: and give them more money . they just want a fun place for them to to work . professor e: right . right . grad f: and everybody gets a trampoline in their office . grad c: well , the the offices are actually a little the , think of um , ramps , coming out of the double helix and then you have these half - domes , glass half - domes , and the offices are in in the glass half - dome . grad a: really ? professor e: yeah . grad f: alright , let 's stop talking about this . grad a: does it exist yet ? professor e: yeah . grad a: they are w now building it ? grad c: uh , as a model . grad a: hmm . grad c: but i th professor e: so , yeah , i think that 's that 's a good point , th th that the date , the , uh , a lot of the this is interacting with , uh , people in italy but also definitely the people in leipzig and the the b the combination of the biology and the leipzig connection might be interesting to these guys , yeah . ok . ok . anyway ! enough of that , let 's talk about your thesis proposal . grad c: yeah , if somebody has something to say . professor e: yep . grad f: you might want to , uh , double - check the spellings of the authors ' names on your references , you had a few , uh , misspells in your slides , there . like i believe you had `` jackendorf `` . professor e: um . grad f: uh , unless there 's a person called `` jackendorf `` , grad a: on that one ? professor e: no , no , no . grad f: yeah . but that 's the only thing i noticed in there . grad a: in the presentation ? grad f: in the presentation . grad a: i 'll probably i c might have i 'll probably have comments for you separately , not important . anyway . grad c: oh , in the presentation here . grad a: yeah , that 's what he was talking about . grad f: yeah . grad c: i was ac actually worried about bibtex . uh . no , that 's quite possible . that 's copy and paste from something . professor e: so i did note i i it looks like the , uh , metaphor did n't get in yet . grad c: uh , it did , there is a reference to srini professor e: well , s reference is one thing , the question is is there any place oh , did you put in something about , grad a: metonymy and metaphor here , right ? professor e: uh , the individual , we 'd talked about putting in something about people had , uh oh yeah , ok . good . i see where you have it . so the top of the second of pa page two you have a sentence . grad c: mm - hmm . professor e: but , what i meant is , i think even before you give this , to wahlster , uh , you should , unless you put it in the text , and i do n't think it 's there yet , about we talked about is the , um , scalability that you get by , um , combining the constructions with the general construal mechanism . is that in there ? grad c: yeah , mmm . um . professor e: uh , ok , so where where is it , cuz i 'll have to take a look . grad c: um , but i i did not focus on that aspect but , um ehhh , um , it 's just underneath , uh , um , that reference to metaphor . so it 's the last paragraph before two . so on page two , um , the main focus professor e: uh , ok . yeah . grad c: but that 's really grad a: that 's not about that , is it ? grad c: yeah . professor e: no , it it it s says it but it does n't say it does n't it d it d grad c: why . professor e: yeah , it does n't give the punch line . grad c: mm - hmm . professor e: cuz let me tell the gang what i think the punch line is , because it 's actually important , which is , that , the constructions , that , uh , nancy and keith and friends are doing , uh , are , in a way , quite general but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . and the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at at the base level , it should com uh , interact with all the metonymies and metaphors so that all of the projections of it also should work . grad f: mm - hmm . professor e: and , similarly , if you introduce a new metaphor , it should then uh , compose with all of the constructions . grad f: mm - hmm . yeah . professor e: and it to the extent that that 's true then then it 's a big win over anything that exists . grad d: so does that mean instead of having tons and tons of rules in your context - free grammar you just have these base constructs and then a general mechanism for coercing them . grad f: yeah . professor e: mm - hmm . so that , you know , for example , uh , in the metaphor case , that you have a kind of direct idea of a source , path , and goal and any metaphorical one and abstract goals and all that sort of stuff { comment } you can do the same grammar . grad d: mmm . professor e: and it is the same grammar . but , um , the trick is that the the way the construction 's written it requires that the object of the preposition for example be a container . well , `` trouble `` is n't a container , but it gets constr construed as a c container . grad d: right . professor e: et cetera . so that 's that 's where this , um , grad d: so with construal you do n't have to have a construction for every possible thing that can fill the rule . professor e: right . so 's it 's it it 's a very big deal , i i in this framework , and the thesis proposal as it stands does n't , um , i do n't think , say that as clearly as it could . grad c: no , it does n't say it at all . no . even though one could argue what if there are basic cases , even . i mean , it seems like nothing is context - free . professor e: oh , nothing is context - free , but there are basic cases . that is , um , there are physical containers , there are physical paths , there you know , et cetera . grad c: but `` walked into the cafe and ordered a drink , `` and `` walked into the cafe and broke his nose , `` that 's sort of professor e: oh , it does n't mean that they 're unambiguous . grad c: mmm . yeah . professor e: i mean , a cafe can be construed as a container , or it can be construed you know as as a obstacle , grad f: uh - huh . professor e: or as some physical object . so there are multiple construals . and in fact that 's part of what has to be done . this is why there 's this interaction between the analysis and the construal . grad c: mm - hmm . yep . professor e: the b the the double arrow . grad c: yep . professor e: so , uh , yeah , i mean , it does n't magically make ambiguity go away . grad c: no . professor e: but it does say that , uh , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle . grad c: mm - hmm . professor e: and if that 's not consistent with other things , then you 've got ta reject that reading . grad c: yep . grad d: you con you conditioned me with your first sentence , and so i thought , `` why would he walk into the cafe and then somehow break his nose ? `` uh , oh , uh grad f: he slipped on the wet floor . professor e: right . grad c: you do n't find that usage , uh uh , i checked for it in the brown national corpus . professor e: yeah . grad c: the `` walk into it `` never really means , w as in walked smack professor e: but `` run into `` does . grad c: yeah , but , y y if you find `` walked smacked into the cafe `` or `` slammed into the wall `` professor e: yeah , no , but `` run into `` does . grad c: mm - hmm . professor e: because you will find `` run into , `` uh , grad d: cars run into telephone poles all the time . professor e: well , or `` into the cafe `` for that m grad c: right . professor e: you know `` his car ran into the cafe . `` grad c: yeah . or you can run into an old friend , or run . professor e: well , you can `` run into `` in that sense too . grad a: yeah , `` run into `` might even be more impact sense than , you know , container sense . professor e: but , uh , right . grad f: depends . professor e: but like , `` run into an old friend `` , it probably needs its own construction . i mean , uh , you know , george would have i 'm sure some exa complicated ex reason why it really was an instance of something else grad a: mm - hmm . mm - hmm . professor e: and maybe it is , but , um , there are idioms and my guess is that 's one of them , but , um i do n't know . grad a: all contact . i mean , there there 's contact that does n't social contact , whatever . i mean . professor e: uh . grad f: sudden surprising contact , professor e: yeah , but it 's it 's it 's it 's right . i yeah , it 's more grad f: right ? grad a: forceful . grad f: but of course , no , i i i mean it has a life of its own . it 's sort of partially inspired by the spatial professor e: well , this is this motivated but yeah grad f: yeah . professor e: oh yeah , mo for sure , motivated , but then you ca n't parse on motivated . grad f: yeah . yeah . right . professor e: uh , grad a: too bad . grad d: you should get a t - shirt that says that . professor e: ok . grad a: there 's there 's lots of things you could make t - shirts out of , but , uh , this has gotten i mean wh we do n't need the words to that . grad c: pro - probably not your marks in the kitchen , today . grad a: what ? oh , no no no no no no no no no , we 're not going there . grad c: not not your marks . grad a: ok . professor e: ok , so , um , grad f: in other news . professor e: anything else you want to ask us about the thesis proposal , you got grad c: well , professor e: we could look at a particular thing and give you feedback on it . grad c: well there actually the i what would have been really nice is to find an example for all of this , uh , from our domain . so maybe if we w if we can make one up now , that would be c incredibly helpful . grad a: so , w where it should illustrate professor e: ok . grad a: uh wh when you say all this , do you mean , like , i do n't know , the related work stuff , grad c: how grad a: as well as , mappings ? grad c: w well we have , for example , a canonical use of something professor e: right right r grad c: and y it 's , you know , we have some constructions and then it 's construed as something , and then we we may get the same constructions with a metaphorical use that 's also relevant to the to the domain . professor e: ok , f let 's let 's suppose you use `` in `` and `` on `` . i mean , that 's what you started with . grad c: mm - hmm . professor e: so `` in the bus `` and `` on the bus , `` um , that 's actually a little tricky in english because to some extent they 're synonyms . ok . grad c: i had two hours w with george on this , so it , professor e: ok , what did he say . grad a: did you ? grad c: um um . grad a: join the club . professor e: right . oh , h that 's grad c: `` on the bus `` is a m is a metaphorical metonymy that relates some meta path metaphorically and you 're on on that path and th w i mean it 's he there 's a platform notion , professor e: yeah , i i believe all that , it 's just grad c: right ? `` he 's on the standing on the bus waving to me . `` professor e: yeah . grad c: but th the regular as we speak `` j johno was on the bus to new york , `` professor e: yeah . yeah . grad c: um , uh , he 's that 's , uh , what did i call it here , the transportation schema , something , professor e: yeah . grad c: where you can be on the first flight , on the second flight , professor e: yeah . grad c: and you can be , you know , on the wagon . professor e: right . so so that that may or may not be what you what you want to do . i mean you could do something much simpler grad c: yeah . professor e: like `` under the bus , `` or something , where grad c: but it 's it 's unfortunately , this is not really something a tourist would ever say . so . professor e: well , unless he was repairing it or something , grad c: yeah . professor e: but yeah . grad c: but um . professor e: uh , but ok . grad c: so in terms of the this grad a: i see . grad c: we had we had initially we 'd started discussing the `` out of film . `` professor e: right . grad c: and there 's a lot of `` out of `` analysis , so , um , professor e: right . grad c: could we capture that with a different construal of grad a: yeah , it 's a little it 's , uh we 've thought about it before , uh t uh to use the examples in other papers , and it 's it 's a little complicated . cuz you 're like , it 's a state of there 's resource , grad f: out of out of film , in particular . grad a: right , and like , what is film , grad f: yeah . grad a: the state you know . you 're out of the state of having film , right ? and somehow film is standing for the re the resour the state of having some resource is just labeled as that resource . grad f: it 's grad a: i mean . grad f: yeah , i mean , grad a: it 's a little bit grad f: but and plus the fact that there 's also s i mean , can you say , like , `` the film ran out `` you know , or , maybe you could say something like `` the film is out `` grad a: yeah , is film the trajector ? grad f: so like the the film went away from where it should be , namely with you , or something , right ? you know . the the film the film is gone , right ? um , i never really knew what was going on , i mean i i find it sort of a little bit farfetched to say that that `` i 'm out of film `` means that i have left the state of having film or something like that , grad a: it 's weird . that grad f: but . grad a: or , `` having `` is also , um , associated with location , professor e: uh . grad a: right ? grad f: yeah . yeah . grad a: so if the film left , you know state is being near film . grad c: so running running out of something is different from being out of somewhere . professor e: or being out of something as , uh as well . so `` running out of it `` definitely has a process aspect to it . grad a: mm - hmm . but that 's from run , yeah . professor e: so , grad f: mm - hmm . professor e: b that 's ok , grad a: yeah . professor e: i mean b but the difference grad c: is the d the final state of running out of something is being out of it . professor e: is grad a: yeah . so th professor e: right . grad f: yeah . you got there . grad a: that part is fine . grad f: you got to out of it . professor e: yeah . grad f: yeah . professor e: but , uh grad f: hmm ! professor e: yeah , so so nob so no one has in in of the , uh , professional linguists , grad a: uh . professor e: they have n't there was this whole thesis on `` out of `` . grad a: there was ? who ? professor e: well , there i thought or there was a paper on it . grad f: out . professor e: huh ? grad f: there was one on on `` out `` or `` out of `` ? professor e: there was a well , it may be just `` out `` . yeah . grad f: ok . professor e: i think there was `` over `` but there was also a paper on `` out `` . grad f: yeah , lind - susan lindner , grad a: oh , yeah , you 're right . yeah . professor e: or something . grad f: right ? the the `` the syrup spread out `` ? professor e: yeah , and all that sort of stuff . grad f: that kind of thing ? grad a: yeah . and undoubtably there 's been reams of work about it in cognitive linguistics , professor e: ok . but anyway . we 're not gon na do that between now and next week . grad a: but . yeah . grad c: yeah . professor e: ok . so , um grad a: it 's not one of the y it 's more straightforward ones forward ones to defend , so you probably do n't want to use it for the purposes grad c: mm - hmm . professor e: right . grad a: th these are you 're addressing like , computational linguists , professor e: ok . grad a: right . or are you ? grad c: there 's gon na be four computational linguists , grad a: ok . but more emphasis on the computational ? or emphasis on the linguist ? grad c: computer it 's more there 's going to be the just four computational linguists , by coincidence , but the rest is , whatever , biocomputing people and physicists . grad a: oh , ok . professor e: no no no , but not for your talk . i 'm - we 're worrying about the th the thes grad c: oh , the thesis ! grad a: oh , i meant this , professor e: it 's just for one guy . grad c: that 's that 's computa should be very computational , grad a: you know , like ok . so i would try to i would stay away from one that involves weird construal stuff . grad c: and , uh , someth professor e: yeah . grad f: yeah . professor e: right . grad a: you know , it 's an obvious one grad f: totally weird stuff . grad c: i mean the the old bakery example might be nice , grad a: but , uh grad c: `` is there a bakery around here `` . so if you c we really just construe it as a grad f: yeah . grad a: around ? grad c: no , it 's the bakery itself grad a: oh . grad c: is it a building ? uh , that you want to go to ? or is it something to eat that you want to buy ? grad a: oh , oh yeah . yeah , we 've thought about that . right . right . grad c: and then grad a: nnn . no . what ? `` bakery `` ca n't be something you 're gon na eat . professor e: no , no . the question is d do you wan na do you wan na construe do you wan na constr - strue grad f: sh grad d: it 's a speech - act . professor e: r exactly . it 's because do you wan na c do you want to view the bakery as a p a place that that i for example , if y grad a: yeah . where you can get baked goods . professor e: well th well , that 's one . you want to buy something . but the other is , uh , yo you might have smelled a smell and are just curious about whether there 'd be a bakery in the neighborhood , or , grad f: mm - hmm . professor e: um , pfff you know , you wonder how people here make their living , and there 're all sorts of reasons why you might be asking about the existence of a bakery grad f: yeah . professor e: that does n't mean , `` i want to buy some baked goods . `` grad a: ok . professor e: but um , those are interesting examples but it 's not clear that they 're mainly construal examples . grad a: so it 's a lot of pragmatics , there , that grad f: yeah . grad c: mmm . professor e: there 's all sorts of stuff going on . grad a: might be beyond what you want to do . professor e: so let 's so let 's think about this from the point of view of construal . so let 's first do a so the metonymy thing is probably the easiest and a and actually the though , the one you have is n't quite grad a: you mean the s you mean `` the steak wants to pay `` ? professor e: n no not that one , that 's that 's a the sort of background . this is the t uh , page five . grad d: about plato and the book ? grad a: oh . professor e: no . grad a: um . grad c: no . grad a: how much does it cost ? professor e: just beyond that . grad f: onward . grad c: where is the castle ? professor e: yeah . grad f: a castle . grad c: how old is it ? how much does it cost ? grad d: oh . grad f: mm - hmm . grad a: to go in , that 's like grad f: two hundred million dollars . professor e: right . it 's not for sale . uh . so grad f: yeah , i think that 's a good example , actually . grad c: s grad a: yeah , that 's good . u grad c: but as nancy just su suggested it 's probably ellipticus . grad a: ellipsis . grad c: huh . grad a: like , `` it `` does n't refer to `` thing , `` it refers to acti you know , j thing standing for activ most relevant activity for a tourist you could think of it that way , but . professor e: yeah . grad f: well , shoot , is n't that i mean , that 's what grad c: well , i mean , my argument here is it 's it 's it 's the same thing as `` plato 's on the top shelf , `` grad f: figuring that out is what this is about . grad a: yeah , yeah , no , i i agree . grad c: i 'm con you know , th that you can refer to a book of plato by using `` plato , `` grad a: yeah . no no , i i 'm agreeing that this is a good , um grad c: and you can refer back to it , and so you can castles have as tourist sites , have admission fees , so you can say `` where is the castle , how much does it cost ? `` um . `` how far is it from here ? `` grad f: mm - hmm . grad c: so , you 're also not referring to the width of the object , or so , grad a: hmm . mm - hmm . grad c: www . grad f: mmm . professor e: ok . can we think of a nice metaphorical use of `` where `` in the tourist 's domain ? um . grad f: hmm . professor e: so you know it 's you you can sometimes use `` where `` f for `` when `` grad f: o professor e: in the sense of , you know , um , where wh where where was , um , `` where was heidelberg , um , in the thirty years ' war ? `` or something . grad c: mm - hmm . grad f: uh , yeah . professor e: you know , or some such thing . um . grad f: like what side were they on , grad a: what ? professor e: yeah . essentially , yeah . grad f: or ? grad a: ok . i was like , `` huh ? it was here . `` like { comment } um . professor e: but anyway th so there are there are cases like that . um , grad a: ah ! or like its developmental state or something like that , you could i guess you could get that . professor e: yeah . grad a: um . professor e: um . grad f: i mean , there 's also things like i mean , s um , i guess i could ask something like `` where can i find out about blah - blah - blah `` in a sort of does n't nece i do n't necessarily have to care about the spatial location , just give me a phone number professor e: yeah . there certainly is that , yeah . grad f: and i 'll call them or something like that ? professor e: you know , `` where could i learn its opening hours , `` or something . grad f: yeah . professor e: but that 's not metaphorical . grad a: hmm . professor e: it 's another grad f: yeah . professor e: so we 're thinking about , um , or we could also think about , uh grad c: well , i i i professor e: how about `` i 'm in a hurry `` ? grad a: state . professor e: it i but it 's a state and the the issue is , is that it may be just a usage , grad f: hmm ? professor e: you know , that it 's not particularly metaphorical , i do n't know . grad f: mmm . grad a: right . so you want a more exotic one version of that . grad f: oh . professor e: yeah . yeah , right . grad a: i 'm really into professor e: ah ! how about i i i you know , `` i 'm in i 'm in a state of exhaustion `` ? grad a: do you really say that ? professor e: or something like that , which a tourist w huh ? grad a: would you really say that ? professor e: a st uh , well , you can certainly say , um , you know , `` i 'm in overload . `` tu - stur tourists will often say that . grad f: yeah . grad d: i i 'm really into art . grad a: yeah , i was gon na say , like grad d: uh professor e: oh , you can do that ? really ? of course that 's that that 's definitely a , uh grad f: fixed . grad a: a fixed expression , yeah . professor e: that 's a , uh right . but . grad a: there 're too there 're all sorts of fixed expressions i do n't like uh `` i 'm out of sorts now ! `` professor e: right . grad a: like { comment } `` i 'm in trouble ! `` grad c: well i when , uh just f u the data that i 've looked at so far that rec professor e: yeah . grad c: i mean , there 's tons of cases for polysemy . professor e: right . grad a: uh - huh . grad c: so , you know , mak re making reference to buildings as institutions , as containers , as build professor e: right . grad c: you know , whatever . um , so ib in mus for example , in museums , you know , as a building or as something where pictures hang versus , you know , ev something that puts on exhibits , so forth . professor e: right . as an institution , grad c: but professor e: yeah . grad c: um . grad a: why do n't you want to use any of those ? grad c: hmm ? grad a: so y you do n't wan na use one that 's grad c: yeah , well no , but this that 's what i have , you know , started doing . professor e: the castle the that old castle one is sort of grad c: metonymy , polysemy . grad d: i love van gogh . professor e: yeah . grad a: `` i wan na go see the van gogh . `` professor e: ah ! grad f: oh geez . grad a: anyway , i 'm sorry . grad c: but i think the argument should be uh , can be made that , you know , despite the fact that this is not the most met metaphorical domain , because people interacting with hti systems try to be straightforward and less lyrical , professor e: yeah . grad c: construal still is , uh , you know , completely , um , key in terms of finding out any of these things , so , um . professor e: right . so that 's that 's that 's a that 's a reasonable point , that it in this domain you 're gon na get less metaphor and more metonymy . grad c: we , uh i with a i looked with a student i looked at the entire database that we have on heidelberg for cases of metonymy . professor e: and polysemy , and stuff like that . yeah . grad c: hardly anything . so not even in descriptions w did we find anything , um , relevant . grad f: i have to go . professor e: alright . yeah . grad c: but ok this is just something we 'll we 'll see , um , professor e: right . s see you . grad c: and deal with . professor e: ok , well . i guess if anybody has additional suggestions , grad c: i mean maybe the `` where is something `` question as a whole , you know , can be construed as , u i locational versus instructional request . professor e: w yeah . grad c: so , if we 're not talk about the lexic grad a: location versus what ? grad c: instruction . grad a: instruction . oh , directions ? yeah . professor e: sure . grad a: oh , i thought that was definitely treated as an example of construal . grad c: yeah . grad a: right ? grad c: yeah but then you 're not on the lexical level , that 's sort of one level higher . grad a: oh , you want a lexical example . grad c: but i do n't need it . professor e: well , you might want both . grad c: mm - hmm . grad a: yeah . grad c: also it would be nice to get ultimately to get a nice mental space example , professor e: we grad c: so , even temporal references are just in the spatial domain are rare . professor e: but it 's it 's easy to make up plausible ones . grad c: when when you 're getting information on objects . professor e: you know . grad c: so , i mean professor e: right , you know you know , where r yeah . what color was this in in in the nain nineteenth century . grad c: yeah . professor e: what was this p instead of wh what you know how was this painted , what color was this painted , um , was this alleyway open . grad c: yeah , maybe we can include that also in our second , uh , data run . professor e: uh . grad c: we c we can show people pictures of objects and then have then ask the system about the objects and engage in conversation on the history and the art and the architecture and so forth . professor e: mm - hmm . ok . so why do n't we plan to give you feedback electronically . wish you a good trip . all success . grad d: for some reason when you said `` feedback electronically `` i thought of that you ever see the simpsons where they 're like the family 's got the buzzers and they buzz each other when they do n't like what the other one is saying ? grad a: yeah . that 's the first one , i think . the very very first one . grad d: it was a very early one . i do n't know if it 's the first one . grad a: mmm . mmm .","output":"the talk will present the work that is currently being done at icsi including examples of inference of user intentions and of the recordings of the on-going data collection . the talk will also outline the theoretical ( x-schemas , image schemas , bayes-nets ) and neural background ."},{"instruction":"what was said about the talk and neurons ?","input":"grad a: ah , so comfortable . grad f: smooth . grad a: mm - hmm . good . i know that he 's going to like , taiwan and other places to eat . so . grad d: on ? am i on ? grad a: yep . yep . grad d: i think i 'm on ? grad b: yeah . grad d: good . good . grad a: bye . grad b: actually grad f: i just had one of the most frustrating meetings of my career . grad a: it 's definitely not the most frustrating meeting i 've ever had . grad d: you a you 're you remember you 're being recorded at this point . grad a: oh , yeah , so , w we did n't yet specify with whom . professor e: yeah . grad f: yeah . professor e: right . grad a: but um . professor e: uh , right . grad a: so that 's why keith and i are going to be a little dazed for the first half m the meeting . professor e: uh . grad f: huh . yeah , i 'm just gon na sit here and professor e: right . yeah , i i i avoided that as long as i could for you guys , grad f: growl . professor e: but , uh grad f: yeah . grad a: mm - hmm . grad f: for which we thank you , by the way . grad a: are very appreciative , yeah . professor e: right . grad f: i know you were you were doing that , but , anyway . grad d: oh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ? grad f: oh , i could tell you had a rough day , man ! grad d: nah . grad a: what ? grad d: i love that story . grad f: yeah , it 's a great story . grad c: ok . grad f: oh my goodness . grad c: oh yeah , um , liz suggested we could start off by uh , doing the digits all at the same time . grad a: what ? grad d: all at the same time . i do n't know if i would get distracted and confused , probably . professor e: e grad a: really ? do we have to like , synchronize ? professor e: well , i think you 're supposed to ok . we can do this . grad f: are you being silly ? grad d: oh wait do we have t professor e: everybody 's got different digits , grad c: yep . professor e: right ? grad d: yeah , do we have to time them at the same time or just overlapping grad f: uh . grad a: you 're kidding . grad c: no , no , just just start whenever you want . professor e: no . grad a: and any rate ? professor e: e yeah , the grad f: alright . professor e: well , they they have s they have the close talking microphones for each of us , grad a: yeah , that 's true . professor e: so grad c: yeah . professor e: yeah , there 's separate channels . grad f: alright . grad a: ok . grad c: yeah . professor e: so when i say grad f: just plug one ear . grad a: you lose . professor e: ok . grad f: ok , bye ! that was a great meeting ! professor e: right . grad d: alright . grad f: so - now , uh , why ? grad c: just to save time . grad f: ok . grad c: does matter for them . grad a: are we gon na start all our meetings out that way from now on ? professor e: no . grad a: oh . too bad . i kinda like it . grad f: well , could we ? grad d: it 's strangely satisfying . grad a: yeah . it 's a ritual . grad d: are we to r just to make sure i know what 's going on , we 're talking about robert 's thesis proposal today ? is that grad c: we could . grad d: true ? grad a: we are ? grad c: we might . grad a: ok . grad d: is professor e: well , you you had s you said there were two things that you might wan na do . one was rehearse your i i talk grad d: oh yes , and that too . grad c: not not rehearse , i mean , i have just not spent any time on it , so i can show you what i 've got , get your input on it , and maybe some suggestions , that would be great . and the same is true for the proposal . i will have time to do some revision and some additional stuff on various airplanes and trains . so , um . i do n't know how much of a chance you had to actually read it grad a: i have n't looked at it grad c: because grad a: yet , grad c: but you could always send me comments per electronic mail grad a: but i will . grad c: and they will be incorporated . grad a: ok . grad c: um , the it basically says , well `` this is construal `` , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model to do some inferences in terms of what is being construed as what grad a: hmm . grad c: in our beloved tourism domain . but , with a focus on grad a: can i s sorry . grad f: i think i need a copy of this , yes . grad c: hmm ? grad d: ok , we can we can we can pass pass my , uh we can pass my extra copy around . grad f: i is there an extra copy around ? grad a: uh . he sent it . ok . you can keep it . grad d: er , actually , my only copy , now that i think about it , grad f: alrigh grad a: ok . grad c: um , i do n't i , uh i do n't need it . grad d: but . i already read half of it , so it 's ok . grad c: um , actually this is the the newest version after your comments , grad f: ok . grad c: and professor e: yeah , no i s i s i see this has got the castle in it , and stuff like that . grad c: yeah . professor e: yep . grad d: oh , maybe the version i did n't have that i mine the w did the one you sent on the email have the professor e: yeah . grad d: that was the most recent one ? professor e: uh , yeah , i think so . grad c: yep . grad d: ok . cuz i read halfway but i did n't see a castle thing . grad a: i 'm changing this . just so you know . grad c: yeah , grad a: but , anyway . grad c: um , if you would have checked your email you may have received a note from yees asking you to send me the , uh , up - to - d grad a: oh . oh , sorry . ok . sorry . grad c: current formalism thing that you presented . grad a: ok . i will . ok . ok . ok . grad c: but for this it does n't matter . but , uh grad a: we can talk about it later . that 's not even ready , so . um , ok ! go on t to , uh , whatever . grad c: and grad a: i 'm making changes . `` do n't worry about that . `` ok . mmm - mmm . oh ! ok , sorry , go on . grad c: and any type of comment whether it 's a spelling or a syntax or grad a: mm - hmm . grad c: readability grad f: there 's only one `` s `` in `` interesting `` . grad c: hmm ? grad f: there 's only one `` s `` in `` interesting `` . on page five . grad c: interesting . grad a: anyway . and y uh , email any time , but most usefully before grad d: the twenty - first i 'm assuming . grad a: the twenty - first ? grad c: twenty - ninth . professor e: no , this is the twenty - first . grad f: that 's grad d: what , today 's the twenty - first ? grad f: well , better hurry up then ! grad d: oh , man ! grad a: before the twenty - ninth , grad c: the twenty - ninth . grad a: ok . grad d: ok . grad c: that 's when i 'm meeting with wolfgang wahlster to sell him this idea . grad a: mm - hmm . ok . grad c: ok ? then i 'm also going to present a little talk at eml , about what we have done here and so of course , i 'm i 'm gon na start out with this slide , so the most relevant aspects of our stay here , and um , then i 'm asking them to imagine that they 're standing somewhere in heidelberg and someone asks them in the morning the cave forty - five is a is a well - known discotheque which is certainly not open at that that time . and so grad f: ok . grad c: they 're supposed to imagine that , you know , do they think the person wants to go there , or just know where it is ? uh , which is probably not , uh , the case in that discotheque example , or in the bavaria example , you just want to know where it is . and so forth . so basically we can make a point that here is ontological knowledge but if it 's nine nine pm in the evening then the discotheque question would be , for example , one that might ask for directions instead of just location . um , and so forth and so forth . that 's sort of motivating it . then what have we done so far ? we had our little bit of , um , um , smartkom stuff , that we did , um , everth grad f: oh , you 've got the parser done . sorry . grad c: that 's the not the construction parser . that 's the , uh , tablet - based parser , grad f: ok . grad a: easy parser . grad f: ok . grad c: and the generation outputter . grad d: halfway done ? yeah . grad c: that 's done . grad a: mmm . grad c: you have to change those strategies , grad d: ok . grad c: right ? that 's , ten words ? grad d: yeah . well , i it , you know . maybe twelve . grad c: twelve ? ok . and , um , and fey is doing the synthesis stuff as we speak . that 's all about that . then i 'm going to talk about the data , you know these things about uh , actually i have an example , probably . two s can you hear that ? or should i turn the l volume on . grad f: mm - hmm . grad a: i could hear it . grad d: i i can hear it . grad f: i heard it . grad d: they might not hear it in the well maybe they will . i do n't know . grad a: this was an actual , um , subject ? ah . grad c: mm - hmm . grad f: sounds like fey . grad a: yeah . grad c: but they 're they 're mimicking the synthesis when they speak to the computer , grad f: oh , ok . grad c: the you can observe that all the time , they 're trying to match their prosody onto the machine . grad f: oh really . interesting . oh , it 's pretty slow . grad c: yeah , you have to grad a: wh grad f: the system breaking . grad a: what is the s ? oh ! grad c: ok . and so forth and so forth . um , i will talk about our problems with the rephrasing , and how we solved it , and some preliminary observations , also , um , i 'm not gon na put in the figures from liz , but i thought it would interesting to , uh , um , point out that it 's basically the same . um , as in every human - human telephone conversation , and the human - computer telephone conversation is of course quite d quite different from , uh , some first , uh , observations . then sort of feed you back to our original problem cuz , uh how to get there , what actually is happening there today , and then maybe talk about the big picture here , e tell a little bit as much as i can about the ntl story . i i wa i do wan na , um i 'm not quite sure about this , whether i should put this in , um , that , you know , you have these two sort of different ideas that are or two different camps of people envisioning how language understanding works , and then , talk a bit about the embodied and simulation approach favored here and as a prelude , i 'll talk about monkeys in italy . and , um , srini was gon na send me some slides but he did n't do it , so from but i have the paper , i can make a resume of that , and then i stole an x - schema from one of your talks i think . grad a: oh . i was like , `` where 'd you get that ? `` ok . grad f: yeah , that looks familiar . grad a: `` looks familiar . `` grad c: i think that 's bergen , chang , something , or the other . grad a: uh . professor e: whatever . grad a: ok . grad c: um , and that 's now i 'm not going to bring that . so that 's basically what i have , so far , and the rest is for airplanes . so x - schemas , then , i would like to do talk about the construction aspect and then at the end about our bayes - net . grad a: mm - hmm . grad c: end of story . anything i forgot that we should mention ? oh , maybe the fmri stuff . should i mention the fact that , um , we 're also actually started going to start to look at people 's brains in a more direct way ? professor e: you certainly can . i mean i y i you know , i do n't know grad a: you might just wan na like , tack that on , as a comment , to something . professor e: right , um . grad c: `` future activities `` something . professor e: well , the time to mention it , if you mention it , is when you talk about mirror neurons , then you should talk about the more recent stuff , about the kicking grad c: yeah . professor e: and , you know , the yeah , yeah and that the plan is to see to what extent the you 'll get the same phenomena with stories about this , so that grad c: mm - hmm . professor e: and that we 're planning to do this , um , which , we are . so that 's one thing . um . depends . i mean , there is a , um , whole language learning story , ok ? grad c: yeah . professor e: which , uh , actually , i i even on your five - layer slide , you you 've got an old one that that leaves that off . grad c: yeah , i i i do have it here . grad a: hmm . professor e: yeah . grad c: um . and , of course , you know , the the big picture is this bit . professor e: right . grad c: but , you know , it would but i do n't think i i am capable of of do pulling this off and doing justice to the matter . i mean , there is interesting stuff in her terms of how language works , so the emergentism story would be nice to be you know , it would be nice to tell people how what 's happening there , plus how the , uh , language learning stuff works , professor e: ok , so , so anyway , i i agree that 's not central . grad c: but grad a: mm - hmm . professor e: what you might wan na do is , um , and may not , but you might wan na this is rip off a bunch of the slides on the anal there the there we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , and , um , how the construction and simulation that ho that whole th grad c: yeah , th that that 's c that comes up to the x - schema slide , grad a: ok , right . grad c: so basically i 'm gon na steal that from nancy , grad a: ok , i can give you a more recent if you want grad c: one of nancy 's st grad a: well , that might have enough . grad c: uh , i yeah , but i also have stuff you trash you left over , professor e: ok . grad c: your quals and your triple - ai . professor e: the quals w the the the quals slides would be fine . grad a: yeah . professor e: you could get it out of there , or some grad a: which i can even email you then , you know , like there probably was a little few changes , not a big deal . yeah , you could steal anything you want , i do n't care . which you 've already done , obviously . so . sorry grad c: well , i i do n't feel bad about it at all grad a: no , you should n't . grad c: because because you are on the , uh , title . grad a: oh , that 's great , that 's great . grad c: i mean on the the , you 're that 's see , that 's you . grad a: i 'm glad to see propagation . professor e: yeah . yeah . grad a: mmm . grad c: hmm ? propagated ? grad a: yes . grad c: i mean i might even mention that this work you 're doing is sort of also with the mpi in leipzig , so . grad a: it 's it 's certainly related , um , grad c: because , um , eml is building up a huge thing in leipzig . grad a: might wan na say . is it ? grad c: so it it 's on biocomputation . would professor e: yeah , it 's different , this is the , uh , dna building , or someth the double helix building . grad c: yeah . professor e: yeah . grad a: kind of a different level of analysis . professor e: the yeah it was it turns out that if if you have multiple billions of dollars , y you can do all sorts of weird things , and grad d: wait , they 're building a building in the shape of dna , grad a: what ? grad d: is that what you said ? professor e: roughly , yeah . grad f: oh ! oh boy ! grad a: o professor e: including cr cross - bridges , grad a: what ? professor e: and grad a: oh my god ! grad f: that 's brilliant ! hhh . professor e: you d you really now i i spent the last time i was there i spent maybe two hours hearing this story which is , um grad a: of what grad d: y you definitely wan na w do n't wan na waste that money on research , grad a: the building ? grad d: you know ? professor e: right . grad d: that 's horrible . professor e: right . well , no , no , y i there 's infinite money . see you th you th you then fill it with researchers . grad a: and give them more money . they just want a fun place for them to to work . professor e: right . right . grad f: and everybody gets a trampoline in their office . grad c: well , the the offices are actually a little the , think of um , ramps , coming out of the double helix and then you have these half - domes , glass half - domes , and the offices are in in the glass half - dome . grad a: really ? professor e: yeah . grad f: alright , let 's stop talking about this . grad a: does it exist yet ? professor e: yeah . grad a: they are w now building it ? grad c: uh , as a model . grad a: hmm . grad c: but i th professor e: so , yeah , i think that 's that 's a good point , th th that the date , the , uh , a lot of the this is interacting with , uh , people in italy but also definitely the people in leipzig and the the b the combination of the biology and the leipzig connection might be interesting to these guys , yeah . ok . ok . anyway ! enough of that , let 's talk about your thesis proposal . grad c: yeah , if somebody has something to say . professor e: yep . grad f: you might want to , uh , double - check the spellings of the authors ' names on your references , you had a few , uh , misspells in your slides , there . like i believe you had `` jackendorf `` . professor e: um . grad f: uh , unless there 's a person called `` jackendorf `` , grad a: on that one ? professor e: no , no , no . grad f: yeah . but that 's the only thing i noticed in there . grad a: in the presentation ? grad f: in the presentation . grad a: i 'll probably i c might have i 'll probably have comments for you separately , not important . anyway . grad c: oh , in the presentation here . grad a: yeah , that 's what he was talking about . grad f: yeah . grad c: i was ac actually worried about bibtex . uh . no , that 's quite possible . that 's copy and paste from something . professor e: so i did note i i it looks like the , uh , metaphor did n't get in yet . grad c: uh , it did , there is a reference to srini professor e: well , s reference is one thing , the question is is there any place oh , did you put in something about , grad a: metonymy and metaphor here , right ? professor e: uh , the individual , we 'd talked about putting in something about people had , uh oh yeah , ok . good . i see where you have it . so the top of the second of pa page two you have a sentence . grad c: mm - hmm . professor e: but , what i meant is , i think even before you give this , to wahlster , uh , you should , unless you put it in the text , and i do n't think it 's there yet , about we talked about is the , um , scalability that you get by , um , combining the constructions with the general construal mechanism . is that in there ? grad c: yeah , mmm . um . professor e: uh , ok , so where where is it , cuz i 'll have to take a look . grad c: um , but i i did not focus on that aspect but , um ehhh , um , it 's just underneath , uh , um , that reference to metaphor . so it 's the last paragraph before two . so on page two , um , the main focus professor e: uh , ok . yeah . grad c: but that 's really grad a: that 's not about that , is it ? grad c: yeah . professor e: no , it it it s says it but it does n't say it does n't it d it d grad c: why . professor e: yeah , it does n't give the punch line . grad c: mm - hmm . professor e: cuz let me tell the gang what i think the punch line is , because it 's actually important , which is , that , the constructions , that , uh , nancy and keith and friends are doing , uh , are , in a way , quite general but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . and the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at at the base level , it should com uh , interact with all the metonymies and metaphors so that all of the projections of it also should work . grad f: mm - hmm . professor e: and , similarly , if you introduce a new metaphor , it should then uh , compose with all of the constructions . grad f: mm - hmm . yeah . professor e: and it to the extent that that 's true then then it 's a big win over anything that exists . grad d: so does that mean instead of having tons and tons of rules in your context - free grammar you just have these base constructs and then a general mechanism for coercing them . grad f: yeah . professor e: mm - hmm . so that , you know , for example , uh , in the metaphor case , that you have a kind of direct idea of a source , path , and goal and any metaphorical one and abstract goals and all that sort of stuff { comment } you can do the same grammar . grad d: mmm . professor e: and it is the same grammar . but , um , the trick is that the the way the construction 's written it requires that the object of the preposition for example be a container . well , `` trouble `` is n't a container , but it gets constr construed as a c container . grad d: right . professor e: et cetera . so that 's that 's where this , um , grad d: so with construal you do n't have to have a construction for every possible thing that can fill the rule . professor e: right . so 's it 's it it 's a very big deal , i i in this framework , and the thesis proposal as it stands does n't , um , i do n't think , say that as clearly as it could . grad c: no , it does n't say it at all . no . even though one could argue what if there are basic cases , even . i mean , it seems like nothing is context - free . professor e: oh , nothing is context - free , but there are basic cases . that is , um , there are physical containers , there are physical paths , there you know , et cetera . grad c: but `` walked into the cafe and ordered a drink , `` and `` walked into the cafe and broke his nose , `` that 's sort of professor e: oh , it does n't mean that they 're unambiguous . grad c: mmm . yeah . professor e: i mean , a cafe can be construed as a container , or it can be construed you know as as a obstacle , grad f: uh - huh . professor e: or as some physical object . so there are multiple construals . and in fact that 's part of what has to be done . this is why there 's this interaction between the analysis and the construal . grad c: mm - hmm . yep . professor e: the b the the double arrow . grad c: yep . professor e: so , uh , yeah , i mean , it does n't magically make ambiguity go away . grad c: no . professor e: but it does say that , uh , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle . grad c: mm - hmm . professor e: and if that 's not consistent with other things , then you 've got ta reject that reading . grad c: yep . grad d: you con you conditioned me with your first sentence , and so i thought , `` why would he walk into the cafe and then somehow break his nose ? `` uh , oh , uh grad f: he slipped on the wet floor . professor e: right . grad c: you do n't find that usage , uh uh , i checked for it in the brown national corpus . professor e: yeah . grad c: the `` walk into it `` never really means , w as in walked smack professor e: but `` run into `` does . grad c: yeah , but , y y if you find `` walked smacked into the cafe `` or `` slammed into the wall `` professor e: yeah , no , but `` run into `` does . grad c: mm - hmm . professor e: because you will find `` run into , `` uh , grad d: cars run into telephone poles all the time . professor e: well , or `` into the cafe `` for that m grad c: right . professor e: you know `` his car ran into the cafe . `` grad c: yeah . or you can run into an old friend , or run . professor e: well , you can `` run into `` in that sense too . grad a: yeah , `` run into `` might even be more impact sense than , you know , container sense . professor e: but , uh , right . grad f: depends . professor e: but like , `` run into an old friend `` , it probably needs its own construction . i mean , uh , you know , george would have i 'm sure some exa complicated ex reason why it really was an instance of something else grad a: mm - hmm . mm - hmm . professor e: and maybe it is , but , um , there are idioms and my guess is that 's one of them , but , um i do n't know . grad a: all contact . i mean , there there 's contact that does n't social contact , whatever . i mean . professor e: uh . grad f: sudden surprising contact , professor e: yeah , but it 's it 's it 's it 's right . i yeah , it 's more grad f: right ? grad a: forceful . grad f: but of course , no , i i i mean it has a life of its own . it 's sort of partially inspired by the spatial professor e: well , this is this motivated but yeah grad f: yeah . professor e: oh yeah , mo for sure , motivated , but then you ca n't parse on motivated . grad f: yeah . yeah . right . professor e: uh , grad a: too bad . grad d: you should get a t - shirt that says that . professor e: ok . grad a: there 's there 's lots of things you could make t - shirts out of , but , uh , this has gotten i mean wh we do n't need the words to that . grad c: pro - probably not your marks in the kitchen , today . grad a: what ? oh , no no no no no no no no no , we 're not going there . grad c: not not your marks . grad a: ok . professor e: ok , so , um , grad f: in other news . professor e: anything else you want to ask us about the thesis proposal , you got grad c: well , professor e: we could look at a particular thing and give you feedback on it . grad c: well there actually the i what would have been really nice is to find an example for all of this , uh , from our domain . so maybe if we w if we can make one up now , that would be c incredibly helpful . grad a: so , w where it should illustrate professor e: ok . grad a: uh wh when you say all this , do you mean , like , i do n't know , the related work stuff , grad c: how grad a: as well as , mappings ? grad c: w well we have , for example , a canonical use of something professor e: right right r grad c: and y it 's , you know , we have some constructions and then it 's construed as something , and then we we may get the same constructions with a metaphorical use that 's also relevant to the to the domain . professor e: ok , f let 's let 's suppose you use `` in `` and `` on `` . i mean , that 's what you started with . grad c: mm - hmm . professor e: so `` in the bus `` and `` on the bus , `` um , that 's actually a little tricky in english because to some extent they 're synonyms . ok . grad c: i had two hours w with george on this , so it , professor e: ok , what did he say . grad a: did you ? grad c: um um . grad a: join the club . professor e: right . oh , h that 's grad c: `` on the bus `` is a m is a metaphorical metonymy that relates some meta path metaphorically and you 're on on that path and th w i mean it 's he there 's a platform notion , professor e: yeah , i i believe all that , it 's just grad c: right ? `` he 's on the standing on the bus waving to me . `` professor e: yeah . grad c: but th the regular as we speak `` j johno was on the bus to new york , `` professor e: yeah . yeah . grad c: um , uh , he 's that 's , uh , what did i call it here , the transportation schema , something , professor e: yeah . grad c: where you can be on the first flight , on the second flight , professor e: yeah . grad c: and you can be , you know , on the wagon . professor e: right . so so that that may or may not be what you what you want to do . i mean you could do something much simpler grad c: yeah . professor e: like `` under the bus , `` or something , where grad c: but it 's it 's unfortunately , this is not really something a tourist would ever say . so . professor e: well , unless he was repairing it or something , grad c: yeah . professor e: but yeah . grad c: but um . professor e: uh , but ok . grad c: so in terms of the this grad a: i see . grad c: we had we had initially we 'd started discussing the `` out of film . `` professor e: right . grad c: and there 's a lot of `` out of `` analysis , so , um , professor e: right . grad c: could we capture that with a different construal of grad a: yeah , it 's a little it 's , uh we 've thought about it before , uh t uh to use the examples in other papers , and it 's it 's a little complicated . cuz you 're like , it 's a state of there 's resource , grad f: out of out of film , in particular . grad a: right , and like , what is film , grad f: yeah . grad a: the state you know . you 're out of the state of having film , right ? and somehow film is standing for the re the resour the state of having some resource is just labeled as that resource . grad f: it 's grad a: i mean . grad f: yeah , i mean , grad a: it 's a little bit grad f: but and plus the fact that there 's also s i mean , can you say , like , `` the film ran out `` you know , or , maybe you could say something like `` the film is out `` grad a: yeah , is film the trajector ? grad f: so like the the film went away from where it should be , namely with you , or something , right ? you know . the the film the film is gone , right ? um , i never really knew what was going on , i mean i i find it sort of a little bit farfetched to say that that `` i 'm out of film `` means that i have left the state of having film or something like that , grad a: it 's weird . that grad f: but . grad a: or , `` having `` is also , um , associated with location , professor e: uh . grad a: right ? grad f: yeah . yeah . grad a: so if the film left , you know state is being near film . grad c: so running running out of something is different from being out of somewhere . professor e: or being out of something as , uh as well . so `` running out of it `` definitely has a process aspect to it . grad a: mm - hmm . but that 's from run , yeah . professor e: so , grad f: mm - hmm . professor e: b that 's ok , grad a: yeah . professor e: i mean b but the difference grad c: is the d the final state of running out of something is being out of it . professor e: is grad a: yeah . so th professor e: right . grad f: yeah . you got there . grad a: that part is fine . grad f: you got to out of it . professor e: yeah . grad f: yeah . professor e: but , uh grad f: hmm ! professor e: yeah , so so nob so no one has in in of the , uh , professional linguists , grad a: uh . professor e: they have n't there was this whole thesis on `` out of `` . grad a: there was ? who ? professor e: well , there i thought or there was a paper on it . grad f: out . professor e: huh ? grad f: there was one on on `` out `` or `` out of `` ? professor e: there was a well , it may be just `` out `` . yeah . grad f: ok . professor e: i think there was `` over `` but there was also a paper on `` out `` . grad f: yeah , lind - susan lindner , grad a: oh , yeah , you 're right . yeah . professor e: or something . grad f: right ? the the `` the syrup spread out `` ? professor e: yeah , and all that sort of stuff . grad f: that kind of thing ? grad a: yeah . and undoubtably there 's been reams of work about it in cognitive linguistics , professor e: ok . but anyway . we 're not gon na do that between now and next week . grad a: but . yeah . grad c: yeah . professor e: ok . so , um grad a: it 's not one of the y it 's more straightforward ones forward ones to defend , so you probably do n't want to use it for the purposes grad c: mm - hmm . professor e: right . grad a: th these are you 're addressing like , computational linguists , professor e: ok . grad a: right . or are you ? grad c: there 's gon na be four computational linguists , grad a: ok . but more emphasis on the computational ? or emphasis on the linguist ? grad c: computer it 's more there 's going to be the just four computational linguists , by coincidence , but the rest is , whatever , biocomputing people and physicists . grad a: oh , ok . professor e: no no no , but not for your talk . i 'm - we 're worrying about the th the thes grad c: oh , the thesis ! grad a: oh , i meant this , professor e: it 's just for one guy . grad c: that 's that 's computa should be very computational , grad a: you know , like ok . so i would try to i would stay away from one that involves weird construal stuff . grad c: and , uh , someth professor e: yeah . grad f: yeah . professor e: right . grad a: you know , it 's an obvious one grad f: totally weird stuff . grad c: i mean the the old bakery example might be nice , grad a: but , uh grad c: `` is there a bakery around here `` . so if you c we really just construe it as a grad f: yeah . grad a: around ? grad c: no , it 's the bakery itself grad a: oh . grad c: is it a building ? uh , that you want to go to ? or is it something to eat that you want to buy ? grad a: oh , oh yeah . yeah , we 've thought about that . right . right . grad c: and then grad a: nnn . no . what ? `` bakery `` ca n't be something you 're gon na eat . professor e: no , no . the question is d do you wan na do you wan na construe do you wan na constr - strue grad f: sh grad d: it 's a speech - act . professor e: r exactly . it 's because do you wan na c do you want to view the bakery as a p a place that that i for example , if y grad a: yeah . where you can get baked goods . professor e: well th well , that 's one . you want to buy something . but the other is , uh , yo you might have smelled a smell and are just curious about whether there 'd be a bakery in the neighborhood , or , grad f: mm - hmm . professor e: um , pfff you know , you wonder how people here make their living , and there 're all sorts of reasons why you might be asking about the existence of a bakery grad f: yeah . professor e: that does n't mean , `` i want to buy some baked goods . `` grad a: ok . professor e: but um , those are interesting examples but it 's not clear that they 're mainly construal examples . grad a: so it 's a lot of pragmatics , there , that grad f: yeah . grad c: mmm . professor e: there 's all sorts of stuff going on . grad a: might be beyond what you want to do . professor e: so let 's so let 's think about this from the point of view of construal . so let 's first do a so the metonymy thing is probably the easiest and a and actually the though , the one you have is n't quite grad a: you mean the s you mean `` the steak wants to pay `` ? professor e: n no not that one , that 's that 's a the sort of background . this is the t uh , page five . grad d: about plato and the book ? grad a: oh . professor e: no . grad a: um . grad c: no . grad a: how much does it cost ? professor e: just beyond that . grad f: onward . grad c: where is the castle ? professor e: yeah . grad f: a castle . grad c: how old is it ? how much does it cost ? grad d: oh . grad f: mm - hmm . grad a: to go in , that 's like grad f: two hundred million dollars . professor e: right . it 's not for sale . uh . so grad f: yeah , i think that 's a good example , actually . grad c: s grad a: yeah , that 's good . u grad c: but as nancy just su suggested it 's probably ellipticus . grad a: ellipsis . grad c: huh . grad a: like , `` it `` does n't refer to `` thing , `` it refers to acti you know , j thing standing for activ most relevant activity for a tourist you could think of it that way , but . professor e: yeah . grad f: well , shoot , is n't that i mean , that 's what grad c: well , i mean , my argument here is it 's it 's it 's the same thing as `` plato 's on the top shelf , `` grad f: figuring that out is what this is about . grad a: yeah , yeah , no , i i agree . grad c: i 'm con you know , th that you can refer to a book of plato by using `` plato , `` grad a: yeah . no no , i i 'm agreeing that this is a good , um grad c: and you can refer back to it , and so you can castles have as tourist sites , have admission fees , so you can say `` where is the castle , how much does it cost ? `` um . `` how far is it from here ? `` grad f: mm - hmm . grad c: so , you 're also not referring to the width of the object , or so , grad a: hmm . mm - hmm . grad c: www . grad f: mmm . professor e: ok . can we think of a nice metaphorical use of `` where `` in the tourist 's domain ? um . grad f: hmm . professor e: so you know it 's you you can sometimes use `` where `` f for `` when `` grad f: o professor e: in the sense of , you know , um , where wh where where was , um , `` where was heidelberg , um , in the thirty years ' war ? `` or something . grad c: mm - hmm . grad f: uh , yeah . professor e: you know , or some such thing . um . grad f: like what side were they on , grad a: what ? professor e: yeah . essentially , yeah . grad f: or ? grad a: ok . i was like , `` huh ? it was here . `` like { comment } um . professor e: but anyway th so there are there are cases like that . um , grad a: ah ! or like its developmental state or something like that , you could i guess you could get that . professor e: yeah . grad a: um . professor e: um . grad f: i mean , there 's also things like i mean , s um , i guess i could ask something like `` where can i find out about blah - blah - blah `` in a sort of does n't nece i do n't necessarily have to care about the spatial location , just give me a phone number professor e: yeah . there certainly is that , yeah . grad f: and i 'll call them or something like that ? professor e: you know , `` where could i learn its opening hours , `` or something . grad f: yeah . professor e: but that 's not metaphorical . grad a: hmm . professor e: it 's another grad f: yeah . professor e: so we 're thinking about , um , or we could also think about , uh grad c: well , i i i professor e: how about `` i 'm in a hurry `` ? grad a: state . professor e: it i but it 's a state and the the issue is , is that it may be just a usage , grad f: hmm ? professor e: you know , that it 's not particularly metaphorical , i do n't know . grad f: mmm . grad a: right . so you want a more exotic one version of that . grad f: oh . professor e: yeah . yeah , right . grad a: i 'm really into professor e: ah ! how about i i i you know , `` i 'm in i 'm in a state of exhaustion `` ? grad a: do you really say that ? professor e: or something like that , which a tourist w huh ? grad a: would you really say that ? professor e: a st uh , well , you can certainly say , um , you know , `` i 'm in overload . `` tu - stur tourists will often say that . grad f: yeah . grad d: i i 'm really into art . grad a: yeah , i was gon na say , like grad d: uh professor e: oh , you can do that ? really ? of course that 's that that 's definitely a , uh grad f: fixed . grad a: a fixed expression , yeah . professor e: that 's a , uh right . but . grad a: there 're too there 're all sorts of fixed expressions i do n't like uh `` i 'm out of sorts now ! `` professor e: right . grad a: like { comment } `` i 'm in trouble ! `` grad c: well i when , uh just f u the data that i 've looked at so far that rec professor e: yeah . grad c: i mean , there 's tons of cases for polysemy . professor e: right . grad a: uh - huh . grad c: so , you know , mak re making reference to buildings as institutions , as containers , as build professor e: right . grad c: you know , whatever . um , so ib in mus for example , in museums , you know , as a building or as something where pictures hang versus , you know , ev something that puts on exhibits , so forth . professor e: right . as an institution , grad c: but professor e: yeah . grad c: um . grad a: why do n't you want to use any of those ? grad c: hmm ? grad a: so y you do n't wan na use one that 's grad c: yeah , well no , but this that 's what i have , you know , started doing . professor e: the castle the that old castle one is sort of grad c: metonymy , polysemy . grad d: i love van gogh . professor e: yeah . grad a: `` i wan na go see the van gogh . `` professor e: ah ! grad f: oh geez . grad a: anyway , i 'm sorry . grad c: but i think the argument should be uh , can be made that , you know , despite the fact that this is not the most met metaphorical domain , because people interacting with hti systems try to be straightforward and less lyrical , professor e: yeah . grad c: construal still is , uh , you know , completely , um , key in terms of finding out any of these things , so , um . professor e: right . so that 's that 's that 's a that 's a reasonable point , that it in this domain you 're gon na get less metaphor and more metonymy . grad c: we , uh i with a i looked with a student i looked at the entire database that we have on heidelberg for cases of metonymy . professor e: and polysemy , and stuff like that . yeah . grad c: hardly anything . so not even in descriptions w did we find anything , um , relevant . grad f: i have to go . professor e: alright . yeah . grad c: but ok this is just something we 'll we 'll see , um , professor e: right . s see you . grad c: and deal with . professor e: ok , well . i guess if anybody has additional suggestions , grad c: i mean maybe the `` where is something `` question as a whole , you know , can be construed as , u i locational versus instructional request . professor e: w yeah . grad c: so , if we 're not talk about the lexic grad a: location versus what ? grad c: instruction . grad a: instruction . oh , directions ? yeah . professor e: sure . grad a: oh , i thought that was definitely treated as an example of construal . grad c: yeah . grad a: right ? grad c: yeah but then you 're not on the lexical level , that 's sort of one level higher . grad a: oh , you want a lexical example . grad c: but i do n't need it . professor e: well , you might want both . grad c: mm - hmm . grad a: yeah . grad c: also it would be nice to get ultimately to get a nice mental space example , professor e: we grad c: so , even temporal references are just in the spatial domain are rare . professor e: but it 's it 's easy to make up plausible ones . grad c: when when you 're getting information on objects . professor e: you know . grad c: so , i mean professor e: right , you know you know , where r yeah . what color was this in in in the nain nineteenth century . grad c: yeah . professor e: what was this p instead of wh what you know how was this painted , what color was this painted , um , was this alleyway open . grad c: yeah , maybe we can include that also in our second , uh , data run . professor e: uh . grad c: we c we can show people pictures of objects and then have then ask the system about the objects and engage in conversation on the history and the art and the architecture and so forth . professor e: mm - hmm . ok . so why do n't we plan to give you feedback electronically . wish you a good trip . all success . grad d: for some reason when you said `` feedback electronically `` i thought of that you ever see the simpsons where they 're like the family 's got the buzzers and they buzz each other when they do n't like what the other one is saying ? grad a: yeah . that 's the first one , i think . the very very first one . grad d: it was a very early one . i do n't know if it 's the first one . grad a: mmm . mmm .","output":"as the talk at eml will also refer to a theoretical framework , it was suggested that along with presenting ntl and the piece on mirror neurons , it also alludes to relevant fmri work . the neural side of the research could be of interest to various groups . the language analysis itself will be introduced in terms of image schemas . on the other hand , it was arranged for more feedback on the thesis proposal to be sent by email . the latest version of the construction formalism will also be needed to complete the presentation ."},{"instruction":"what was the general discussion of the meeting ?","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"a pressing concern for the group is the darpa meeting in july , which is only a short time away , and for which they would like to have some progress . plp results for the front-end look good , with the group also reporting progress in segmentation : thilo 's segmenter will now be used and ways of improving performance investigated ; the classifier segmentation is progressing well , especially in the use of prosody for identifying interruption . work on the front end continues , with improvements of 3-5 % being made ."},{"instruction":"what was decided on darpa ?","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"a pressing concern for the group is the darpa meeting in july , which is only a short time away , and for which they would like to have some progress ."},{"instruction":"what was said on transcripts ?","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"for the darpa meeting in july , the group proposed that they should have the question answering mock-up and transcriber interface ready for then , and also have data available ."},{"instruction":"what was the status of transcription ?","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"the final english smartkom demo will be presented to the whole institute once the system is de-bugged and stabilised ."},{"instruction":"what change has occurred to the segmenter ?","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"segmentation for the recogniser has been done by hand which the group consider `` cheating '' , instead now they want to use thilo 's automatic segmenter ."},{"instruction":"what is the status of the segmenter","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"the classifier segmentation work is going well , but needs more data to improve results since non-native speaker data can not be used ."},{"instruction":"what change has occurred to the segmenter ?","input":"phd c: what channel am i on ? phd e: channel . phd c: oh , channel two . phd g: make sure to turn your microphone on . phd e: channel . phd g: there 's a battery . grad b: there we go . phd g: ok . your channel number 's already on this blank sheet . grad b: yeah . phd g: so you just if you can professor f: channel five ? channel five . phd e: channel whatever . professor f: i 'm on channel five . grad b: camera one , camera two . phd e: what am i ? professor f: little low ? phd e: channel four ? professor f: channel five . phd e: this number four ? ok . professor f: channel five . ok . phd g: the gai the gain 's up at it what it usually is , professor f: is it ? phd g: but if you think it 's yeah . it 's sort of a default . but i can set it higher if you like . professor f: oh . maybe it should be a little higher . phd g: yeah ? professor f: it 's not showing much . test , test , test , test , test , test , test , test , test , test . ok , that that seems better ? yeah ? ok , good . ah , that 's good , that 's good . that 's ahh . mmm . so i i had a question for adam . have we started already ? phd g: well , we started recording , but yeah . professor f: yeah . is jane around or ? phd d: i saw her earlier . professor f: uh . phd d: i think phd g: she can just walk in , i guess , or phd d: yeah . she 'll probably come up . professor f: right . phd g: since we 're starting late i figured we 'd better just start . professor f: yeah . great idea . i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because it occurred to me that this is late may and the darpa meeting is in mid july . uh , but i do n't remember w what we i know that we were gon na do something with the transcriber interface is one thing , but i thought there was a second thing . anybody remember ? phd g: well , we were gon na do a mock - up , like , question answering or something , i thought , that was totally separate from the interface . do you remember ? remember , like , asking questions and retrieving , but in a pre - stored fashion . professor f: mm - hmm . right . phd g: that was the thing we talked about , i think , before the transcriber professor f: yeah . phd g: come on in . professor f: alright . so anyway , you have to sort out that out and get somebody going on it cuz we 're got a got a month left basically . so . phd g: you like these . right ? ok , good . professor f: ok . um ok . so , what are we g else we got ? you got you just wrote a bunch of stuff . phd g: no . that was all , um , previously here . professor f: oh . phd g: i was writing the digits and then i realized i could xerox them , professor f: oh , oh . phd g: because i did n't want people to turn their heads from these microphones . so . we all , by the way , have the same digit form , for the record . so . professor f: that 's cool . phd g: yeah . professor f: so , the choice is , uh , which which do we want more , the the the comparison , uh , of everybody saying them at the same time or the comparison of people saying the same digits at different times that ? phd g: it 's just cuz i did n't have any more digit sheets . professor f: i know that . but , you know , which opportunity should we phd g: so . yeah . phd c: unison . professor f: exploit ? unison . phd g: i mean , it actually it might be good to have them separately and have the same exact strings . i mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison . professor f: i guess we 'll see phd g: i do n't know . professor f: i i guess it 's dependent on phd g: see how long we go . professor f: how long we go and how good the snack is out there . phd e: but anyway , they wo n't be identical as somebody is saying zero in some sometimes , you know , saying o , and so , it 's not i not identical . professor f: yeah . hmm . get some advance intelligence . phd g: right . right . professor f: yeah . we 'd have to train . phd g: we 'd be like a chorus . phd e: ok . professor f: yeah . we 'd have to get s get some experience . phd c: greek chorus . grad b: yeah . phd g: yes . professor f: yeah . really boring chorus . um . do we have an agenda ? adam usually tries to put those together , but he 's ill . phd d: i 've got a couple of things to talk about . professor f: so . yeah . uh ju what what might those be ? phd d: uh , ibm stuff and , um , just getting uh , meeting information organized . professor f: meeting info organized . ok . um . phd c: are you implying that it 's currently disorganized ? phd d: in my mind . professor f: is there stuff that 's happened about , um , uh , the sri recognizer et cetera , tho those things that were happening before with ? phd c: well . professor f: y y you guys were doing a bunch of experiments with different front - ends and then with is is that still sort of where it was , uh , the other day ? phd c: we 're improving . professor f: we 're improving . phd c: yeah . phd d: now the the you saw the note that the plp now is getting basically the same as the mfcc . professor f: right . phd d: right ? phd c: yeah . actually it looks like it 's getting better . professor f: right . oh . phd c: so . but but it 's not professor f: just with with age , kind of . phd c: with age . yeah . professor f: yeah . yeah . phd c: but , uh , that 's not d directly related to me . does n't mean we ca n't talk about it . um , it seems it looks l i have n't the it 's the experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the sri system and just applying them to the icsi front - end . professor f: mm - hmm . that 's pretty funny . phd c: yeah . professor f: ok . phd g: so you just need to copy over to this one . phd c: just had to take the reciprocal of the number because they have different meanings in the two systems . postdoc a: ok . professor f: ah ! yeah . well , that 's always good to do . phd c: yeah . professor f: ok . ok . uh phd c: but one issue actually that just came up in discussion with liz and and don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations . professor f: yeah . phd c: because in all our previous experiments , we had the uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . professor f: mm - hmm . phd c: and so now with thilo 's segmenter working so well , i think we should consider doing a phd e: mmm . so . grad b: come on . phd c: uh , doing phd e: yeah . we but professor f: y think you think we should increase the error rate . phd e: anyway . yeah . phd c: yeah . phd e: yeah . professor f: good . phd c: yeah . professor f: yeah . phd e: that - that 's what i wanted to do anyway , phd c: yeah . phd e: so we should just get together and phd g: yeah . phd c: yeah . phd g: and even the good thing is that since you , um , have high recall , { comment } even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones , phd c: right . phd e: yeah . yeah . phd g: but i know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're we 're getting insertions in places what that you may well be cutting out . phd c: well phd e: yeah . professor f: mm - hmm . phd g: so we do need some kind of pre - segmentation . phd c: we should we should consider doing some extra things , like , um , you know , retraining or adapting the the models for background noise to the to this environment , for instance . phd g: mmm . yeah . phd e: yeah . phd g: and , yeah , using thilo 's , you know , posteriors or some kind of or phd c: so . phd g: right now they 're they 're discrete , phd e: yeah . phd g: yes or no for a speaker , to consider those particular speaker background models . phd c: right . phd g: so . there 's lots of ins interesting things that could be done . phd e: yeah . yeah . we should do that . phd g: so . professor f: good . so , uh , why do n't we , uh , do the ibm stuff ? phd d: yeah . so , um , talked with brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before . professor f: you had some thing about that ? right . phd d: and so professor f: the , uh , chuck chunks . phd d: yeah . the chuck chunks . phd e: hmm . phd d: right . and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one professor f: yeah . yeah . phd d: and that would help keep them from getting lost . and , um , so adam wrote a little script to generate those style , uh , beeps phd c: where 'd you get the digits from ? phd d: and so we 're i came up here and just recorded the numbers one through ten . postdoc a: they sound really good . phd d: so . does it sound ok ? phd g: that 's a great idea . postdoc a: yeah . phd d: so , um yeah . we just used those . phd c: and do you splice them into the waveform ? or ? phd d: yeah . he then he d i recorded actually , i recorded one through ten three times at three different speeds and then he picked . phd c: right . mm - hmm . phd d: he liked the fastest one , so he just cut those out and spliced them in between , uh , two beeps . postdoc a: it sounds like a radio announcer 's voice . really . phd e: it will be funny uh postdoc a: yeah , yeah . phd d: does it ? phd e: it will be funny when you 're really reading digits , and then there are the chunks with with your digits in ? phd d: yeah . with my postdoc a: oh that 's right . phd g: oh , right . phd e: yeah . postdoc a: now actually , phd d: that 'll throw them , postdoc a: we 're are we handling ? phd d: huh ? professor f: uh , maybe we should have you record a , b , c for those or something . phd d: yeah . { comment } huh ! maybe . and she said it was n't gon na the transcriber said it would n't be a problem cuz they can actually make a template , uh , that has beep , number , beep . so for them it 'll be very quick phd e: ok . phd d: to to put those in there when they 're transcribing . professor f: yeah . phd d: so , um , we we 're gon na send them one more sample meeting , uh , and thilo has run his segmentation . adam 's gon na generate the chunked file . and then , um , i 'll give it to brian and they can try that out . and when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription . professor f: ok . do w do what do you have any idea of the turn - around on on those steps you just said ? phd g: great . phd d: uh . our s our on our side ? professor f: uh . phd d: or including ibm 's ? professor f: including ibm 's . phd d: well , i do n't know . the last one seemed like it took a couple of weeks . um , maybe even three . professor f: ok . phd d: uh , that 's just the i b m side . our side is quick . i mean , i i do n't know . how long does your ? phd e: it should @ @ be finished today or something . yeah . professor f: well , i meant the overall thing . phd d: yeah . professor f: e e u u { comment } the reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . uh , e a , you know , further hiring of transcribers . phd d: mm - hmm . mm - hmm . professor f: and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . phd d: right . professor f: and , uh , so it 'd be it 'd be good to sort of get that resolved , uh , soon as we could , phd d: yeah . i yeah , i i hope @ @ { comment } we can get a better estimate from this one that we send them . professor f: and then phd d: so . um . professor f: mm - hmm . phd d: i i do n't know yet how long that 'll take . professor f: yeah . um i mean in particular i would i would really hope that when we do this darpa meeting in july that we sort of have we 're we 're into production mode , somehow phd d: mm - hmm . professor f: you know , that we we actually have a stream going and we know how how well it does and how and how it operates . phd d: yeah . professor f: i think that would that would certainly be a a very good thing to know . phd d: right . right . professor f: ok . uh . maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions . postdoc a: ok . so , um , we uh , the transcribers have continued to work past what i 'm calling `` set one `` , which was the s the set that i 've been , uh ok , talking about up to this point , but , uh , they 've gotten five meetings done in that set . right now they 're in the process of being edited . um , the , um let 's see , i hired two transcribers today . i 'm thinking of hiring another one , which will because we 've had a lot of attrition . and that will bring our total to professor f: they die off after they do this for a while . postdoc a: yeah . well , you know , it 's it 's various things . phd d: burn - out . professor f: yeah . postdoc a: so , one of them had a baby . um , you know , one of them really w was n't planning phd c: oh , that was an unfor unforeseen side effect of postdoc a: eh , one of them , um , had never planned to work past january . i mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in january and and and and um , so it makes sense . uh , through attrition we we 've we 're down to to two , but they 're really solid . we 're really lucky the two that we kept . and , um well , i do n't mean i do n't mean anything against the others . { comment } what i mean is we 've got a good cause a good core . no . we had a good core phd g: well , they wo n't hear this since they 're going . they wo n't be transcribing this meeting . postdoc a: yeah , but still . i mean , i d it 's just a matter of we w we 're we 've got , uh , professor f: no backs . postdoc a: two of the ones who who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a a lot of hours , which is wonderful , and excellent work . and so , then , in addition , um , i hired two more today and i 'm planning to h hire a third one with this within this coming week , but but the plan is just as , uh , morgan was saying we discussed this , and the plan right now is to keep the staff on the on the leaner side , you know , rather than hiring , like , eight to ten right now , professor f: mm - hmm . postdoc a: because if the ibm thing comes through really quickly , then , um , we would n't wan na have to , uh , you know , lay people off and stuff . so . and this way it 'll i mean , i got really a lot of response for for my notice and i think i could hire additional people if i wish to . professor f: yeah . an - and the other thing is , i mean , in the unlikely event and since we 're so far from this , it 's a little hard to plan this way in the unlikely event that we actually find that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know , all the stuff that that was sitting there has been transcribed and they 're and they 're faster the the pipeline is faster than uh , than the generation , um , eh , i in in the day e event that that day actually dawns , uh , i i bet we could find some other stuff for them to do . postdoc a: oh , yes . professor f: so i i think that , eh , eh , a as we were talking , if we if we hire twelve , then we could , you know , run into a problem later . i mean , we also just could n't sustain that forever . but but , um for all sorts of reasons but if we hire f you know , f we have five on staff five or six on staff at any given time , then it 's a small enough number so we can be flexible either way . postdoc a: good . ok . professor f: good . phd g: it 'd be great , too , if , um , we can we might need some help again getting the tighter boundaries or some hand to experiment with , um you know , to have a ground truth for this segmentation work , which i guess you have some already that was really helpful , and we could probably use more . phd e: mmm , yeah . that was a thing i i planned working on , is , uh , to use the the transcriptions which are done by now , and to to use them as , uh phd g: oh . oh , the new ones phd e: yeah . phd g: with the tighter boundaries . yeah . phd e: yeah . and to use them for for training a or for fo whatever . yeah . to to create some speech - nonspeech labels out of them , and yeah , but that that 's a thing w was w what i 'm just looking into . phd g: ok . postdoc a: the the the pre - segmentations are so much are s so extremely helpful . now there was , uh , i g guess so , a couple weeks ago i needed some new ones and it happened to be during the time that he was on vacation f for just very few days you were away . but it happened to be during that time i needed one , phd e: yeah . postdoc a: so i so i started them on the non - pre - segmented and then switched them over to yours and , um , they , um you know , they always appreciate that when they have that available . and he 's , uh , usually , eh , uh , um um . so they really appreciate it . but i was gon na say that they do adjust it once in a while . you know , once in a while there 's something like , phd e: yeah , sure . postdoc a: um , and e actually you talked to them . did n't you ? did you ? have you ? phd e: yeah . i talked to helen . postdoc a: and and and she was and so , i asked her i mean , they 're very perceptive . i really want to have this meeting of the transcribers . i have n't done it yet , but i wan na do that and she 's out of town , um , for a couple of weeks , but i wan na do that when she returns . um , cuz she was saying , you know , in a in a span of very short period we asked it seems like the ones that need to be adjusted are these these these things , and she was saying the short utterances , uh , the , um phd g: hmm . phd e: mmm . yeah . postdoc a: you know , i mean , you 're you 're aware of this . but but actually i it 's so correct for so much of the time , that it 's an enormous time saver phd e: yeah . postdoc a: and it just gets tweaked a little around the boundaries . so . phd g: that 's great . postdoc a: um . yeah . i think it 'd be interesting to combine these . phd e: yeah . phd g: is there actually a record of where they change ? i mean , you can compare , do a diff on the just so that we knew postdoc a: you could do it . it 's it 's complicated in that um , hhh , i hhh , i phd e: yeah . actually , when when they create new yeah , new segments or something , it will be , uh , not that easy but hmm . i think one could do that . phd g: i mean , if we keep a old copy of the old time marks phd e: yeah . phd g: just so that if we run it we know whether we 're which ones were cheating phd e: yeah . yeah . that would be great , yeah , to know that . phd g: and postdoc a: there is a there is one problem with that and that is when they start part way through then what i do is i merge what they 've done with the pre - segmented version . phd g: which one would be good . phd e: yeah . postdoc a: so it 's not a pure it 's not a pure condition . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . phd g: mm - hmm . postdoc a: and , um @ @ { comment } i , uh the it was n't possible for about four of the recent ones . but , it will be possible in the future phd e: yeah . postdoc a: because we we 're , um . phd e: it would . phd g: mmm , that 's great . phd e: yeah . phd g: yeah . as long as we have a record , i guess , of the original automatic one , we can always find out how well we would do fr from the recognition side by using those boundaries . phd e: yeah . yeah . phd g: um . phd e: yeah . phd g: you know , a completely non - cheating version . phd e: yeah . phd g: also if you need someone to record this meeting , i mean , i 'm happy to for the transcribers i could do it , or chuck or adam . postdoc a: thank you . professor f: ok . so , uh , u you were saying something about organizing the meeting info ? phd d: yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of the directory structure for all of the meeting professor f: did you record it ? phd d: no . for all the meeting recorder data . we should have . um . and so we 've got a plan for what we 're gon na do there . and then , jane also s prepared a um , started getting all of the the meetings organized , so she prepared a a spreadsheet , which i spent the last couple of days adding to . so i went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . and so , the idea is that we can take this and then export it as html and put it on the meeting recorder web page so we can keep people updated about what 's going on . phd g: oh , great . phd d: um , i 've got ta get some more information from jane cuz i have some some gaps here that i need to get her to fill in , but so far , um , as of monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . and , um uh , some other interesting things , average number of speakers per meeting is six . um , and i 'm gon na have on here the total amount that 's been transcribed so far , but i 've got a bunch of uh , that 's what i have to talk to jane about , figuring out exactly which ones have have been completed and so forth . but , um , this 'll be a nice thing that we can put up on the the web site and people can be informed of the status of various different ones . and it 'll also list , uh , like under the status , if it 's at ibm or if it 's at icsi , uh , or if it 's completed or which ones we 're excluding and and there 's a place for comments , so we can , um , say why we 're excluding things and so forth . so . professor f: now would the ones that , um , are already transcribed we h we have enough there that c you know , we 've already done some studies and so forth and um , should n't we go through and do the business - es u of of having the , um , uh , participants approve it , uh , for approve the transcriptions for distribution and so forth ? postdoc a: um , interesting idea . in principle , i i would say yes , although i still am doing some the final - pass editing , trying to convert it over to the master file as the being the channelized version and it 's yeah , it seems like i get into that a certain way and then something else intervenes { comment } and i have to stop . cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and and doing spot - checking here and there . so , um , uh , i guess it would make sense to wait until th that 's done , um , but but professor f: well , le let me put in another sort of a milestone kind of as as i did with the , uh , uh the the pipeline . postdoc a: yeah . professor f: um , we are gon na have this darpa meeting in the middle of july , postdoc a: yes . professor f: and i think it w it 'd be given that we 've been we 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . um . postdoc a: it 'll certainly be done by then . yeah . professor f: right . so we can s we we wan na be able to say `` here is a subset that is available right now `` postdoc a: mm - hmm . that 's right . professor f: and that 's has been through the legal issues and so forth . postdoc a: that 's right . professor f: so . postdoc a: yeah . that 's right . so that professor f: ok ? postdoc a: ok . professor f: so , by before july . phd c: and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version postdoc a: well , maybe professor f: well , in principle , yes . but , i mean , i if if if somebody actually did get into some legal issue with it then we phd c: bu yeah . but th i mean , the editing will continue . presumably if if s errors are found , they will be fixed , but they wo n't change the the content of the meetings . phd d: content , really . postdoc a: well , see , this is the this is the issue . subtleties . phd c: so . phd g: well , i if jane is clarifying question question , then , you know , how can they agree to it before they know her final version ? postdoc a: the other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @ { comment } could 've been transcribed in the other way . professor f: yeah . phd g: thing postdoc a: and no and they would n't have been slanderous if it had been this other word . you know ? professor f: i it you know , there there is a point at which i agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . right ? and you do n't you there 's no way that we 're gon na go back and ask everybody `` do you approve this , uh , you know this document now ? `` so so i think what it is is that the the the the thing that they sign i i have n't looked at it in a while , but it has to be open enough that it sort of says `` ok , from now on you know , now that i 've read this , you can use do anything you want with these data . `` postdoc a: mm - hmm . professor f: and , uh but , i i think we wan na so , assuming that it 's in that kind of wording , which i do n't remember , um , i think i we just wan na have enough confidence ourselves that it 's so close to the final form it 's gon na be in , a year from now that they 're postdoc a: mm - hmm . i agree . mmm . i totally agree . it 's just , uh , a question of , uh , if if the person is using the transcript as the way of them judging what they said and whether it was slanderous , then it seems like it 's it 's i it needs to be more correct than if we could count on them re - listening to the meeting . professor f: uh . postdoc a: because it becomes , eh , in a way a a f uh , a legal document i if they 've agreed to that . professor f: well , i forget how we end right . i forget how we ended up on this , but i remember my taking the position of not making it so so easy for everybody to observe everything and adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio . and i do n't remember who won , adam or me , but postdoc a: well , if it 's only the transcript , though i mean , th this this is my point , that that professor f: uh , the uh , that that 's why i 'm bringing this up again , because i ca n't remember how we ended up . postdoc a: then it becomes professor f: that it was the transcrip he wanted to do a web interface that would make it postdoc a: well , if it 's just the audio well . professor f: that would give you access to the transcript and the audio . that 's what adam wanted . postdoc a: mm - hmm . professor f: and i do n't remember how we ended up . phd g: i mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . and , i mean , i would say `` no `` . like , i do n't wan na know , but some people might be really interested and then y in other words , they would be informed if there was some significant change other than typos and things like that . professor f: you decided you were whispering satanic incantations under your breath when you were phd g: well , i do n't know what happened to the small heads thing , but i j um , i 'm just saying that , like , you know , you can sort of say that any things that are deemed professor f: they disappeared from view . phd g: anyway . i mean , i agree that at some point people probably wo n't care about typos but they would care about significant meaning changes and then they could be asked for their consent , i guess , if if those change . cuz assumi assuming we we do n't really distribute things that have any significant changes from what they sign anyway . phd c: tha that 's how about having them approve the audio and not the transcripts ? phd g: oh , my god . postdoc a: that would be simpler , professor f: uh . postdoc a: if we could count on them listening . phd g: but no one will listen to the hours and hours of phd d: talk . phd c: well , that 's o k . grad b: that 's phd c: we just have to give them a chance to listen to it , and if they do n't , that 's their problem . grad b: hmm , hmm . phd g: you you d that 's like postdoc a: unfortunately , uh , in in the sign thing that they signed , it says `` transcripts `` . phd c: no , i 'm serious . postdoc a: `` you 'll be you 'll be provided the transcripts when they 're available . `` phd c: really ? grad b: mmm . phd c: mmm . professor f: yeah . phd e: yeah . phd g: i i i think postdoc a: yeah . phd g: that 's a lot to ask for people that have been in a lot of meetings . postdoc a: yeah . professor f: w anyway , have n't we we 've gone down this path a number of times . i know this can lead to extended conversations and and not really get anywhere , so let let me just suggest that uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . postdoc a: yes . professor f: ok . so so that in july we can tell people `` yes , we have this and you can use it `` . postdoc a: yes . it 's done , ready , available . good . professor f: uh . so , let 's see . what else we got ? uh . don did did a report about his project in class and , uh an oral and written written version . phd g: well . professor f: so that was stuff he was doing with you . yeah . phd g: i mean , it 's i guess one thing we 're learning is that the amount we have eight meetings there because we could n't use the non - native all non - native meetings and it 's , well , probably below threshold on enough data for us for the things we 're looking at because the prosodic features are very noisy and so you you need a lot of data in order to model them . um , so we 're starting to see some patterns and we 're hoping that maybe with , i do n't know , double or triple the data with twenty meetings or so , that we would start to get better results . but we did find that some of the features that , i gue jane would know about , that are expressing sort of the distance of , um , boundaries from peaks in the utterance and some local , um , range pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . um , so these are based on forced alignment . word features like , um , word frequency and whether or not something 's a backchannel and so forth . so , we 're starting to see , i think , some interesting patterns . professor f: so the dominant features , including everything , were those those quasi - cheating things . right ? where these are grad b: sometimes not . phd g: i think it depends what you 're looking at , a actually . grad b: yeah . sometimes positions in sentences obviously , or in spurts , was helpful . i do n't know if that 's cheating , too . phd g: right . um , phd c: spurts would n't be . right ? phd g: spurts is not cheating except that of course you know the real words , grad b: right . phd g: but roughly speaking , the recognized words are gon na give you a similar type of position . grad b: right . would they give you the same number of words , though ? professor f: right . phd g: it 's either early or late . phd c: no phd g: not exactly , but i grad b: but ra somewhat ? professor f: on the average . phd g: y yeah it should be . well , we do n't know and actually that 's one of the things we 're interested in doing , is a sort of professor f: uh - huh . phd c: have you tried using just time , as opposed to number of words ? phd g: so . grad b: i think ti uh just p time position , like when the word starts ? phd c: yeah . grad b: i do n't know if that was in the phd c: well , no , i mean t time time position relative to the beginning of the spurt . phd g: eh you know , uh grad b: start . phd g: yeah , grad b: yeah . there 's all these things to do . phd g: uh , we did n't try it , but it 's s grad b: like , there 's a lot of different features you could just pull out . phd c: yeah . i mean that would n't be cheating because you can detect pause pretty well within the time . grad b: right . phd g: right . professor f: how about time position normalized by speak phd g: and it depends on speaking rate professor f: yeah . yeah . phd g: speaking rate . yeah . grad b: yeah . phd g: yeah . that 's actually why i did n't use it at first . professor f: yeah . phd c: mm - hmm . phd g: but we one of the interesting things was i guess you reported on some te punctuation type grad b: yeah . phd g: finding sentence boundaries , finding disfluency boundaries , and then i had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where you know , if i 'm talking now and someone and and andreas is about to interrupt me , is he gon na choose a certain place in my speech , either prosodically or word - based . and there the prosodic features actually showed up and a neat thing even though the word features were available . and a neat thing there too is i tried some putting the speaker so , i gave everybody a short version of their name . so the real names are in there , which we could n't use . uh , we should use i ds or something . and those do n't show up . so that means that overall , um , it was n't just modeling morgan , or it was n't just modeling a single person , professor f: mm - hmm . phd g: um , but was sort of trying to , uh , get a general idea the model the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . so . the but the main limitation now is i because we 're only looking at things that happen every ten words or every twenty words , we need more more data and more data per speaker . so . it 'd also be interesting to look at the edu meetings because we did include meeting type as a feature , so whether you were in a r meeting recorder meeting or a robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meetings . grad b: mm - hmm . phd g: and so the classifier learns more about morgan than it does about sort of the average person , professor f: mm - hmm . phd g: which is not bad . it 'd probably do better than um , but it was n't generalizing . professor f: yeah . phd g: so it 's and i think don , um well , we have a long list of things he 's starting to look at now over the summer , where we can and he 'll be able to report on more things in the future . but it was great that we could at least go from the you know , jane 's transcripts and the , uh , recognizer output and get it to this point . and i think it 's something mari can probably use in her preliminary report like , `` yeah , we 're at the point where we 're training these classifiers and we 're just reporting very preliminary but suggestive results that some features , both word and pro prosodic , work . `` the other thing that was interesting to me is that the pitch features are better than in switchboard . and i think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than than the switchboard telephone bandwidth . phd c: w wh wh wh better in what sense ? phd g: um . well , first of all , the pitch tracks are m have less , um , halvings and doublings than than switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring are completely devoid of pitch information , professor f: mm - hmm . phd g: in other words the pitch tracker just did n't get a high enough probability of voicing for words for for , you know , five word professor f: hmm . phd g: there are much fewer than in switchboard . so the missing we had a big missing data problem in switchboard and , so the features were n't as reliable cuz they were often just not available . phd d: could it have to do with the the lower frequency cut - off on the switchboard ? phd g: so that 's actually good . ma - maybe . i mean , the tele we had telephone bandwidth for switchboard and we had the an annoying sort of telephone handset movement problem that i think may also affect it . phd d: hmm . phd g: so we 're just getting better signals in in this data . which is nice . so . professor f: yeah . phd g: anyway , don 's been doing a great job and we hope to continue with , um , andreas 's help and also some of thilo 's help on this , professor f: great . phd e: y phd g: to to try to get a non - cheating version of how all this would work . phd e: yeah . sure . yeah . professor f: has has , uh ? we just i think , just talked about this the other day , but h has has anybody had a chance to try changing , uh , insertion penalty sort of things with the with the , uh uh , using the tandem system input for the ? phd c: oh , yeah . i tried that . it did n't , um , help dramatically . the phd d: were they out of balance ? i did n't i did n't notice . phd c: there were a little the relative number of i think there were a higher number of deletions , actually . professor f: oh . phd c: so , you , uh so , actually it it preferred to have a positive er , negative insertion penalty , phd g: deletions ? phd c: which means that , um professor f: uh - huh . phd c: but , you know , it did n't change th the by adjusting that the , um professor f: ok . phd c: yeah . the error changed by probably one percent or so . but , you know , given that that word error rate is so high , that 's not a professor f: ok . so that so that 's so that 's not the problem . phd c: that 's not the problem . no . professor f: yeah . phd c: but , uh , we s just , um , uh you know , chuck and i talked and the @ @ { comment } next thing to do is probably to tune the um , the size of the gaussian system , um , @ @ { comment } to to this to this feature vector , which we have n't done at all . we just used the same configuration as we used for the for the standard system . professor f: hmm . phd c: and , for instance , uh , dan @ @ { comment } dan just sent me a message saying that cmu used , um , something like ten gaussians per cluster you know , each each mixture has ten gaussians phd d: mm - hmm . hmm . we 're using sixty - four , phd c: and and we 're using sixty - four , phd d: right ? phd c: so that 's obviously a big difference phd d: yeah . phd c: and it might be way off and give very poorly trained , uh , you know , gaussians that way , professor f: hmm . phd c: uh , an and poorly trained mixture weights . so so , we have the turn - around time on the training when we train only the a male system with , uh , you know , our small training set , is less than twenty - four hours , so we can run lots of uh , basically just brute force , try a whole bunch of different um , settings . professor f: ok . phd c: and , uh , with the new machines it 'll be even better . so . professor f: yeah . we get twelve of those , phd c: yeah . professor f: huh ? phd c: but the plp features work um , uh , you know , continue to improve the , professor f: ok . phd c: um as i said before , the uh using dan 's , uh , uh , vocal tract normalization option works very well . so , um , @ @ { comment } i ran one experiment where we 're just did the vocal tract le normalization only in the test data , professor f: mm - hmm . phd c: so i did n't bother to retrain the models at all , and it improved by one percent , which is about what we get with uh , with , you know , just @ @ { comment } actually doing both training and test normalization , um , with , um , the , uh uh , with the standard system . so , in a few hours we 'll have the numbers for the for retraining everything with vocal tract length normalization and so , that might even improve it further . professor f: great . phd c: so , it looks like the p l - fea p features { comment } do very well now with after having figured out all these little tricks to to get it to work . professor f: yeah . phd c: so . professor f: good . phd g: wait . so you mean you improve one percent over a system that does n't have any v t l in it already ? phd c: exactly . yeah . phd g: ok . professor f: yeah . ok . so then then we 'll have our baseline to to compare the currently hideous , uh , uh , new thing with . phd c: right . a right . and and what that suggests also is of course that the current switchboard mlp is n't trained on very good features . professor f: but yeah . phd c: uh , because it was trained on whatever , you know , was used , uh , last time you did hub - five stuff , which did n't have any of the professor f: right . but all of these effects were j like a couple percent . phd c: uh . professor f: right ? i mean , y the phd c: well , but if you add them all up you have , uh , almost five percent difference now . professor f: add all of them . i thought one was one point five percent and one was point eight . phd c: yeah . and now we have another percent with the v t professor f: that 's three point three . phd c: um , actually , and it 's , um , what 's actually qu interesting is that with um , well , you m prob maybe another half percent if you do the vtl in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um , uh , the n best lists , uh , and optimizing the weights , um , uh than phd d: than you do with the standard ? phd c: yeah . so professor f: yeah . but the part that 's actually adjustment of the front - end per se as opposed to doing putting vtln in or something is it was a couple percent . phd c: right . professor f: right ? it was it was there was there was one thing that was one and a half percent and one that was point eight . so and and let me see if i remember what they were . one of them was , uh , the change to , uh because it did it all at once , { comment } to uh , from bark scale to mel scale , phd c: mm - hmm . professor f: which i really feel like saying in quotes , because @ @ { comment } they 're essentially the same scale but the but but but any i individual particular implementation of those things puts things in a particular place . phd g: yeah . why did that cha ? phd c: mm - hmm . professor f: so that 's why i wanted to look i still have n't looked at it yet . i i wan na look at exactly where the filters were in the two , phd c: mm - hmm . professor f: and it it 's probably something like there 's one fewer or one more filter in the sub one kilohertz band phd c: mm - hmm . professor f: and for whatever reason with this particular experiment it was better one way or the other . phd g: hmm . professor f: um , it could be there 's something more fundamental but it you know , i i do n't know it yet . and the other and the other that was like one and a half or something , and then there was point eight percent , which was what was the other thing ? phd d: well , that was combined with the triangular . right ? professor f: yeah . those those two were together . phd d: yeah . right . professor f: we d were n't able to separate them out cuz it was just done in one thing . but then there was a point eight percent which was something else . phd d: the low - frequency cut - off . professor f: do you remember the ? oh , yeah . so that was that was , uh that one i can claim credit for , uh , i in terms of screwing it up in the first place . so that someone e until someone else fixed it , which is that , um , i never put when i u we had some problems before with offsets . this inf this went back to , uh , i think wall street journal . phd c: hmm . professor f: so we we had , uh ea everybody else who was doing wall street journal knew that there were big dc offsets in th in these data in those data and and and nobody happened to mention it to us , phd c: hmm . professor f: and we were getting these , like , really terrible results , like two , three times the error everybody else was getting . and then in casual conversation someone ment mentioned `` uh , well , i guess , you know , of course you 're taking care of the offsets . `` i said `` what offsets ? `` grad b:  phd c: mm - hmm . professor f: and at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen { comment } and wroop ! phd c: mm - hmm . professor f: there 's this big dc offset . so , um , in plp phd g: there was a like a hum or some or when they recorded it ? professor f: no . it 's just , it it 's it 's not at all uncommon for for recorded electronics to have different , um , dc offsets . phd g: or just ? huh . professor f: it 's it 's , you know , no big deal . it 's you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . the thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . uh , but with p l p , we did n't actually have that . we had we had the equivalent of pre - emphasis in a a , uh , fletcher - munson style weighting that occurs in the middle of p l but it does n't actually have a zero at zero frequency , phd g: hmm . professor f: like , eh , uh , typical simple fr pre - emphasis does . we had something more fancy . it was later on it did n't have that . so at that point i reali `` oh sh we better have a have a high - pass filter `` just , you know just take care of the problem . so i put in a high - pass filter at , uh , i think ninety ninety hertz or so uh , for a sixteen kilohertz sampling rate . and i never put anything in to adjust it for different different sampling rates . and so well , so , you know , the code does n't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at instead of at ninety . phd c: hmm . professor f: so , um , i do n't know if dan fixed it or or , uh , what he phd c: well , he made it a parameter . professor f: he made it a parameter . so . yeah , i guess if he did it right , he did fix it and then and then it 's taking care of sampling rate , which is great . phd d: what what is the parameter ? professor f: he had a phd d: is it , uh , just the f lower cut - off that you want ? phd c: it 's called , uh , h - hpf . professor f: h yeah . does hpf on on his feat feature . phd c: u and but hpf , you know , when you put a number after it , uses that as the hertz value of the cut - off . phd d: mm - hmm . oh , ok . professor f: yeah . phd c: so . professor f: i mean , frankly , we never did that with the rasta filter either , phd c: mm - hmm . professor f: so the rasta filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is another old old bug of mine . phd c: mm - hmm . professor f: but , um um . so that that was the problem there was th we we we had always intended to cut off below a hundred hertz phd c: mm - hmm . professor f: and it just was n't doing it , so now it is . so , that hep that helped us by , like , eight tenths of a percent . it still was n't a big deal . phd c: ok . well , but , um well , uh , again , after completing the current experiments , we 'll we can add up all the uh differences professor f: oh , yeah . phd c: and and an professor f: but but , i guess my my point was that that , um , the hybrid system thing that we did was , uh , primitive in many ways . phd c: y right . professor f: and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have a a a competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . phd c: mm - hmm . professor f: uh , unless you call well , if you call vtl the front - en front - end , that 's , uh , a little more . but that 's sort of more both , kind of . phd d: one experiment we should we 'll probably need to do though when um , at some point , is , since we 're using that same the net that was trained on plp without all these things in it , for the tandem system , we may wan na go back and retrain , professor f: right ? but . phd c: well , that 's what i meant , in fact . yeah . phd d: yeah , yeah , for the tandem . you know , so we can see if it what effect it has on the tandem processing . phd c: so so , the thing is is do we expect ? professor f: mm - hmm . phd c: eh at this point i 'm as i mean , you know e i 'm wondering is it can we expect , uh , a tandem system to do better than a properly trained you know , a gaussian system trained directly on the features with , you know , the right ch choice of parameters ? professor f: well , that 's what we 're seeing in other areas . yes . right ? so , it 's so , um , um phd d: so , we but but we may not . i mean , if it does n't perform as well , we may not know why . right ? cuz we need to do the exact experiment . phd c: right . professor f: i mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . so . um . now the thing is , in some databases i would n't expect it to necessarily give you much and and part of what i view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth , phd c: mm - hmm . professor f: and allows you to feed them to the other system with this through this funnel . um , so i think i think that 's the real power of it . i would n't expect huge in huge improvements . um , but it should at least be roughly the same and maybe a little better . phd c: mm - hmm . professor f: if it 's , you know , like way way worse then , you know phd c: right . phd d: so , morgan , an another thing that andreas and i were talking about was , so @ @ { comment } in the first experiment that he did we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either mfcc or plp . professor f: mm - hmm . mm - hmm . phd d: but one thing we could do is professor f: let let me let me just ask you something . when you say take the fifty - six outputs , these are the pre final nonlinearity outputs phd d: yeah . through the regular tandem outputs . professor f: and they 're and through the klt . phd d: through the klt . all that kinda stuff . professor f: ok . and so so then you u do you use all fifty - six of the klt phd d: that 's what we did . professor f: or ? phd d: right ? so one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that professor f: ok . yes . phd d: so we treated the th first thirteen as though they were standard features . professor f: yes . yeah . phd d: i mean , did dan do experiments like that to ? professor f: uh . talk with stephane . he did some things like that . it was either him or carmen . i forget . phd c: mm - hmm . phd d: mmm . professor f: i mean these were all different databases and different you know , in htk and all that , phd d: yeah . professor f: so i it it may not apply . but my recollection of it was that it did n't make it better but it did n't make it worse . phd d: hmm . professor f: but , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components . phd d: cuz in a sense , the net 's already got quite a bit of context in those features , professor f: yeah . phd d: so if we did deltas and double - deltas on top of those , we 're getting sort of even more . professor f: which could be good or not . phd d: yeah . professor f: yeah . yeah . worth trying . phd c: but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems debugged now and i mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to this to the sri system , phd d: mm - hmm . yeah . phd c: but it 's professor f: there might be , cuz that 's a pretty big difference . phd c: yeah . and i 'm wondering how we can how we can debug that . professor f: but phd d: yeah . phd c: i mean how um . professor f: hmm . phd c: i 'm actually f quite sure that the feeding the features into the system and training it up , professor f: what if ? phd c: that that i think that 's this that 's essentially the same as we use with the ce with the p l p fe features . and that 's obviously working great . so . i um . phd d: yeah . there could be a bug in in the somewhere before that . phd c: there we could the another degree of freedom is how do you generate the k l t transform ? phd d: mm - hmm . phd c: right ? we to professor f: that 's phd d: right . professor f: well , and another one is the normalization of the inputs to the net . phd c: yeah . professor f: these nets are trained with particular normalization and when that gets screwed up it it can really hurt it . phd d: i 'm doing what eric e eric coached me through then that part of it , so i 'm pretty confident in that . professor f: ok . phd d: i mean , the only slight difference is that i use normalization values that , um , andreas calculated from the original { comment } plp , phd c: right . phd d: which is right . phd c: right . phd d: n yeah . so , i u i do oh , we actually do n't do that normalization for the plp , do we ? for the st just the straight plp features ? phd c: no . the the sri system does it . phd d: s r i system does that . right . phd c: yeah . professor f: right . well , you might e e phd c: so , there 's there is there is room for bugs that we might not have discovered , phd d: so that 's that 's another yeah . professor f: yeah . phd d: mm - hmm . professor f: yeah . i i would actually double check with stephane at this point , phd c: but professor f: cuz he 's probably the one here i mean , he and dan are the ones who are at this point most experienced with the tandem phd d: mm - hmm . professor f: thing and there may there may be some little bit here and there that is not not being handled right . phd d: yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print the the values out in ascii and , you know , look at them , see if they 're professor f: not unless you had a lot of time phd g: well professor f: and phd g: eh , and also they 're not i mean , as i understand it , you you do n't have a way to optimize the features for the final word error . right ? phd c: right . phd g: i mean , these are just discriminative , but they 're not , um , optimized for the final phd c: they 're optimized for phone discrimination , not for phd g: right . so it there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually that you 're actually professor f: that 's right . well , the other yeah , th the phd c: mm - mmm . professor f: well , you actually are . but but it but in an indirect way . phd g: well , right . it 's indirect , so you do n't know professor f: so wha w what an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . so , what what you what you do in the full procedure is you , um , uh , have an embedded training . so in fact you the the net is trained on , uh , uh , a , uh , viterbi alignment of the training data that comes from your full system . and so that 's where the feedback comes all around , so that it is actually discriminant . you can prove that it 's it 's a , uh if you believe in the viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh by training up on local local , uh local frames . but , um , we are n't actually doing that here , because we did we did that for a hybrid system , and now we 're plugging it into another system and so it is n't i i i it would n't quite apply here . phd c: do y phd d: so another huge experiment we could do would be to take the tandem features , uh , do sri forced alignments using those features , and then re - do the net with those . professor f: mm - hmm . phd g: mmm , uh exactly . exactly . professor f: yeah . phd g: so that you can optimize it for the word error . phd c: but professor f: yeah . another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be . phd g: yeah . professor f: so that would save a lot of time . phd c: and there 's a mismatch in the phone sets . so , you 're using a l a long a larger phone set than what phd d: mmm . professor f: yeah . actually all those things could could could could , uh could affect it as well . phd d: yeah . yeah . professor f: the other thing , uh , just to mention that stephane this was an innovation of stephane 's , which was a pretty neat one , uh , and might particularly apply here , given all these things we 're mentioning . um , stephane 's idea was that , um , discriminant , uh , approaches are great . even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . um , however , there 's times when it is not good . uh , when something about the test set is different enough from the training set that that , uh , the discrimination that you 're learning is is is not a good one . phd c: mm - hmm . professor f: so , uh , his idea was to take as the input feature vector to the , uh , gaussian mixture system , uh , a concatenation of the neural net outputs and the regular features . phd c: oh , we already talked about that . phd g: yeah . that professor f: yeah . phd c: el phd d: mm - hmm . phd g: did n't you did you do that already phd c: yeah . no , but we we when when we when i first started corresponding with dan about how to go about this , i think that was one of the things that we definitely went there . phd g: or ? oh . that makes a lot of sense . huh . professor f: yeah . yeah . i mean , i 'm sure that stephane was n't the first to think of it , phd c: yeah . professor f: but actually stephane did it phd c: uh - huh . and i does it help ? professor f: and and and it helped a lot . phd c: oh , ok . professor f: yeah . so that 's that that 's our current best best system in the , uh uh , in the aurora thing . phd c: oh . ok . phd g: yeah . that makes sense . phd c: and do you do a klt transform on the con on the combined feature vector ? professor f: yeah . phd g: as you should never do worse . professor f: i i , uh , missed what you said . phd c: do you d you do a klt transform on the combined feature vector ? professor f: yeah . phd c: ok . professor f: well , actually , i , uh you should check with him , because he tried several different combinations . phd c: because you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction . professor f: yeah . i , uh , th what i do n't remember is which came out best . so he did one where he put o put e the whole thing into one klt , and another one , since the the plp things are already orthogonalized , he left them alone and and just did a klt on the on the on the net outputs phd c: mm - hmm . mmm . professor f: and then concatenated that . and i do n't remember which was better . phd d: did he did he try to ? so he always ended up with a feature vector that was twice as long as either one of the ? professor f: no . i do n't know , i i i do n't know . you have to check with him . phd d: yeah . phd c: ok . actually , i have to run . professor f: i 'm into big ideas these days . phd g: yeah . phd c: uh . phd g: we need to close up cuz i need to save the data and , um , get a call . professor f: not to mention the fact that we 're missing snacks . yeah . phd g: right . professor f: uh phd g: did people wan na do the digits professor f: um . phd g: or , um , do them together ? professor f: i i g i think , given that we 're in a hurry for snacks , maybe we should do them together . phd g: i do n't know . should we just ? ok . i mean , are we trying to do them in synchrony ? that might be fun . professor f: well , it 's it 's it 's not you know , it 's not gon na work out phd g: adam 's not here , so he 's not here to tell me no . professor f: but we could we could just , uh , uh , see if we find a rhythm , you know , what phd g: sure . professor f: uh , o 's or zeroes , we wan na agree on that ? phd g: maybe just whatever people would naturally do ? i do n't know . professor f: oh , but if we were a singing group , we would wan na decide . right ? phd g: be harmony . yeah . { comment } yeah . postdoc a: mine 's identical to yours . professor f: we might wa postdoc a: is that correct ? phd g: sorry . so i set up and we did n't have enough digit forms postdoc a: oh . i see . professor f: so these are excellent . phd g: so i xeroxed the same one seven times . postdoc a: oh . i see . professor f: why do n't we do zer i anyone have a problem with saying zero ? is zero ok ? phd g: no . postdoc a: yeah . professor f: ok . one and a two and three . phd g: e professor f: once more with feeling . phd g: and th professor f: no , just k just kidding . oh , yeah . it was .","output":"to improve the performance of thilo 's automatic segmenter , this is going to be retrained and adapted to run with thilo 's posteriors and speaker background models ."},{"instruction":"summarize the meeting","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"the team was coming close to finalizing the model for aurora . they were still trying to make some improvements to improve their score . the team began with a discussion about how reverberation could be better accounted for . the professor thought that experimenting with different filters could help achieve a better signal-to-noise ratio . the new system for estimating silence probabilities that the team had added to the model was very effective , but it created a 220ms latency in the vad . the team was not sure what kinds of constraints would be placed on latency eventually . they wanted to play it safe . the models , over all , were performing well , though the team intended to keep improving them . the team was also trying to figure out how to deal with different kinds of background noise . the meeting ended with a discussion of logistical issues ."},{"instruction":"summarize the discussion on deletions and improving the net","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"adding the neural net was doubling the number of deletions . the model did not improve significantly , however , thought it became better at some tasks . the results were a mixed basket and it was decided that further experimentation was necessary ."},{"instruction":"what did the professor think about the neural net ?","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"the professor was interested in knowing what impact the neural net had in the older models which did not have pure features . the professor believed it was worthwhile to improve the net , though he also expressed that nets were occasionally over used ."},{"instruction":"what did the team discuss about the most noisy cases ?","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"the team thought that the most noisy cases were the distant microphone testing . that is when there were non-stationary noises in the background , like from a car , a babble or subway . these presented a unique challenge for the model that could potentially be best solved with a neural net ."},{"instruction":"summarize the discussion on vad results","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"the vad neural net had twelve times nine inputs and two outputs . the system had improved significantly . it added some latency but the team could potentially run it in parallel ."},{"instruction":"what did the professor think about vad latency ?","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"the professor wanted to know how much latency the vad was adding to the model . the professor thought that the process could work in parallel . the professor informed the team that the max latency was unknown ."},{"instruction":"what did phd c say about the breakdown of the latency ?","input":"phd a: ok , we 're going . phd c: eight , eight ? phd d: this is three . phd c: three . phd d: yep . yep . professor b: test . hmm . let 's see . move it bit . test ? test ? ok , i guess it 's alright . so , let 's see . yeah , barry 's not here and dave 's not here . um , i can say about just q just quickly to get through it , that dave and i submitted this asru . phd a: this is for asru . professor b: yeah . so . um . yeah , it 's it 's interesting . i mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine db . so , phd d: hmm . professor b: um , phd a: you mean , from the actual , uh , recordings ? professor b: a fair amount of phd d: k phd a: it 's nine db ? professor b: yeah . yeah . um and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on at at , uh at ogi . um , but one of the differences that we found between the two systems that we were using , { comment } the the aurora htk system baseline system { comment } and the system that we were the the uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . and the , uh , aurora htk , it was like twenty . phd d: yep . s sixty - four . professor b: uh . phd d: s sixty - four . professor b: sixty - four ? uh . phd d: yeah , if you 're using the baseline . professor b: is that the ba band center ? phd d: no , the edge . professor b: the edge is really , uh , sixty - four ? phd d: yeah . professor b: for some reason , uh , dave thought it was twenty , phd d: so the , uh , center would be somewhere around like hundred professor b: but . phd d: and hundred and hundred hundred and maybe it 's like fi hundred hertz . professor b: but do you know , for instance , h how far down it would be at twenty hertz ? what the how much rejection would there be at twenty hertz , let 's say ? phd d: at twenty hertz . professor b: yeah , any idea what the curve looks like ? phd d: twenty hertz frequency oh , it 's it 's zero at twenty hertz , right ? the filter ? phd c: yea - actually , the left edge of the first filter is at sixty - four . phd d: sixt - s sixty - four . phd c: so phd d: so anything less than sixty - four is zero . phd c: mmm . professor b: it 's actually set to zero ? what kind of filter is that ? phd c: yeah . phd d: yeah . professor b: is this oh , from the from phd c: it this is the filter bank in the frequency domain that starts at sixty - four . professor b: oh , so you , uh so you really set it to zero , the fft ? phd d: yeah , phd c: yeah . phd d: yeah . so it 's it 's a weight on the ball spectrum . triangular weighting . professor b: right . ok . um ok . so that 's that 's a little different than dave thought , i think . but but , um , still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was there their experimentation with , uh , say , throwing away that filter or something ? and , uh phd d: uh , throwing away the first ? professor b: yeah . phd d: um , yeah , we we 've tried including the full full bank . right ? from zero to four k . phd c: mm - hmm . phd d: and that 's always worse than using sixty - four hertz . professor b: right , but the question is , whether sixty - four hertz is is , uh , too , uh , low . phd d: yeah , i mean , make it a hundred or so ? professor b: yeah . phd d: i t i think i 've tried a hundred and it was more or less the same , or slightly worse . professor b: on what test set ? phd d: on the same , uh , speechdat - car , aurora . professor b: um , it was on the speechdat - car . phd d: yeah . so i tried a hundred to four k . yeah . professor b: um , phd d: so it was professor b: and on and on the , um , um , ti - digits also ? phd d: no , no , no . i think i just tried it on speechdat - car . professor b: mmm . that 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room . phd d: mm - hmm . professor b: would that be more like well , you 'd think that 'd be more like speechdat - car , i guess , in terms of the noise . the speechdat - car is more , uh , sort of roughly stationary , a lot of it . and and ti - digits maybe is not so much as phd d: yeah . phd c: mm - hmm . professor b: yeah . phd d: yeah . professor b: mm - hmm . ok . well , maybe it 's not a big deal . but , um anyway , that was just something we wondered about . but , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . uh , the signal - to - noise ratio , you know , looks a fair amount better if you if you high - pass filter it from this room . phd d: yeah . professor b: but , um but it 's still pretty noisy . even even for a hundred hertz up , it 's it 's still fairly noisy . the signal - to - noise ratio is is is actually still pretty bad . phd c: mm - hmm . phd a: hmm . professor b: so , um , i mean , the main the the phd a: so that 's on th that 's on the f the far field ones though , right ? yeah . professor b: yeah , that 's on the far field . yeah , the near field 's pretty good . phd a: so wha what is , uh what 's causing that ? professor b: well , we got a a video projector in here , uh , and , uh which we keep on during every every session we record , phd a: yeah . professor b: which , you know , i i w we were aware of phd a: uh - huh . professor b: but but we thought it was n't a bad thing . phd a: yeah . professor b: i mean , that 's a nice noise source . uh , and there 's also the , uh uh , air conditioning . phd a: hmm . professor b: which , uh , you know , is a pretty low frequency kind of thing . phd a: mm - hmm . professor b: but but , uh so , those are those are major components , i think , phd a: i see . professor b: uh , for the stationary kind of stuff . phd a: mmm . professor b: um , but , um , it , uh i guess , i maybe i said this last week too but it it it really became apparent to us that we need to to take account of noise . and , uh , so i think when when he gets done with his prelim study i think one of the next things we 'd want to do is to take this , uh uh , noise , uh , processing stuff and and , uh uh , synthesize some speech from it . phd a: when are his prelims ? professor b: and then um , i think in about , um , a little less than two weeks . phd a: oh . wow . professor b: yeah . yeah . so . uh , it might even be sooner . uh , let 's see , this is the sixteenth , seventeenth ? yeah , i do n't know if he 's before it might even be in a week . phd a: so , i professor b: a week , phd a: huh . i i guessed that they were gon na do it some time during the semester professor b: week and a half . phd a: but they 'll do it any time , huh ? professor b: they seem to be well , the semester actually is starting up . phd a: is it already ? professor b: yeah , the semester 's late late august they start here . phd a: yikes . professor b: so they do it right at the beginning of the semester . phd a: yeah . professor b: yeah . so , uh yep . i mean , that that was sort of one i mean , the overall results seemed to be first place in in in the case of either , um , artificial reverberation or a modest sized training set . uh , either way , uh , i uh , it helped a lot . and but if you had a a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set i thought that one thing with the htk is that is has the as we 're using the configuration we 're using is w s is being bound by the terms of aurora , we have all those parameters just set as they are . so even if we had a hundred times as much data , we would n't go out to , you know , ten or t or a hundred times as many gaussians or anything . so , um , it 's kind of hard to take advantage of of of big chunks of data . uh , whereas the other one does sort of expand as you have more training data . phd c: mm - hmm . phd d: mmm , yeah . professor b: it does it automatically , actually . and so , um , uh , that one really benefited from the larger set . and it was also a diverse set with different noises and so forth . uh , so , um , that , uh that seemed to be so , if you have that that better recognizer that can that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do u use speaker adaptation . and and not bother with with this acoustic , uh , processing . but i think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing . phd c: mm - hmm . professor b: so . that 's sort of what we found . phd d: hmm . phd a: i , um uh , started working on the uh mississippi state recognizer . so , i got in touch with joe and and , uh , from your email and things like that . phd d: oh , ok . phd a: and , uh , they added me to the list uh , the mailing list . phd d: ok , great . phd a: and he gave me all of the pointers and everything that i needed . and so i downloaded the , um there were two things , uh , that they had to download . one was the , uh , i guess the software . and another wad was a , um , sort of like a sample a sample run . so i downloaded the software and compiled all of that . and it compiled fine . phd d: eight . phd a: no problems . phd d: oh , eh , great . phd a: and , um , i grabbed the sample stuff but i have n't , uh , compiled it . phd d: that sample was released only yesterday or the day before , right ? phd a: no well , i have n't grabbed that one yet . so there 's two . phd d: oh , there is another short sample set phd a: there was another short one , yeah . phd d: o o sample . phd a: and so i have n't grabbed the latest one that he just , uh , put out yet . phd d: ok . oh , ok . f yeah , ok . phd a: so . um , but , the software seemed to compile fine and everything , so . and , um , so . professor b: is there any word yet about the issues about , um , adjustments for different feature sets or anything ? phd a: no , i i d you asked me to write to him and i think i forgot to ask him about that . or if i did ask him , he did n't reply . professor b: yeah . phd a: i i do n't remember yet . uh , i 'll i 'll d i 'll double check that and ask him again . professor b: yeah . yeah , it 's like that that could r turn out to be an important issue for us . phd d: hmm . mmm . phd a: yeah . yeah . professor b: yeah . phd d: cuz they have it phd a: maybe i 'll send it to the list . yeah . phd d: cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what i feel . because they have this document explaining the recognizer . phd a: uh - huh . phd d: and they have these tables with , uh , various language model weights , insertion penalties . phd a: ok , i have n't seen that one yet . phd d: u phd a: so . phd d: uh , it 's th it 's there on that web . phd a: ok . phd d: and , uh , on that , i mean , they have run some experiments using various insertion penalties and all those phd a: and so they 've picked the values . phd d: yeah , i think they pi p phd a: oh , ok . phd d: yeah , they picked the values from phd a: ok . professor b: for r w what test set ? phd d: uh , p the one that they have reported is a nist evaluation , wall street journal . professor b: but that has nothing to do with what we 're testing on , right ? phd c: mm - hmm . phd d: you know . no . so they 're , like um so they are actually trying to , uh , fix that those values using the clean , uh , training part of the wall street journal . which is i mean , the aurora . aurora has a clean subset . professor b: right . phd d: i mean , they want to train it and then this they 're going to run some evaluations . professor b: so they 're set they 're setting it based on that ? phd d: yeah . professor b: ok . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . phd a: yeah . professor b: but , um , phd d: yeah . professor b: uh but it 's still worth , i think , just since you know , just chatting with joe about the issue . phd a: yeah , ok . do you think that 's something i should just send to him professor b: um phd a: or do you think i should send it to this there 's an a m a mailing list . professor b: well , it 's not a secret . i mean , we 're , you know , certainly willing to talk about it with everybody , but i think i think that , um um , it 's probably best to start talking with him just to phd a: ok . professor b: uh @ @ { comment } you know , it 's a dialogue between two of you about what you know , what does he think about this and what what you know what could be done about it . phd a: yeah . ok . professor b: um , if you get ten people in involved in it there 'll be a lot of perspectives based on , you know , how phd a: yeah . professor b: you know . phd a: right . professor b: uh but , i mean , i think it all should come up eventually , phd a: ok . professor b: but if if if there is any , uh , uh , way to move in a way that would that would , you know , be more open to different kinds of features . but if if , uh if there is n't , and it 's just kind of shut down and and then also there 's probably not worthwhile bringing it into a larger forum where where political issues will come in . phd a: yeah . ok . phd d: oh . so this is now it 's it 's compiled under solaris ? phd a: yeah . phd d: yeah , ok . phd a: yep . phd d: because he there was some mail r saying that it 's may not be stable for linux and all those . phd a: yeah . yeah , i that was a particular version . phd d: susi phd a: yeah , susi or whatever it was phd d: yeah . yeah , yeah . phd a: but we do n't have that . phd d: yeah , ok . phd a: so . should be ok . phd d: ok , that 's fine . phd a: yeah , it compiled fine actually . phd d: yeah . phd a: no no errors . nothing . so . professor b: uh , this is slightly off topic phd d: that 's good . professor b: but , uh , i noticed , just glancing at the , uh , hopkins workshop , uh , web site that , uh , um one of the thing i do n't know well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition . phd a: hmm . professor b: so and jeff , uh the two jeffs were phd a: who 's the second jeff ? professor b: uh oh , uh , do you know geoff zweig ? phd a: no . professor b: oh . uh , he he , uh he was here for a couple years phd a: oh , ok . professor b: and he , uh got his phd . he and he 's , uh , been at ibm for the last couple years . phd a: oh , ok . professor b: so . phd a: wow . that would be neat . professor b: uh , so he did he did his phd on dynamic bayes - nets , uh , for for speech recognition . he had some continuity built into the model , presumably to handle some , um , inertia in the in the production system , and , um phd a: hmm . professor b: so . phd d: hmm . phd c: um , i 've been playing with , first , the , um , vad . um , so it 's exactly the same approach , but the features that the vad neural network use are , uh , mfcc after noise compensation . oh , i think i have the results . professor b: what was it using before ? phd c: before it was just p l phd d:  phd c: so . phd d: yeah , it was actually no . not i mean , it was just the noisy features i guess . phd c: yeah , phd d: yeah , yeah , yeah , phd c: noisy noisy features . phd d: not compensated . phd c: um this is what we get after this so , actually , we , yeah , here the features are noise compensated and there is also the lda filter . um , and then it 's a pretty small neural network which use , um , nine frames of of six features from c - zero to c - fives , plus the first derivatives . and it has one hundred hidden units . phd a: is that nine frames u s uh , centered around the current frame ? or phd c: yeah . mm - hmm . professor b: s so , i 'm i 'm sorry , there 's there 's there 's how many how many inputs ? phd c: so it 's twelve times nine . professor b: twelve times nine inputs , and a hundred , uh , hidden . phd c: hidden and phd d: two outputs . phd c: two outputs . professor b: two outputs . ok . so i guess about eleven thousand parameters , which actually should n't be a problem , even in in small phones . yeah . phd c: mm - hmm . phd a: so , i 'm i 'm s so what is different between this and and what you phd c: it should be ok . so the previous syst it 's based on the system that has a fifty - three point sixty - six percent improvement . it 's the same system . the only thing that changed is the n a p eh a es the estimation of the silence probabilities . phd a: ah . ok . phd c: which now is based on , uh , cleaned features . professor b: and , it 's a l it 's a lot better . phd a: wow . phd c: yeah . professor b: that 's great . phd c: um so it 's it 's not bad , but the problem is still that the latency is too large . professor b: what 's the latency ? phd c: because um the the latency of the vad is two hundred and twenty milliseconds . and , uh , the vad is used uh , i for on - line normalization , and it 's used before the delta computation . so if you add these components it goes t to a hundred and seventy , right ? professor b: i i 'm confused . you started off with two - twenty and you ended up with one - seventy ? phd c: with two an two hundred and seventy . professor b: two - seventy . phd c: if yeah , if you add the c delta comp delta computation professor b: oh . phd c: which is done afterwards . um professor b: so it 's two - twenty . i the is this are these twenty - millisecond frames ? is that why ? is it after downsampling ? or phd c: the two - twenty is one hundred milliseconds for the um no , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . um then there is , um , the neural network which use nine frames . so it adds forty milliseconds . professor b: a ok . phd c: um , after that , um , you have the um , filtering of the silence probabilities . which is a million filter it , and it creates a one hundred milliseconds delay . so , um professor b:  phd d: plus there is a delta at the input . phd c: yeah , and there is the delta at the input which is , professor b: one hundred milliseconds for smoothing . phd c: um so it 's @ @ professor b: uh , median . phd c:  phd d: it 's like forty plus forty plus professor b: and then forty phd c: mmm . forty this forty plus twenty , plus one hundred . professor b: forty p phd c: uh phd d: so it 's two hundred actually . phd c: yeah , there are twenty that comes from there is ten that comes from the lda filters also . right ? phd d: oh , ok . phd c: uh , so it 's two hundred and ten , yeah . phd d: if you are using professor b: uh phd c: plus the frame , phd d: t if you are using three frames phd c: so it 's two - twenty . phd d: if you are phrasing f { comment } using three frames , it is thirty here for delta . phd c: yeah , i think it 's it 's five frames , but . phd d: so five frames , that 's twenty . ok , so it 's who un { comment } two hundred and ten . professor b: uh , p wait a minute . it 's forty forty for the for the cleaning of the speech , phd c: so . forty cleaning . professor b: forty for the i n ann , a hundred for the smoothing . phd c: yeah . professor b: well , but at ten , phd c: twenty for the delta . professor b: twenty for delta . phd d: at th at the input . i mean , that 's at the input to the net . phd c: yeah . professor b: delta at input to net ? phd d: and there i phd c: yeah . phd d: yeah . so it 's like s five , six cepstrum plus delta at nine nine frames of professor b: and then ten milliseconds for phd d: fi - there 's an lda filter . professor b: ten milliseconds for lda filter , and t and ten another ten milliseconds you said for the frame ? phd c: for the frame i guess . i computed two - twenty yeah , well , it 's i guess it 's for the fr the professor b: ok . and then there 's delta besides that ? phd c: so this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream , professor b: ok . phd c: which is um , delta and double - deltas , which is fifty milliseconds . professor b: yeah . no , i mean , the after the noise part , the forty the the other hundred and eighty well , i mean , wait a minute . some of this is , uh is , uh is in parallel , is n't it ? i mean , the lda oh , you have the lda as part of the v d - uh , vad ? or phd c: the vad use , uh , lda filtered features also . professor b: oh , it does ? phd c: mm - hmm . professor b: ah . so in that case there is n't too much in parallel . uh phd c: no . there is , um , just downsampling , upsampling , and the lda . professor b: um , so the delta at the end is how much ? phd c: it 's fifty . phd d: it 's professor b: fifty . alright . so phd c: but well , we could probably put the delta , um , before on - line normalization . it should not that make a big difference , phd a: what if you used a smaller window for the delta ? phd c: because phd a: could that help a little bit ? i mean , i guess there 's a lot of things you could do to phd c: yeah . professor b: yeah . phd c: yeah , professor b: so phd c: but , nnn professor b: yeah . so if you if you put the delta before the , uh , ana on - line if yeah phd c: mm - hmm . professor b: uh then then it could go in parallel . phd c: cuz i professor b: and then y then you do n't have that additive phd c: yeah , phd d: yep . phd c: cuz the time constant of the on - line normalization is pretty long compared to the delta window , professor b: ok . phd c: so . it should not make professor b: ok . and you ought to be able to shove tw , uh sh uh pull off twenty milliseconds from somewhere else to get it under two hundred , right ? i mean phd a: is two hundred the d professor b: the hundred milla phd c: mm - hmm . professor b: mill a hundred milliseconds for smoothing is sort of an arbitrary amount . it could be eighty and and probably do @ @ phd c: yeah , phd a: i a hun phd c: yeah . phd a: uh wh - what 's the baseline you need to be under ? two hundred ? professor b: well , we do n't know . they 're still arguing about it . phd c:  phd a: oh . professor b: i mean , if it 's two if if it 's , uh if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we could we could , uh , meet it by moving the delta back . phd a: so , how do you know that what you have is too much if they 're still deciding ? professor b: uh , we do n't , but it 's just i mean , the main thing is that since that we got burned last time , and you know , by not worrying about it very much , we 're just staying conscious of it . phd a: uh - huh . oh , ok , i see . professor b: and so , th i mean , if if if a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here . so phd a: ah , ok . professor b: uh phd a: but still , that 's that 's a pretty big , uh , win . and it does n't seem like you 're in terms of your delay , you 're , uh , that professor b: he added a bit on , i guess , because before we were we were had were able to have the noise , uh , stuff , uh , and the lva be in parallel . phd c: hmm . professor b: and now he 's he 's requiring it to be done first . phd c: well , but i think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so . professor b: right . well , so you say let 's say ten milliseconds seconds for the lda . phd c: and and but the lda is , well , pretty short right now . professor b: well , ten . and then forty for the other . phd c: yeah . phd d: yeah , the lda lda we do n't know , is , like is it very crucial for the features , right ? phd c: no . i just this is the first try . phd d: yeah . professor b: right , phd c: i mean , i maybe the lda 's not very useful then . professor b: so you could start pulling back , phd d: s s h professor b: but phd d: yeah , professor b: but i think you have phd d: l professor b: i mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? but yo w were you doing that before ? phd c: mmm . well , in the proposal , um , the input of the vad network were just three frames , i think . phd d: on the in the mm - hmm . just yeah , just the static , no delta . professor b: right . phd c: uh , static features . professor b: so , what you have now is fort uh , forty for the the noise , twenty for the delta , and ten for the lda . that 's seventy milliseconds of stuff which was formerly in parallel , phd c:  professor b: right ? so i think , phd c: mm - hmm . professor b: you know , that 's that 's the difference as far as the timing , right ? phd c: yeah . professor b: um , and you could experiment with cutting various pieces of these back a bit , but i mean , we 're s we 're not we 're not in terrible shape . phd a: yeah , that 's what it seems like to me . it 's pretty good . professor b: yeah . phd c: mm - hmm . professor b: it 's it 's not like it 's adding up to four hundred milliseconds or something . phd a: where where is this where is this fifty - seven point o two in in comparison to the last evaluation ? professor b: well , it 's i think it 's better than anything , uh , anybody got . phd a: oh , is that right ? phd c: yeah . the best was fifty - four point five . professor b: yeah . phd d: point s phd a: oh . professor b: yeah . uh phd c: and our system was forty - nine , but with the neural network . phd a: wow . so this is almost ten percent . professor b: with the f with the neural net . yeah , and r and phd c: it would phd d: yeah , so this is this is like the first proposal . the proposal - one . it was forty - four , actually . professor b: yeah . yeah . and we still do n't have the neural net in . so so it 's phd a: wow . professor b: you know . so it 's we 're we 're doing better . phd a: this is this is really good . professor b: i mean , we 're getting better recognition . i mean , i 'm sure other people working on this are not sitting still either , but phd a: yeah . professor b: but but , uh uh , i mean , the important thing is that we learn how to do this better , and , you know . so . um , yeah . so , our , um yeah , you can see the kind of kind of numbers that we 're having , say , on speechdat - car which is a hard task , cuz it 's really , um i think it 's just sort of sort of reasonable numbers , starting to be . i mean , it 's still terri phd c: mm - hmm . yeah , even for a well - matched case it 's sixty percent error rate reduction , professor b: yeah . phd c: which is professor b: yeah . probably half . good ! phd c: um , yeah . so actually , this is in between what we had with the previous vad and what sunil did with an idl vad . which gave sixty - two percent improvement , right ? phd d: yeah , it 's almost that . phd c: so phd d: it 's almost an average somewhere around phd c: yeah . phd d: yeah . phd a: what was that ? say that last part again ? phd c: so , if you use , like , an idl vad , uh , for dropping the frames , phd d: o o or the best we can get . phd c: the best that we can get i that means that we estimate the silence probability on the clean version of the utterances . then you can go up to sixty - two percent error rate reduction , globally . phd a: mmm . phd c: mmm yeah . phd a: so that would be even that would n't change this number down here to sixty - two ? phd c: yeah . professor b: yeah . so you you were get phd c: if you add a g good v very good vad , that works as well as a vad working on clean speech , phd a: yeah . yeah . phd c: then you wou you would go phd a: so that 's sort of the best you could hope for . phd c: mm - hmm . phd a: i see . professor b: probably . yeah . so fi si fifty - three is what you were getting with the old vad . phd c: yeah . professor b: and , uh and sixty - two with the the , you know , quote , unquote , cheating vad . and fifty - seven is what you got with the real vad . phd c: mm - hmm . professor b: that 's great . phd c: uh , yeah , the next thing is , i started to play well , i do n't want to worry too much about the delay , no . maybe it 's better to wait professor b: ok . phd c: for the decision professor b: yeah . phd c: from the committee . uh , but i started to play with the , um , uh , tandem neural network . mmm i just did the configuration that 's very similar to what we did for the february proposal . and um . so . there is a f a first feature stream that use uh straight mfcc features . professor b: mm - hmm . phd c: well , these features actually . and the other stream is the output of a neural network , using as input , also , these , um , cleaned mfcc . um phd a: those are th those are th what is going into the tandem net ? phd c: i do n't have the comp mmm ? phd a: those two ? phd c: so there is just this feature stream , { comment } the fifteen mfcc plus delta and double - delta . professor b: no . phd a: yeah ? phd c: um , so it 's makes forty - five features { comment } that are used as input to the htk . and then , there is there are more inputs that comes from the tandem mlp . phd a: oh , oh . ok . i see . professor b: yeah , h he likes to use them both , phd a: uh - huh . professor b: cuz then it has one part that 's discriminative , phd c: yeah . um professor b: one part that 's not . phd a: right . ok . phd c: so , um , uh , yeah . right now it seems that i i just tested on speechdat - car while the experiment are running on your on ti - digits . well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . um , phd a: compared to these numbers ? phd c: compared to these numbers , yeah . um , professor b: y phd c: like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the hm case . professor b: you 're just using the full ninety features ? phd c: the professor b: y you have ninety features ? phd c: i i have , um from the networks , it 's twenty - eight . so professor b: and from the other side it 's forty - five . phd c: so , d i it 's forty - five . professor b: so it 's you have seventy - three features , phd c: yeah . professor b: and you 're just feeding them like that . phd c: yeah . professor b: there is n't any klt or anything ? phd c: mm - hmm . there 's a klt after the neural network , as as before . phd a: that 's how you get down to twenty - eight ? phd c: yeah . phd a: why twenty - eight ? phd c: i do n't know . phd a: oh . phd c: uh . it 's i i i it 's because it 's what we did for the first proposal . we tested , uh , trying to go down phd a: ah . professor b: it 's a multiple of seven . phd c: and yeah . phd d: yeah . phd c: so um . phd d: yeah . phd c: i wanted to do something very similar to the proposal as a first first try . phd d: yeah . phd a: i see . professor b: yeah . phd a: yeah . that makes sense . phd c: but we have to for sure , we have to go down , because the limit is now sixty features . professor b: yeah . phd c: so , uh , we have to find a way to decrease the number of features . um phd a: so , it seems funny that i do n't know , maybe i do n't u quite understand everything , { comment } but that adding features i guess i guess if you 're keeping the back - end fixed . maybe that 's it . because it seems like just adding information should n't give worse results . but i guess if you 're keeping the number of gaussians fixed in the recognizer , then professor b: well , yeah . phd c: mmm . professor b: but , i mean , just in general , adding information suppose the information you added , well , was a really terrible feature and all it brought in was noise . phd a: yeah . professor b: right ? so so , um or or suppose it was n't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier . phd a: uh - huh . professor b: right ? in that case you would n't necessarily expect it to be better at all . phd a: oh , yeah , i was n't necessarily saying it should be better . i 'm just surprised that you 're getting fifteen percent relative worse on the wel professor b: uh - huh . phd c: but it 's worse . professor b: on the highly mismatched condition . phd a: on the highly mismatch . phd c: yeah , i phd a: yeah . professor b: so , `` highly mismatched condition `` means that in fact your training is a bad estimate of your test . phd c: uh - huh . professor b: so having having , uh , a g a l a greater number of features , if they are n't maybe the right features that you use , certainly can e can easily , uh , make things worse . i mean , you 're right . if you have if you have , uh , lots and lots of data , and you have and your your your training is representative of your test , then getting more sources of information should just help . but but it 's it does n't necessarily work that way . phd a: huh . phd c: mm - hmm . professor b: so i wonder , um , well , what 's your what 's your thought about what to do next with it ? phd c: um , i do n't know . i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the professor b: mm - hmm . phd d: so , was the training set same as the p the february proposal ? ok . phd c: yeah , it 's the same training set , so it 's timit with the ti - digits ' , uh , noises , uh , added . phd d:  professor b: mm - hmm . phd c: um professor b: well , we might uh , we might have to experiment with , uh better training sets . again . but , phd c: mm - hmm . professor b: i the other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have different the rest of it is different , right ? so , um , uh , for instance , what 's the effect of just putting the neural net on without the o other other path ? phd c: mm - hmm . professor b: i mean , you know what the straight features do . phd c: yeah . professor b: that gives you this . you know what it does in combination . phd c: mm - hmm . professor b: you do n't necessarily know what phd a: what if you did the would it make sense to do the klt on the full set of combined features ? instead of just on the phd c: yeah . i g i guess . um . the reason i did it this ways is that in february , it we we tested different things like that , so , having two klt , having just a klt for a network , or having a global klt . phd a: oh , i see . phd c: and phd a: so you tried the global klt before phd c: well phd a: and it did n't really phd c: yeah . and , uh , th yeah . phd a: i see . phd c: the differences between these configurations were not huge , but it was marginally better with this configuration . phd a: uh - huh . uh - huh . professor b: but , yeah , that 's obviously another thing to try , phd c: um . professor b: since things are things are different . phd c: mm - hmm . mm - hmm . professor b: and i guess if the these are all so all of these seventy - three features are going into , um , the , uh the hmm . phd c: yeah . professor b: and is are i i are are any deltas being computed of tha of them ? phd c: of the straight features , yeah . professor b: n not of the phd c: so . but n th the , um , tandem features are u used as they are . professor b: are not . phd c: so , yeah , maybe we can add some context from these features also as dan did in in his last work . professor b: could . i yeah , but the other thing i was thinking was , um uh , now i lost track of what i was thinking . but . phd a: what is the you said there was a limit of sixty features or something ? phd c: mm - hmm . phd a: what 's the relation between that limit and the , um , forty - eight uh , forty eight hundred bits per second ? professor b: oh , i know what i was gon na say . phd c: um , not no relation . professor b: no relation . phd a: so i i i do n't understand , phd c: the f the forty - eight hundred bits is for transmission of some features . phd a: because i i mean , if you 're only using h phd c: and generally , i it s allows you to transmit like , fifteen , uh , cepstrum . professor b: the issue was that , um , this is supposed to be a standard that 's then gon na be fed to somebody 's recognizer somewhere which might be , you know , it it might be a concern how many parameters are use u used and so forth . and so , uh , they felt they wanted to set a limit . so they chose sixty . some people wanted to use hundreds of parameters and and that bothered some other people . phd a: uh - huh . professor b: u and so they just chose that . i i i think it 's kind of r arbitrary too . but but that 's that 's kind of what was chosen . i i remembered what i was going to say . what i was going to say is that , um , maybe maybe with the noise removal , uh , these things are now more correlated . so you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another . phd c: mm - hmm . professor b: and , um , they 're being fed into these , uh , variants , only gaussians and so forth , and and , uh , phd c: mm - hmm . professor b: so maybe it would be a better idea now than it was before to , uh , have , uh , one klt over everything , to de - correlate it . phd c: mm - hmm . yeah , i see . professor b: maybe . you know . phd d: what are the s n rs in the training set , timit ? phd c: it 's , uh , ranging from zero to clean ? yeah . from zero to clean . phd d: mm - hmm . professor b: yeah . so we found this this , uh this macrophone data , and so forth , that we were using for these other experiments , to be pretty good . phd c: mm - hmm . professor b: so that 's i after you explore these other alternatives , that might be another way to start looking , is is just improving the training set . phd c: mm - hmm . professor b: i mean , we were getting , uh , lots better recognition using that , than of course , you do have the problem that , um , u i { comment } we are not able to increase the number of gaussians , uh , or anything to , uh , uh , to match anything . so we 're only improving the training of our feature set , but that 's still probably something . phd a: so you 're saying , add the macrophone data to the training of the neural net ? the tandem net ? professor b: yeah , that 's the only place that we can train . phd a: yeah . professor b: we ca n't train the other stuff with anything other than the standard amount , phd a: right . professor b: so . um , um phd a: what what was it trained on again ? the one that you used ? phd c: it 's timit with noise . phd a: uh - huh . professor b: yeah . phd c: so , yeah , it 's rather a small professor b: how big is the net , by the way ? phd c: um , uh , it 's , uh , five hundred hidden units . and professor b: and again , you did experiments back then where you made it bigger and it and that was that was sort of the threshold point . much less than that , it was worse , phd c: yeah . professor b: and phd c: yeah . professor b: much more than that , it was n't much better . hmm . phd c: yeah . @ @ ? phd d: so is it is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you that is done on the timit after adding noise ? phd c:  phd d: so it 's i all the noises are from the ti - digits , phd c: yeah . phd d: right ? so you i phd c: um they k uh phd d: well , it it 's like the high mismatch of the speechdat - car after cleaning up , maybe having more noise than the the training set of timit after clean s after you do the noise clean - up . phd c: mmm . phd d: i mean , earlier you never had any compensation , you just trained it straight away . phd c: mm - hmm . phd d: so it had like all these different conditions of s n rs , actually in their training set of neural net . phd c: mm - hmm . mm - hmm . phd d: but after cleaning up you have now a different set of s n rs , right ? phd c: yeah . phd d: for the training of the neural net . phd c: mm - hmm . phd d: and is it something to do with the mismatch that that 's created after the cleaning up , like the high mismatch phd c: you mean the the most noisy occurrences on speechdat - car might be a lot more noisy than phd d: mm - hmm . of that i mean , the snr after the noise compensation of the speechdat - car . professor b: oh , so right . so the training the the neural net is being trained with noise compensated stuff . phd c: maybe . phd d: yeah . phd c: yeah , yeah . professor b: which makes sense , phd d: yeah . professor b: but , uh , you 're saying yeah , the noisier ones are still going to be , even after our noise compensation , are still gon na be pretty noisy . phd d: yeah . phd c: mm - hmm . phd d: yeah , so now the after - noise compensation the neural net is seeing a different set of s n rs than that was originally there in the training set . of timit . because in the timit it was zero to some clean . professor b: right . yes . phd d: so the net saw all the snr @ @ conditions . professor b: right . phd d: now after cleaning up it 's a different set of snr . professor b: right . phd d: and that snr may not be , like , com covering the whole set of s n rs that you 're getting in the speechdat - car . professor b: right , but the speechdat - car data that you 're seeing is also reduced in noise by the noise compensation . phd c: yeah . phd d: yeah , yeah , yeah , yeah , it is . but , i 'm saying , there could be some some issues of professor b: so . phd c: mm - hmm . professor b: yeah . phd c: well , if the initial range of snr is different , we the problem was already there before . and professor b: yeah . phd c: because mmm professor b: yeah , i mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set . phd c: hmm . professor b: uh phd d: on the test set , yeah . professor b: right ? i mean , you 're saying there 's a mismatch in noise that was n't there before , phd d: hmm . mm - hmm . professor b: but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch . phd d: mm - hmm . professor b: so , i mean , this may be heaven forbid , this noise compensation process may be imperfect , but . uh , so maybe it 's treating some things differently . phd c: yeah , uh phd d: well , i i do n't know . i i just that could be seen from the ti - digits , uh , testing condition because , um , the noises are from the ti - digits , right ? noise phd c: yeah . so phd d: so cleaning up the ti - digits and if the performance goes down in the ti - digits mismatch high mismatch like this phd c: clean training , yeah . phd d: on a clean training , or zero db testing . phd c: yeah , we 'll so we 'll see . uh . phd d: yeah . phd c: maybe . phd d: then it 's something to do . phd c: mm - hmm . professor b: i mean , one of the things about phd c: yeah . professor b: i mean , the macrophone data , um , i think , you know , it was recorded over many different telephones . phd c: mm - hmm . professor b: and , um , so , there 's lots of different kinds of acoustic conditions . i mean , it 's not artificially added noise or anything . so it 's not the same . i do n't think there 's anybody recording over a car from a car , but i think it 's it 's varied enough that if if doing this adjustments , uh , and playing around with it does n't , uh , make it better , the most uh , it seems like the most obvious thing to do is to improve the training set . um i mean , what we were uh the condition it it gave us an enormous amount of improvement in what we were doing with meeting recorder digits , even though there , again , these m macrophone digits were very , very different from , uh , what we were going on here . i mean , we were n't talking over a telephone here . but it was just i think just having a a nice variation in acoustic conditions was just a good thing . phd c: mm - hmm . yep . phd d: mmm . phd c: yeah , actually to s eh , what i observed in the hm case is that the number of deletion dramatically increases . it it doubles . professor b: number of deletions . phd c: when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know how to interpret that , but , mmm professor b: yeah . me either . phd c: t phd a: and and did an other numbers stay the same ? insertion substitutions stay the same ? phd c: they p stayed the same , phd a: roughly ? phd c: they maybe they are a little bit uh , lower . phd a: uh - huh . phd c: they are a little bit better . yeah . but professor b: did they increase the number of deletions even for the cases that got better ? phd c: mm - hmm . professor b: say , for the i mean , it phd c: no , it does n't . professor b: so it 's only the highly mismatched ? phd c: no . professor b: and it remind me again , the `` highly mismatched `` means that the phd c: clean training and professor b: uh , sorry ? phd c: it 's clean training well , close microphone training and distant microphone , um , high speed , i think . professor b: close mike training phd c: well the most noisy cases are the distant microphone for testing . professor b: right . so well , maybe the noise subtraction is subtracting off speech . phd c: separating . yeah . professor b: wh phd c: but yeah . i mean , but without the neural network it 's well , it 's better . it 's just when we add the neural networks . professor b: yeah , right . phd c: the feature are the same except that professor b: uh , that 's right , that 's right . um phd a: well that that says that , you know , the , um the models in in , uh , the recognizer are really paying attention to the neural net features . phd c: yeah . phd a: uh . phd c: mm - hmm . professor b: but , yeah , actually the timit noises are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? it 's it 's pretty different . is n't it ? phd c: uh , there is a car noise . so there are f just four noises . um , uh , `` car `` , i think , `` babble `` , phd d: `` babble . `` phd c: `` subway `` , right ? and phd d: `` street `` or `` airport `` or something . phd c: and `` street `` is n't phd d: or `` train station `` . phd c: `` train station `` , yeah . phd d: yeah . phd c: so it 's mostly well , `` car `` is stationary , professor b: mm - hmm . phd c: `` babble `` , it 's a stationary background plus some voices , professor b: mm - hmm . phd c: some speech over it . and the other two are rather stationary also . professor b: well , i i think that if you run it actually , you maybe you remember this . when you in in the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with the the pure features as well , did it make things better to have the neural net ? phd c: mm - hmm . professor b: was it about the same ? uh , w i phd c: it was b a little bit worse . professor b: than ? phd c: than just the features , yeah . professor b: so , until you put the second path in with the pure features , the neural net was n't helping at all . phd c: mm - hmm . professor b: well , that 's interesting . phd c: it was helping , uh , if the features are b were bad , professor b: yeah . phd c: i mean . just plain p l ps or m f professor b: yeah . phd c: c cs . as soon as we added lda on - line normalization , and all these things , then professor b: they were doing similar enough things . well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . phd c: yeah , professor b: and and the thing i i have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . phd c: mm - hmm . professor b: maybe that they 're a lot worse . you know ? and , um but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and and and , uh , what you 'd have with just the pure features , then maybe there is some problem of a of a , uh , combination of these things , or correlation between them somehow . phd c: mm - hmm . professor b: if it really is that the net is hurting you at the moment , then i think the issue is to focus on on , uh , improving the the net . phd c: yeah , professor b: um . phd c: mm - hmm . professor b: so what 's the overall effe i mean , you have n't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? but it 's but of course that one 's weighted lower , phd c: y yeah , oh . yeah . professor b: so i wonder what the net effect is . phd c: i d i i think it 's it was one or two percent . that 's not that bad , but it was l like two percent relative worse on speechdat - car . i have to to check that . well , i have i will . phd d: well , it will overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five point two five eight . professor b: right . phd c: mm - hmm . hmm . professor b: right . so the so the worst it could be , if the others were exactly the same , is four , phd d: is it like professor b: and and , uh , in fact since the others are somewhat better phd d: yeah , so it 's four . is i so either it 'll get cancelled out , or you 'll get , like , almost the same . professor b: uh . phd c: yeah , it was it was slightly worse . phd d: slightly bad . yeah . phd c: um , professor b: yeah , it should be pretty close to cancelled out . phd d: yeah . phd a: you know , i 've been wondering about something . phd c: mm - hmm . phd a: in the , um a lot of the , um the hub - five systems , um , recently have been using lda . and and they , um they run lda on the features right before they train the models . so there 's the the lda is is right there before the h m phd d: yeah . phd a: so , you guys are using lda but it seems like it 's pretty far back in the process . phd d: uh , this lda is different from the lda that you are talking about . the lda that you saying is , like , you take a block of features , like nine frames or something , { comment } and then do an lda on it , phd a: yeah . uh - huh . phd d: and then reduce the dimensionality to something like twenty - four or something like that . phd a: yeah , you c you c you can . phd d: and then feed it to hmm . phd a: i mean , it 's you know , you 're just basically i phd d: yeah , so this is like a two d two dimensional tile . phd a: you 're shifting the feature space . yeah . phd d: so this is a two dimensional tile . and the lda that we are f applying is only in time , not in frequency high cost frequency . so it 's like more like a filtering in time , rather than doing a r phd a: ah . ok . so what i what about , um i u what i w i mean , i do n't know if this is a good idea or not , but what if you put ran the other kind of lda , uh , on your features right before they go into the hmm ? phd d: uh , it phd c: mm - hmm . no , actually , i think i phd d: m phd c: well . what do we do with the ann is is something like that except that it 's not linear . but it 's it 's like a nonlinear discriminant analysis . phd a: yeah . right , it 's the it 's right . the so yeah , so it 's sort of like phd c: but . phd a: the tandem stuff is kind of like i nonlinear lda . phd c: yeah . it 's phd a: i g phd c: yeah . phd a: yeah . professor b: yeah . phd a: but i mean , w but the other features that you have , um , th the non - tandem ones , phd c: uh . mm - hmm . yeah , i know . that that yeah . well , in the proposal , they were transformed u using pca , but phd a: uh - huh . phd c: yeah , it might be that lda could be better . professor b: the a the argument i is kind of i in and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob i mean , discriminative things are good . lda , neural nets , they 're good . phd a: yeah . professor b: uh , they 're good because you you you learn to distinguish between these categories that you want to be good at distinguishing between . and pca does n't do that . it pac - pca low - order pca throws away pieces that are uh , maybe not not gon na be helpful just because they 're small , basically . phd a: right . professor b: but , uh , the problem is , training sets are n't perfect and testing sets are different . so you f you you face the potential problem with discriminative stuff , be it lda or neural nets , that you are training to discriminate between categories in one space but what you 're really gon na be g getting is is something else . phd a: uh - huh . professor b: and so , uh , stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . so you have a good set of features that everybody 's worked really hard to make , phd a: yeah . professor b: and then , uh , you you discriminately train it , but you also take the path that that does n't have that , phd a: uh - huh . professor b: and putting those in together . and that that seem so it 's kind of like a combination of the uh , what , uh , dan has been calling , you know , a feature uh , you know , a feature combination versus posterior combination or something . it 's it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these these other things . and that seemed , at least in the last one , as he was just saying , he he when he only did discriminative stuff , i it actually was was it did n't help at all in this particular case . phd a: yeah . professor b: there was enough of a difference , i guess , between the testing and training . but by having them both there the fact is some of the time , the discriminative stuff is gon na help you . phd a: mm - hmm . professor b: and some of the time it 's going to hurt you , phd a: right . professor b: and by combining two information sources if , you know if if phd a: so you would n't necessarily then want to do lda on the non - tandem features because now you 're doing something to them that professor b: that i i i think that 's counter to that idea . phd a: yeah , right . professor b: now , again , it 's we 're just trying these different things . we do n't really know what 's gon na work best . but if that 's the hypothesis , at least it would be counter to that hypothesis to do that . phd a: right . professor b: um , and in principle you would think that the neural net would do better at the discriminant part than lda . phd a: right . yeah . well y professor b: though , maybe not . phd a: yeah . exactly . i mean , we , uh we were getting ready to do the tandem , uh , stuff for the hub - five system , and , um , andreas and i talked about it , and the idea w the thought was , `` well , uh , yeah , that i you know th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the lda in place of the neural net , so that we can you know , show a clear path . professor b: right . phd a: you know , that you have it without it , then you have the lda , then you have the neural net , and you can see , theoretically . so . i was just wondering i i professor b: well , i think that 's a good idea . phd a: yeah . professor b: did did you do that phd a: um . no . professor b: or tha that 's a phd a: that 's what that 's what we 're gon na do next as soon as i finish this other thing . so . professor b: yeah . yeah . no , well , that 's a good idea . i i phd a: we just want to show . professor b: i yeah . phd a: i mean , it everybody believes it , professor b: oh , no it 's a g phd a: but you know , we just professor b: no , no , but it might not not even be true . phd a: yeah . professor b: i mean , it 's it 's it 's it 's it 's a great idea . i mean , one of the things that always disturbed me , uh , in the the resurgence of neural nets that happened in the eighties was that , um , a lot of people because neural nets were pretty easy to to use a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh uh , versions of them . phd a: yeah . mm - hmm . yeah . professor b: and , uh , people were doing recurrent nets but not looking at iir filters , and you know , i mean , uh , so i think , yeah , it 's definitely a good idea to try it . phd a: yeah , and everybody 's putting that on their systems now , and so , i that 's what made me wonder about this , professor b: well , they 've been putting them in their systems off and on for ten years , phd a: but . professor b: but but but , uh , phd a: yeah , what i mean is it 's it 's like in the hub - five evaluations , you know , and you read the system descriptions and everybody 's got , you know , lda on their features . professor b: and now they all have that . i see . phd a: and so . professor b: yeah . phd a: uh . phd c: it 's the transformation they 're estimating on well , they are trained on the same data as the final hmm are . phd a: yeah , so it 's different . yeah , exactly . cuz they do n't have these , you know , mismatches that that you guys have . phd c: mm - hmm . phd a: so that 's why i was wondering if maybe it 's not even a good idea . phd c: mm - hmm . phd a: i do n't know . i i do n't know enough about it , phd c: mm - hmm . phd a: but um . professor b: i mean , part of why i i think part of why you were getting into the klt y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was and combining the the different temporal ranges was the key thing that was happening or whether it was this discriminant thing , right ? so you were just trying i think you r i mean , this is it does n't have the lda aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ? phd c: mm - hmm . professor b: i think you were . phd c: mm - hmm . yeah . professor b: does something . it does n't work as well . yeah . yeah . phd d: so , yeah , i 've been exploring a parallel vad without neural network with , like , less latency using snr and energy , um , after the cleaning up . so what i 'd been trying was , um , uh after the b after the noise compensation , n i was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . so that if if they are , like , pretty c close to one , which means it 's speech . and if it is n if it is close to zero , which is so it 's like a scale @ @ probability value . so i was trying , uh , with full band and multiple bands , m ps uh separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . uh , the advantage being like it does n't have the latency of the neural net if it if it can professor b: mm - hmm . phd d: g and it gave me like , uh , one point one more than one percent relative improvement . so , from fifty - three point six it went to fifty f four point eight . so it 's , like , only slightly more than a percent improvement , professor b: mm - hmm . phd d: just like which means that it 's it 's doing a slightly better job than the previous vad , professor b: mm - hmm . phd d: uh , at a l lower delay . professor b: mm - hmm . phd d: um , so , um professor b: but i d i 'm sorry , phd d: so u professor b: does it still have the median filter stuff ? phd d: it still has the median filter . professor b: so it still has most of the delay , phd d: so professor b: it just does n't phd d: yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . the forty plus twenty . professor b: well , w i phd d: at the input of the neural net you have this , uh , f nine frames of context plus the delta . professor b: oh , plus the delta , phd c: mm - hmm . professor b: right . ok . phd d: yeah . so that delay , plus the lda . professor b: mm - hmm . phd d: uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output . professor b: mm - hmm . mm - hmm . phd d: um . so . yeah . so the the di the biggest the problem f for me was to find a consistent threshold that works well across the different databases , because i t i try to make it work on tr speechdat - car professor b: mm - hmm . phd d: and it fails on ti - digits , or if i try to make it work on that it 's just the italian or something , it does n't work on the finnish . professor b: mm - hmm . phd d: so , um . so there are there was , like , some problem in balancing the deletions and insertions when i try different thresholds . professor b: mm - hmm . phd d: so the i 'm still trying to make it better by using some other features from the after the p clean up maybe , some , uh , correlation auto - correlation or some s additional features of to mainly the improvement of the vad . i 've been trying . professor b: now this this this , uh , `` before and after clean `` , it sounds like you think that 's a good feature . that that , it you th think that the , uh the i it appears to be a good feature , right ? phd d: mm - hmm . professor b: what about using it in the neural net ? phd d: yeah . phd c: yeah , eventually we could could just phd d: yeah , so yeah , so that 's the yeah . so we 've been thinking about putting it into the neural net also . professor b: yeah . phd d: because they did that itself phd c: then you do n't have to worry about the thresholds and phd d: there 's a threshold and yeah . professor b: yeah . phd c: but just phd d: yeah . so that that 's , uh professor b: yeah . so if we if we can live with the latency or cut the latencies elsewhere , then then that would be a , uh , good thing . phd d: yeah . yeah . professor b: um , anybody has anybody you guys or or naren , uh , somebody , tried the , uh , um , second th second stream thing ? uh . phd d: oh , i just i just h put the second stream in place and , uh ran one experiment , but just like just to know that everything is fine . professor b: uh - huh . phd d: so it was like , uh , forty - five cepstrum plus twenty - three mel log mel . professor b: yeah . phd d: and and , just , like , it gave me the baseline performance of the aurora , which is like zero improvement . professor b: yeah . yeah . phd d: so i just tried it on italian just to know that everything is but i i did n't export anything out of it because it was , like , a weird feature set . professor b: yeah . phd d: so . professor b: yeah . well , what i think , you know , would be more what you 'd want to do is is is , uh , put it into another neural net . right ? phd c: mm - hmm . phd d: yeah , yeah , yeah , yeah . professor b: and then but , yeah , we 're we 're not quite there yet . so we have to figure out the neural nets , i guess . phd c: yeah . phd d: the uh , other thing i was wondering was , um , if the neural net , um , has any because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional some four plus some f few more conditions which it has n't seen , actually , phd c: mm - hmm . phd d: from the f f while testing . phd c: yeah , yeah . right . phd d: um instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like the the we have the vad flag . i mean , should we f feed the vad flag , also , at the input so that it it has some additional discriminating information at the input ? phd c: hmm - hmm ! um professor b: wh - uh , the the vad what ? phd d: we have the vad information also available at the back - end . professor b: uh - huh . phd d: so if it is something the neural net is not able to discriminate the classes professor b: yeah . phd d: i mean because most of it is sil i mean , we have dropped some silence f we have dropped so silence frames ? professor b: mm - hmm . phd d: no , we have n't dropped silence frames still . phd c: uh , still not . yeah . phd d: yeah . so phd c: th phd d: the b b biggest classification would be the speech and silence . so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . phd a: what do y do you have that feature available for the test data ? phd d: well , i mean , we have we are transferring the vad to the back - end feature to the back - end . because we are dropping it at the back - end after everything all the features are computed . phd a: oh , oh , i see . phd d: so phd a: i see . phd d: so the neural so that is coming from a separate neural net or some vad . phd a: ok . ok . phd d: which is which is certainly giving a phd a: so you 're saying , feed that , also , into the neural net . phd d: to yeah . so it it 's an additional discriminating information . phd a: yeah . yeah . right . phd d: so that professor b: you could feed it into the neural net . the other thing { comment } you could do is just , um , p modify the , uh , output probabilities of the of the , uh , uh , um , neural net , tandem neural net , { comment } based on the fact that you have a silence probability . phd d: mm - hmm . professor b: right ? phd c: mm - hmm . professor b: so you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize . phd c: yeah . professor b: uh , i mean , you 'd have to do the nonlinearity part and deal with that . uh , i mean , go backwards from what the nonlinearity would , you know would be . phd d: through t to the soft max . professor b: but but , uh phd c: yeah , so maybe , yeah , when phd a: but in principle would n't it be better to feed it in ? and let the net do that ? professor b: well , u not sure . phd a: hmm . professor b: i mean , let 's put it this way . i mean , y you you have this complicated system with thousands and thousand parameters phd a: yeah . professor b: and you can tell it , uh , `` learn this thing . `` or you can say , `` it 's silence ! go away ! `` i mean , i mean , i does n't ? i think i think the second one sounds a lot more direct . phd a: what what if you professor b: uh . phd a: right . so , what if you then , uh since you know this , what if you only use the neural net on the speech portions ? professor b: well , uh , phd c: that 's what phd a: well , i guess that 's the same . uh , that 's similar . professor b: yeah , i mean , y you 'd have to actually run it continuously , phd a: but i mean i mean , train the net only on professor b: but it 's @ @ well , no , you want to train on on the nonspeech also , because that 's part of what you 're learning in it , to to to generate , that it 's it has to distinguish between . phd d: speech . phd a: but i mean , if you 're gon na if you 're going to multiply the output of the net by this other decision , uh , would then you do n't care about whether the net makes that distinction , right ? professor b: well , yeah . but this other thing is n't perfect . phd a: ah . professor b: so that you bring in some information from the net itself . phd a: right , ok . that 's a good point . professor b: yeah . now the only thing that that bothers me about all this is that i i i the the fact i i it 's sort of bothersome that you 're getting more deletions . phd c: yeah . but so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh , professor b: is too high . phd c: too too high or professor b: yeah . so maybe so phd c: if it 's the case , then multiplying it again by i by something ? phd d: it may not be it professor b: yeah . phd c: mm - hmm . phd d: yeah , it it may be too it 's too high in a sense , like , everything is more like a , um , flat probability . professor b: yeah . phd c: oh - eee - hhh . phd d: so , like , it 's not really doing any distinction between speech and nonspeech phd c: uh , yeah . phd d: or , i mean , different among classes . professor b: yeah . phd c: mm - hmm . phd a: be interesting to look at the yeah , for the i wonder if you could do this . but if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the the other ones , do you do you see more peaks or something ? phd c: yeah . yeah , like the entropy of the the output , phd a: yeah . professor b: yeah , for instance . phd c: or professor b: but i bu phd c: it it seems that the vad network does n't well , it does n't drop , uh , too many frames because the dele the number of deletion is reasonable . but it 's just when we add the tandem , the final mlp , and then professor b: yeah . now the only problem is you do n't want to ta i guess wait for the output of the vad before you can put something into the other system , phd c: u professor b: cuz that 'll shoot up the latency a lot , right ? am i missing something here ? phd c: but phd d: mm - hmm . phd c: yeah . right . professor b: yeah . so that 's maybe a problem with what i was just saying . but but i i guess phd a: but if you were gon na put it in as a feature it means you already have it by the time you get to the tandem net , right ? phd d: um , well . we w we do n't have it , actually , professor b: no . phd d: because it 's it has a high rate energy phd a: ah . phd d: the vad has a professor b: yeah . phd a: ok . professor b: it 's kind of done in i mean , some of the things are , not in parallel , but certainly , it would be in parallel with the with a tandem net . phd a: right . professor b: in time . so maybe , if that does n't work , um but it would be interesting to see if that was the problem , anyway . and and and then i guess another alternative would be to take the feature that you 're feeding into the vad , and feeding it into the other one as well . phd c: mm - hmm . professor b: and then maybe it would just learn learn it better . phd c: mm - hmm . professor b: um but that 's yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up up too high , phd c: mm - hmm . professor b: at some point where the vad is saying it 's actually speech . phd c: yeah . professor b: which is probably true . phd c: so , m professor b: cuz well , the v a if the vad said since the vad is is is right a lot , uh phd c: yeah . professor b: hmm . anyway . might be . phd c: mm - hmm . professor b: yeah . well , we just started working with it . but these are these are some good ideas i think . phd c: mm - hmm . yeah , and the other thing well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n do we want to work on the targets ? or , like , instead of using phonemes , using more context dependent units ? phd a: for the tandem net you mean ? phd c: well , i 'm yeah . phd a: hmm . phd c: i 'm thinking , also , a w about dan 's work where he he trained a network , not on phoneme targets but on the hmm state targets . and it was giving s slightly better results . professor b: problem is , if you are going to run this on different m test sets , including large vocabulary , phd c: yeah . yeah . professor b: um , phd c: uh professor b: i think phd c: mmm . i was just thinking maybe about , like , generalized diphones , and come up with a a reasonable , not too large , set of context dependent units , and and yeah . and then anyway we would have to reduce this with the klt . professor b: yeah . phd c: so . but i do n't know . professor b: yeah . well , maybe . but i d i d it it i it 's all worth looking at , phd c: mm - hmm . professor b: but it sounds to me like , uh , looking at the relationship between this and the speech noise stuff is is is probably a key thing . phd c: mm - hmm . professor b: that and the correlation between stuff . phd a: so if , uh if the , uh , high mismatch case had been more like the , uh , the other two cases { comment } in terms of giving you just a better performance , { comment } how would this number have changed ? phd c: mm - hmm . oh , it would be yeah . around five percent better , i guess . if if i phd a: y like sixty ? professor b: well , we do n't know what 's it 's gon na be the ti - digits yet . he has n't got the results back yet . phd c: yeah . if you extrapolate the speechdat - car well - matched and medium - mismatch , it 's around , yeah , maybe five . phd a: uh - huh . yeah . so this would be sixty - two ? professor b: sixty - two . phd a: which is professor b: yeah . phd c: sixty - two , yeah . phd d: somewhere around sixty , must be . right ? yeah . phd c: well , it 's around five percent , because it 's s right ? if everything is five percent . phd d: yeah . yeah . phd a: all the other ones were five percent , phd c: mm - hmm . phd a: the professor b: yeah . phd c: i d i d i just have the speechdat - car right now , so phd a: yeah . phd c: it 's running it shou we should have the results today during the afternoon , phd a: hmm . phd c: but well . professor b: hmm . well um so i wo n't be here for phd a: when when do you leave ? professor b: uh , i 'm leaving next wednesday . may or may not be in in the morning . i leave in the afternoon . um , phd a: but you 're professor b: so i phd a: are you you 're not gon na be around this afternoon ? professor b: yeah . phd a: oh . professor b: oh , well . i 'm talking about next week . i 'm leaving leaving next wednesday . phd a: uh - huh . professor b: this afternoon uh oh , right , for the meeting meeting ? yeah , that 's just cuz of something on campus . phd a: ah , ok , ok . professor b: yeah . but , um , yeah , so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . and the week after that i wo n't . by that time you 'll be { comment } uh , you 'll both be gone from here . so there 'll be no definitely no meeting on on september sixth . uh , phd a: what 's september sixth ? professor b: and uh , that 's during eurospeech . phd a: oh , oh , right . ok . professor b: so , uh , sunil will be in oregon . uh , stephane and i will be in denmark . uh right ? so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . um , but , uh i guess , just i mean , you guys should probably meet . and maybe barry barry will be around . and and then uh , uh , we 'll start up again with dave and dave and barry and stephane and us on the , uh , twentieth . no . thirteenth ? about a month ? phd a: so , uh , you 're gon na be gone for the next three weeks or something ? professor b: i 'm gone for two and a half weeks starting starting next wed - late next wednesday . phd a: so that 's you wo n't be at the next three of these meetings . is that right ? professor b: uh , i wo n't it 's probably four because of is it three ? let 's see , twenty - third , thirtieth , sixth . that 's right , next three . and the the third one wo n't probably wo n't be a meeting , cuz cuz , uh , su - sunil , stephane , and i will all not be here . phd a: oh , right . right . professor b: um mmm . { comment } so it 's just , uh , the next two where there will be there , you know , may as well be meetings , phd a: ok . professor b: but i just wo n't be at them . and then starting up on the thirteenth , uh , we 'll have meetings again but we 'll have to do without sunil here somehow . phd a: when do you go back ? professor b: so . phd d: thirty - first , august . professor b: yeah . yeah . so . cool . phd a: when is the evaluation ? november , or something ? professor b: yeah , it was supposed to be november fifteenth . has anybody heard anything different ? phd c: i do n't know . the meeting in is the five and six of december . so phd d: p s it 's like yeah , it 's tentatively all full . yeah . phd c: mm - hmm . phd d: uh , that 's a proposed date , i guess . phd c: yeah , um so the evaluation should be on a week before or phd a: yeah . professor b: yep . but , no , this is good progress . so . uh ok . phd a: should we do digits ? professor b: guess we 're done . digits ? yep . phd a: ok . professor b: it 's a wrap .","output":"phd c explained that the silence probabilities had a 100ms delay , the delta at the input had a 40ms delay , and a 10ms delay was created by lda filters ."}]